[
    {
        "q": "Which stage of the Data Science Lifecycle comes immediately after Data Collection?",
        "type": "mcq",
        "o": [
            "Data Preparation",
            "Exploratory Analysis",
            "Model Building",
            "Deployment"
        ]
    },
    {
        "q": "In which phase do we typically clean missing values, handle outliers, and perform feature scaling?",
        "type": "mcq",
        "o": [
            "Data Preparation",
            "Data Collection",
            "Exploratory Analysis",
            "Monitoring"
        ]
    },
    {
        "q": "What is the main goal of the Exploratory Data Analysis (EDA) phase?",
        "type": "mcq",
        "o": [
            "To understand the data and find patterns",
            "To train machine learning models",
            "To deploy the final model",
            "To collect raw data from sources"
        ]
    },
    {
        "q": "Which of the following is NOT typically part of the Data Collection phase?",
        "type": "mcq",
        "o": [
            "Removing duplicate records",
            "Web scraping",
            "Database queries",
            "API calls"
        ]
    },
    {
        "q": "Model Building phase primarily involves ______.",
        "type": "fill_blank",
        "answers": ["training", "evaluating"],
        "other_options": ["collecting", "deploying", "monitoring", "visualizing"]
    },
    {
        "q": "The process of putting a trained model into production so it can make predictions on new data is called ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Preparation", "Collection"]
    },
    {
        "q": "After a model is deployed, we enter the ______ phase to track its performance over time.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Data Preparation",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Which phase often involves creating visualizations like histograms, scatter plots, and correlation matrices?",
        "type": "mcq",
        "o": [
            "Exploratory Analysis",
            "Data Preparation",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "Match the Data Science Lifecycle phases with their primary activities:",
        "type": "match",
        "left": ["Data Collection", "Data Preparation", "Exploratory Analysis", "Model Building"],
        "right": ["Gathering raw data from sources", "Cleaning and transforming data", "Visualizing and summarizing data", "Training and selecting algorithms"]
    },
    {
        "q": "In the Data Science Lifecycle, feature engineering is primarily performed during the Data Preparation phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Data drift and model performance degradation are mainly addressed in the Monitoring phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the standard Data Science Lifecycle phases in correct order:",
        "type": "rearrange",
        "words": ["Data Collection", "Data Preparation", "Exploratory Analysis", "Model Building", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?\n\nimport pandas as pd\nprint(pd.__version__)",
        "type": "mcq",
        "c": "import pandas as pd\nprint(pd.__version__)",
        "o": [
            "The version number of pandas",
            "An error",
            "None",
            "pd"
        ]
    },
    {
        "q": "During which phase would you typically split the data into training and testing sets?",
        "type": "mcq",
        "o": [
            "Data Preparation",
            "Data Collection",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "It is acceptable to skip the Exploratory Analysis phase if the dataset is very small.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which of the following is the primary purpose of the Data Collection phase?",
        "type": "mcq",
        "o": [
            "Gather raw data from various sources",
            "Remove missing values",
            "Train predictive models",
            "Create dashboards for stakeholders"
        ]
    },
    {
        "q": "In the Data Preparation phase, the process of converting categorical variables into numerical format is called ______.",
        "type": "fill_blank",
        "answers": ["encoding"],
        "other_options": ["scaling", "imputation", "normalization"]
    },
    {
        "q": "Which phase is most likely to involve calculating summary statistics like mean, median, and standard deviation?",
        "type": "mcq",
        "o": [
            "Exploratory Analysis",
            "Model Building",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "Hyperparameter tuning using GridSearchCV or RandomizedSearchCV typically happens during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Data Preparation",
            "Exploratory Analysis",
            "Deployment"
        ]
    },
    {
        "q": "Model serialization (saving the trained model to disk) is a key step just before ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Collection", "Training"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\ntips = sns.load_dataset('tips')\nprint(tips.head())",
        "o": [
            "First 5 rows of the built-in tips dataset",
            "An error because matplotlib is imported",
            "A blank plot",
            "None"
        ]
    },
    {
        "q": "Match each lifecycle phase to its most common tool/technique:",
        "type": "match",
        "left": ["Data Collection", "Data Preparation", "Exploratory Analysis", "Model Building", "Deployment", "Monitoring"],
        "right": ["BeautifulSoup / Scrapy", "pandas .fillna() and sklearn Pipeline", "sns.pairplot() and df.corr()", "cross_val_score() and GridSearchCV", "FastAPI / Flask / MLflow Model Registry", "Evidently AI or model drift detection metrics"]
    },
    {
        "q": "In production, a model that was performing well suddenly drops in accuracy. Which lifecycle phase should be triggered immediately?",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Data Collection",
            "Exploratory Analysis",
            "Model Building"
        ]
    },
    {
        "q": "Creating a correlation heatmap is usually done in the ______ phase.",
        "type": "fill_blank",
        "answers": ["Exploratory Analysis"],
        "other_options": ["Deployment", "Monitoring", "Collection"]
    },
    {
        "q": "Rearrange these steps in the correct order for a typical Model Building phase:",
        "type": "rearrange",
        "words": ["Choose algorithm", "Split data", "Train model", "Evaluate with metrics", "Tune hyperparameters"]
    },
    {
        "q": "It is safe to perform feature selection after the train-test split to avoid data leakage.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.model_selection import train_test_split\nX = [[1],[2],[3],[4]]\ny = [0,1,0,1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\nprint(len(X_train), len(X_test))",
        "o": [
            "2 2",
            "3 1",
            "4 0",
            "Error"
        ]
    },
    {
        "q": "Concept drift and data drift are both detected and handled primarily during the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Data Preparation",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Saving a trained Scikit-learn model using joblib or pickle is a task belonging to the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Collection", "Preparation"]
    },
    {
        "q": "A/B testing of two deployed models is considered part of the Monitoring phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "A company receives streaming click data from a website in real time. The process of ingesting and storing this continuous flow belongs to which phase?",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Data Preparation",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "You discover that the 'age' column contains negative values and strings like 'unknown'. Fixing these issues is part of ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Exploratory Analysis", "Model Building", "Deployment"]
    },
    {
        "q": "Identifying that sales spike every December using a time-series decomposition plot happens during ______.",
        "type": "mcq",
        "o": [
            "Exploratory Analysis",
            "Monitoring",
            "Data Collection",
            "Model Building"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import numpy as np\nx = np.array([1, 2, 3, 4, 5])\nprint(x[[0, 2, 4]])",
        "o": [
            "[1 3 5]",
            "[2 4]",
            "[0 2 4]",
            "IndexError"
        ]
    },
    {
        "q": "Building an ensemble by combining Random Forest, XGBoost, and a Neural Network occurs in the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Data Preparation",
            "Monitoring"
        ]
    },
    {
        "q": "The practice of wrapping preprocessing steps and the model together inside a single scikit-learn Pipeline is recommended during ______.",
        "type": "fill_blank",
        "answers": ["Model Building", "Deployment"],
        "other_options": ["Collection", "Monitoring", "Exploratory"]
    },
    {
        "q": "Match the phase to its typical deliverable:",
        "type": "match",
        "left": ["Data Collection", "Exploratory Analysis", "Model Building", "Deployment", "Monitoring"],
        "right": ["Raw parquet files in data lake", "Jupyter notebook with insights and charts", "Trained model artifact (model.pkl)", "REST API endpoint /predict", "Weekly performance dashboard with KS-statistic"]
    },
    {
        "q": "Shadow deployment (running a new model alongside the live one without affecting predictions) is a technique used in the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "Rearrange these actions into the correct chronological order in a production Data Science project:",
        "type": "rearrange",
        "words": ["Write unit tests for the prediction function", "Set up Prometheus + Grafana alerts", "Create Docker image", "Register model in MLflow", "Push code to GitHub"]
    },
    {
        "q": "Using SHAP or LIME to explain individual predictions is most commonly done after the model is already in production.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nscaler = StandardScaler()\ndata = np.array([[1000], [2000], [3000]])\nprint(scaler.fit_transform(data).flatten())",
        "o": [
            "[-1.22474487  0.          1.22474487]",
            "[0. 0. 0.]",
            "[1000. 2000. 3000.]",
            "ValueError"
        ]
    },
    {
        "q": "Canary release means gradually rolling out the new model to 100% of traffic immediately.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Detecting that the distribution of incoming features has shifted significantly compared to training data is known as ______ detection.",
        "type": "fill_blank",
        "answers": ["drift"],
        "other_options": ["leakage", "bias", "overfitting"]
    },
    {
        "q": "In most organizations, the Monitoring phase is optional and can be ignored after successful deployment.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Creating a baseline model using only the mean of the target variable is a common first step in the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Exploratory Analysis",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "A data scientist spends two days negotiating API rate limits and OAuth tokens with an external vendor. This effort belongs to which lifecycle phase?",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Data Preparation",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "You notice strong multicollinearity between 'house_area_sqft' and 'house_area_sqm' during VIF calculation. Removing one of them happens in ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Exploratory Analysis", "Model Building", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\n\ndf = pd.DataFrame({'A': [1, 2, None, 4]})\nprint(df['A'].isna().sum())",
        "o": [
            "1",
            "0",
            "4",
            "TypeError"
        ]
    },
    {
        "q": "Using cross-validation to compare Logistic Regression vs SVM vs Gradient Boosting is a core activity of the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Exploratory Analysis",
            "Deployment",
            "Data Collection"
        ]
    },
    {
        "q": "The first time a model serves a prediction to a real customer through a live endpoint marks the transition from Model Building to ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Preparation", "Collection"]
    },
    {
        "q": "Match these real-world artifacts to their lifecycle phase:",
        "type": "match",
        "left": ["dbt models", "Great Expectations suite", "Feature Store registration", "Optuna study database", "Kubernetes Deployment YAML"],
        "right": ["Data Preparation", "Data Preparation", "Data Preparation", "Model Building", "Deployment"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import warnings\nwarnings.filterwarnings('ignore')\nprint('No warning will appear')",
        "o": [
            "No warning will appear",
            "A DeprecationWarning",
            "An error",
            "Nothing is printed"
        ]
    },
    {
        "q": "Setting up automated retraining every Sunday at 2 AM using Airflow or GitHub Actions belongs primarily to the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "Rearrange these monitoring alerts from most urgent to least urgent:",
        "type": "rearrange",
        "words": ["Prediction latency > 500ms", "Data drift p-value < 0.01", "Accuracy dropped 12% vs last week", "CPU usage 92%"]
    },
    {
        "q": "Exploratory Analysis should always be performed only once at the beginning of the project and never repeated later.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.metrics import confusion_matrix\ny_true = [0, 1, 1, 0]\ny_pred = [0, 1, 0, 0]\nprint(confusion_matrix(y_true, y_pred)[1,1])",
        "o": [
            "1",
            "2",
            "3",
            "0"
        ]
    },
    {
        "q": "A champion-challenger framework where 5% of traffic goes to a new model while 95% stays on the old one is a strategy used in ______.",
        "type": "fill_blank",
        "answers": ["Deployment", "Monitoring"],
        "other_options": ["Collection", "Preparation", "Analysis"]
    },
    {
        "q": "Target leakage (accidentally using future information in features) is most dangerous when it goes undetected during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Data Preparation",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "Writing a detailed 'Model Card' documenting limitations, intended use, and ethical considerations is a best practice associated with the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "It is impossible to have data quality issues appear for the first time after a model has been in production for six months.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "A sudden upstream schema change breaks your ETL pipeline at 3 AM. The team that gets paged belongs to which lifecycle phase responsibility?",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Model Building",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Creating synthetic samples with SMOTE or CTGAN to balance an imbalanced dataset is performed during ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Monitoring", "Deployment", "Collection"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\ns = pd.Series([10, 20, 30], index=['x', 'y', 'z'])\nprint(s.loc['y':'z'])",
        "o": [
            "20\n30",
            "10\n20",
            "20",
            "KeyError"
        ]
    },
    {
        "q": "Designing a multi-armed bandit system to dynamically allocate traffic between competing models happens in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "Match these MLOps tools to the lifecycle phase they primarily serve:",
        "type": "match",
        "left": ["Weights & Biases", "DVC", "Prefect", "Seldon Core", "NannyML"],
        "right": ["Model Building", "Data Preparation", "Data Collection", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from datetime import datetime\nprint(datetime.now().strftime('%Y-%m-%d %H:%M:%S')[:10])",
        "o": [
            "Today's date in YYYY-MM-DD format",
            "Current time only",
            "An error",
            "2025-11-24"
        ]
    },
    {
        "q": "Implementing a rollback button in the UI that instantly switches back to the previous model version is a safety feature of the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Preparation", "Analysis"]
    },
    {
        "q": "Rearrange these activities in the order they typically occur when a severe performance drop is detected in production:",
        "type": "rearrange",
        "words": ["Trigger alert", "Investigate logs", "Compare feature distributions", "Decide to retrain", "Promote new model version"]
    },
    {
        "q": "Using t-SNE or UMAP to visualize high-dimensional embeddings of customer data is a technique used in the Exploratory Analysis phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import numpy as np\na = np.array([[1, 2], [3, 4]])\nprint(a.shape, a.ndim, a.size)",
        "o": [
            "(2, 2) 2 4",
            "(2, 2) 2 2",
            "(4,) 1 4",
            "Error"
        ]
    },
    {
        "q": "A business stakeholder asks, 'Why did this particular loan application get rejected?' The most appropriate lifecycle phase to answer this question is ______.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Data Collection"
        ]
    },
    {
        "q": "Applying log transformation to right-skewed features like income or page views is typically decided during ______.",
        "type": "fill_blank",
        "answers": ["Exploratory Analysis"],
        "other_options": ["Deployment", "Monitoring", "Collection"]
    },
    {
        "q": "Containerizing your model with Docker and pushing the image to ECR/GCR/Artifact Registry is a prerequisite for modern ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Preparation", "Building"]
    },
    {
        "q": "In a well-managed project, the same random_state value should be used across all train-test splits and cross-validation folds to ensure reproducibility.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Calculating PSI (Population Stability Index) on a monthly basis for all input features is a standard practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Data Preparation",
            "Model Building",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Which of the following is the LEAST common source of data in the Data Collection phase for a fraud detection project?",
        "type": "mcq",
        "o": [
            "Historical weather data",
            "Transaction logs",
            "Device fingerprinting",
            "IP geolocation"
        ]
    },
    {
        "q": "In the Monitoring phase, the metric 'prediction latency at p99' suddenly jumps from 80 ms to 1.8 s. This is classified as a ______ issue.",
        "type": "fill_blank",
        "answers": ["performance"],
        "other_options": ["accuracy", "fairness", "drift"]
    },
    {
        "q": "Match these advanced techniques to the lifecycle phase where they are most frequently applied:",
        "type": "match",
        "left": ["Adversarial validation", "Target encoding with smoothing", "SHAP summary plots123", "Gradual traffic shifting", "Residual analysis on production predictions"],
        "right": ["Data Preparation", "Data Preparation", "Exploratory Analysis", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\n\ndf = pd.DataFrame({'category': ['A','B','A','C','B']})\nprint(pd.get_dummies(df, prefix='', prefix_sep='').sum(axis=0))",
        "o": [
            "A    2\nB    2\nC    1",
            "A    3\nB    2\nC    1",
            "Error: too many columns",
            "All zeros"
        ]
    },
    {
        "q": "Implementing a feature store that serves the exact same feature values to both training and serving environments prevents ______.",
        "type": "fill_blank",
        "answers": ["training-serving skew"],
        "other_options": ["overfitting", "underfitting", "concept drift"]
    },
    {
        "q": "Rearrange these Deployment strategies from safest to riskiest:",
        "type": "rearrange",
        "words": ["Shadow mode", "Canary (1% traffic)", "Blue-Green", "Direct 100% cutover"]
    },
    {
        "q": "A model that was trained on data from 2018–2022 starts performing poorly in 2025 because customer behavior changed after a major global event. This is an example of concept drift.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer([('ohe', OneHotEncoder(sparse=False), [0])], remainder='drop')\nimport pandas as pd\nX = pd.DataFrame({'city': ['Tokyo', 'Paris', 'Tokyo']})\nprint(ct.fit_transform(X).sum(axis=0))",
        "o": [
            "[2. 1.]",
            "[1. 1. 2.]",
            "[3. 3.]",
            "Error"
        ]
    },
    {
        "q": "Running statistical tests (Kolmogorov-Smirnov, Chi-square) between training and current batch distributions is a core task in ______.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Deployment", "Preparation", "Collection"]
    },
    {
        "q": "In the Data Collection phase, deciding to sample only 1% of raw logs to reduce storage cost is an example of ______ sampling.",
        "type": "mcq",
        "o": [
            "stratified",
            "reservoir",
            "systematic",
            "convenience"
        ]
    },
    {
        "q": "Creating a 'data drift report' using Evidently AI and sending it automatically by email every Monday is part of the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "The practice of 'versioning' both data and code together ensures full experiment reproducibility across the entire lifecycle.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import numpy as np\nnp.random.seed(0)\nprint(np.random.permutation(5))",
        "o": [
            "[2 0 4 1 3]",
            "Random different numbers every time",
            "[0 1 2 3 4]",
            "Error"
        ]
    },
    {
        "q": "Using Optuna with pruning to stop unpromising hyperparameter trials early is a technique used exclusively in the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Monitoring", "Deployment", "Collection"]
    },
    {
        "q": "A junior data scientist merges two datasets on 'customer_id' without verifying that the ID format is identical in both sources. This mistake will most likely be discovered during ______.",
        "type": "mcq",
        "o": [
            "Exploratory Analysis",
            "Model Building",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "A healthcare project cannot use public APIs due to HIPAA regulations. The team decides to collect data via secure SFTP drops from hospital partners. This constraint primarily affects which phase?",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Deployment",
            "Monitoring",
            "Model Building"
        ]
    },
    {
        "q": "You realize that the target variable 'churn' was mistakenly calculated using data from the next month instead of the previous one. Fixing this requires returning to the ______ phase.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Deployment", "Monitoring", "Exploratory Analysis"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\nidx = pd.date_range('2025-01-01', periods=5, freq='D')\nts = pd.Series([10, 20, 30, 40, 50], index=idx)\nprint(ts.asfreq('2D').fillna('missing'))",
        "o": [
            "2025-01-01     10\n2025-01-03     30\n2025-01-05     50\nwith missing in between",
            "All values become missing",
            "Error: freq not supported",
            "Original series unchanged"
        ]
    },
    {
        "q": "Match these fairness-related activities to their most appropriate lifecycle phase:",
        "type": "match",
        "left": ["Disparate impact ratio calculation", "Adversarial debiasing", "Post-processing equalized odds", "Bias audit dashboard", "Protected attribute removal"],
        "right": ["Exploratory Analysis", "Model Building", "Model Building", "Monitoring", "Data Preparation"]
    },
    {
        "q": "Implementing online learning where the model updates weights with every new labeled batch in production is an advanced form of ______.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Deployment", "Model Building", "Collection"]
    },
    {
        "q": "Rearrange these steps when onboarding a brand-new raw data source:",
        "type": "rearrange",
        "words": ["Profile the schema", "Set up ingestion pipeline", "Create data quality tests", "Add to feature store", "Document in data catalog"]
    },
    {
        "q": "A recommender system deployed six months ago now suggests winter coats to users in Australia during their summer. This failure is due to inadequate handling of seasonality during the Exploratory Analysis phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.ensemble import IsolationForest\nmodel = IsolationForest(contamination=0.1, random_state=42)\nX = [[-1], [0], [1], [10]]\nprint(model.fit_predict(X))",
        "o": [
            "[ 1  1  1 -1]",
            "[ 1  1 -1  1]",
            "All 1s",
            "ValueError"
        ]
    },
    {
        "q": "Creating a 'golden dataset' with manually verified labels for continuous model evaluation in production is a best practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Data Collection",
            "Deployment",
            "Model Building"
        ]
    },
    {
        "q": "Using polynomial features of degree 3 on a dataset with only 50 samples will most likely cause issues detected during ______.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Deployment", "Monitoring", "Collection"]
    },
    {
        "q": "The business decides to expand the model from US-only to global traffic. The safest way is to first deploy it in shadow mode for non-US users. This technique belongs to the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "Running pd.cut() to convert continuous age into ordinal bins like 'young', 'middle-aged', 'senior' is usually done after observing the target distribution in ______.",
        "type": "fill_blank",
        "answers": ["Exploratory Analysis"],
        "other_options": ["Monitoring", "Deployment", "Collection"]
    },
    {
        "q": "Model explainability is only required for regulated industries like finance and healthcare, not for e-commerce or gaming.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import joblib, os\ntemp_file = 'temp_model.pkl'\njoblib.dump('dummy', temp_file)\nprint(os.path.getsize(temp_file) > 0)",
        "o": [
            "True",
            "False",
            "FileNotFoundError",
            "PermissionError"
        ]
    },
    {
        "q": "Triggering automatic retraining only when PSI > 0.2 on any feature is an example of ______ retraining strategy.",
        "type": "fill_blank",
        "answers": ["drift-triggered", "event-triggered"],
        "other_options": ["time-based", "manual", "continuous"]
    },
    {
        "q": "A retail company wants to predict next-day sales using only data available at 2 AM. Including 'total_sales_today' as a feature would introduce ______.",
        "type": "fill_blank",
        "answers": ["target leakage"],
        "other_options": ["multicollinearity", "concept drift", "overfitting"]
    },
    {
        "q": "In a computer vision project, augmenting images with random rotation, flip, and brightness changes is performed during the ______ phase.",
        "type": "mcq",
        "o": [
            "Data Preparation",
            "Model Building",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import torch\nt = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\nprint(t @ t.T)",
        "o": [
            "tensor([[ 5., 11.],\n        [11., 25.]])",
            "tensor([[1, 4],\n        [9, 16]])",
            "Error: shape mismatch",
            "tensor([[4, 8],\n        [6, 16]])"
        ]
    },
    {
        "q": "Match these real-world failure modes to the lifecycle phase where they are usually first detected:",
        "type": "match",
        "left": ["Model predicts negative prices", "API returns 500 errors under load", "Predictions skewed against protected group", "Training features missing in production", "Model accuracy drops every January"],
        "right": ["Model Building", "Deployment", "Monitoring", "Data Preparation", "Monitoring"]
    },
    {
        "q": "Using a holdout dataset that was never touched during development to make the final go/no-go decision happens at the end of the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Deployment", "Monitoring", "Exploratory Analysis"]
    },
    {
        "q": "Rearrange these actions in the correct sequence when a new country is added to an existing fraud model:",
        "type": "rearrange",
        "words": ["Collect labeled data from new country", "Analyze distribution differences", "Retrain with combined data", "Validate on local holdout", "Deploy with region-specific threshold"]
    },
    {
        "q": "Serving predictions from a GPU instance for a text-generation model but accidentally falling back to CPU when GPU is saturated is handled through ______ configuration.",
        "type": "fill_blank",
        "answers": ["autoscaling", "fallback"],
        "other_options": ["caching", "batching", "prefetching"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from functools import partial\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nscaler = partial(StandardScaler, with_mean=False)\nprint(scaler().fit_transform(np.array([[1, 2], [3, 4]])))",
        "o": [
            "array([[0.57735027, 0.57735027],\n       [1.73205081, 1.15470054]]) with slight floating difference",
            "Same as original array",
            "TypeError",
            "array([[1., 2.],\n       [3., 4.]])"
        ]
    },
    {
        "q": "A model that perfectly separates classes on training data but fails on validation is suffering from ______.",
        "type": "mcq",
        "o": [
            "overfitting",
            "underfitting",
            "data drift",
            "sampling bias"
        ]
    },
    {
        "q": "The practice of storing raw inference requests for 30 days to enable future debugging and retraining is called ______ logging.",
        "type": "fill_blank",
        "answers": ["shadow", "payload", "request"],
        "other_options": ["error", "metric", "trace"]
    },
    {
        "q": "Running A/B tests between two deployed models for 2 weeks and declaring a winner based on revenue lift is part of the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Data Collection"
        ]
    },
    {
        "q": "In time-series forecasting, using future values to create lagged features for past timestamps constitutes a classic case of data leakage.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import re\ntext = \"The price is $100 and €200\"\nprint(len(re.findall(r'\\p{Sc}', text, re.UNICODE)))",
        "o": [
            "2",
            "0",
            "1",
            "Error"
        ]
    },
    {
        "q": "Creating an interactive Streamlit or Dash app for business users to explore model predictions and override them when needed is a deliverable of the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "The lifecycle is strictly linear and should never loop back to earlier phases after deployment.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "A credit risk model is rejected by the regulator because the team cannot prove which features influenced a high-risk score. The missing piece was proper ______ documentation.",
        "type": "fill_blank",
        "answers": ["explainability", "interpretability"],
        "other_options": ["monitoring", "versioning", "scaling"]
    },
    {
        "q": "In a ride-sharing pricing model, multiplying 'distance_km' by 'surge_multiplier' inside the feature engineering step is safe only if surge_multiplier is known at ______ time.",
        "type": "mcq",
        "o": [
            "prediction",
            "training",
            "collection",
            "monitoring"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'value': [1, 2, np.nan, 4, np.nan]})\nprint(df['value'].interpolate(method='linear').tolist())",
        "o": [
            "[1.0, 2.0, 2.6666666666666665, 4.0, 4.0]",
            "[1.0, 2.0, 3.0, 4.0, 5.0]",
            "[1.0, 2.0, nan, 4.0, nan]",
            "MethodError"
        ]
    },
    {
        "q": "Match these specialized lifecycle extensions to their primary domain:",
        "type": "match",
        "left": ["Batch scoring on Hadoop", "Federated learning", "Model calibration platform", "Human-in-the-loop labeling", "Continuous integration for notebooks"],
        "right": ["Deployment", "Data Collection", "Model Building", "Data Preparation", "Model Building"]
    },
    {
        "q": "When a model must run on edge devices with only 64 KB RAM, quantization and pruning become critical activities during the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Preparation", "Analysis"]
    },
    {
        "q": "Rearrange these events in the order they should trigger a model retraining pipeline:",
        "type": "rearrange",
        "words": ["Ground-truth labels arrive", "Data drift alert fires", "Business KPI drops", "New raw data lands", "Model validation fails"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.calibration import calibration_curve\nimport numpy as np\ny_true = np.array([0, 0, 1, 1])\ny_prob = np.array([0.1, 0.4, 0.6, 0.9])\nfop, mpv = calibration_curve(y_true, y_prob, n_bins=2)\nprint(len(fop), len(mpv))",
        "o": [
            "2 2",
            "4 4",
            "10 10",
            "ValueError"
        ]
    },
    {
        "q": "Serving the exact same model version that achieved 0.892 AUC in staging to production prevents ______ discrepancy.",
        "type": "fill_blank",
        "answers": ["staging-production", "train-serve"],
        "other_options": ["concept", "data", "target"]
    },
    {
        "q": "A sentiment analysis model trained on movie reviews performs poorly on customer support tickets. This is primarily due to insufficient ______ during initial data collection.",
        "type": "mcq",
        "o": [
            "domain coverage",
            "feature scaling",
            "hyperparameter tuning",
            "model monitoring"
        ]
    },
    {
        "q": "Implementing rate limiting and circuit breakers around your prediction endpoint is considered infrastructure work in the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import mlflow\nmlflow.set_tracking_uri('file:///tmp/mlruns')\nwith mlflow.start_run():\n    mlflow.log_param('alpha', 0.5)\nprint(mlflow.active_run() is not None)",
        "o": [
            "True",
            "False",
            "None",
            "AttributeError"
        ]
    },
    {
        "q": "Using differential privacy when training a model on sensitive medical records adds noise during the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Deployment", "Monitoring", "Collection"]
    },
    {
        "q": "The model owner receives an email that says 'Model XYZ v27 has been automatically retired because no traffic for 90 days'. This automation belongs to the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "Running a daily job that compares model predictions against eventually arriving true labels and logs disagreement rate is called ______ evaluation.",
        "type": "fill_blank",
        "answers": ["offline", "delayed", "ground-truth"],
        "other_options": ["real-time", "online", "shadow"]
    },
    {
        "q": "It is acceptable to use test set labels to choose the final model as long as the improvement is statistically significant.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "A company uses third-party cookies for user tracking, but a new privacy law bans them next quarter. The team must find alternative signals before the ban. This risk is identified and mitigated earliest in the ______ phase.",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Monitoring",
            "Deployment",
            "Model Building"
        ]
    },
    {
        "q": "Converting free-text survey responses into TF-IDF vectors and then applying Truncated SVD for dimensionality reduction happens during ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Exploratory Analysis", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\ndf = pd.DataFrame({'group': ['A','A','B','B'], 'value': [10, 15, 20, 25]})\nprint(df.groupby('group')['value'].apply(lambda x: x.max() - x.min()))",
        "o": [
            "group\nA    5\nB    5",
            "group\nA   15\nB   25",
            "10\n15\n20\n25",
            "ValueError"
        ]
    },
    {
        "q": "Match these cutting-edge practices to their dominant lifecycle phase:",
        "type": "match",
        "left": ["Data-centric AI (CleanLab)", "LLM-as-a-judge evaluation", "Retrieval-augmented generation (RAG)", "Self-supervised pre-training", "Model distillation for mobile"],
        "right": ["Data Preparation", "Monitoring", "Deployment", "Model Building", "Deployment"]
    },
    {
        "q": "When a forecasting model must produce 10,000 predictions per second with sub-10ms latency, the team chooses ONNX Runtime with GPU instead of scikit-learn. This decision belongs to the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Preparation"]
    },
    {
        "q": "Rearrange these steps when migrating a legacy SPSS model to Python in production:",
        "type": "rearrange",
        "words": ["Reverse-engineer original logic", "Re-implement in pandas + sklearn", "Validate outputs match 99.99%", "Containerize new version", "Switch traffic with feature flag"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import lightgbm as lgb\nparams = {'objective': 'binary', 'metric': 'auc', 'verbosity': -1}\ntrain_data = lgb.Dataset([[0],[1],[0],[1]], label=[0,1,0,1])\nmodel = lgb.train(params, train_data, num_boost_round=1)\nprint(round(model.predict([[0]])[0], 4) > 0.5)",
        "o": [
            "False",
            "True",
            "Exactly 0.5",
            "RuntimeError"
        ]
    },
    {
        "q": "Using counterfactual explanations ('What if salary was 10% higher?') to help loan applicants understand rejections is a post-deployment feature in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "A churn model trained in Europe suddenly sees a flood of traffic from Asia due to a viral campaign. The accuracy appears to plummet overnight. This scenario is known as ______ shift.",
        "type": "fill_blank",
        "answers": ["covariate", "prior", "population"],
        "other_options": ["concept", "label", "seasonal"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from datetime import datetime, timedelta\nstart = datetime(2025, 1, 1)\nprint((start + timedelta(days=100)).month)",
        "o": [
            "4",
            "3",
            "5",
            "1"
        ]
    },
    {
        "q": "Implementing a 'model marketplace' where data scientists can publish and version models for internal reuse is an organizational improvement targeting the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Preparation"
        ]
    },
    {
        "q": "Applying winsorization at 1st and 99th percentiles to cap extreme transaction amounts is typically decided after seeing heavy tails in ______.",
        "type": "fill_blank",
        "answers": ["Exploratory Analysis"],
        "other_options": ["Monitoring", "Deployment", "Collection"]
    },
    {
        "q": "An insurance pricing model must be auditable for years after deployment. Storing input features, model version, raw prediction, and final decision for every quote is known as ______ logging.",
        "type": "fill_blank",
        "answers": ["audit", "decision", "inference"],
        "other_options": ["shadow", "performance", "drift"]
    },
    {
        "q": "Running weekly 'model fairness regression tests' that fail the CI pipeline if demographic parity drops below 0.8 is a modern practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Data Collection"
        ]
    },
    {
        "q": "It is fine to exclude weekends from training data for a daily sales model if you also exclude them at inference time.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which lifecycle phase is most negatively impacted when the business changes the definition of the target variable (e.g., churn window from 30 to 90 days) without informing the data science team?",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "A team spends three weeks labeling 50,000 images using an external crowd-sourcing platform. This activity is classified under ______.",
        "type": "fill_blank",
        "answers": ["Data Collection"],
        "other_options": ["Data Preparation", "Model Building", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\ndf = pd.DataFrame({'date': pd.date_range('2025-01-01', periods=6)})\ndf['is_weekend'] = df['date'].dt.dayofweek.isin([5,6])\nprint(df['is_weekend'].sum())",
        "o": [
            "2",
            "3",
            "4",
            "0"
        ]
    },
    {
        "q": "Match these ethical/ML governance artifacts to the phase they are typically created:",
        "type": "match",
        "left": ["Datasheet for Datasets", "Model Card", "AI Impact Assessment", "Responsible AI Checklist", "Inference Data Retention Policy"],
        "right": ["Data Collection", "Deployment", "Data Collection", "Model Building", "Monitoring"]
    },
    {
        "q": "Using a pre-trained BERT model and only fine-tuning the classification head on your small dataset is called ______ fine-tuning.",
        "type": "fill_blank",
        "answers": ["parameter-efficient", "few-shot", "transfer learning"],
        "other_options": ["full", "zero-shot", "continual"]
    },
    {
        "q": "Rearrange these actions when preparing a dataset for a Kaggle-style competition submission:",
        "type": "rearrange",
        "words": ["Load train.csv", "Perform EDA", "Engineer features on train", "Apply identical transformations to test.csv", "Generate predictions", "Create submission.csv"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from scipy.stats import ks_2samp\nimport numpy as np\nnp.random.seed(0)\na = np.random.normal(0, 1, 100)\nb = np.random.normal(0.5, 1, 100)\nprint(ks_2samp(a, b).pvalue < 0.05)",
        "o": [
            "True",
            "False",
            "Exactly 0.05",
            "RuntimeWarning"
        ]
    },
    {
        "q": "Implementing a gradual rollout where the percentage of users seeing the new model increases only after manual sign-off at each stage is called ______ deployment.",
        "type": "fill_blank",
        "answers": ["ring-based", "progressive", "staged"],
        "other_options": ["shadow", "canary", "blue-green"]
    },
    {
        "q": "A computer vision model for defect detection works perfectly in the lab but fails in the factory because of different lighting. This gap is known as ______ drift.",
        "type": "mcq",
        "o": [
            "covariate",
            "prior",
            "concept",
            "label"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pickle, io\nbuffer = io.BytesIO()\npickle.dump({'model': 'dummy'}, buffer)\nprint(len(buffer.getvalue()) > 50)",
        "o": [
            "True",
            "False",
            "TypeError",
            "PicklingError"
        ]
    },
    {
        "q": "Creating a 'prediction explanation API' that returns top 5 contributing features for every request is a feature added during the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Using focal loss instead of cross-entropy to handle severe class imbalance (1:1000) is a modification made during the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Data Preparation", "Deployment", "Monitoring"]
    },
    {
        "q": "The marketing team launches a 50%-off campaign never seen in training data. The demand forecasting model outputs impossibly low numbers. This failure occurs because the model was never exposed to such ______ during training.",
        "type": "fill_blank",
        "answers": ["regime", "scenario", "promotion"],
        "other_options": ["season", "holiday", "weekday"]
    },
    {
        "q": "Running a quarterly 'model inventory audit' to identify and decommission unused models is a governance task in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "It is impossible for a model to experience data drift if the input feature distributions remain perfectly stationary over time.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "In a multi-tenant SaaS product, isolating each customer's data during training to prevent information leakage is a requirement handled primarily in the ______ phase.",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Data Preparation",
            "Model Building",
            "Deployment"
        ]
    },
    {
        "q": "A forecasting model must respect inventory constraints (cannot predict selling 100 units if only 70 are in stock). Enforcing such business rules happens after the ML prediction in the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Preparation"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\nprint(df.agg({'A': 'sum', 'B': 'mean'}).to_dict())",
        "o": [
            "{'A': 6, 'B': 5.0}",
            "{'A': 2.0, 'B': 5.0}",
            "Error",
            "{'sum': 6, 'mean': 5.0}"
        ]
    },
    {
        "q": "Match these privacy-preserving techniques to their primary lifecycle phase:",
        "type": "match",
        "left": ["k-anonymity on raw tables", "Local differential privacy in mobile app", "Secure multi-party computation for training", "Homomorphic encryption for inference", "Synthetic data generation with GANs"],
        "right": ["Data Preparation", "Data Collection", "Model Building", "Deployment", "Data Preparation"]
    },
    {
        "q": "When a model is deployed to 50 edge locations worldwide, ensuring zero-downtime updates across all locations requires ______ deployment strategy.",
        "type": "fill_blank",
        "answers": ["rolling", "blue-green", "canary"],
        "other_options": ["shadow", "direct", "phased"]
    },
    {
        "q": "Rearrange these steps for building a recommendation system with alternating least squares (ALS):",
        "type": "rearrange",
        "words": ["Create user-item interaction matrix", "Handle cold-start users", "Train ALS on Spark", "Generate top-N recommendations", "Evaluate with NDCG@10 on holdout"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(ngram_range=(2,2))\ntext = ['I love data science', 'data science is fun']\nprint(cv.fit_transform(text).sum())",
        "o": [
            "2",
            "4",
            "5",
            "0"
        ]
    },
    {
        "q": "Storing every model artifact in an immutable registry with cryptographic hash to satisfy regulatory reproducibility requirements is a practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "A fraud model flags legitimate transactions during Black Friday because the volume and velocity are unprecedented. This is known as ______ drift caused by a special event.",
        "type": "fill_blank",
        "answers": ["seasonal", "event-driven", "temporary"],
        "other_options": ["permanent", "gradual", "sudden"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import numpy as np\narr = np.arange(9).reshape(3,3)\nprint(np.linalg.matrix_rank(arr))",
        "o": [
            "2",
            "3",
            "1",
            "LinAlgError"
        ]
    },
    {
        "q": "Implementing a feedback loop where customer support agents can mark predictions as correct/incorrect and route them back to retraining is called ______ learning.",
        "type": "fill_blank",
        "answers": ["human-in-the-loop", "active", "online"],
        "other_options": ["batch", "supervised", "reinforcement"]
    },
    {
        "q": "Creating a 'stale model detector' that alerts when the model is older than 6 months without retraining is a governance control in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "In a survival analysis project, censoring flags must be created before any modeling. This critical step belongs to the ______ phase.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Exploratory Analysis", "Model Building", "Monitoring"]
    },
    {
        "q": "Using Prophet or NeuralProphet to automatically detect and model multiple seasonality patterns is most helpful during the ______ phase for time-series problems.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Exploratory Analysis",
            "Data Preparation",
            "Deployment"
        ]
    },
    {
        "q": "It is acceptable to retrain a credit scoring model using features that include 'loan_approved' flag if that flag is from a previous manual process.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "In a recommendation system, calculating user and item embeddings using matrix factorization with implicit feedback (e.g., clicks, views) is primarily done during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Data Preparation",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "A telecom company receives call detail records (CDRs) in 15-minute batches from network switches. Scheduling the Spark job that transforms and loads them into the lake belongs to the ______ phase.",
        "type": "fill_blank",
        "answers": ["Data Collection"],
        "other_options": ["Data Preparation", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pandas as pd\ns = pd.Series([100, 200, 300], index=['a','b','c'])\nprint(s.pct_change().iloc[-1])",
        "o": [
            "0.5",
            "0.6666666666666666",
            "1.0",
            "NaN"
        ]
    },
    {
        "q": "Match these advanced monitoring concepts to their definitions:",
        "type": "match",
        "left": ["Prediction drift", "Ground truth lag", "Shadow dataset", "Virtual labels", "Model staleness metric"],
        "right": ["Distribution shift in model outputs", "Delay between prediction and label availability", "Copy of production traffic stored for future labeling", "Labels inferred from downstream user actions", "Days since last retraining"]
    },
    {
        "q": "Running hierarchical forecasting where country-level forecasts are reconciled with state-level and city-level forecasts using MinT or optimal reconciliation is part of the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Deployment", "Monitoring", "Preparation"]
    },
    {
        "q": "Rearrange these steps for a successful multi-modal model deployment (text + image):",
        "type": "rearrange",
        "words": ["Create combined preprocessing pipeline", "Train CLIP-like model", "Export to TorchScript", "Build inference service with separate text/image endpoints", "Load balancing with health checks"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from sklearn.utils import resample\nimport numpy as np\nnp.random.seed(42)\nX = np.array([1,2,3,4,5,6,7,8,9,10])\nprint(len(resample(X, n_samples=5, replace=False)))",
        "o": [
            "5",
            "10",
            "Error: cannot sample without replacement",
            "8"
        ]
    },
    {
        "q": "Implementing probabilistic scoring (e.g., returning prediction intervals instead of point estimates) for a demand forecasting model is decided during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Preparation"
        ]
    },
    {
        "q": "A click-through rate (CTR) model shows high calibration error on mobile devices but not on desktop. This platform-specific issue is typically detected during ______.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Model Building", "Deployment", "Collection"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(tf.__version__[0])",
        "o": [
            "2",
            "1",
            "Error",
            "None"
        ]
    },
    {
        "q": "Creating a 'cold-start' sub-model that uses only content-based features for users with fewer than 5 interactions happens during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Data Preparation",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "Using cross-feature interaction terms (e.g., age × income) only after confirming their importance via a decision tree is a technique from the ______ phase.",
        "type": "fill_blank",
        "answers": ["Exploratory Analysis"],
        "other_options": ["Model Building", "Monitoring", "Deployment"]
    },
    {
        "q": "Deploying a model that supports both batch inference (daily jobs) and real-time inference (API) using the same artifact is called ______ architecture.",
        "type": "fill_blank",
        "answers": ["hybrid", "dual-mode", "unified"],
        "other_options": ["online-offline", "streaming", "lambda"]
    },
    {
        "q": "In reinforcement learning projects for ad bidding, the exploration-exploitation trade-off must continue in production. This requirement blurs the line between Model Building and ______.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Data Collection",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "It is safe to drop rows containing missing target values during training because they provide no supervision signal.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "A fraud detection system must never let a single fraudulent transaction worth more than $100,000 pass undetected. The team therefore optimizes for recall at the 99.995th percentile instead of AUC. This decision is made during the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Preparation"
        ]
    },
    {
        "q": "In a speech-to-text pipeline, applying voice activity detection (VAD) to remove silent segments before feeding audio to the model is a preprocessing step belonging to ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Data Collection", "Model Building", "Deployment"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import numpy as np\nx = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nprint(x.shape)",
        "o": [
            "(2, 2, 2)",
            "(2, 2)",
            "(4, 2)",
            "(8,)"
        ]
    },
    {
        "q": "Match these niche data science roles to the lifecycle phase they primarily own:",
        "type": "match",
        "left": ["Analytics Engineer", "ML Platform Engineer", "Data Label Ops Manager", "Model Risk Manager", "Responsible AI Lead"],
        "right": ["Data Preparation", "Deployment", "Data Collection", "Monitoring", "Model Building"]
    },
    {
        "q": "Using model cascading (run cheap linear model first, expensive deep model only if confidence < 0.7) to reduce average latency and cost is an optimization done in the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Preparation"]
    },
    {
        "q": "Rearrange these actions when implementing a sequential A/B/C/D test for four different recommendation algorithms:",
        "type": "rearrange",
        "words": ["Define success metric", "Set minimum detectable effect", "Calculate required sample size", "Implement traffic splitting logic", "Run experiment for 14 days", "Perform statistical significance test"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import jax.numpy as jnp\nkey = jnp.array([0, 0], dtype=jnp.uint32)\nprint(jnp.array_equal(jax.random.uniform(key, shape=(3,)), jax.random.uniform(key, shape=(3,))))",
        "o": [
            "True",
            "False",
            "RuntimeError",
            "TypeError"
        ]
    },
    {
        "q": "Implementing model versioning with semantic versioning (major.minor.patch) and automatic rollback on regression is a governance feature of the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "A demand planning model trained on weekly aggregated data fails to capture intra-week patterns after a major shift to same-day delivery. The root cause is ______ aggregation during preparation.",
        "type": "fill_blank",
        "answers": ["excessive", "lossy", "premature"],
        "other_options": ["insufficient", "delayed", "incorrect"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import torch\nt = torch.randn(2, 3)\nprint(t.is_contiguous(), t.T.is_contiguous())",
        "o": [
            "True False",
            "True True",
            "False False",
            "False True"
        ]
    },
    {
        "q": "Using quantile regression to predict the 10th, 50th, and 90th percentiles of delivery time instead of just the mean is a technique introduced in the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Exploratory Analysis",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "Running daily anomaly detection on model input distributions using Isolation Forest and alerting only when >3 features are flagged simultaneously is a sophisticated ______ technique.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Deployment", "Preparation", "Building"]
    },
    {
        "q": "Creating a 'feature impact dashboard' that shows how much revenue would change if a particular feature were removed is typically built during the ______ phase for stakeholder communication.",
        "type": "mcq",
        "o": [
            "Exploratory Analysis",
            "Model Building",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "In a real-time bidding system, the inference service has exactly 50 ms to respond. Adding any caching layer that risks stale features violates the ______ constraint.",
        "type": "fill_blank",
        "answers": ["latency", "SLA", "real-time"],
        "other_options": ["accuracy", "cost", "throughput"]
    },
    {
        "q": "Deploying separate models for different geographic regions because a global model underperforms in certain countries is called model ______.",
        "type": "fill_blank",
        "answers": ["sharding", "segmentation", "localization"],
        "other_options": ["federation", "distillation", "ensembling"]
    },
    {
        "q": "A pharmaceutical company trains a molecule property prediction model. The most critical success factor is ensuring zero contamination between training molecules and the final benchmark test set. The process that guarantees this separation is called ______.",
        "type": "fill_blank",
        "answers": ["scaffold splitting", "temporal splitting", "cluster-centric splitting"],
        "other_options": ["random splitting", "stratified splitting", "group splitting"]
    },
    {
        "q": "In a high-frequency trading model, the feature 'bid-ask spread at t-1ms' is computed from the same market data feed used for labeling. This creates ______ leakage unless explicitly blocked.",
        "type": "mcq",
        "o": [
            "look-ahead",
            "survivorship",
            "selection",
            "sampling"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import duckdb\ncon = duckdb.connect(':memory:')\ncon.execute('CREATE TABLE t(x INTEGER)')\ncon.execute('INSERT INTO t VALUES (1),(NULL),(3)')\nprint(con.execute('SELECT avg(x) FROM t').fetchone()[0])",
        "o": [
            "2.0",
            "NULL",
            "1.3333333333333333",
            "Error"
        ]
    },
    {
        "q": "Match these rare but critical lifecycle events to their phase:",
        "type": "match",
        "left": ["Regulatory model re-validation", "Catastrophic data center outage", "Legal discovery request for historical predictions", "Discovery of mislabeled ground truth batch", "Vendor deprecates external enrichment API"],
        "right": ["Monitoring", "Deployment", "Monitoring", "Data Collection", "Data Collection"]
    },
    {
        "q": "Using Monte Carlo Dropout at inference time to estimate epistemic uncertainty is a technique that turns a standard neural network into a ______ model.",
        "type": "fill_blank",
        "answers": ["Bayesian approximate", "probabilistic", "uncertainty-aware"],
        "other_options": ["deterministic", "ensemble", "calibrated"]
    },
    {
        "q": "Rearrange these actions when decommissioning a legacy fraud model that has been live for 5 years:",
        "type": "rearrange",
        "words": ["Notify compliance team", "Archive model artifacts immutably", "Remove from inference cluster", "Redirect traffic to new model", "Delete monitoring dashboards after 90 days"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import polars as pl\ndf = pl.DataFrame({'id': [1,2,3], 'val': ['x', 'y', None]})\nprint(df.fill_null('missing').to_dicts())",
        "o": [
            "[{'id': 1, 'val': 'x'}, {'id': 2, 'val': 'y'}, {'id': 3, 'val': 'missing'}]",
            "Error: strategy not supported",
            "[{'id': 1, 'val': 'x'}, {'id': 2, 'val': 'y'}, {'id': 3, 'val': None}]",
            "[]"
        ]
    },
    {
        "q": "A model serving 10 million predictions per day starts consuming 30% more GPU memory after a seemingly minor code change. This regression would be caught earliest by ______ monitoring.",
        "type": "fill_blank",
        "answers": ["resource", "infrastructure", "profiling"],
        "other_options": ["accuracy", "latency", "drift"]
    },
    {
        "q": "In a multi-label classification task with 500 possible labels, using binary relevance with one-vs-rest classifiers instead of a single multi-output model is known as ______ decomposition.",
        "type": "mcq",
        "o": [
            "label",
            "feature",
            "instance",
            "problem"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import sympy as sp\nx = sp.symbols('x')\nprint(sp.integrate(sp.sin(x), (x, 0, sp.pi)))",
        "o": [
            "2",
            "0",
            "pi",
            "Symbolic expression"
        ]
    },
    {
        "q": "Implementing a 'kill switch' that instantly disables all model-based decisions and falls back to a rule-based engine is a mandatory risk control in the ______ phase for high-stakes applications.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Monitoring",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "Using time-weighted features where recent transactions contribute exponentially more to the customer risk score is a design choice made during ______ to handle concept drift naturally.",
        "type": "fill_blank",
        "answers": ["Data Preparation", "Feature Engineering"],
        "other_options": ["Model Building", "Monitoring", "Deployment"]
    },
    {
        "q": "A computer vision model deployed on factory robots suddenly stops working after the maintenance team replaces fluorescent lights with LED ones. This is an example of ______ shift caused by physical environment change.",
        "type": "fill_blank",
        "answers": ["lighting", "illumination", "environmental"],
        "other_options": ["seasonal", "temporal", "population"]
    },
    {
        "q": "Running a quarterly 'model explainability drift' report that compares current SHAP values to those from 12 months ago is an advanced practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "It is acceptable to use the same database for storing raw production inference logs and training datasets as long as proper access controls are in place.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In drug discovery, a model is trained on patented compounds from 1980–2010 and tested on a competitor’s 2024 patent filings. The performance drop is primarily due to ______ splitting not being used.",
        "type": "fill_blank",
        "answers": ["temporal", "time-based"],
        "other_options": ["random", "scaffold", "stratified"]
    },
    {
        "q": "A bank’s anti-money-laundering system flags 0.001% of transactions. Using simple random undersampling would discard 99.999% of clean data. The smarter approach is ______ sampling.",
        "type": "mcq",
        "o": [
            "near-miss or one-sided",
            "SMOTE + Tomek",
            "random oversampling",
            "cluster centroids"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import sqlalchemy as sa\nengine = sa.create_engine('sqlite:///:memory:')\nwith engine.begin() as conn:\n    conn.execute(sa.text('CREATE TABLE t (x INT)'))\n    conn.execute(sa.text('INSERT INTO t VALUES (42)'))\n    result = conn.execute(sa.text('SELECT x*2 FROM t')).fetchone()[0]\nprint(result)",
        "o": [
            "84",
            "42",
            "None",
            "OperationalError"
        ]
    },
    {
        "q": "Match these exotic deployment environments to their biggest constraint:",
        "type": "match",
        "left": ["Satellite edge node", "Wearable medical device", "Underwater drone", "Factory PLC", "Quantum cloud hybrid"],
        "right": ["Bandwidth < 10 KB/s", "Battery + < 2 MB RAM", "Intermittent acoustic comms", "Deterministic 1 ms cycle time", "Coherence time < 100 µs"]
    },
    {
        "q": "Using conformal prediction to produce statistically guaranteed prediction sets (e.g., “delivery time will be in [32, 41] min with 95% confidence”) is added during the ______ phase.",
        "type": "fill_blank",
        "answers": ["Model Building", "Deployment"],
        "other_options": ["Monitoring", "Preparation", "Collection"]
    },
    {
        "q": "Rearrange these steps when rolling out a new pricing model that directly affects revenue:",
        "type": "rearrange",
        "words": ["Shadow pricing for 2 weeks", "Canary region (5% customers)", "A/B test with holdout", "Executive sign-off", "Full rollout with circuit breaker"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import pyarrow as pa\ntelf = pa.table({'a': [1, 2, None, 4]})\nprint(elf.combine_chunks().to_pandas()['a'].mean())",
        "o": [
            "2.3333333333333335",
            "2.5",
            "nan",
            "ArrowInvalid"
        ]
    },
    {
        "q": "A model trained on English customer reviews is deployed globally. The worst degradation occurs in Japanese and Arabic markets. This failure mode is called ______ shift.",
        "type": "fill_blank",
        "answers": ["language", "linguistic", "script"],
        "other_options": ["geographic", "cultural", "temporal"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "from functools import lru_cache\n@lru_cache(maxsize=2)\ndef f(x):\n    print('called', x)\n    return x * x\nf(1); f(2); f(1); f(3)\nprint('calls printed:', 3)",
        "o": [
            "called 1\ncalled 2\ncalled 3\ncalls printed: 3",
            "called 1\ncalled 2\ncalls printed: 3",
            "called 1\ncalled 2\ncalled 1\ncalled 3\ncalls printed: 3",
            "Error"
        ]
    },
    {
        "q": "Running evals on held-out human preference data every time a new LLM fine-tune is produced is known as ______ validation in the modern LLM lifecycle.",
        "type": "mcq",
        "o": [
            "offline",
            "red-team",
            "preference",
            "constitutional"
        ]
    },
    {
        "q": "Implementing a model that outputs not only the prediction but also a cryptographic proof that it was generated by the exact registered model version is called ______ inference.",
        "type": "fill_blank",
        "answers": ["verifiable", "zero-knowledge", "trusted"],
        "other_options": ["encrypted", "secure", "auditable"]
    },
    {
        "q": "In a self-driving car stack, the perception model runs at 30 FPS while planning runs at 10 Hz. Deciding which perception outputs to drop or aggregate is a real-time decision in the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Monitoring",
            "Data Preparation"
        ]
    },
    {
        "q": "Using a technique called 'test-time augmentation' (averaging predictions over flipped, rotated, color-jittered versions of the same image) improves robustness during ______ only.",
        "type": "fill_blank",
        "answers": ["inference", "serving", "deployment"],
        "other_options": ["training", "validation", "monitoring"]
    },
    {
        "q": "A telecom tower anomaly detection model is retrained only when the tower’s firmware version changes. This is an example of ______-triggered retraining.",
        "type": "mcq",
        "o": [
            "metadata",
            "event",
            "configuration",
            "external"
        ]
    },
    {
        "q": "You can safely delete raw inference logs older than 7 days if your regulator only requires 6-month auditability of final decisions, not inputs.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "In quantum machine learning experiments, the training dataset must be repeatedly loaded into quantum states. The bottleneck that forces the team to limit dataset size to 256 samples belongs to the ______ phase.",
        "type": "mcq",
        "o": [
            "Data Collection",
            "Model Building",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "A reinforcement learning agent for energy grid balancing is trained in simulation for 10 million episodes but crashes on the first real dispatch command because the real API returns 503 on rate limit. This failure occurs at the boundary of ______ and ______.",
        "type": "fill_blank",
        "answers": ["Model Building", "Deployment"],
        "other_options": ["Monitoring", "Preparation", "Collection", "Analysis"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import zarr, numpy as np\nz = zarr.open_array('temp.zarr', mode='w', shape=(3,3), dtype='f4')\nz[:] = np.arange(9).reshape(3,3)\nprint(z[1,1])",
        "o": [
            "4",
            "5",
            "1",
            "FileNotFoundError"
        ]
    },
    {
        "q": "Match these extreme-scale challenges to their dominant lifecycle phase:",
        "type": "match",
        "left": ["Petabyte-scale feature joins", "Million-QPS inference", "10-year model audit trail", "Labeling 100 million images", "Training on 10,000 GPUs"],
        "right": ["Data Preparation", "Deployment", "Monitoring", "Data Collection", "Model Building"]
    },
    {
        "q": "Running a model entirely inside a browser using WebAssembly and ONNX Runtime Web to avoid sending sensitive medical images to the cloud is a privacy pattern from the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Collection"]
    },
    {
        "q": "Rearrange these steps for a successful LLM red-teaming exercise before release:",
        "type": "rearrange",
        "words": ["Write jailbreak prompts", "Run automated safety eval suite", "Engage external red team", "Fix harmful responses", "Freeze weights", "Publish system card"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import dask.array as da\nx = da.random.random((1000,1000), chunks=(100,100))\nprint((x > 0.5).sum().compute() > 400_000)",
        "o": [
            "True",
            "False",
            "Exactly 500000",
            "MemoryError"
        ]
    },
    {
        "q": "In a nuclear reactor monitoring system, the model is not allowed to be updated without a 6-month regulatory review. The team therefore implements extensive ______ instead of frequent retraining.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Deployment", "Preparation", "Building"]
    },
    {
        "q": "Using 'teacher forcing' during training but 'autoregressive sampling' at inference creates a mismatch known as ______ discrepancy.",
        "type": "mcq",
        "o": [
            "exposure",
            "train-test",
            "scheduling",
            "curriculum"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import cupy as cp\nx = cp.array([1, 2, 3])\nprint(cp.get_array_module(x).__name__)",
        "o": [
            "cupy",
            "numpy",
            "Error",
            "builtin"
        ]
    },
    {
        "q": "Implementing a model that refuses to answer if the user query contains PII detected by a separate NER model is called ______-time content moderation.",
        "type": "fill_blank",
        "answers": ["inference", "runtime", "serving"],
        "other_options": ["training", "monitoring", "collection"]
    },
    {
        "q": "A satellite image segmentation model trained on 30 cm resolution performs poorly on newly acquired 15 cm imagery. This is an example of ______ shift caused by sensor upgrade.",
        "type": "mcq",
        "o": [
            "resolution",
            "spectral",
            "spatial",
            "temporal"
        ]
    },
    {
        "q": "Creating a synthetic dataset using a diffusion model to train a downstream classifier when real data is too sensitive is called ______ data generation.",
        "type": "fill_blank",
        "answers": ["privacy-preserving", "differential-private", "generative"],
        "other_options": ["augmented", "simulated", "bootstrapped"]
    },
    {
        "q": "Running a daily 'model carbon footprint' report that tracks CO₂ equivalent emissions from training and inference is an emerging practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Model Building",
            "Deployment",
            "Data Collection"
        ]
    },
    {
        "q": "You can legally deploy a facial recognition model in production even if it was trained on scraped internet photos without explicit consent in the EU after May 2018.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "In a causal inference project using double machine learning, the most important step that distinguishes it from standard prediction is explicitly modeling the ______ before residualizing the outcome.",
        "type": "fill_blank",
        "answers": ["treatment", "propensity"],
        "other_options": ["outcome", "confounders", "instrument"]
    },
    {
        "q": "A medical diagnosis model is trained on hospital A data and deployed to hospital B. The drop in performance is primarily due to ______ bias caused by different patient demographics and equipment.",
        "type": "mcq",
        "o": [
            "site-specific",
            "selection",
            "spectrum",
            "label"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import vaex\ndf = vaex.from_arrays(x=[1,2,3,4,5])\nprint(df.x.rolling_mean(3).tolist())",
        "o": [
            "[None, None, 2.0, 3.0, 4.0]",
            "[2.0, 2.5, 3.0, 3.5, 4.0]",
            "[1.0, 1.5, 2.0, 2.5, 3.0]",
            "Error"
        ]
    },
    {
        "q": "Match these advanced causal inference techniques to their primary phase:",
        "type": "match",
        "left": ["Propensity score trimming", "Double/debiased ML", "Target trial emulation", "Instrumental variable with 2SLS", "Synthetic control method"],
        "right": ["Data Preparation", "Model Building", "Data Collection", "Model Building", "Model Building"]
    },
    {
        "q": "Using a technique called 'prompt chaining' where the output of one LLM call becomes the system prompt for the next call is common in the ______ phase for complex agentic workflows.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Collection"]
    },
    {
        "q": "Rearrange these steps when conducting a counterfactual fairness audit on a deployed loan model:",
        "type": "rearrange",
        "words": ["Generate counterfactuals by flipping protected attribute", "Run through black-box model", "Check if decision changes", "Compute individual discrimination score", "Aggregate to group-level metric"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import modin.pandas as pd\ndf = pd.DataFrame({'a': [10, 20, 30]})\nprint(df.a.pct_change().iloc[2])",
        "o": [
            "0.5",
            "1.0",
            "0.0",
            "NaN"
        ]
    },
    {
        "q": "Implementing 'prompt injection detection' that scans every user message for known jailbreak patterns before forwarding to the LLM is a safety layer added during ______.",
        "type": "fill_blank",
        "answers": ["Deployment", "inference"],
        "other_options": ["Monitoring", "Training", "Collection"]
    },
    {
        "q": "In a genome-wide association study (GWAS), applying Bonferroni correction or FDR control after computing millions of p-values is a post-processing step in the ______ phase.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Exploratory Analysis",
            "Data Preparation",
            "Monitoring"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import ray\ndataset = ray.data.range(10)\nprint(dataset.map(lambda x: x['id'] * 2).take(3))",
        "o": [
            "[0, 2, 4]",
            "[2, 4, 6]",
            "[0, 1, 2]",
            "RuntimeError"
        ]
    },
    {
        "q": "Using 'retrieval-augmented generation' (RAG) to ground LLM responses in company-specific documents instead of relying on parametric knowledge is a pattern from the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", " Monitoring", "Preparation"]
    },
    {
        "q": "Running a 'distributional shift test' using Maximum Mean Discrepancy (MMD) between training and current production data is an advanced technique in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Data Preparation",
            "Model Building",
            "Exploratory Analysis"
        ]
    },
    {
        "q": "In a clinical trial randomization system, the model that assigns patients to arms must be completely deterministic and auditable. This requirement forces the team to seed the RNG and log it during ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Building", "Collection"]
    },
    {
        "q": "Creating a 'model lineage graph' that shows exactly which dataset version → feature pipeline → experiment → model version → deployment slot is currently live is a feature of modern ______ platforms.",
        "type": "mcq",
        "o": [
            "MLOps",
            "DataOps",
            "LLMOps",
            "Model Governance"
        ]
    },
    {
        "q": "It is acceptable for a production fraud model to use features derived from the exact same transaction being scored as long as they are computed before the label is known.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In a multi-agent LLM system for customer support, one agent summarizes the conversation, another decides whether to escalate, and a third generates the final reply. Coordinating these agents happens entirely in the ______ phase.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "A team discovers that their sentiment model has 99% accuracy on English but only 61% on Spanish because the training data was 98% English. This is an example of ______ imbalance.",
        "type": "fill_blank",
        "answers": ["language", "linguistic", "representation"],
        "other_options": ["class", "feature", "temporal"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import ibis\nconn = ibis.sqlite.connect(':memory:')\nt = conn.create_table('t', {'x': [1,2,3]}, overwrite=True)\nprint(t.mutate(y = t.x * 2).execute().y.sum())",
        "o": [
            "12",
            "6",
            "18",
            "RuntimeError"
        ]
    },
    {
        "q": "Match these emerging LLM-specific lifecycle concepts to their meaning:",
        "type": "match",
        "left": ["Constitutional AI", "RLAIF", "Process reward model", "Self-instruct", "Red-teaming with LLMs"],
        "right": ["Training with AI-generated feedback", "Using principles instead of human values", "Rewarding step-by-step reasoning", "Bootstrapping instruction data", "Automated adversarial prompt generation"]
    },
    {
        "q": "Running a model on a secure enclave (Intel SGX or AWS Nitro) so that even the cloud provider cannot read the weights or input data is known as ______ execution.",
        "type": "fill_blank",
        "answers": ["confidential", "trusted", "enclave"],
        "other_options": ["encrypted", "federated", "private"]
    },
    {
        "q": "Rearrange these steps when creating a fully auditable clinical decision support system:",
        "type": "rearrange",
        "words": ["Log raw patient input with hash", "Run deterministic model", "Store prediction + SHAP values", "Generate human-readable explanation", "Sign entire record with private key"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import torchdistill\ntorchdistill.register('custom_loss')\ndef dummy():\n    return 42\nprint(torchdistill.registry.get('custom_loss')())",
        "o": [
            "42",
            "None",
            "KeyError",
            "ImportError"
        ]
    },
    {
        "q": "In a factory setting, the vision model must run on a PLC with no floating-point unit. Converting the model to fixed-point 8-bit integers (INT8) with post-training quantization is required during ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Preparation"]
    },
    {
        "q": "Using 'speculative decoding' where a small draft model proposes tokens and the large model verifies them to achieve 2–3× speedup is a latency optimization done at ______ time.",
        "type": "mcq",
        "o": [
            "inference",
            "training",
            "validation",
            "monitoring"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import lance\nuri = lance.write_dataset([{'x': 1}, {'x': 2}], 'temp.lance', mode='create')\nprint(lance.dataset(uri).to_table().column(0).to_pylist())",
        "o": [
            "[1, 2]",
            "[2, 1]",
            "[]",
            "LanceError"
        ]
    },
    {
        "q": "Implementing a 'human override workflow' where a clinician can correct a model diagnosis and automatically trigger a high-priority retraining ticket is called ______ learning integration.",
        "type": "fill_blank",
        "answers": ["human-in-the-loop", "interactive", "active"],
        "other_options": ["supervised", "online", "continual"]
    },
    {
        "q": "A weather forecasting model trained on reanalysis data from 1979–2010 fails to predict the intensity of storms after 2020 due to climate non-stationarity. This is an extreme case of ______ drift.",
        "type": "mcq",
        "o": [
            "non-stationary",
            "climate",
            "regime",
            "catastrophic"
        ]
    },
    {
        "q": "Running a 'model archaeology' investigation to figure out why a 4-year-old deployed model still uses a deprecated country code mapping is a rare but necessary task in the ______ phase.",
        "type": "fill_blank",
        "answers": ["Monitoring"],
        "other_options": ["Deployment", "Preparation", "Building"]
    },
    {
        "q": "Creating a 'prompt registry' with versioned, tested prompts that are centrally approved before being used in production is an emerging governance practice for ______ systems.",
        "type": "mcq",
        "o": [
            "LLM",
            "vision",
            "tabular",
            "audio"
        ]
    },
    {
        "q": "It is possible to achieve perfect calibration on a held-out test set while still having severe real-world miscalibration due to distribution shift.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In a federated learning setup across 1,000 hospitals, the central server never sees raw patient data. The phase that enforces this privacy guarantee by design is ______.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Data Collection",
            "Deployment",
            "Monitoring"
        ]
    },
    {
        "q": "A team builds a multimodal model that takes audio + video + text. The hardest alignment challenge—synchronizing 30 fps video frames with 16 kHz audio and variable-length captions—must be solved during ______.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Model Building", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tiledb\nctx = tiledb.Ctx()\nwith tiledb.open(tiledb.Array.create('temp.tdb', tiledb.ArraySchema(domain=tiledb.Domain([tiledb.Dim(name='x', domain=(0, 3), tile=4, dtype='int64')]), attrs=[tiledb.Attr(name='a', dtype='float64')])), mode='w') as A:\n    A[:] = {'a': [3.14, 2.71, 1.41, 1.61]}\nprint(tiledb.open('temp.tdb')['a'][:].tolist())",
        "o": [
            "[3.14, 2.71, 1.41, 1.61]",
            "[0.0, 0.0, 0.0, 0.0]",
            "TileDBError",
            "[]"
        ]
    },
    {
        "q": "Match these bleeding-edge concepts to their primary lifecycle phase:",
        "type": "match",
        "left": ["Neurosymbolic program synthesis", "Mixture-of-Depths routing", "Test-time training", "In-context continual learning", "Homomorphic model updates"],
        "right": ["Model Building", "Deployment", "Deployment", "Model Building", "Model Building"]
    },
    {
        "q": "Running a 70B-parameter LLM on a single consumer GPU by offloading layers to CPU/RAM and using 4-bit quantization with dynamic expert selection is possible thanks to ______ inference engines.",
        "type": "fill_blank",
        "answers": ["continuous batching", "paged attention", "speculative"],
        "other_options": ["tensor parallel", "pipeline parallel", "data parallel"]
    },
    {
        "q": "Rearrange these steps when implementing a privacy budget accountant for a production system using differential privacy:",
        "type": "rearrange",
        "words": ["Set total ε budget for the year", "Track per-query privacy loss", "Block queries when budget exhausted", "Log every privacy expenditure", "Generate annual privacy report"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import torch.nn.functional as F\nimport torch\nlogits = torch.tensor([[100.0, 0.0, 0.0]])\nprint(F.softmax(logits, dim=-1)[0][0].item() > 0.999999)",
        "o": [
            "True",
            "False",
            "Exactly 1.0",
            "OverflowError"
        ]
    },
    {
        "q": "Deploying a vision-language model that can answer questions about live camera feeds in real time while running entirely on a smart glasses device is constrained primarily by ______ during the deployment phase.",
        "type": "fill_blank",
        "answers": ["power", "thermal", "compute"],
        "other_options": ["bandwidth", "storage", "latency"]
    },
    {
        "q": "Using 'chain-of-verification' prompting where the model first lists possible hallucinations, then verifies each claim against retrieved documents, is a reliability technique applied at ______ time.",
        "type": "mcq",
        "o": [
            "inference",
            "training",
            "validation",
            "monitoring"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import torchaudio\nwaveform, sr = torchaudio.load('nonexistent.wav')\nprint('no error')",
        "o": [
            "RuntimeError",
            "FileNotFoundError",
            "returns None, None",
            "prints 'no error'"
        ]
    },
    {
        "q": "Implementing a 'model watermarking' scheme that embeds an undetectable signal in generated images to prove they came from your system is a post-training modification done before ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Monitoring", "Training", "Collection"]
    },
    {
        "q": "In a space mission, the anomaly detection model running on the spacecraft cannot be updated for 8 months due to communication blackouts. The team therefore uses ______ learning with on-board synthetic negative mining.",
        "type": "mcq",
        "o": [
            "self-supervised",
            "unsupervised",
            "continual",
            "one-shot"
        ]
    },
    {
        "q": "Running a 'prompt drift detector' that compares the distribution of user prompts month-over-month and alerts when new jailbreak patterns emerge is a new form of ______ monitoring.",
        "type": "fill_blank",
        "answers": ["input", "behavioral", "prompt"],
        "other_options": ["output", "performance", "latency"]
    },
    {
        "q": "Creating a 'knowledge cutoff manifest' that explicitly lists which world events the model was and was not trained on is now required for transparency in the ______ phase of state-of-the-art LLMs.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Data Collection",
            "Monitoring"
        ]
    },
    {
        "q": "A production model can still suffer from catastrophic forgetting even if it was never retrained, simply because the input distribution evolved far beyond training conditions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In a nuclear power plant safety system, the ML model is legally classified as 'safety-related software'. The strictest lifecycle requirement is full ______ traceability from requirements to deployed binary.",
        "type": "fill_blank",
        "answers": ["requirements"],
        "other_options": ["data", "model", "code"]
    },
    {
        "q": "A robotics manipulation model trained in simulation works perfectly in the lab but fails catastrophically on real hardware due to unmodeled friction and backlash. This gap is known as the ______ gap.",
        "type": "mcq",
        "o": [
            "sim-to-real",
            "reality",
            "domain",
            "physical"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import jax\nimport jax.numpy as jnp\nrng = jax.random.PRNGKey(0)\nk1, k2 = jax.random.split(rng)\nprint(jax.random.normal(k1).shape == jax.random.normal(k2).shape)",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match these exotic hardware accelerators to their primary deployment constraint:",
        "type": "match",
        "left": ["Cerebras Wafer-Scale Engine", "Groq Language Processing Unit", "Graphcore IPU", "Tenstorrent Wormhole", "Photonic AI chip"],
        "right": ["Only one chip per rack", "Deterministic 10 Tbps routing", "Colossus interconnect required", "Scalable via mesh", "No heat tolerance above 40°C"]
    },
    {
        "q": "Running a 2-trillion-parameter model with 16-way tensor parallelism + 64-way pipeline parallelism + ZeRO-3 offload while achieving 58% MFU is only possible thanks to advanced ______ orchestration.",
        "type": "fill_blank",
        "answers": ["3D parallelism", "hybrid parallelism", "multi-dimensional"],
        "other_options": ["data parallelism", "model parallelism", "expert parallelism"]
    },
    {
        "q": "Rearrange these steps when conducting a formal model verification for a safety-critical drone collision avoidance system:",
        "type": "rearrange",
        "words": ["Define formal specification in temporal logic", "Train neural network controller", "Run bounded model checking", "Generate counterexamples", "Apply verified repair or shielding"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import triton\n@triton.jit\ndef add(x_ptr, y_ptr, out_ptr, n, BLOCK_SIZE: tl.constexpr):\n    pid = tl.program_id(0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    x = tl.load(x_ptr + offsets, mask=offsets < n)\n    y = tl.load(y_ptr + offsets, mask=offsets < n)\n    tl.store(out_ptr + offsets, x + y, mask=offsets < n)\nprint('kernel defined')",
        "o": [
            "kernel defined",
            "RuntimeError",
            "compiles to PTX",
            "prints nothing"
        ]
    },
    {
        "q": "In a brain-computer interface, the model decodes neural spikes into intended movements in <50 ms. Missing this latency budget can cause physical harm. This constraint dominates the ______ phase.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Collection"]
    },
    {
        "q": "Using 'activation patching' during inference to surgically remove a specific harmful behavior (e.g., refusal circumvention) discovered post-deployment is called ______ intervention.",
        "type": "mcq",
        "o": [
            "circuit-level",
            "representation engineering",
            "ablation",
            "steering"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import flash_attn\nprint(hasattr(flash_attn, 'flash_attn_func'))",
        "o": [
            "True",
            "False",
            "AttributeError",
            "ImportError if CUDA missing"
        ]
    },
    {
        "q": "Deploying a model that runs partially on a quantum processing unit (QPU) for feature mapping while classical layers run on GPU is called ______ computing architecture.",
        "type": "fill_blank",
        "answers": ["hybrid quantum-classical", "quantum-enhanced", "QML"],
        "other_options": ["pure quantum", "simulated quantum", "annealing"]
    },
    {
        "q": "In a missile defense system, the model must provide a verifiable proof that its decision satisfies formal safety invariants within 10 μs. This requirement forces the use of ______ networks.",
        "type": "mcq",
        "o": [
            "verifiable",
            "certified",
            "provable",
            "neural certificate"
        ]
    },
    {
        "q": "Running a 'hallucination leaderboard' that continuously evaluates the deployed LLM against freshly curated factual questions and automatically rolls back if score drops >3% is a new form of ______ monitoring.",
        "type": "fill_blank",
        "answers": ["truthfulness", "factual", "knowledge"],
        "other_options": ["latency", "safety", "toxicity"]
    },
    {
        "q": "Creating a 'model obituary' document when sunsetting a 6-year-old recommendation model—including final metrics, business impact, and lessons learned—is an emerging best practice in the ______ phase.",
        "type": "mcq",
        "o": [
            "Monitoring",
            "Deployment",
            "Model Building",
            "Data Collection"
        ]
    },
    {
        "q": "A production model trained with standard empirical risk minimization can still be adversarially robust if the training data was perfectly clean and infinite",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "In a deep brain stimulation device, the closed-loop ML controller adjusts voltage in real time based on neural feedback. The phase that requires FDA pre-market approval for every coefficient change is ______.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "A model trained on 8-bit quantized weights is deployed to a microcontroller with only 6-bit multiply-accumulate units. The workaround of emulating 8-bit using multiple 6-bit ops is done during ______.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Model Building", "Monitoring", "Preparation"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import bitsandbytes as bnb\nprint(bnb.__version__[0] >= '0' and bnb.functional.is_available())",
        "o": [
            "True",
            "False",
            "AttributeError",
            "CUDA not available"
        ]
    },
    {
        "q": "Match these frontier-scale training tricks to their purpose:",
        "type": "match",
        "left": ["Sequence packing", "FlashAttention-3", "RingAttention", "DeepSpeed Ulysses", "Blackhole optimizer"],
        "right": ["Reduce padding waste", "Avoid materializing full attention matrix", "Overlap all-reduce across nodes", "3D parallelism for 100k+ GPUs", "Skip gradient update on low-loss tokens"]
    },
    {
        "q": "Running inference on a model that was trained with reversible layers so that activations can be recomputed on-the-fly instead of stored, slashing memory from O(n) to O(1), is possible thanks to ______ architecture.",
        "type": "fill_blank",
        "answers": ["reversible networks", "memory-efficient", "checkpoint-free"],
        "other_options": ["residual", "recurrent", "transformer"]
    },
    {
        "q": "Rearrange these steps when launching a 100k+ H100 training run for a new foundation model:",
        "type": "rearrange",
        "words": ["Reserve superpod for 90 days", "Pre-flight cluster health check", "Load tokenizer + dataset shards", "Start ZeRO-3 + FSDP training", "Enable fault-tolerant checkpointing", "Begin continuous validation loop"]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import transformer_engine\nprint(hasattr(transformer_engine.pytorch, 'Float8Linear'))",
        "o": [
            "True",
            "False",
            "ImportError",
            "None"
        ]
    },
    {
        "q": "In an implantable cardiac defibrillator, the shock decision model must be mathematically proven to never trigger on sinus rhythm. This forces the team to use ______ neural networks with formal guarantees.",
        "type": "fill_blank",
        "answers": ["verifiably safe", "certified robust", "Lipschitz-bounded"],
        "other_options": ["spiking", "binary", "analog"]
    },
    {
        "q": "Using 'latent adversarial training' where the model is forced to ignore toxic concepts in its internal representations (not just outputs) is a safety technique applied during ______.",
        "type": "mcq",
        "o": [
            "Model Building",
            "Deployment",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import vllm\nprint(vllm.__version__[0] >= '0' and hasattr(vllm, 'LLM'))",
        "o": [
            "True",
            "False",
            "ImportError",
            "CUDA required"
        ]
    },
    {
        "q": "Deploying a 405B-parameter model with 32-way tensor + 8-way pipeline parallelism across 4 superpods connected by 800 Gbps InfiniBand is only feasible with ______ attention.",
        "type": "fill_blank",
        "answers": ["ring", "blockwise", "distributed"],
        "other_options": ["flash", "sparse", "linear"]
    },
    {
        "q": "In a Mars rover autonomy stack, the model must run for 5 years without any software update due to 20-minute light-speed delay. The team therefore uses radiation-hardened FPGA with triple modular redundancy during ______.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "Running 'activation quantization-aware training' with straight-through estimator to produce a model that runs in pure INT4 end-to-end with <1% accuracy loss is an extreme optimization done during ______.",
        "type": "fill_blank",
        "answers": ["Model Building"],
        "other_options": ["Deployment", "Monitoring", "Preparation"]
    },
    {
        "q": "Creating a 'model constitution' — a hardcoded set of 100 ethical principles that override any learned behavior via classifier steering — is a safety pattern from the ______ phase of frontier LLMs.",
        "type": "mcq",
        "o": [
            "Deployment",
            "Model Building",
            "Monitoring",
            "Data Collection"
        ]
    },
    {
        "q": "A model trained with standard stochastic gradient descent can achieve certified robustness against any L2 perturbation of radius 2.0 without additional techniques.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which phase of the data science lifecycle involves handling missing values and outliers?",
        "type": "mcq",
        "o": [
            "Data Preparation",
            "Data Collection",
            "Exploratory Analysis",
            "Model Building"
        ]
    },
    {
        "q": "What is the primary goal of the Exploratory Data Analysis (EDA) phase?",
        "type": "mcq",
        "o": [
            "Understand data patterns and relationships",
            "Deploy models to production",
            "Collect raw data from sources",
            "Monitor model performance"
        ]
    },
    {
        "q": "During model monitoring, ______ tracking helps detect when model performance degrades over time.",
        "type": "fill_blank",
        "answers": ["drift"],
        "other_options": ["accuracy", "bias", "variance"]
    },
    {
        "q": "Match the data science lifecycle phase with its primary activity:",
        "type": "match",
        "left": ["Data Collection", "Data Preparation", "Model Building", "Deployment"],
        "right": ["Gathering raw data from sources", "Cleaning and transforming data", "Training machine learning algorithms", "Making models available for use"]
    },
    {
        "q": "What is the output of the following code?",
        "type": "mcq",
        "c": "import pandas as pd\nprint(pd.isnull(float('nan')))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "The process of feature scaling and one-hot encoding typically occurs during the ______ phase.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Data Collection", "Model Building", "Monitoring"]
    },
    {
        "q": "A/B testing is commonly used during the model deployment phase to compare model performance.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which of the following is NOT typically part of the model building phase?",
        "type": "mcq",
        "o": [
            "Data collection from APIs",
            "Hyperparameter tuning",
            "Algorithm selection",
            "Cross-validation"
        ]
    },
    {
        "q": "Rearrange the data science lifecycle phases in correct sequential order:",
        "type": "rearrange",
        "words": ["Data Collection", "Data Preparation", "Exploratory Analysis", "Model Building", "Deployment", "Monitoring"]
    },
    {
        "q": "What is the output of the following code?",
        "type": "mcq",
        "c": "from sklearn.model_selection import train_test_split\nX = [[1], [2], [3], [4]]\ny = [0, 1, 0, 1]\nprint(len(train_test_split(X, y, test_size=0.25)[0]))",
        "o": [
            "3",
            "4",
            "1",
            "2"
        ]
    },
    {
        "q": "In the monitoring phase, ______ bias detection helps ensure models don't discriminate against protected groups.",
        "type": "fill_blank",
        "answers": ["fairness"],
        "other_options": ["selection", "confirmation", "measurement"]
    },
    {
        "q": "Data visualization techniques like histograms and scatter plots are primarily used during the exploratory analysis phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which phase involves creating APIs or web interfaces for model consumption?",
        "type": "mcq",
        "o": [
            "Deployment",
            "Data Collection",
            "Model Building",
            "Data Preparation"
        ]
    },
    {
        "q": "Match the data science concept with its appropriate lifecycle phase:",
        "type": "match",
        "left": ["Cross-validation", "Data cleaning", "Dashboard creation", "Performance metrics"],
        "right": ["Model Building", "Data Preparation", "Deployment", "Monitoring"]
    },
    {
        "q": "The process of converting categorical variables into numerical format occurs during data preparation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In a data pipeline, data validation checks like verifying value ranges typically occur during the ______ stage.",
        "type": "fill_blank",
        "answers": ["Data Preparation"],
        "other_options": ["Data Collection", "Model Monitoring", "Business Understanding"]
    },
    {
        "q": "What is the primary purpose of creating a baseline model?",
        "type": "mcq",
        "o": [
            "To establish minimum performance expectations",
            "To deploy in production immediately",
            "To replace all future models",
            "To eliminate the need for data cleaning"
        ]
    },
    {
        "q": "Rearrange the steps for handling missing data in the correct workflow order:",
        "type": "rearrange",
        "words": ["Identify", "Analyze", "Choose", "Implement", "Validate"]
    },
    {
        "q": "Match the deployment strategy with its description:",
        "type": "match",
        "left": ["Canary Deployment", "Blue-Green Deployment", "Shadow Deployment", "A/B Testing"],
        "right": ["Gradual rollout to small user subset", "Two identical environments switched instantly", "Model runs parallel without affecting users", "Compare two versions with different user groups"]
    },
    {
        "q": "What is the output of this pandas code for detecting missing values?",
        "type": "mcq",
        "c": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, np.nan]})\nprint(df.isnull().sum().sum())",
        "o": [
            "2",
            "1",
            "0",
            "3"
        ]
    },
    {
        "q": "Concept drift detection is more relevant to model monitoring than data preparation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which technique is specifically used for addressing class imbalance during data preparation?",
        "type": "mcq",
        "o": [
            "SMOTE (Synthetic Minority Over-sampling Technique)",
            "One-hot encoding",
            "Principal Component Analysis",
            "K-means clustering"
        ]
    },
    {
        "q": "The ______ phase often involves creating interactive dashboards for business stakeholders.",
        "type": "fill_blank",
        "answers": ["Deployment"],
        "other_options": ["Data Collection", "Model Building", "Data Preparation"]
    },
    {
        "q": "What does this scikit-learn code demonstrate about the model lifecycle?",
        "type": "mcq",
        "c": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\npipe = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression())])",
        "o": [
            "Combining preprocessing and modeling steps",
            "Deploying a model to production",
            "Monitoring model performance",
            "Collecting new training data"
        ]
    },
    {
        "q": "During exploratory analysis, a Q-Q plot is primarily used to assess ______.",
        "type": "fill_blank",
        "answers": ["normality"],
        "other_options": ["correlation", "causation", "variance"]
    },
    {
        "q": "Model versioning and experiment tracking tools like MLflow are most critical during the model building phase.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which of these is NOT a common metric for monitoring regression models in production?",
        "type": "mcq",
        "o": [
            "F1-score",
            "MAE (Mean Absolute Error)",
            "RMSE (Root Mean Square Error)",
            "R-squared"
        ]
    },
    {
        "q": "Match the data quality issue with its appropriate handling technique:",
        "type": "match",
        "left": ["Duplicate records", "Inconsistent formatting", "Outliers", "Missing timestamps"],
        "right": ["Deduplication", "Standardization", "Winsorizing", "Imputation based on patterns"]
    },
    {
        "q": "Rearrange the model evaluation workflow steps:",
        "type": "rearrange",
        "words": ["Split", "Train", "Predict", "Evaluate", "Compare"]
    },
    {
        "q": "Feature stores are architectural components that primarily support the deployment and monitoring phases.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the key difference between holdout validation and cross-validation?",
        "type": "mcq",
        "o": [
            "Cross-validation uses multiple train-test splits",
            "Holdout validation is more computationally expensive",
            "Cross-validation uses only one test set",
            "Holdout validation provides more reliable performance estimates"
        ]
    },
    {
        "q": "The practice of ______ involves periodically retraining models with new data to maintain performance.",
        "type": "fill_blank",
        "answers": ["refreshing"],
        "other_options": ["debugging", "archiving", "validating"]
    },
    {
        "q": "Which deployment approach allows rolling back to previous model versions quickly?",
        "type": "mcq",
        "o": [
            "Blue-Green Deployment",
            "Shadow Deployment",
            "Canary Deployment",
            "A/B Testing"
        ]
    },
    {
        "q": "A data scientist notices their model's performance is declining in production. This phase of the lifecycle is called model ______.",
        "type": "fill_blank",
        "answers": ["monitoring"],
        "other_options": ["building", "collection", "cleaning"]
    },
    {
        "q": "What is the primary goal of creating a 'champion-challenger' framework during deployment?",
        "type": "mcq",
        "o": [
            "To safely test new models against the current production model",
            "To collect more training data from user interactions",
            "To clean and prepare data more efficiently",
            "To visualize data distributions for stakeholders"
        ]
    },
    {
        "q": "Rearrange the typical workflow for addressing data quality issues:",
        "type": "rearrange",
        "words": ["Detect", "Document", "Diagnose", "Remediate", "Prevent"]
    },
    {
        "q": "Match the data science artifact with its primary lifecycle phase:",
        "type": "match",
        "left": ["Data Quality Report", "Feature Importance Chart", "Model API Endpoint", "Performance Dashboard"],
        "right": ["Data Preparation", "Model Building", "Deployment", "Monitoring"]
    },
    {
        "q": "What does this code output suggest about the data preparation?",
        "type": "mcq",
        "c": "print(\"Missing values per column:\")\nprint(\"Age: 5%\\nIncome: 12%\\nEducation: 0%\")\nprint(\"Recommended action: Imputation for Income\")",
        "o": [
            "Different columns require different missing value strategies",
            "All missing values should be dropped immediately",
            "The dataset is too small for reliable modeling",
            "No data preparation is needed"
        ]
    },
    {
        "q": "During feature engineering, creating interaction terms between 'age' and 'income' would generate a ______ feature.",
        "type": "fill_blank",
        "answers": ["derived"],
        "other_options": ["categorical", "target", "redundant"]
    },
    {
        "q": "Data lineage tracking becomes increasingly important as models move from development to production.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which technique is most appropriate for detecting data drift in production systems?",
        "type": "mcq",
        "o": [
            "Population Stability Index (PSI)",
            "Principal Component Analysis (PCA)",
            "K-means Clustering",
            "Linear Regression"
        ]
    },
    {
        "q": "The process of converting a Jupyter notebook into a production-ready script typically occurs during the ______ phase.",
        "type": "fill_blank",
        "answers": ["deployment"],
        "other_options": ["exploratory analysis", "data collection", "model building"]
    },
    {
        "q": "What is the key advantage of using containerization (e.g., Docker) in model deployment?",
        "type": "mcq",
        "o": [
            "Consistent environment across development and production",
            "Faster model training times",
            "Automatic feature selection",
            "Improved data visualization capabilities"
        ]
    },
    {
        "q": "A sudden drop in model prediction confidence scores might indicate ______ in the incoming data.",
        "type": "fill_blank",
        "answers": ["drift"],
        "other_options": ["bias", "leakage", "correlation"]
    },
    {
        "q": "Business metrics should be considered alongside technical metrics during model monitoring.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which of these is NOT a common challenge during the data collection phase?",
        "type": "mcq",
        "o": [
            "Hyperparameter optimization",
            "API rate limiting",
            "Data privacy compliance",
            "Schema inconsistencies"
        ]
    },
    {
        "q": "Match the validation technique with its best use case:",
        "type": "match",
        "left": ["Time Series Split", "Stratified K-Fold", "Train-Test Split", "Leave-One-Out"],
        "right": ["Temporal data", "Imbalanced classes", "Large datasets", "Very small datasets"]
    },
    {
        "q": "Rearrange the steps for ethical model deployment:",
        "type": "rearrange",
        "words": ["Bias", "Fairness", "Transparency", "Privacy", "Testing", "Documentation"]
    },
    {
        "q": "Feature stores help maintain consistency between features used in training and inference.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of calculating SHAP values during model interpretation?",
        "type": "mcq",
        "o": [
            "To understand feature contributions to individual predictions",
            "To deploy models faster to production",
            "To collect more training data",
            "To clean missing values automatically"
        ]
    },
    {
        "q": "The practice of ______ involves serving predictions through real-time APIs rather than batch processing.",
        "type": "fill_blank",
        "answers": ["online"],
        "other_options": ["offline", "parallel", "distributed"]
    },
    {
        "q": "When collecting data from multiple databases, dealing with different join keys across systems is a ______ problem.",
        "type": "fill_blank",
        "answers": ["schema integration"],
        "other_options": ["computational", "visualization", "deployment"]
    },
    {
        "q": "In a real-time recommendation system, which deployment pattern would be most suitable?",
        "type": "mcq",
        "o": [
            "Online inference with low-latency API",
            "Batch processing once per day",
            "Manual model execution on demand",
            "Static pre-computed predictions"
        ]
    },
    {
        "q": "Rearrange the data validation checks from simplest to most complex:",
        "type": "rearrange",
        "words": ["Data type", "Value range", "Uniqueness", "Business rule", "Cross-field relationship"]
    },
    {
        "q": "Match the data science tool with its primary lifecycle function:",
        "type": "match",
        "left": ["Great Expectations", "MLflow", "Evidently AI", "Kubeflow"],
        "right": ["Data validation", "Experiment tracking", "Production monitoring", "Pipeline orchestration"]
    },
    {
        "q": "What does this scenario describe: 'A model trained on summer data performs poorly when applied to winter conditions'?",
        "type": "mcq",
        "o": [
            "Covariate shift in feature distribution",
            "Perfect model generalization",
            "Successful deployment strategy",
            "Data collection best practice"
        ]
    },
    {
        "q": "Creating aggregations like '30-day rolling averages' is an example of ______ engineering.",
        "type": "fill_blank",
        "answers": ["temporal feature"],
        "other_options": ["data collection", "model deployment", "performance monitoring"]
    },
    {
        "q": "Data contracts between data producers and consumers help prevent breaking changes in upstream systems.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which approach is most effective for detecting label drift in classification models?",
        "type": "mcq",
        "o": [
            "Monitoring changes in class distribution over time",
            "Tracking feature correlation matrices",
            "Measuring API response times",
            "Counting database table rows"
        ]
    },
    {
        "q": "The process of ______ involves automatically retraining models when performance drops below a threshold.",
        "type": "fill_blank",
        "answers": ["continuous training"],
        "other_options": ["data collection", "feature selection", "exploratory analysis"]
    },
    {
        "q": "What is the main advantage of using feature stores in machine learning systems?",
        "type": "mcq",
        "o": [
            "Ensuring consistent feature calculation across training and serving",
            "Reducing model training time by 90%",
            "Eliminating the need for data validation",
            "Automatically deploying models to production"
        ]
    },
    {
        "q": "When exploratory analysis reveals a strong seasonal pattern, this might warrant creating ______ features for modeling.",
        "type": "fill_blank",
        "answers": ["time-based"],
        "other_options": ["text", "image", "audio"]
    },
    {
        "q": "Shadow deployment allows comparing new model performance without affecting real users.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection consideration is most critical for models subject to GDPR compliance?",
        "type": "mcq",
        "o": [
            "Right to be forgotten and data deletion mechanisms",
            "Maximizing data collection from all possible sources",
            "Using the fastest available database technology",
            "Collecting data without user consent for better models"
        ]
    },
    {
        "q": "Match the data preparation challenge with its mitigation strategy:",
        "type": "match",
        "left": ["High cardinality categorical", "Class imbalance", "Multicollinearity", "Non-stationary time series"],
        "right": ["Target encoding or embedding", "Resampling techniques", "Feature selection or PCA", "Differencing or decomposition"]
    },
    {
        "q": "Rearrange the MLOps maturity levels from basic to advanced:",
        "type": "rearrange",
        "words": ["Manual", "ML pipeline", "CI/CD", "Automated retraining", "Full automation"]
    },
    {
        "q": "Data versioning is as important as model versioning in reproducible machine learning.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of calculating prediction stability in model monitoring?",
        "type": "mcq",
        "o": [
            "Detecting when model predictions become erratic or unreliable",
            "Measuring how quickly the model makes predictions",
            "Determining the most important features in the model",
            "Calculating the cost of model training"
        ]
    },
    {
        "q": "The practice of ______ analysis helps identify whether poor performance affects specific user segments disproportionately.",
        "type": "fill_blank",
        "answers": ["slice"],
        "other_options": ["cluster", "trend", "correlation"]
    },
    {
        "q": "A team discovers their training and inference pipelines use slightly different logic for calculating 'customer lifetime value'. This creates a ______ mismatch.",
        "type": "fill_blank",
        "answers": ["training-serving skew"],
        "other_options": ["data collection", "monitoring", "exploratory"]
    },
    {
        "q": "For a fraud detection system where new attack patterns emerge constantly, which model update strategy is most appropriate?",
        "type": "mcq",
        "o": [
            "Active learning with human-in-the-loop feedback",
            "Static model deployed once without changes",
            "Annual retraining on historical data only",
            "Eliminating model monitoring to reduce costs"
        ]
    },
    {
        "q": "Rearrange the steps for implementing a data quality monitoring system:",
        "type": "rearrange",
        "words": ["Define", "Measure", "Alert", "Investigate", "Rectify"]
    },
    {
        "q": "Match the statistical test with its use case in data validation:",
        "type": "match",
        "left": ["Kolmogorov-Smirnov", "Chi-square", "ADF", "Levene's"],
        "right": ["Distribution similarity", "Category proportion", "Stationarity", "Variance equality"]
    },
    {
        "q": "What principle does this scenario violate: 'A healthcare model uses future diagnosis codes to predict current disease risk'?",
        "type": "mcq",
        "o": [
            "Temporal validity - using future information not available at prediction time",
            "Data privacy - protecting patient information",
            "Model interpretability - understanding feature importance",
            "Computational efficiency - optimizing training speed"
        ]
    },
    {
        "q": "When preparing text data, converting words to numerical vectors while preserving semantic relationships is called word ______.",
        "type": "fill_blank",
        "answers": ["embeddings"],
        "other_options": ["tokenization", "cleaning", "parsing"]
    },
    {
        "q": "Calculating prediction intervals provides more information than point estimates alone.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which monitoring approach best detects when a model's assumptions about data distributions no longer hold?",
        "type": "mcq",
        "o": [
            "Distribution shift detection using statistical distance measures",
            "Tracking only overall accuracy metrics",
            "Monitoring server CPU utilization",
            "Counting the number of prediction requests"
        ]
    },
    {
        "q": "The practice of ______ involves systematically testing model performance across different demographic segments.",
        "type": "fill_blank",
        "answers": ["fairness auditing"],
        "other_options": ["data collection", "feature engineering", "model deployment"]
    },
    {
        "q": "What is the primary benefit of using differential privacy during data collection?",
        "type": "mcq",
        "o": [
            "Protecting individual privacy while maintaining aggregate insights",
            "Speeding up data processing pipelines",
            "Reducing model training time",
            "Automating feature engineering"
        ]
    },
    {
        "q": "When deploying to edge devices with limited memory, model ______ techniques like quantization become crucial.",
        "type": "fill_blank",
        "answers": ["optimization"],
        "other_options": ["monitoring", "collection", "validation"]
    },
    {
        "q": "Synthetic data generation can help address class imbalance while preserving privacy.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building a model that must generalize across geographic regions?",
        "type": "mcq",
        "o": [
            "Stratified sampling to ensure regional representation",
            "Collecting data only from the most convenient location",
            "Using synthetic data exclusively",
            "Ignoring geographic factors entirely"
        ]
    },
    {
        "q": "Match the data governance concept with its implementation:",
        "type": "match",
        "left": ["Data Lineage", "Access Control", "Data Catalog", "Retention Policy"],
        "right": ["Tracking data origin and transformations", "Role-based permissions for data access", "Discoverable inventory of datasets", "Automated deletion of expired data"]
    },
    {
        "q": "Rearrange the model debugging workflow when performance degrades:",
        "type": "rearrange",
        "words": ["Reproduce", "Isolate", "Hypothesize", "Test", "Fix"]
    },
    {
        "q": "Concept drift can occur even when feature distributions remain unchanged.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of calculating confidence scores alongside predictions?",
        "type": "mcq",
        "o": [
            "Indicating when the model is uncertain about its predictions",
            "Making the model run faster during inference",
            "Reducing the size of training data needed",
            "Automatically deploying models without human review"
        ]
    },
    {
        "q": "The process of ______ involves automatically generating new features from existing ones to improve model performance.",
        "type": "fill_blank",
        "answers": ["feature synthesis"],
        "other_options": ["data collection", "model monitoring", "deployment"]
    },
    {
        "q": "In a multi-tenant SaaS platform, creating separate feature stores for each customer helps maintain data ______.",
        "type": "fill_blank",
        "answers": ["isolation"],
        "other_options": ["integration", "redundancy", "compression"]
    },
    {
        "q": "Which data collection approach is most suitable for building a model that must adapt to rapidly changing user preferences?",
        "type": "mcq",
        "o": [
            "Online learning with continuous data streams",
            "Quarterly batch data collection",
            "Static historical datasets only",
            "Manual data entry processes"
        ]
    },
    {
        "q": "Rearrange the stages of data catalog curation:",
        "type": "rearrange",
        "words": ["Discover", "Classify", "Document", "Validate", "Publish"]
    },
    {
        "q": "Match the edge computing deployment pattern with its characteristic:",
        "type": "match",
        "left": ["Edge Inference", "Federated Learning", "Edge Training", "Model Distillation"],
        "right": ["Predictions on local devices", "Training across decentralized devices", "On-device model updates", "Small model learning from large model"]
    },
    {
        "q": "What data preparation principle is violated when features are engineered using knowledge of future events?",
        "type": "mcq",
        "o": [
            "Temporal consistency - using information not available at prediction time",
            "Feature importance - selecting the most predictive features",
            "Data normalization - scaling features appropriately",
            "Dimensionality reduction - reducing feature space size"
        ]
    },
    {
        "q": "For time-series data with multiple seasonal patterns, ______ decomposition helps separate trend, seasonal, and residual components.",
        "type": "fill_blank",
        "answers": ["STL"],
        "other_options": ["PCA", "ICA", "LDA"]
    },
    {
        "q": "Data mesh architecture decentralizes data ownership to domain-oriented teams.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which monitoring technique is most effective for detecting adversarial attacks on computer vision models?",
        "type": "mcq",
        "o": [
            "Anomaly detection on prediction confidence distributions",
            "Tracking average prediction latency",
            "Monitoring GPU memory usage",
            "Counting API request volumes"
        ]
    },
    {
        "q": "The practice of ______ learning trains models across decentralized data sources without raw data exchange.",
        "type": "fill_blank",
        "answers": ["federated"],
        "other_options": ["supervised", "unsupervised", "reinforcement"]
    },
    {
        "q": "What is the primary advantage of using knowledge graphs in data preparation?",
        "type": "mcq",
        "o": [
            "Capturing complex relationships between entities",
            "Reducing data storage requirements",
            "Speeding up numerical computations",
            "Automating model deployment processes"
        ]
    },
    {
        "q": "When dealing with sensor data from IoT devices, ______ filtering helps remove high-frequency noise while preserving signals.",
        "type": "fill_blank",
        "answers": ["Kalman"],
        "other_options": ["Bayesian", "Particle", "Butterworth"]
    },
    {
        "q": "Causal inference techniques require careful consideration of confounding variables.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is essential for building models that comply with 'right to explanation' regulations?",
        "type": "mcq",
        "o": [
            "Maintaining audit trails of data provenance and transformations",
            "Collecting maximum possible data from all sources",
            "Using black-box models exclusively for better accuracy",
            "Eliminating data validation to speed up collection"
        ]
    },
    {
        "q": "Match the data compression technique with its typical use case:",
        "type": "match",
        "left": ["Dictionary encoding", "Delta encoding", "Quantization", "Pruning"],
        "right": ["Repeated string patterns", "Sequential numeric data", "Floating point precision reduction", "Removing insignificant model weights"]
    },
    {
        "q": "Rearrange the steps for implementing differential privacy:",
        "type": "rearrange",
        "words": ["Define", "Calculate", "Add", "Aggregate", "Release"]
    },
    {
        "q": "Homomorphic encryption allows computation on encrypted data without decryption.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of using attention mechanisms in data preparation for sequential data?",
        "type": "mcq",
        "o": [
            "Weighing the importance of different time steps or elements",
            "Reducing the memory footprint of datasets",
            "Accelerating data collection from APIs",
            "Automating data cleaning procedures"
        ]
    },
    {
        "q": "The process of ______ involves creating simulated environments to test model robustness before deployment.",
        "type": "fill_blank",
        "answers": ["digital twinning"],
        "other_options": ["data labeling", "feature engineering", "performance monitoring"]
    },
    {
        "q": "Which data validation approach is most critical for ensuring regulatory compliance in healthcare models?",
        "type": "mcq",
        "o": [
            "Provenance tracking and audit trail validation",
            "Maximum data collection without validation",
            "Eliminating data quality checks for speed",
            "Using only synthetic data to avoid regulations"
        ]
    },
    {
        "q": "For graph neural networks, ______ propagation updates node representations based on neighborhood information.",
        "type": "fill_blank",
        "answers": ["message"],
        "other_options": ["error", "gradient", "signal"]
    },
    {
        "q": "In a supply chain optimization model, creating digital simulations of logistics networks before real-world deployment is called ______ modeling.",
        "type": "fill_blank",
        "answers": ["what-if"],
        "other_options": ["predictive", "descriptive", "causal"]
    },
    {
        "q": "Which data collection method is most appropriate for building models that must respect indigenous data sovereignty?",
        "type": "mcq",
        "o": [
            "Community-led data governance with informed consent protocols",
            "Scraping public data without permission",
            "Purchasing data from third-party aggregators",
            "Using only synthetic data generation"
        ]
    },
    {
        "q": "Rearrange the workflow for implementing federated learning across hospitals:",
        "type": "rearrange",
        "words": ["Local", "Aggregate", "Distribute", "Update", "Validate"]
    },
    {
        "q": "Match the neuromorphic computing concept with its data processing characteristic:",
        "type": "match",
        "left": ["Spiking Neural Networks", "Memristor Crossbars", "Event-Based Sensors", "Analog Processing"],
        "right": ["Time-encoded information processing", "In-memory computation", "Asynchronous data capture", "Continuous value operations"]
    },
    {
        "q": "What data ethics principle is demonstrated when a model intentionally excludes zip code data to prevent postal discrimination?",
        "type": "mcq",
        "o": [
            "Prox variable mitigation to prevent indirect bias",
            "Feature importance optimization",
            "Data minimization for efficiency",
            "Model compression for deployment"
        ]
    },
    {
        "q": "For quantum machine learning, encoding classical data into quantum states is called quantum ______.",
        "type": "fill_blank",
        "answers": ["embedding"],
        "other_options": ["compilation", "entanglement", "decoherence"]
    },
    {
        "q": "Differential privacy guarantees become stronger when applied across multiple queries on the same dataset.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which monitoring approach is crucial for AI systems operating in safety-critical domains like autonomous vehicles?",
        "type": "mcq",
        "o": [
            "Real-time uncertainty quantification with fallback mechanisms",
            "Monthly batch performance reports",
            "Tracking only average accuracy metrics",
            "Monitoring data storage costs"
        ]
    },
    {
        "q": "The practice of ______ learning uses unlabeled data to improve model performance on related labeled tasks.",
        "type": "fill_blank",
        "answers": ["semi-supervised"],
        "other_options": ["supervised", "unsupervised", "self-supervised"]
    },
    {
        "q": "What is the primary benefit of using topological data analysis in exploratory analysis?",
        "type": "mcq",
        "o": [
            "Identifying shape and connectivity patterns in high-dimensional data",
            "Reducing computational requirements for simple datasets",
            "Automating data collection from APIs",
            "Speeding up model training times"
        ]
    },
    {
        "q": "When preparing data for reinforcement learning, the ______ process balances exploration of new actions with exploitation of known rewards.",
        "type": "fill_blank",
        "answers": ["trade-off"],
        "other_options": ["optimization", "validation", "normalization"]
    },
    {
        "q": "Causal forest algorithms can estimate heterogeneous treatment effects across different data subgroups.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data validation approach is essential for models processing real-time satellite imagery?",
        "type": "mcq",
        "o": [
            "Geospatial consistency checks and cloud cover detection",
            "Validating only data storage formats",
            "Checking data age without content validation",
            "Eliminating validation for faster processing"
        ]
    },
    {
        "q": "Match the sustainable AI practice with its environmental benefit:",
        "type": "match",
        "left": ["Model Pruning", "Knowledge Distillation", "Early Exit Networks", "Green AI Metrics"],
        "right": ["Reduced computation energy", "Smaller model footprint", "Dynamic inference cost", "Carbon-aware training scheduling"]
    },
    {
        "q": "Rearrange the steps for implementing explainable AI in regulated industries:",
        "type": "rearrange",
        "words": ["Interpretability", "Documentation", "Validation", "Auditing", "Compliance"]
    },
    {
        "q": "Synthetic data generated through GANs can preserve statistical properties while protecting privacy.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary challenge when deploying models for low-resource language processing?",
        "type": "mcq",
        "o": [
            "Data scarcity and limited annotated corpora",
            "Excessive computational requirements",
            "Overabundance of training data",
            "Lack of model architecture choices"
        ]
    },
    {
        "q": "The process of ______ alignment ensures AI systems optimize for human-intended goals rather than proxy metrics.",
        "type": "fill_blank",
        "answers": ["value"],
        "other_options": ["data", "model", "feature"]
    },
    {
        "q": "Which data collection methodology is most appropriate for studying rare events like earthquake prediction?",
        "type": "mcq",
        "o": [
            "Transfer learning from related domains with abundant data",
            "Waiting for sufficient natural occurrences",
            "Using only synthetic data generation",
            "Collecting irrelevant but abundant data"
        ]
    },
    {
        "q": "For multimodal learning, ______ alignment ensures corresponding features from different modalities represent similar concepts.",
        "type": "fill_blank",
        "answers": ["cross-modal"],
        "other_options": ["temporal", "spatial", "semantic"]
    },
    {
        "q": "In wildlife conservation models, dealing with uneven camera trap deployment creates ______ bias in animal sighting data.",
        "type": "fill_blank",
        "answers": ["sampling"],
        "other_options": ["measurement", "selection", "confirmation"]
    },
    {
        "q": "Which data preparation technique is essential for models analyzing ancient manuscript digitizations?",
        "type": "mcq",
        "o": [
            "Damage pattern recognition and ink bleed correction",
            "Standard RGB normalization only",
            "Eliminating all imperfect images",
            "Using raw pixel values without processing"
        ]
    },
    {
        "q": "Rearrange the archaeological data analysis workflow for site prediction models:",
        "type": "rearrange",
        "words": ["Remote", "Ground", "Artifact", "Context", "Pattern"],
        "c": "sensing -> survey -> analysis -> mapping -> recognition"
    },
    {
        "q": "Match the specialized data type with its unique preparation challenge:",
        "type": "match",
        "left": ["LiDAR point clouds", "Hyperspectral imagery", "Seismic waveforms", "Bioacoustic recordings"],
        "right": ["Density variation normalization", "Spectral band correlation", "Time-series alignment", "Background noise filtration"]
    },
    {
        "q": "What data collection principle is violated when marine biology models use only surface-level water samples for deep-sea ecosystem predictions?",
        "type": "mcq",
        "o": [
            "Ecological representativeness across depth gradients",
            "Data storage efficiency principles",
            "Computational resource optimization",
            "Model deployment speed requirements"
        ]
    },
    {
        "q": "For climate models, ______ weighting adjusts for uneven distribution of weather stations across geographical regions.",
        "type": "fill_blank",
        "answers": ["spatial"],
        "other_options": ["temporal", "population", "economic"]
    },
    {
        "q": "Phenological data from historical garden records requires cross-referencing with climate data for validation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which monitoring approach is crucial for coral reef health assessment models using underwater imagery?",
        "type": "mcq",
        "o": [
            "Bleaching progression tracking with seasonal baselines",
            "Counting total image pixels processed",
            "Monitoring server response times only",
            "Tracking data storage costs per image"
        ]
    },
    {
        "q": "The process of ______ correction accounts for instrument decay in long-term astronomical observations.",
        "type": "fill_blank",
        "answers": ["calibration"],
        "other_options": ["normalization", "validation", "authentication"]
    },
    {
        "q": "What is the primary data challenge in building predictive models for rare disease diagnosis?",
        "type": "mcq",
        "o": [
            "Extreme class imbalance with limited positive examples",
            "Excessive computational requirements for small datasets",
            "Overabundance of high-quality training data",
            "Lack of relevant medical variables to collect"
        ]
    },
    {
        "q": "In agricultural yield prediction, ______ interpolation estimates soil conditions between sampling points.",
        "type": "fill_blank",
        "answers": ["spatial"],
        "other_options": ["temporal", "spectral", "dimensional"]
    },
    {
        "q": "Digital humanities projects require special consideration for historical context in text data preparation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data validation approach is essential for paleoclimate models using ice core samples?",
        "type": "mcq",
        "o": [
            "Cross-dating with known volcanic eruption timelines",
            "Validating only laboratory equipment models",
            "Checking data file formats without content review",
            "Eliminating validation for older samples"
        ]
    },
    {
        "q": "Match the cultural heritage data type with its preservation challenge:",
        "type": "match",
        "left": ["3D artifact scans", "Fading pigment analysis", "Brittle document handling", "Oral history recordings"],
        "right": ["Resolution vs storage trade-offs", "Multispectral imaging requirements", "Non-contact digitization protocols", "Background noise and speaker identification"]
    },
    {
        "q": "Rearrange the steps for building endangered language documentation models:",
        "type": "rearrange",
        "words": ["Field", "Transcribe", "Annotate", "Validate", "Archive"],
        "c": "recording -> phonetically -> grammatically -> with speakers -> digitally"
    },
    {
        "q": "Seabird migration models must account for both satellite tracking gaps and weather pattern influences.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying flood prediction models in data-scarce regions?",
        "type": "mcq",
        "o": [
            "Transfer learning from hydrologically similar regions",
            "Waiting for perfect sensor network deployment",
            "Using only theoretical models without local data",
            "Eliminating model monitoring to reduce costs"
        ]
    },
    {
        "q": "The process of ______ normalization adjusts for varying collection methodologies across museum specimen databases.",
        "type": "fill_blank",
        "answers": ["protocol"],
        "other_options": ["data", "feature", "model"]
    },
    {
        "q": "Which data collection strategy is most appropriate for building urban soundscape classification models?",
        "type": "mcq",
        "o": [
            "Stratified placement across diverse neighborhood types",
            "Concentrating sensors in quiet areas only",
            "Using only laboratory-generated sound samples",
            "Collecting data during single time periods"
        ]
    },
    {
        "q": "For glacier retreat analysis, ______ correlation helps align satellite imagery with ground truth measurements.",
        "type": "fill_blank",
        "answers": ["temporal"],
        "other_options": ["spatial", "spectral", "dimensional"]
    },
    {
        "q": "In computational folklore studies, analyzing tale type distributions across regions requires handling ______ data with geographic dependencies.",
        "type": "fill_blank",
        "answers": ["cultural"],
        "other_options": ["numerical", "temporal", "spatial"]
    },
    {
        "q": "Which data preparation technique is crucial for building models that analyze medieval parchment using multispectral imaging?",
        "type": "mcq",
        "o": [
            "Palimpsest layer separation and ink spectral signature isolation",
            "Simple RGB channel averaging",
            "Eliminating all damaged manuscript sections",
            "Using only visible light spectrum data"
        ]
    },
    {
        "q": "Rearrange the workflow for building predictive models of archaeological site discovery:",
        "type": "rearrange",
        "words": ["Geophysical", "Satellite", "Field", "Stratigraphic", "Cultural"],
        "c": "survey -> imagery -> walking -> analysis -> context"
    },
    {
        "q": "Match the esoteric data type with its unique modeling consideration:",
        "type": "match",
        "left": ["Tree ring chronologies", "Ice core gas bubbles", "Coral skeletal density", "Speleothem layers"],
        "right": ["Cross-dating with master sequences", "Atmospheric composition reconstruction", "Sea surface temperature proxies", "Paleorainfall chemical signatures"]
    },
    {
        "q": "What data ethics principle is paramount when working with indigenous knowledge systems in ecological models?",
        "type": "mcq",
        "o": [
            "Respecting intellectual property and cultural protocols",
            "Maximizing data extraction for model accuracy",
            "Standardizing all traditional knowledge formats",
            "Prioritizing computational efficiency over context"
        ]
    },
    {
        "q": "For analyzing historical ship logbooks, ______ recognition converts handwritten weather observations into structured data.",
        "type": "fill_blank",
        "answers": ["pattern"],
        "other_options": ["character", "voice", "image"]
    },
    {
        "q": "Bioacoustic models for insect population monitoring must account for seasonal calling behavior variations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is essential for models predicting volcanic activity using gas emission data?",
        "type": "mcq",
        "o": [
            "Cross-referencing with seismic and thermal monitoring systems",
            "Validating only sensor calibration dates",
            "Checking data format consistency alone",
            "Eliminating outlier gas readings automatically"
        ]
    },
    {
        "q": "The process of ______ alignment matches pollen core samples with geological time periods using radiocarbon dating.",
        "type": "fill_blank",
        "answers": ["temporal"],
        "other_options": ["spatial", "spectral", "dimensional"]
    },
    {
        "q": "What is the primary data challenge in building models for predicting manuscript preservation needs?",
        "type": "mcq",
        "o": [
            "Multimodal degradation factor correlation across materials",
            "Excessive computational requirements for simple predictions",
            "Overabundance of perfectly preserved examples",
            "Lack of relevant environmental variables to monitor"
        ]
    },
    {
        "q": "In digital musicology, ______ analysis reveals compositional patterns across historical periods.",
        "type": "fill_blank",
        "answers": ["stylistic"],
        "other_options": ["acoustic", "harmonic", "temporal"]
    },
    {
        "q": "Astronomical transient detection models require real-time processing of telescope data streams.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building linguistic diversity preservation models?",
        "type": "mcq",
        "o": [
            "Community-partnered recording with speaker metadata",
            "Automated web scraping of written texts only",
            "Using only laboratory speech samples",
            "Focusing exclusively on major world languages"
        ]
    },
    {
        "q": "Match the specialized analysis technique with its cultural heritage application:",
        "type": "match",
        "left": ["X-ray fluorescence", "Photogrammetry", "Multispectral imaging", "Acoustic tomography"],
        "right": ["Pigment elemental composition", "3D structure from photographs", "Faded text recovery", "Tree internal structure mapping"]
    },
    {
        "q": "Rearrange the steps for analyzing historical climate from ship logbooks:",
        "type": "rearrange",
        "words": ["Digitize", "Transcribe", "Georeference", "Calibrate", "Reanalyze"],
        "c": "images -> handwritten text -> positions -> instruments -> climate"
    },
    {
        "q": "Cryospheric models must account for both satellite altimetry gaps and snow density variations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying earthquake early warning models in regions with limited seismic networks?",
        "type": "mcq",
        "o": [
            "Integration of complementary data like GPS and satellite measurements",
            "Waiting for perfect sensor coverage deployment",
            "Using only theoretical ground motion models",
            "Eliminating false alarms by increasing detection thresholds"
        ]
    },
    {
        "q": "The process of ______ normalization accounts for different sampling intensities in biodiversity surveys.",
        "type": "fill_blank",
        "answers": ["effort"],
        "other_options": ["data", "species", "habitat"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing ancient DNA from archaeological remains?",
        "type": "mcq",
        "o": [
            "Contamination screening and endogenous DNA authentication",
            "Validating only sequencing machine models",
            "Checking file formats without content review",
            "Eliminating all damaged DNA sequences"
        ]
    },
    {
        "q": "For analyzing historical land use from aerial photographs, ______ classification distinguishes between agricultural patterns.",
        "type": "fill_blank",
        "answers": ["land cover"],
        "other_options": ["color", "texture", "shape"]
    },
    {
        "q": "In sports analytics, player tracking data requires ______ smoothing to reduce noise from sensor inaccuracies while preserving movement patterns.",
        "type": "fill_blank",
        "answers": ["trajectory"],
        "other_options": ["data", "signal", "image"]
    },
    {
        "q": "Which data preparation technique is essential for building fraud detection models in decentralized finance?",
        "type": "mcq",
        "o": [
            "Smart contract interaction graph analysis and transaction pattern isolation",
            "Simple aggregation of total transaction volumes",
            "Eliminating all complex financial instruments",
            "Using only traditional banking transaction data"
        ]
    },
    {
        "q": "Rearrange the workflow for building e-sports performance prediction models:",
        "type": "rearrange",
        "words": ["API", "Feature", "Team", "Meta", "Performance"],
        "c": "data extraction -> engineering -> composition analysis -> game analysis -> prediction"
    },
    {
        "q": "Match the emerging data domain with its unique modeling challenge:",
        "type": "match",
        "left": ["NFT transaction networks", "VR movement patterns", "Drone swarm coordination", "Smart city IoT streams"],
        "right": ["Wash trading detection and provenance tracking", "Motion sickness prediction and spatial awareness", "Collision avoidance and formation maintenance", "Cross-system anomaly correlation and privacy preservation"]
    },
    {
        "q": "What data quality issue is most critical when building models for predicting supply chain disruptions?",
        "type": "mcq",
        "o": [
            "Temporal misalignment across global logistics data sources",
            "Excessive data volume from IoT sensors",
            "Perfect data quality in all systems",
            "Lack of relevant economic indicators"
        ]
    },
    {
        "q": "For space weather prediction, ______ indices measure solar activity impacts on Earth's magnetosphere.",
        "type": "fill_blank",
        "answers": ["geomagnetic"],
        "other_options": ["atmospheric", "oceanic", "terrestrial"]
    },
    {
        "q": "Digital twin models of manufacturing equipment require real-time sensor fusion from multiple data streams.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is crucial for autonomous farming equipment using computer vision?",
        "type": "mcq",
        "o": [
            "Cross-validation with manual crop scouting and soil sampling",
            "Validating only camera hardware specifications",
            "Checking image file formats without content review",
            "Eliminating all ambiguous field conditions"
        ]
    },
    {
        "q": "The process of ______ learning adapts game AI behavior based on real-time player interaction patterns.",
        "type": "fill_blank",
        "answers": ["adaptive"],
        "other_options": ["supervised", "unsupervised", "reinforcement"]
    },
    {
        "q": "What is the primary data challenge in building predictive maintenance models for wind turbines?",
        "type": "mcq",
        "o": [
            "Imbalanced data with rare failure events and varying environmental conditions",
            "Excessive computational requirements for simple predictions",
            "Overabundance of identical failure examples",
            "Lack of relevant sensor types to deploy"
        ]
    },
    {
        "q": "In quantum computing research, ______ benchmarking characterizes gate fidelity across processor iterations.",
        "type": "fill_blank",
        "answers": ["randomized"],
        "other_options": ["sequential", "parallel", "distributed"]
    },
    {
        "q": "Synthetic data generation for autonomous vehicle training must preserve rare edge case scenarios.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building ocean plastic detection models?",
        "type": "mcq",
        "o": [
            "Multi-spectral satellite imagery combined with drone verification",
            "Relying solely on beach cleanup reports",
            "Using only laboratory plastic samples",
            "Focusing exclusively on surface-level observations"
        ]
    },
    {
        "q": "Match the specialized monitoring technique with its industrial application:",
        "type": "match",
        "left": ["Acoustic emission testing", "Thermographic analysis", "Vibration spectroscopy", "Eddy current testing"],
        "right": ["Crack detection in pressure vessels", "Electrical component failure prediction", "Rotating machinery health assessment", "Metal surface defect identification"]
    },
    {
        "q": "Rearrange the steps for building music recommendation systems:",
        "type": "rearrange",
        "words": ["Audio", "Collaborative", "Content-based", "Context", "Hybrid"],
        "c": "feature extraction -> filtering -> analysis -> awareness -> recommendation"
    },
    {
        "q": "Federated learning for healthcare must address both privacy preservation and statistical heterogeneity across institutions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying AI models for disaster response coordination?",
        "type": "mcq",
        "o": [
            "Robustness to communication network failures and data incompleteness",
            "Waiting for perfect situational awareness",
            "Using only high-resolution satellite imagery",
            "Eliminating all uncertain predictions"
        ]
    },
    {
        "q": "The process of ______ normalization accounts for different sensor types in environmental monitoring networks.",
        "type": "fill_blank",
        "answers": ["cross-sensor"],
        "other_options": ["data", "temporal", "spatial"]
    },
    {
        "q": "Which data validation approach is essential for models detecting deepfake media?",
        "type": "mcq",
        "o": [
            "Multi-modal consistency checking and artifact detection",
            "Validating only video compression formats",
            "Checking file sizes without content analysis",
            "Eliminating all low-resolution media"
        ]
    },
    {
        "q": "For carbon credit verification, ______ analysis correlates satellite data with ground-based emissions measurements.",
        "type": "fill_blank",
        "answers": ["validation"],
        "other_options": ["exploratory", "predictive", "prescriptive"]
    },
    {
        "q": "In astroinformatics, processing data from radio telescopes requires special handling of ______ interference from terrestrial sources.",
        "type": "fill_blank",
        "answers": ["radio frequency"],
        "other_options": ["cosmic", "atmospheric", "solar"]
    },
    {
        "q": "Which data preparation technique is crucial for building models that analyze medieval climate from vineyard harvest records?",
        "type": "mcq",
        "o": [
            "Phenological date calibration and growing degree day reconstruction",
            "Simple date averaging across regions",
            "Eliminating all incomplete historical records",
            "Using only temperature data without agricultural context"
        ]
    },
    {
        "q": "Rearrange the workflow for building predictive models of protein folding:",
        "type": "rearrange",
        "words": ["Sequence", "Structure", "Energy", "Folding", "Validation"],
        "c": "alignment -> prediction -> minimization -> pathway -> experimental"
    },
    {
        "q": "Match the exotic data source with its preprocessing challenge:",
        "type": "match",
        "left": ["Gravitational wave detectors", "Neutrino observatories", "Dark matter maps", "Cosmic microwave background"],
        "right": ["Noise subtraction from seismic vibrations", "Background radiation filtering", "Mass distribution estimation from lensing", "Galactic foreground removal"]
    },
    {
        "q": "What data ethics consideration is unique to models analyzing historical human remains?",
        "type": "mcq",
        "o": [
            "Cultural sensitivity and descendant community consultation",
            "Maximizing data extraction from all available samples",
            "Standardizing all burial context information",
            "Prioritizing computational efficiency over ethical review"
        ]
    },
    {
        "q": "For analyzing ancient trade routes, ______ modeling reconstructs missing archaeological evidence from fragmentary data.",
        "type": "fill_blank",
        "answers": ["network"],
        "other_options": ["linear", "statistical", "geographic"]
    },
    {
        "q": "Exoplanet detection models must account for stellar variability and instrument systematics in transit photometry.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is essential for models predicting glacier lake outburst floods?",
        "type": "mcq",
        "o": [
            "Multi-temporal satellite imagery correlation with ground observations",
            "Validating only digital elevation model resolution",
            "Checking data formats without geographic context",
            "Eliminating all small glacier lakes from analysis"
        ]
    },
    {
        "q": "The process of ______ alignment matches dendrochronological records with archaeological timber samples.",
        "type": "fill_blank",
        "answers": ["cross-dating"],
        "other_options": ["temporal", "spatial", "chemical"]
    },
    {
        "q": "What is the primary data challenge in building models for predicting archaeological site preservation?",
        "type": "mcq",
        "o": [
            "Integrating disparate data types from remote sensing to soil chemistry",
            "Excessive computational requirements for simple correlations",
            "Overabundance of perfectly preserved site examples",
            "Lack of relevant environmental monitoring techniques"
        ]
    },
    {
        "q": "In digital epigraphy, ______ analysis reveals carving techniques from 3D scans of ancient inscriptions.",
        "type": "fill_blank",
        "answers": ["stroke"],
        "other_options": ["color", "text", "surface"]
    },
    {
        "q": "Paleomagnetic data from ocean cores requires careful removal of secondary magnetic overprints.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building models of historical urban growth?",
        "type": "mcq",
        "o": [
            "Multi-source integration of maps, tax records, and archaeological layers",
            "Relying solely on modern satellite imagery",
            "Using only written historical accounts",
            "Focusing exclusively on building foundation dates"
        ]
    },
    {
        "q": "Match the specialized analytical method with its archaeological application:",
        "type": "match",
        "left": ["Strontium isotope analysis", "Pollen sequence dating", "Optically stimulated luminescence", "Residue analysis"],
        "right": ["Human migration patterns", "Vegetation history reconstruction", "Ceramic last firing date", "Ancient vessel contents identification"]
    },
    {
        "q": "Rearrange the steps for analyzing historical epidemics from burial records:",
        "type": "rearrange",
        "words": ["Skeletal", "Isotope", "Radiocarbon", "Demographic", "Epidemiological"],
        "c": "pathology -> analysis -> dating -> reconstruction -> modeling"
    },
    {
        "q": "Cosmological simulations must account for both dark matter halo formation and baryonic physics.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for cultural heritage climate risk assessment?",
        "type": "mcq",
        "o": [
            "Material-specific vulnerability curves and microclimate modeling",
            "Waiting for perfect environmental monitoring",
            "Using only average climate projections",
            "Eliminating all uncertain preservation predictions"
        ]
    },
    {
        "q": "The process of ______ calibration adjusts for different measurement techniques in historical meteorological data.",
        "type": "fill_blank",
        "answers": ["instrument"],
        "other_options": ["data", "temporal", "spatial"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing ancient metal provenance?",
        "type": "mcq",
        "o": [
            "Lead isotope ratio verification and trace element fingerprinting",
            "Validating only sample weight measurements",
            "Checking laboratory numbers without chemical analysis",
            "Eliminating all corroded metal samples"
        ]
    },
    {
        "q": "For analyzing historical textile trade, ______ characterization identifies dye sources from chemical signatures.",
        "type": "fill_blank",
        "answers": ["provenance"],
        "other_options": ["color", "fiber", "weave"]
    },
    {
        "q": "In bioacoustic monitoring of forest ecosystems, dealing with overlapping animal vocalizations requires ______ separation algorithms.",
        "type": "fill_blank",
        "answers": ["source"],
        "other_options": ["signal", "frequency", "temporal"]
    },
    {
        "q": "Which data preparation technique is essential for building models that predict material properties from quantum chemistry simulations?",
        "type": "mcq",
        "o": [
            "Wavefunction feature extraction and Hamiltonian matrix transformation",
            "Simple averaging of atomic positions",
            "Eliminating all high-energy state calculations",
            "Using only bulk material measurements without quantum data"
        ]
    },
    {
        "q": "Rearrange the workflow for building predictive models of enzyme function from sequence data:",
        "type": "rearrange",
        "words": ["Multiple", "Active", "Catalytic", "Substrate", "Function"],
        "c": "sequence alignment -> site identification -> residue prediction -> specificity -> annotation"
    },
    {
        "q": "Match the computational microscopy technique with its data reconstruction challenge:",
        "type": "match",
        "left": ["Cryo-electron tomography", "Structured illumination", "Light sheet fluorescence", "Atomic force microscopy"],
        "right": ["Missing wedge artifact correction", "Super-resolution pattern demixing", "Photobleaching compensation", "Tip convolution effect removal"]
    },
    {
        "q": "What data quality issue is most critical when building models for predicting crystal structure from powder diffraction?",
        "type": "mcq",
        "o": [
            "Peak overlap and preferred orientation effects",
            "Excessive computational requirements for simple structures",
            "Perfect peak separation in all samples",
            "Lack of relevant symmetry information"
        ]
    },
    {
        "q": "For analyzing historical art techniques, ______ imaging reveals underdrawings and pigment layering.",
        "type": "fill_blank",
        "answers": ["multispectral"],
        "other_options": ["ultraviolet", "infrared", "x-ray"]
    },
    {
        "q": "Single-cell RNA sequencing data requires normalization for library size and batch effects before clustering.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is essential for models predicting protein-ligand binding affinities?",
        "type": "mcq",
        "o": [
            "Experimental crystallography and isothermal titration calorimetry correlation",
            "Validating only molecular weight calculations",
            "Checking file formats without structural review",
            "Eliminating all flexible binding sites"
        ]
    },
    {
        "q": "The process of ______ mapping reconstructs neural connectivity from electron microscopy volumes.",
        "type": "fill_blank",
        "answers": ["connectome"],
        "other_options": ["functional", "structural", "diffusion"]
    },
    {
        "q": "What is the primary data challenge in building models for predicting archaeological ceramic provenance?",
        "type": "mcq",
        "o": [
            "Integrating elemental composition with mineralogical and stylistic features",
            "Excessive computational requirements for simple classifications",
            "Overabundance of perfectly documented production sites",
            "Lack of relevant analytical techniques"
        ]
    },
    {
        "q": "In synchrotron data analysis, ______ correction compensates for beam intensity fluctuations during measurements.",
        "type": "fill_blank",
        "answers": ["normalization"],
        "other_options": ["calibration", "alignment", "reconstruction"]
    },
    {
        "q": "Mass spectrometry imaging data requires spatial segmentation before molecular feature extraction.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building models of historical shipbuilding techniques?",
        "type": "mcq",
        "o": [
            "3D laser scanning combined with timber provenancing and tool mark analysis",
            "Relying solely on historical ship drawings",
            "Using only modern ship construction data",
            "Focusing exclusively on sail plan configurations"
        ]
    },
    {
        "q": "Match the specialized spectroscopy technique with its archaeological application:",
        "type": "match",
        "left": ["Raman spectroscopy", "XRF mapping", "FTIR analysis", "LIBS profiling"],
        "right": ["Pigment identification non-destructively", "Elemental distribution visualization", "Organic residue characterization", "Depth-resolved elemental composition"]
    },
    {
        "q": "Rearrange the steps for analyzing historical metalworking technologies:",
        "type": "rearrange",
        "words": ["Ore", "Slag", "Metal", "Artifact", "Technology"],
        "c": "provenancing -> composition -> microstructure -> function -> reconstruction"
    },
    {
        "q": "Neutron scattering data requires corrections for background radiation and sample container effects.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for predicting museum object conservation needs?",
        "type": "mcq",
        "o": [
            "Material degradation kinetics and environmental parameter sensitivity",
            "Waiting for perfect condition assessment data",
            "Using only visual inspection reports",
            "Eliminating all complex composite objects"
        ]
    },
    {
        "q": "The process of ______ registration aligns multi-modal cultural heritage imaging data.",
        "type": "fill_blank",
        "answers": ["image"],
        "other_options": ["data", "temporal", "spatial"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing ancient DNA preservation?",
        "type": "mcq",
        "o": [
            "Damage pattern authentication and modern contamination screening",
            "Validating only DNA concentration measurements",
            "Checking sequence length without damage analysis",
            "Eliminating all short DNA fragments"
        ]
    },
    {
        "q": "For analyzing historical glass production, ______ analysis identifies raw material sources from trace elements.",
        "type": "fill_blank",
        "answers": ["chemical"],
        "other_options": ["optical", "thermal", "mechanical"]
    },
    {
        "q": "In precision agriculture, variable rate technology systems use ______ maps to optimize fertilizer application across fields.",
        "type": "fill_blank",
        "answers": ["prescription"],
        "other_options": ["yield", "soil", "topographic"]
    },
    {
        "q": "Which data fusion approach is most critical for building digital twins of complex manufacturing processes?",
        "type": "mcq",
        "o": [
            "Multi-rate sensor synchronization and physics-informed data assimilation",
            "Simple averaging of all sensor readings",
            "Using only the highest frequency data streams",
            "Eliminating all low-resolution sensor data"
        ]
    },
    {
        "q": "Rearrange the data pipeline for real-time sports analytics during live broadcasts:",
        "type": "rearrange",
        "words": ["Player", "Computer", "Statistical", "Broadcast", "Audience"],
        "c": "tracking -> vision processing -> model inference -> graphics overlay -> engagement"
    },
    {
        "q": "Match the unconventional data source with its predictive modeling application:",
        "type": "match",
        "left": ["Social media sentiment", "Satellite night lights", "Mobile app usage patterns", "Public transit card swipes"],
        "right": ["Economic indicator forecasting", "Urban development monitoring", "Mental health trend analysis", "Pandemic spread modeling"]
    },
    {
        "q": "What unique data quality challenge arises when using citizen science observations for ecological modeling?",
        "type": "mcq",
        "o": [
            "Observer bias and spatial sampling inconsistency",
            "Excessive data volume from professional scientists",
            "Perfect measurement precision across all observers",
            "Lack of geographic coverage in populated areas"
        ]
    },
    {
        "q": "For predictive maintenance in aviation, ______ learning algorithms can identify anomalous engine patterns before failures occur.",
        "type": "fill_blank",
        "answers": ["anomaly"],
        "other_options": ["supervised", "reinforcement", "transfer"]
    },
    {
        "q": "Quantum machine learning models require special consideration for the Noisy Intermediate-Scale Quantum (NISQ) era limitations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation strategy is essential for AI systems generating synthetic training data for autonomous vehicles?",
        "type": "mcq",
        "o": [
            "Reality gap assessment and domain adaptation testing",
            "Validating only rendering quality metrics",
            "Checking file sizes without scene complexity review",
            "Eliminating all rare weather conditions"
        ]
    },
    {
        "q": "The process of ______ learning enables models to adapt to new manufacturing defects without complete retraining.",
        "type": "fill_blank",
        "answers": ["few-shot"],
        "other_options": ["deep", "ensemble", "multi-task"]
    },
    {
        "q": "What is the primary data challenge in building supply chain resilience models for perishable goods?",
        "type": "mcq",
        "o": [
            "Integrating real-time temperature monitoring with logistics delay predictions",
            "Excessive data quality from all transportation modes",
            "Overabundance of perfect delivery records",
            "Lack of relevant environmental sensors"
        ]
    },
    {
        "q": "In computational creativity systems, ______ evaluation metrics assess both novelty and usefulness of generated artworks.",
        "type": "fill_blank",
        "answers": ["aesthetic"],
        "other_options": ["technical", "commercial", "traditional"]
    },
    {
        "q": "Federated learning for mobile keyboard prediction must preserve privacy while learning from user typing patterns.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection approach is most appropriate for building wildfire risk assessment models?",
        "type": "mcq",
        "o": [
            "Multi-scale integration of satellite imagery, weather stations, and fuel moisture sensors",
            "Relying solely on historical fire perimeter maps",
            "Using only temperature data without vegetation context",
            "Focusing exclusively on human ignition sources"
        ]
    },
    {
        "q": "Match the edge computing scenario with its data processing constraint:",
        "type": "match",
        "left": ["Agricultural drones", "Medical wearables", "Smart traffic lights", "Offshore wind turbines"],
        "right": ["Limited flight time processing", "Battery-powered continuous monitoring", "Real-time pedestrian detection", "Intermittent satellite connectivity"]
    },
    {
        "q": "Rearrange the workflow for building personalized education recommendation systems:",
        "type": "rearrange",
        "words": ["Knowledge", "Learning", "Assessment", "Adaptation", "Recommendation"],
        "c": "graph construction -> behavior tracking -> gap analysis -> path optimization -> content delivery"
    },
    {
        "q": "Synthetic data for robotics training must preserve physical constraints and collision dynamics.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying AI models for financial fraud detection across multiple countries?",
        "type": "mcq",
        "o": [
            "Regulatory compliance and cross-jurisdictional pattern adaptation",
            "Waiting for identical fraud patterns in all regions",
            "Using only credit card transaction data",
            "Eliminating all small transaction monitoring"
        ]
    },
    {
        "q": "The process of ______ alignment ensures reinforcement learning agents optimize for human-intended outcomes in complex games.",
        "type": "fill_blank",
        "answers": ["value"],
        "other_options": ["policy", "state", "reward"]
    },
    {
        "q": "Which data validation approach is essential for models detecting deepfake audio in voice authentication systems?",
        "type": "mcq",
        "o": [
            "Spectral artifact detection and liveness verification",
            "Validating only audio file formats",
            "Checking recording duration without content analysis",
            "Eliminating all short voice samples"
        ]
    },
    {
        "q": "For smart grid optimization, ______ forecasting balances renewable generation with electricity demand patterns.",
        "type": "fill_blank",
        "answers": ["load"],
        "other_options": ["weather", "price", "maintenance"]
    },
    {
        "q": "In computational archaeology, analyzing pottery fragment curvature requires ______ geometry to reconstruct complete vessel shapes.",
        "type": "fill_blank",
        "answers": ["differential"],
        "other_options": ["euclidean", "algebraic", "fractal"]
    },
    {
        "q": "Which data preprocessing technique is essential for building models that predict protein function from amino acid sequences?",
        "type": "mcq",
        "o": [
            "Evolutionary conservation scoring and structural motif embedding",
            "Simple amino acid frequency counting",
            "Eliminating all hydrophobic residues",
            "Using only sequence length without positional information"
        ]
    },
    {
        "q": "Rearrange the workflow for analyzing historical climate from ice core data:",
        "type": "rearrange",
        "words": ["Layer", "Isotope", "Gas", "Dating", "Climate"],
        "c": "counting -> ratio measurement -> bubble analysis -> validation -> reconstruction"
    },
    {
        "q": "Match the specialized imaging technique with its cultural heritage analysis application:",
        "type": "match",
        "left": ["Hyperspectral imaging", "Terahertz tomography", "Neutron radiography", "Optical coherence tomography"],
        "right": ["Pigment identification and mapping", "Text recovery in sealed documents", "Hidden structure visualization", "Layer thickness measurement in paintings"]
    },
    {
        "q": "What unique data integration challenge arises when building models of ancient trade networks?",
        "type": "mcq",
        "o": [
            "Temporal uncertainty in artifact dating and route persistence",
            "Perfect preservation of all trade goods",
            "Complete written records of all transactions",
            "Identical measurement units across civilizations"
        ]
    },
    {
        "q": "For analyzing historical handwriting, ______ variation modeling accounts for individual scribe characteristics while maintaining text recognition accuracy.",
        "type": "fill_blank",
        "answers": ["style"],
        "other_options": ["size", "color", "pressure"]
    },
    {
        "q": "Paleogenomic data requires special processing to account for post-mortem DNA damage patterns.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is crucial for models predicting material degradation in historical buildings?",
        "type": "mcq",
        "o": [
            "Multi-temporal photogrammetry correlation with environmental monitoring",
            "Validating only current condition assessments",
            "Checking image resolution without material analysis",
            "Eliminating all complex architectural features"
        ]
    },
    {
        "q": "The process of ______ reconstruction estimates original colors from faded historical textiles using spectral reflectance data.",
        "type": "fill_blank",
        "answers": ["color"],
        "other_options": ["pattern", "fiber", "weave"]
    },
    {
        "q": "What is the primary data challenge in building models for predicting archaeological site locations?",
        "type": "mcq",
        "o": [
            "Integrating sparse ground truth with remote sensing false positives",
            "Excessive computational requirements for simple terrain analysis",
            "Overabundance of perfectly documented site locations",
            "Lack of relevant geographical data sources"
        ]
    },
    {
        "q": "In archaeometallurgy, ______ analysis traces metal artifacts to their geological sources using trace element fingerprints.",
        "type": "fill_blank",
        "answers": ["provenance"],
        "other_options": ["hardness", "conductivity", "magnetism"]
    },
    {
        "q": "Digital reconstruction of fragmentary ancient texts requires handling of multiple possible word completions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building models of historical land use change?",
        "type": "mcq",
        "o": [
            "Multi-temporal map regression with field verification and pollen analysis",
            "Relying solely on modern satellite imagery",
            "Using only written historical accounts",
            "Focusing exclusively on political boundary changes"
        ]
    },
    {
        "q": "Match the archaeological dating method with its calibration requirement:",
        "type": "match",
        "left": ["Radiocarbon dating", "Luminescence dating", "Dendrochronology", "Argon-argon dating"],
        "right": ["Atmospheric carbon-14 fluctuation correction", "Environmental dose rate estimation", "Tree-ring master sequence alignment", "Neutron flux monitoring during irradiation"]
    },
    {
        "q": "Rearrange the steps for analyzing ancient diet from skeletal remains:",
        "type": "rearrange",
        "words": ["Collagen", "Isotope", "Dental", "Archaeobotanical", "Dietary"],
        "c": "extraction -> ratio measurement -> microwear analysis -> evidence integration -> reconstruction"
    },
    {
        "q": "Computational analysis of ancient languages must account for phonological changes over time.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for cultural heritage disaster risk assessment?",
        "type": "mcq",
        "o": [
            "Material vulnerability functions and multi-hazard interaction modeling",
            "Waiting for perfect environmental monitoring networks",
            "Using only single-hazard risk assessments",
            "Eliminating all uncertain climate projections"
        ]
    },
    {
        "q": "The process of ______ alignment matches fragmentary inscriptions using letter form and linguistic analysis.",
        "type": "fill_blank",
        "answers": ["epigraphic"],
        "other_options": ["digital", "visual", "textual"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing ancient metal composition?",
        "type": "mcq",
        "o": [
            "Reference material analysis and measurement uncertainty quantification",
            "Validating only sample weight measurements",
            "Checking instrument calibration dates without material standards",
            "Eliminating all corroded surface layers"
        ]
    },
    {
        "q": "For analyzing historical glass artifacts, ______ characterization identifies manufacturing techniques from bubble patterns and annealing marks.",
        "type": "fill_blank",
        "answers": ["technological"],
        "other_options": ["chemical", "optical", "thermal"]
    },
    {
        "q": "In sports biomechanics, analyzing an athlete's ______ curve helps optimize training by identifying torque production across joint angles.",
        "type": "fill_blank",
        "answers": ["force-length"],
        "other_options": ["velocity-power", "angle-torque", "time-acceleration"]
    },
    {
        "q": "Which data fusion technique is most critical for autonomous underwater vehicle navigation in featureless environments?",
        "type": "mcq",
        "o": [
            "Doppler Velocity Log integration with inertial measurement units",
            "Simple GPS waypoint following",
            "Visual odometry using coral patterns",
            "Magnetic compass navigation alone"
        ]
    },
    {
        "q": "Rearrange the signal processing chain for gravitational wave detection:",
        "type": "rearrange",
        "words": ["Strain", "Noise", "Matched", "Statistical", "Astrophysical"],
        "c": "measurement -> subtraction -> filtering -> significance -> interpretation"
    },
    {
        "q": "Match the esoteric sensor type with its data calibration challenge:",
        "type": "match",
        "left": ["Atom interferometers", "Superconducting qubits", "Biological sensors", "Quantum gravity detectors"],
        "right": ["Vibration isolation and wavefunction stability", "Cryogenic temperature maintenance", "Living organism response normalization", "Cosmic background subtraction"]
    },
    {
        "q": "What unique data quality issue arises when using muon tomography for pyramid interior mapping?",
        "type": "mcq",
        "o": [
            "Atmospheric variation effects on cosmic ray flux",
            "Perfect muon detection in all weather conditions",
            "Identical penetration depth for all muons",
            "Lack of suitable detection materials"
        ]
    },
    {
        "q": "For predicting solar flare impacts, ______ indices measure coronal mass ejection propagation through the heliosphere.",
        "type": "fill_blank",
        "answers": ["space weather"],
        "other_options": ["solar activity", "geomagnetic", "atmospheric"]
    },
    {
        "q": "Quantum error correction codes require special consideration for the trade-off between logical qubit overhead and fault-tolerance thresholds.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation strategy is essential for brain-computer interface models translating neural signals to device commands?",
        "type": "mcq",
        "o": [
            "Cross-session generalization and intentional vs spontaneous movement discrimination",
            "Validating only electrode impedance measurements",
            "Checking signal amplitude without pattern recognition",
            "Eliminating all noisy neural channels"
        ]
    },
    {
        "q": "The process of ______ learning enables prosthetic devices to adapt to individual user movement patterns without explicit programming.",
        "type": "fill_blank",
        "answers": ["adaptive"],
        "other_options": ["supervised", "reinforcement", "transfer"]
    },
    {
        "q": "What is the primary data challenge in building exoplanet atmospheric composition models?",
        "type": "mcq",
        "o": [
            "Spectral extraction from stellar contamination and instrument systematics",
            "Excessive signal-to-noise ratio in all observations",
            "Overabundance of high-resolution spectral data",
            "Lack of relevant molecular absorption databases"
        ]
    },
    {
        "q": "In synthetic biology, ______ optimization designs DNA sequences for predictable protein expression levels.",
        "type": "fill_blank",
        "answers": ["codon"],
        "other_options": ["gene", "plasmid", "promoter"]
    },
    {
        "q": "Magnetohydrodynamic simulations of fusion plasmas require handling of multiple spatial and temporal scales simultaneously.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection approach is most appropriate for building models of deep-sea hydrothermal vent ecosystems?",
        "type": "mcq",
        "o": [
            "Autonomous vehicle transects with in situ mass spectrometry and DNA sampling",
            "Relying solely on surface water samples",
            "Using only laboratory simulations",
            "Focusing exclusively on temperature measurements"
        ]
    },
    {
        "q": "Match the extreme environment monitoring system with its data transmission constraint:",
        "type": "match",
        "left": ["Deep ocean observatories", "Arctic ice stations", "Volcano monitoring networks", "Space telescope arrays"],
        "right": ["Acoustic modem bandwidth limitations", "Satellite link seasonal availability", "Radio signal atmospheric interference", "Deep space network scheduling constraints"]
    },
    {
        "q": "Rearrange the workflow for building quantum chemistry models of catalytic reactions:",
        "type": "rearrange",
        "words": ["Electronic", "Reaction", "Transition", "Energy", "Catalytic"],
        "c": "structure calculation -> pathway exploration -> state optimization -> barrier computation -> activity prediction"
    },
    {
        "q": "Neuromorphic computing architectures require special data encoding for temporal spike patterns.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for predicting space debris collision probabilities?",
        "type": "mcq",
        "o": [
            "Orbital uncertainty propagation and covariance realism",
            "Waiting for perfect tracking of all debris objects",
            "Using only two-body gravitational models",
            "Eliminating all small debris particles from analysis"
        ]
    },
    {
        "q": "The process of ______ tomography reconstructs internal structures using cosmic ray muon absorption patterns.",
        "type": "fill_blank",
        "answers": ["muon"],
        "other_options": ["x-ray", "neutron", "optical"]
    },
    {
        "q": "Which data validation approach is essential for models detecting dark matter interactions?",
        "type": "mcq",
        "o": [
            "Background radiation subtraction and multiple detector consistency checks",
            "Validating only detector temperature readings",
            "Checking data acquisition rates without event classification",
            "Eliminating all low-energy particle interactions"
        ]
    },
    {
        "q": "For analyzing gravitational lensing effects, ______ mapping reconstructs dark matter distributions from distorted galaxy images.",
        "type": "fill_blank",
        "answers": ["mass"],
        "other_options": ["light", "energy", "density"]
    },
    {
        "q": "In computational ethology, tracking individual ants in a colony requires solving the multiple object ______ problem across thousands of nearly identical individuals.",
        "type": "fill_blank",
        "answers": ["tracking"],
        "other_options": ["recognition", "segmentation", "classification"]
    },
    {
        "q": "Which data preprocessing technique is essential for building models that predict fold changes in RNA-seq data from single-cell sequencing?",
        "type": "mcq",
        "o": [
            "UMI deduplication and size factor normalization",
            "Simple read count averaging across cells",
            "Eliminating all low-expression genes",
            "Using only raw read counts without normalization"
        ]
    },
    {
        "q": "Rearrange the workflow for analyzing neural population coding in motor cortex:",
        "type": "rearrange",
        "words": ["Spike", "Tuning", "Population", "Decoding", "Movement"],
        "c": "sorting -> curve fitting -> vector analysis -> algorithm -> prediction"
    },
    {
        "q": "Match the specialized microscopy data with its unique artifact correction requirement:",
        "type": "match",
        "left": ["Expansion microscopy", "Light-field microscopy", "Lattice light-sheet", "STED super-resolution"],
        "right": ["Swelling distortion compensation", "View deconvolution and refocusing", "Striping artifact removal", "Excitation depletion pattern correction"]
    },
    {
        "q": "What unique data integration challenge arises when building whole-brain connectomes from electron microscopy volumes?",
        "type": "mcq",
        "o": [
            "Section alignment and missing slice interpolation across terabytes of data",
            "Perfect section alignment with no missing data",
            "Identical staining intensity across all sections",
            "Lack of sufficient computational storage"
        ]
    },
    {
        "q": "For analyzing protein dynamics, ______ correlation spectroscopy extracts diffusion coefficients from fluorescence fluctuations.",
        "type": "fill_blank",
        "answers": ["fluorescence"],
        "other_options": ["Raman", "infrared", "circular"]
    },
    {
        "q": "Cryo-EM single particle analysis requires extensive 2D classification to separate different conformational states.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is crucial for models predicting gene regulatory networks from single-cell ATAC-seq data?",
        "type": "mcq",
        "o": [
            "Chromatin conformation capture correlation and motif enrichment validation",
            "Validating only sequencing depth metrics",
            "Checking file formats without peak calling verification",
            "Eliminating all weakly accessible regions"
        ]
    },
    {
        "q": "The process of ______ registration aligns serial section electron microscopy images using landmark matching and elastic deformation.",
        "type": "fill_blank",
        "answers": ["image"],
        "other_options": ["data", "volume", "section"]
    },
    {
        "q": "What is the primary data challenge in building models for predicting alternative splicing patterns?",
        "type": "mcq",
        "o": [
            "Junction read quantification and isoform abundance estimation",
            "Excessive computational requirements for simple counting",
            "Overabundance of complete isoform sequences",
            "Lack of relevant sequencing technologies"
        ]
    },
    {
        "q": "In mass cytometry, ______ normalization standardizes signal intensity across different metal isotopes and time.",
        "type": "fill_blank",
        "answers": ["bead"],
        "other_options": ["cell", "signal", "peak"]
    },
    {
        "q": "Spatial transcriptomics data requires integration of gene expression with histological image features.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building comprehensive models of cell lineage tracing?",
        "type": "mcq",
        "o": [
            "Barcode sequencing with temporal sampling and single-cell resolution",
            "Relying solely on static snapshot imaging",
            "Using only bulk population measurements",
            "Focusing exclusively on embryonic stages"
        ]
    },
    {
        "q": "Match the biophysical measurement technique with its data analysis challenge:",
        "type": "match",
        "left": ["Optical tweezers", "Patch clamp", "AFM force spectroscopy", "FRAP recovery analysis"],
        "right": ["Brownian motion subtraction", "Series resistance compensation", "Cantilever drift correction", "Bleaching profile fitting"]
    },
    {
        "q": "Rearrange the steps for building predictive models of protein phase separation:",
        "type": "rearrange",
        "words": ["Sequence", "Molecular", "Coarse-grained", "Phase", "Condensate"],
        "c": "feature extraction -> dynamics simulation -> modeling -> diagram prediction -> property calculation"
    },
    {
        "q": "Calcium imaging data analysis must account for neuropil contamination and motion artifacts.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for drug response prediction in patient-derived organoids?",
        "type": "mcq",
        "o": [
            "Batch effect correction and clinical variable integration",
            "Waiting for identical growth conditions across all organoids",
            "Using only single time point measurements",
            "Eliminating all heterogeneous organoid cultures"
        ]
    },
    {
        "q": "The process of ______ inference reconstructs gene regulatory networks from perturbation response data.",
        "type": "fill_blank",
        "answers": ["network"],
        "other_options": ["causal", "statistical", "bayesian"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing chromatin accessibility dynamics?",
        "type": "mcq",
        "o": [
            "Replicate concordance and transcription factor footprint validation",
            "Validating only sequencing library concentrations",
            "Checking read lengths without peak quality assessment",
            "Eliminating all low-coverage regions"
        ]
    },
    {
        "q": "For analyzing membrane protein dynamics, ______ tracking follows individual molecules in living cells to extract diffusion properties.",
        "type": "fill_blank",
        "answers": ["single-particle"],
        "other_options": ["ensemble", "population", "bulk"]
    },
    {
        "q": "In digital humanities, analyzing the evolution of narrative structures across centuries requires ______ modeling of plot elements.",
        "type": "fill_blank",
        "answers": ["network"],
        "other_options": ["linear", "statistical", "hierarchical"]
    },
    {
        "q": "Which data processing technique is essential for reconstructing damaged ancient manuscripts using multispectral imaging?",
        "type": "mcq",
        "o": [
            "Spectral unmixing and pigment signature isolation",
            "Simple contrast enhancement of visible light images",
            "Eliminating all damaged manuscript sections",
            "Using only infrared reflectance without spectral analysis"
        ]
    },
    {
        "q": "Rearrange the workflow for computational analysis of historical social networks:",
        "type": "rearrange",
        "words": ["Entity", "Relationship", "Network", "Centrality", "Historical"],
        "c": "recognition -> extraction -> construction -> analysis -> interpretation"
    },
    {
        "q": "Match the digital archaeology method with its data reconstruction challenge:",
        "type": "match",
        "left": ["Photogrammetry of ruins", "LIDAR of dense vegetation", "Ground penetrating radar", "3D pottery reconstruction"],
        "right": ["Occluded surface completion", "Canopy penetration and ground classification", "Signal attenuation compensation", "Fragment matching and surface interpolation"]
    },
    {
        "q": "What unique data quality issue arises when analyzing historical climate from ship logbook weather observations?",
        "type": "mcq",
        "o": [
            "Observer bias and instrument calibration inconsistencies",
            "Perfect weather recording by all ship captains",
            "Identical measurement units across all logbooks",
            "Lack of geographic position data"
        ]
    },
    {
        "q": "For analyzing the spread of historical epidemics, ______ modeling incorporates transportation networks and population mobility patterns.",
        "type": "fill_blank",
        "answers": ["compartmental"],
        "other_options": ["statistical", "agent-based", "network"]
    },
    {
        "q": "Computational analysis of musical style evolution requires handling of incomplete historical scores and notation variations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is crucial for models predicting archaeological site locations using machine learning?",
        "type": "mcq",
        "o": [
            "Ground truth verification and false positive rate assessment in surveyed areas",
            "Validating only satellite image resolution",
            "Checking data formats without field verification",
            "Eliminating all uncertain predictions"
        ]
    },
    {
        "q": "The process of ______ alignment matches historical maps to modern coordinate systems using control points.",
        "type": "fill_blank",
        "answers": ["georeferencing"],
        "other_options": ["temporal", "spatial", "projective"]
    },
    {
        "q": "What is the primary data challenge in building models of linguistic change over centuries?",
        "type": "mcq",
        "o": [
            "Sparse textual evidence and orthographic variation normalization",
            "Excessive computational requirements for simple word counting",
            "Overabundance of perfectly transcribed historical texts",
            "Lack of relevant linguistic theory"
        ]
    },
    {
        "q": "In art historical analysis, ______ recognition identifies artist hands through brushstroke pattern analysis.",
        "type": "fill_blank",
        "answers": ["style"],
        "other_options": ["face", "object", "color"]
    },
    {
        "q": "Digital reconstruction of fragmentary ancient sculptures requires handling of symmetry assumptions and material constraints.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building models of historical urban soundscapes?",
        "type": "mcq",
        "o": [
            "Multi-source integration of written descriptions, architectural acoustics, and sound propagation modeling",
            "Relying solely on modern audio recordings",
            "Using only subjective historical accounts",
            "Focusing exclusively on musical performances"
        ]
    },
    {
        "q": "Match the historical data type with its computational analysis method:",
        "type": "match",
        "left": ["Census records", "Trade ledgers", "Personal correspondence", "Legal documents"],
        "right": ["Demographic network analysis", "Economic flow modeling", "Social relationship extraction", "Legal concept evolution tracking"]
    },
    {
        "q": "Rearrange the steps for analyzing historical land use from aerial photographs:",
        "type": "rearrange",
        "words": ["Image", "Feature", "Temporal", "Land", "Change"],
        "c": "preprocessing -> extraction -> analysis -> use classification -> detection"
    },
    {
        "q": "Computational analysis of historical texts must account for spelling variations and evolving grammatical structures.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for cultural heritage preservation prioritization?",
        "type": "mcq",
        "o": [
            "Multi-criteria decision analysis incorporating historical significance and vulnerability",
            "Waiting for perfect condition assessment of all sites",
            "Using only architectural value without cultural context",
            "Eliminating all sites with incomplete documentation"
        ]
    },
    {
        "q": "The process of ______ normalization standardizes historical monetary values across different currencies and time periods.",
        "type": "fill_blank",
        "answers": ["currency"],
        "other_options": ["data", "temporal", "spatial"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing historical climate from tree ring data?",
        "type": "mcq",
        "o": [
            "Cross-dating verification and climate signal coherence testing",
            "Validating only tree core sample diameters",
            "Checking ring counts without quality control",
            "Eliminating all young trees from analysis"
        ]
    },
    {
        "q": "For analyzing the evolution of scientific ideas, ______ modeling tracks concept relationships across citation networks.",
        "type": "fill_blank",
        "answers": ["topic"],
        "other_options": ["network", "semantic", "evolutionary"]
    },
    {
        "q": "In precision viticulture, creating ______ maps from soil electrical conductivity helps optimize irrigation zones within vineyards.",
        "type": "fill_blank",
        "answers": ["management"],
        "other_options": ["yield", "topographic", "drainage"]
    },
    {
        "q": "Which data fusion technique is most critical for building digital twins of smart buildings?",
        "type": "mcq",
        "o": [
            "BIM model integration with real-time IoT sensor streams",
            "Simple averaging of temperature readings",
            "Using only architectural drawings without sensor data",
            "Eliminating all low-frequency sensor updates"
        ]
    },
    {
        "q": "Rearrange the data processing pipeline for autonomous agricultural robots:",
        "type": "rearrange",
        "words": ["Sensor", "Obstacle", "Path", "Actuator", "Task"],
        "c": "fusion -> detection -> planning -> control -> execution"
    },
    {
        "q": "Match the smart city application with its unique data privacy challenge:",
        "type": "match",
        "left": ["Smart parking", "Waste management", "Public transit", "Energy grid"],
        "right": ["Vehicle movement pattern anonymization", "Residential habit inference prevention", "Individual travel route protection", "Household consumption pattern masking"]
    },
    {
        "q": "What unique data quality issue arises when using drone imagery for crop health monitoring?",
        "type": "mcq",
        "o": [
            "Sun angle variation and shadow effects on vegetation indices",
            "Perfect lighting conditions throughout the day",
            "Identical flight altitude for all surveys",
            "Lack of sufficient spatial resolution"
        ]
    },
    {
        "q": "For predictive maintenance in smart factories, ______ learning detects anomalous vibration patterns before equipment failure.",
        "type": "fill_blank",
        "answers": ["unsupervised"],
        "other_options": ["supervised", "reinforcement", "semi-supervised"]
    },
    {
        "q": "Digital twins of urban water systems must account for both real-time sensor data and hydraulic simulation models.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation strategy is essential for AI systems managing microgrid energy distribution?",
        "type": "mcq",
        "o": [
            "Real-time power flow validation and contingency scenario testing",
            "Validating only voltage readings without load balancing",
            "Checking data formats without grid stability analysis",
            "Eliminating all renewable energy sources from testing"
        ]
    },
    {
        "q": "The process of ______ learning enables smart traffic systems to adapt to unusual congestion patterns without manual intervention.",
        "type": "fill_blank",
        "answers": ["reinforcement"],
        "other_options": ["supervised", "unsupervised", "transfer"]
    },
    {
        "q": "What is the primary data challenge in building supply chain visibility models for perishable pharmaceuticals?",
        "type": "mcq",
        "o": [
            "Temperature excursion prediction and cold chain integrity monitoring",
            "Excessive data quality from all logistics partners",
            "Overabundance of perfect delivery records",
            "Lack of relevant environmental sensors"
        ]
    },
    {
        "q": "In precision livestock farming, ______ analysis of animal movement patterns can early-detect health issues.",
        "type": "fill_blank",
        "answers": ["behavioral"],
        "other_options": ["genetic", "nutritional", "environmental"]
    },
    {
        "q": "Smart building occupancy sensors must balance energy efficiency with occupant privacy preservation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection approach is most appropriate for building urban air quality models?",
        "type": "mcq",
        "o": [
            "Multi-scale sensor deployment with mobile monitoring and satellite data fusion",
            "Relying solely on fixed regulatory stations",
            "Using only meteorological data without pollution measurements",
            "Focusing exclusively on industrial emission sources"
        ]
    },
    {
        "q": "Match the IoT application domain with its data latency requirement:",
        "type": "match",
        "left": ["Structural health monitoring", "Smart irrigation", "Inventory management", "Emergency response"],
        "right": ["Near real-time with periodic analysis", "Weather-dependent delayed control", "Batch processing with daily updates", "Millisecond response critical"]
    },
    {
        "q": "Rearrange the workflow for smart waste management optimization:",
        "type": "rearrange",
        "words": ["Fill-level", "Collection", "Route", "Fuel", "Operational"],
        "c": "monitoring -> scheduling -> optimization -> efficiency -> analytics"
    },
    {
        "q": "Predictive maintenance models for wind turbines must account for both mechanical wear and environmental factors.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying AI models for autonomous shipping port operations?",
        "type": "mcq",
        "o": [
            "Safety-critical system redundancy and failure mode analysis",
            "Waiting for perfect weather conditions",
            "Using only crane operation data without vessel tracking",
            "Eliminating all human-operated equipment"
        ]
    },
    {
        "q": "The process of ______ forecasting predicts building energy demand using weather data and occupancy patterns.",
        "type": "fill_blank",
        "answers": ["load"],
        "other_options": ["solar", "wind", "price"]
    },
    {
        "q": "Which data validation approach is essential for smart water quality monitoring networks?",
        "type": "mcq",
        "o": [
            "Multi-parameter consistency checking and sensor drift detection",
            "Validating only data transmission rates",
            "Checking timestamps without parameter correlation",
            "Eliminating all outlier measurements automatically"
        ]
    },
    {
        "q": "For precision agriculture, ______ zoning divides fields into management areas based on soil and yield data analysis.",
        "type": "fill_blank",
        "answers": ["management"],
        "other_options": ["irrigation", "fertilizer", "harvest"]
    },
    {
        "q": "In computational paleography, analyzing the ______ of ink deposition can reveal the writing speed and pressure used by medieval scribes.",
        "type": "fill_blank",
        "answers": ["microtopography"],
        "other_options": ["chemistry", "viscosity", "absorption"]
    },
    {
        "q": "Which data processing technique is essential for recovering faded iron-gall ink manuscripts using hyperspectral imaging?",
        "type": "mcq",
        "o": [
            "Spectral angle mapping and material classification",
            "Simple contrast stretching of visible spectrum",
            "Eliminating all damaged parchment areas",
            "Using only ultraviolet reflectance without spectral analysis"
        ]
    },
    {
        "q": "Rearrange the workflow for computational analysis of historical book provenance:",
        "type": "rearrange",
        "words": ["Marginalia", "Ownership", "Library", "Geographic", "Provenance"],
        "c": "transcription -> mark identification -> stamp analysis -> trajectory -> reconstruction"
    },
    {
        "q": "Match the archaeometric technique with its data interpretation challenge:",
        "type": "match",
        "left": ["Portable XRF of metals", "Raman spectroscopy of glass", "Stable isotopes in teeth", "OSL dating of sediments"],
        "right": ["Surface contamination effects", "Fluorescence background subtraction", "Dietary signal separation", "Partial bleaching assessment"]
    },
    {
        "q": "What unique data integration challenge arises when building models of ancient Mediterranean trade routes?",
        "type": "mcq",
        "o": [
            "Fragmentary evidence reconciliation across archaeological and textual sources",
            "Complete shipwreck inventories for all routes",
            "Identical pottery styles across all trading partners",
            "Lack of relevant underwater archaeology data"
        ]
    },
    {
        "q": "For analyzing historical paper degradation, ______ modeling predicts acid hydrolysis rates from environmental conditions.",
        "type": "fill_blank",
        "answers": ["kinetic"],
        "other_options": ["statistical", "mechanical", "chemical"]
    },
    {
        "q": "Computational analysis of historical watermarks requires handling of chain line variations and paper sheet orientation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which validation approach is crucial for models reconstructing fragmentary ancient wall paintings?",
        "type": "mcq",
        "o": [
            "Pigment chemistry matching and plaster layer stratigraphy correlation",
            "Validating only digital image resolution",
            "Checking file formats without material analysis",
            "Eliminating all small fragments from reconstruction"
        ]
    },
    {
        "q": "The process of ______ analysis identifies workshop traditions through tool mark patterns on ancient sculptures.",
        "type": "fill_blank",
        "answers": ["stylistic"],
        "other_options": ["chemical", "geometric", "statistical"]
    },
    {
        "q": "What is the primary data challenge in building models of historical sound propagation in ancient theaters?",
        "type": "mcq",
        "o": [
            "Acoustic parameter estimation from ruined structures and material degradation",
            "Perfect preservation of all ancient performance spaces",
            "Identical construction materials across all theaters",
            "Lack of relevant architectural measurement techniques"
        ]
    },
    {
        "q": "In numismatic analysis, ______ recognition identifies minting workshops through die linkage studies.",
        "type": "fill_blank",
        "answers": ["die"],
        "other_options": ["face", "symbol", "inscription"]
    },
    {
        "q": "Digital reconstruction of ancient musical instruments requires handling of both acoustic physics and material properties.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data collection strategy is most appropriate for building models of historical textile production?",
        "type": "mcq",
        "o": [
            "Multi-analytical approach combining microscopy, chemistry, and weaving pattern analysis",
            "Relying solely on written production accounts",
            "Using only modern textile manufacturing data",
            "Focusing exclusively on fiber type identification"
        ]
    },
    {
        "q": "Match the archaeological material with its computational analysis method:",
        "type": "match",
        "left": ["Ceramic thin sections", "Metal alloy compositions", "Glass bead chemistry", "Wood species identification"],
        "right": ["Petrographic image analysis", "Multivariate statistical analysis", "Laser ablation ICP-MS mapping", "Dendrological pattern matching"]
    },
    {
        "q": "Rearrange the steps for analyzing historical parchment degradation:",
        "type": "rearrange",
        "words": ["Collagen", "Damage", "Environmental", "Conservation", "Preservation"],
        "c": "analysis -> assessment -> correlation -> strategy -> prioritization"
    },
    {
        "q": "Computational analysis of ancient languages must handle both phonetic changes and semantic shifts over time.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary consideration when deploying models for historical document dating?",
        "type": "mcq",
        "o": [
            "Multi-feature correlation including ink chemistry, parchment aging, and writing style evolution",
            "Waiting for perfectly dated reference documents",
            "Using only handwriting analysis without material science",
            "Eliminating all documents with uncertain provenance"
        ]
    },
    {
        "q": "The process of ______ mapping tracks the geographic distribution of archaeological find spots through time.",
        "type": "fill_blank",
        "answers": ["distribution"],
        "other_options": ["density", "cluster", "spatial"]
    },
    {
        "q": "Which data validation approach is essential for models analyzing ancient diet from dental microwear?",
        "type": "mcq",
        "o": [
            "Modern analogue comparison and experimental archaeology validation",
            "Validating only microscope magnification settings",
            "Checking image resolution without pattern recognition",
            "Eliminating all worn teeth from analysis"
        ]
    },
    {
        "q": "For analyzing historical climate impacts on societies, ______ modeling correlates paleoclimate proxies with archaeological settlement patterns.",
        "type": "fill_blank",
        "answers": ["correlative"],
        "other_options": ["predictive", "descriptive", "explanatory"]
    }
]