[
    {
        "q": "What does the acronym GDPR stand for in the context of data privacy?",
        "type": "mcq",
        "o": [
            "General Data Protection Regulation",
            "Global Data Privacy Rules",
            "General Digital Public Rights",
            "Global Digital Protection Regulation"
        ]
    },
    {
        "q": "Which term describes the process of removing personally identifiable information from a dataset so that the individuals can no longer be identified?",
        "type": "mcq",
        "o": [
            "Anonymization",
            "Normalization",
            "Augmentation",
            "Regularization"
        ]
    },
    {
        "q": "Under GDPR, the 'Right to be ______' allows individuals to request the deletion of their personal data.",
        "type": "fill_blank",
        "answers": [
            "forgotten"
        ],
        "other_options": [
            "hidden",
            "processed",
            "saved"
        ]
    },
    {
        "q": "Simply removing a sensitive attribute (like race or gender) from a dataset guarantees that the AI model will be free of bias.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the data privacy concept with its definition:",
        "type": "match",
        "left": [
            "Consent",
            "Data Minimization",
            "Right to Access",
            "Breach Notification"
        ],
        "right": [
            "User agreement to data processing",
            "Collecting only necessary data",
            "User ability to view their stored data",
            "Informing users of data leaks"
        ]
    },
    {
        "q": "What ethical issue is most likely present in the following code scenario?",
        "type": "mcq",
        "c": "# A hiring model trained only on resumes from the last 10 years\n# during which 90% of hires were men.\nmodel.fit(X_train, y_train)",
        "o": [
            "Historical Bias",
            "Overfitting",
            "High Latency",
            "Data Leakage"
        ]
    },
    {
        "q": "Rearrange the words to form a core principle of data ethics:",
        "type": "rearrange",
        "words": [
            "AI",
            "should",
            "avoid",
            "creating",
            "unfair",
            "bias"
        ]
    },
    {
        "q": "What is the primary goal of 'Explainable AI' (XAI)?",
        "type": "mcq",
        "o": [
            "To make model decisions understandable to humans",
            "To make models run faster",
            "To encrypt data more securely",
            "To reduce the storage size of the model"
        ]
    },
    {
        "q": "In the context of AI, ______ refers to the ability to see how a model works, while ______ refers to who is responsible for its actions.",
        "type": "fill_blank",
        "answers": [
            "transparency",
            "accountability"
        ],
        "other_options": [
            "opacity",
            "efficiency",
            "latency",
            "accuracy"
        ]
    },
    {
        "q": "What is the output of this code regarding PII (Personally Identifiable Information)?",
        "type": "mcq",
        "c": "pii_columns = ['SSN', 'Email']\nprint('Salary' in pii_columns)",
        "o": [
            "False",
            "True",
            "Error",
            "None"
        ]
    },
    {
        "q": "Which of the following is considered a 'Black Box' model due to low interpretability?",
        "type": "mcq",
        "o": [
            "Deep Neural Networks",
            "Linear Regression",
            "Decision Trees (shallow)",
            "Logistic Regression"
        ]
    },
    {
        "q": "Algorithmic accountability implies that developers are not responsible for the unintended consequences of their AI systems.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the type of bias to its description:",
        "type": "match",
        "left": [
            "Selection Bias",
            "Confirmation Bias",
            "Automation Bias"
        ],
        "right": [
            "Data chosen is not representative",
            "Seeking information that supports existing beliefs",
            "Over-relying on machine outcomes over human judgment"
        ]
    },
    {
        "q": "What is the primary purpose of the following code snippet?",
        "type": "mcq",
        "c": "import hashlib\ndef hash_data(data):\n    return hashlib.sha256(data.encode()).hexdigest()",
        "o": [
            "Pseudonymization/Hashing",
            "Data Visualization",
            "Statistical Analysis",
            "Linear Regression"
        ]
    },
    {
        "q": "Rearrange the words to define a privacy law concept:",
        "type": "rearrange",
        "words": [
            "Privacy",
            "by",
            "design",
            "is",
            "essential"
        ]
    },
    {
        "q": "Which US law specifically regulates the collection of personal information from children under the age of 13?",
        "type": "mcq",
        "o": [
            "COPPA (Children's Online Privacy Protection Act)",
            "HIPAA (Health Insurance Portability and Accountability Act)",
            "OSHA (Occupational Safety and Health Act)",
            "SOX (Sarbanes-Oxley Act)"
        ]
    },
    {
        "q": "In the context of 'Fairness', using a variable like 'Zip Code' which correlates highly with 'Race' is an example of a ______ variable.",
        "type": "fill_blank",
        "answers": [
            "proxy"
        ],
        "other_options": [
            "target",
            "dummy",
            "random"
        ]
    },
    {
        "q": "What is the primary ethical concern illustrated in this code snippet?",
        "type": "mcq",
        "c": "# Training a credit model excluding 'Race' \n# but including 'Zip_Code' which is segregated by race\nfeatures = ['Income', 'Zip_Code', 'Age']\nmodel.train(features, target)",
        "o": [
            "Proxy Bias / Redlining",
            "Syntax Error",
            "Memory Overflow",
            "Vanishing Gradient"
        ]
    },
    {
        "q": "Match the privacy technique with its mechanism:",
        "type": "match",
        "left": [
            "Differential Privacy",
            "Federated Learning",
            "Encryption",
            "Aggregation"
        ],
        "right": [
            "Adding statistical noise to mask individuals",
            "Training models locally on devices without sharing data",
            "Converting data into unreadable code",
            "Summarizing data into groups (e.g., averages)"
        ]
    },
    {
        "q": "Rearrange the words to form a principle regarding user control:",
        "type": "rearrange",
        "words": [
            "Users",
            "must",
            "consent",
            "to",
            "data",
            "collection"
        ]
    },
    {
        "q": "A 'Model Card' is a document used to increase ______ by detailing a model's intended use, limitations, and performance metrics.",
        "type": "fill_blank",
        "answers": [
            "transparency"
        ],
        "other_options": [
            "latency",
            "bandwidth",
            "security"
        ]
    },
    {
        "q": "What data ethics concept is being applied in the following code?",
        "type": "mcq",
        "c": "import numpy as np\n\n# Adding random noise to the true salary to protect individual privacy\nepsilon = 0.5\nnoise = np.random.laplace(0, 1/epsilon)\nprivate_salary = true_salary + noise",
        "o": [
            "Differential Privacy",
            "Data Augmentation",
            "Feature Scaling",
            "Backpropagation"
        ]
    },
    {
        "q": "The 'Right to Explanation' refers to a user's right to understand why an algorithmic decision was made about them.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which tool is commonly used to visualize 'feature importance' to explain individual predictions of black-box models?",
        "type": "mcq",
        "o": [
            "SHAP (SHapley Additive exPlanations)",
            "SQL Database",
            "Docker Containers",
            "Kubernetes"
        ]
    },
    {
        "q": "Match the sector with its specific US privacy regulation:",
        "type": "match",
        "left": [
            "Healthcare",
            "Education",
            "California Residents",
            "Financial Services"
        ],
        "right": [
            "HIPAA",
            "FERPA",
            "CCPA/CPRA",
            "GLBA"
        ]
    },
    {
        "q": "What is the output of the following code designed to mask PII?",
        "type": "mcq",
        "c": "text = \"Contact John at john@example.com\"\nmasked = text.replace(\"john@example.com\", \"[REDACTED]\")\nprint(masked)",
        "o": [
            "Contact John at [REDACTED]",
            "Contact [REDACTED] at john@example.com",
            "Contact John at john@example.com",
            "Error"
        ]
    },
    {
        "q": "Rearrange the words to describe a risk in predictive policing:",
        "type": "rearrange",
        "words": [
            "Feedback",
            "loops",
            "can",
            "reinforce",
            "existing",
            "prejudices"
        ]
    },
    {
        "q": "Collecting data about a user's browsing history without their knowledge or permission is primarily a violation of:",
        "type": "mcq",
        "o": [
            "Informed Consent",
            "Data Quality",
            "Model Accuracy",
            "Computational Efficiency"
        ]
    },
    {
        "q": "In the context of consent, ______ means the user is automatically enrolled and must take action to withdraw, whereas ______ means the user must explicitly agree to join.",
        "type": "fill_blank",
        "answers": [
            "opt-out",
            "opt-in"
        ],
        "other_options": [
            "sign-up",
            "log-off",
            "shut-down",
            "start-up"
        ]
    },
    {
        "q": "It is ethically acceptable to scrape public data from a website even if it violates the website's Terms of Service (ToS).",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which type of privacy attack involves an adversary trying to determine if a specific individual's data was used to train a machine learning model?",
        "type": "mcq",
        "o": [
            "Membership Inference Attack",
            "SQL Injection",
            "DDoS Attack",
            "Man-in-the-Middle Attack"
        ]
    },
    {
        "q": "In the context of k-anonymity, 'k' refers to the minimum number of individuals who must share the same values for ______ attributes.",
        "type": "fill_blank",
        "answers": [
            "quasi-identifier"
        ],
        "other_options": [
            "sensitive",
            "target",
            "encrypted"
        ]
    },
    {
        "q": "What is the calculated Disparate Impact Ratio based on this code output?",
        "type": "mcq",
        "c": "group_a_hired = 80\ngroup_a_applicants = 100\n# Selection Rate A = 0.8\n\ngroup_b_hired = 40\ngroup_b_applicants = 100\n# Selection Rate B = 0.4\n\nprint(group_b_selection_rate / group_a_selection_rate)",
        "o": [
            "0.5",
            "2.0",
            "0.4",
            "1.2"
        ]
    },
    {
        "q": "Match the risk level in the EU AI Act with its example application:",
        "type": "match",
        "left": [
            "Unacceptable Risk",
            "High Risk",
            "Limited Risk",
            "Minimal Risk"
        ],
        "right": [
            "Social Scoring Systems",
            "Medical Device AI",
            "Chatbots / Deepfakes",
            "Spam Filters"
        ]
    },
    {
        "q": "Rearrange the words to define the concept of 'Model Drift' regarding ethics:",
        "type": "rearrange",
        "words": [
            "Models",
            "degrade",
            "as",
            "real-world",
            "data",
            "changes"
        ]
    },
    {
        "q": "Compliance with the law is exactly the same thing as being ethical.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What security concept is missing in this hashing function that makes it vulnerable to Rainbow Table attacks?",
        "type": "mcq",
        "c": "import hashlib\n\ndef store_password(password):\n    # Vulnerable implementation\n    return hashlib.sha256(password.encode()).hexdigest()",
        "o": [
            "Salt",
            "Loop",
            "Integer",
            "String"
        ]
    },
    {
        "q": "The 'Four-Fifths Rule' (or 80% rule) is a guideline often used by regulators to detect potential ______ in hiring practices.",
        "type": "fill_blank",
        "answers": [
            "adverse impact"
        ],
        "other_options": [
            "overfitting",
            "latency",
            "convergence"
        ]
    },
    {
        "q": "Which fairness metric requires that the True Positive Rate be equal across all protected groups?",
        "type": "mcq",
        "o": [
            "Equal Opportunity",
            "Demographic Parity",
            "Accuracy Parity",
            "Statistical Parity"
        ]
    },
    {
        "q": "What is the output of the following code checking for missing data transparency?",
        "type": "mcq",
        "c": "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'age': [25, np.nan, 30]})\nprint(df['age'].isnull().sum())",
        "o": [
            "1",
            "0",
            "2",
            "NaN"
        ]
    },
    {
        "q": "Match the anonymization technique to its description:",
        "type": "match",
        "left": [
            "Suppression",
            "Generalization",
            "Perturbation",
            "Pseudonymization"
        ],
        "right": [
            "Deleting data cells entirely",
            "Replacing specific values with ranges (e.g., age 20-30)",
            "Adding random noise to values",
            "Replacing IDs with artificial identifiers"
        ]
    },
    {
        "q": "Human-in-the-loop (HITL) architecture ensures that an AI system cannot make high-stakes decisions without human review.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the words to describe 'Survivorship Bias':",
        "type": "rearrange",
        "words": [
            "Focusing",
            "only",
            "on",
            "successes",
            "ignores",
            "failures"
        ]
    },
    {
        "q": "Which Python library is specifically designed to help developers assess and mitigate unfairness in AI models?",
        "type": "mcq",
        "o": [
            "Fairlearn",
            "Pandas",
            "Matplotlib",
            "Flask"
        ]
    },
    {
        "q": "In the context of data ethics, '______' refers to the reuse of data for a purpose other than what the user originally consented to.",
        "type": "fill_blank",
        "answers": [
            "secondary use"
        ],
        "other_options": [
            "primary key",
            "foreign key",
            "binary search"
        ]
    },
    {
        "q": "Which privacy-preserving technology allows computations to be performed on encrypted data without ever decrypting it first?",
        "type": "mcq",
        "o": [
            "Homomorphic Encryption",
            "Symmetric Encryption",
            "End-to-End Encryption",
            "Public Key Infrastructure"
        ]
    },
    {
        "q": "In the context of statistical bias, ______ Paradox occurs when a trend appears in several different groups of data but disappears or reverses when these groups are combined.",
        "type": "fill_blank",
        "answers": [
            "Simpson's"
        ],
        "other_options": [
            "Fermi's",
            "Moravec's",
            "Braess's"
        ]
    },
    {
        "q": "What type of adversarial attack involves injecting malicious data into a training set to corrupt the learning process?",
        "type": "mcq",
        "c": "# Attacker adds incorrectly labeled samples \n# to shift the decision boundary\ntrain_data.append(malicious_samples)",
        "o": [
            "Data Poisoning",
            "Model Inversion",
            "Evasion Attack",
            "Gradient Descent"
        ]
    },
    {
        "q": "Match the advanced privacy model with its specific improvement:",
        "type": "match",
        "left": [
            "l-diversity",
            "t-closeness",
            "k-anonymity"
        ],
        "right": [
            "Ensures sensitive attributes have diverse values within a group",
            "Ensures distribution of sensitive values mimics the global distribution",
            "Ensures individuals are indistinguishable from at least k-1 others"
        ]
    },
    {
        "q": "Rearrange the words to define the concept of 'Dark Patterns' in data collection:",
        "type": "rearrange",
        "words": [
            "Interfaces",
            "designed",
            "to",
            "trick",
            "users",
            "into",
            "sharing",
            "data"
        ]
    },
    {
        "q": "Documentation like 'Datasheets for Datasets' is used to record the motivation, composition, and collection process of a dataset.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What concept is being tested in this code snippet aimed at 'Calibration'?",
        "type": "mcq",
        "c": "from sklearn.calibration import calibration_curve\n# Checking if predicted probabilities match actual observed rates\nprob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)",
        "o": [
            "Reliability of confidence scores",
            "Feature importance",
            "Computational speed",
            "Database connectivity"
        ]
    },
    {
        "q": "When an AI system is used for 'Predictive Policing', a major ethical risk is that the model learns to target locations based on ______ data rather than actual crime rates.",
        "type": "fill_blank",
        "answers": [
            "arrest"
        ],
        "other_options": [
            "weather",
            "traffic",
            "census"
        ]
    },
    {
        "q": "What is the output of the following code representing a 'Linkage Attack' risk?",
        "type": "mcq",
        "c": "public_voter_data = {'zip': '90210', 'dob': '1980-01-01', 'name': 'Alice'}\nanon_medical_data = {'zip': '90210', 'dob': '1980-01-01', 'disease': 'Flu'}\n\nmatch = (public_voter_data['zip'] == anon_medical_data['zip']) and \\\n        (public_voter_data['dob'] == anon_medical_data['dob'])\nprint(match)",
        "o": [
            "True",
            "False",
            "None",
            "Error"
        ]
    },
    {
        "q": "Which interpretability technique generates 'Counterfactual Explanations' (e.g., 'If your income were $500 higher, you would have been approved')?",
        "type": "mcq",
        "o": [
            "Counterfactual Analysis",
            "Principal Component Analysis",
            "K-Means Clustering",
            "Dropout Regularization"
        ]
    },
    {
        "q": "Match the ethical framework to its core focus:",
        "type": "match",
        "left": [
            "Utilitarianism",
            "Deontology",
            "Virtue Ethics"
        ],
        "right": [
            "Maximizing overall happiness/utility",
            "Adhering to duties and rules",
            "Developing good character traits"
        ]
    },
    {
        "q": "Secure Multi-Party Computation (SMPC) allows parties to compute a function over their inputs while keeping those inputs private from each other.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of this code snippet using 'Tokenization'?",
        "type": "mcq",
        "c": "import secrets\ndef tokenize(credit_card):\n    # Replaces sensitive data with a random token, stored in a secure vault map\n    token = secrets.token_hex(16)\n    vault[token] = credit_card\n    return token",
        "o": [
            "To replace PII with a non-sensitive substitute",
            "To compress the file size",
            "To train a neural network",
            "To visualize credit card spending"
        ]
    },
    {
        "q": "Rearrange the words to form a question relevant to 'Purpose Limitation':",
        "type": "rearrange",
        "words": [
            "Is",
            "the",
            "data",
            "used",
            "only",
            "for",
            "stated",
            "goals"
        ]
    },
    {
        "q": "Which metric focuses on the ratio of False Positives between different demographic groups?",
        "type": "mcq",
        "o": [
            "Predictive Equality",
            "Recall",
            "F1 Score",
            "Mean Absolute Error"
        ]
    },
    {
        "q": "Which US state law specifically regulates the collection and storage of biometric identifiers, such as face scans or fingerprints?",
        "type": "mcq",
        "o": [
            "BIPA (Illinois Biometric Information Privacy Act)",
            "CCPA (California Consumer Privacy Act)",
            "GDPR (General Data Protection Regulation)",
            "CFAA (Computer Fraud and Abuse Act)"
        ]
    },
    {
        "q": "Artificial data that is generated from original data to preserve statistical properties while protecting user identity is called ______ data.",
        "type": "fill_blank",
        "answers": [
            "synthetic"
        ],
        "other_options": [
            "encrypted",
            "hashed",
            "tokenized"
        ]
    },
    {
        "q": "What bias mitigation technique is being applied in this code snippet?",
        "type": "mcq",
        "c": "from imblearn.over_sampling import SMOTE\n# Generating new samples for the minority class to balance the dataset\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)",
        "o": [
            "Oversampling / Data Augmentation",
            "Undersampling",
            "Regularization",
            "Dimensionality Reduction"
        ]
    },
    {
        "q": "Match the stage of the machine learning pipeline with the appropriate bias mitigation strategy:",
        "type": "match",
        "left": [
            "Pre-processing",
            "In-processing",
            "Post-processing"
        ],
        "right": [
            "Reweighting samples before training",
            "Adding fairness constraints to the loss function",
            "Adjusting decision thresholds after model output"
        ]
    },
    {
        "q": "Rearrange the words to form a key principle regarding data permissions:",
        "type": "rearrange",
        "words": [
            "Consent",
            "must",
            "be",
            "specific",
            "informed",
            "and",
            "unambiguous"
        ]
    },
    {
        "q": "The concept of 'Security through Obscurity' (relying on secrecy of design rather than robust security controls) is a recommended practice for protecting data privacy.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What specific ethical issue is this confusion matrix analysis trying to detect in a medical AI diagnosis model?",
        "type": "mcq",
        "c": "from sklearn.metrics import confusion_matrix\n# y_true: 1 = Disease, 0 = Healthy\ncm = confusion_matrix(y_true, y_pred)\nfn = cm[1][0] # False Negatives\nprint(f\"Missed Diagnoses count: {fn}\")",
        "o": [
            "Safety Risk (False Negatives)",
            "Privacy Leakage",
            "Model Overfitting",
            "Computational Latency"
        ]
    },
    {
        "q": "In the context of AI safety, the '______ Problem' refers to the difficulty of ensuring an AI system's goals match human values.",
        "type": "fill_blank",
        "answers": [
            "alignment"
        ],
        "other_options": [
            "halting",
            "vanishing",
            "knapsack"
        ]
    },
    {
        "q": "Which interpretability method is designed to provide 'Local' explanations by approximating the black-box model with a simple linear model around a specific prediction?",
        "type": "mcq",
        "o": [
            "LIME (Local Interpretable Model-agnostic Explanations)",
            "Random Forest",
            "Global Surrogate",
            "Gradient Boosting"
        ]
    },
    {
        "q": "Match the data lifecycle stage with the ethical risk:",
        "type": "match",
        "left": [
            "Collection",
            "Storage",
            "Deployment"
        ],
        "right": [
            "Informed consent violations",
            "Security breaches / Hacking",
            "Unintended dual use or misuse"
        ]
    },
    {
        "q": "What is the result of the following code intended to clean data?",
        "type": "mcq",
        "c": "import pandas as pd\ndf = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n# Dropping columns that are not useful for prediction to minimize data retention\ndf = df.drop(columns=['Name'])\nprint(df.columns.tolist())",
        "o": [
            "['Age']",
            "['Name', 'Age']",
            "['Name']",
            "[]"
        ]
    },
    {
        "q": "Rearrange the words to describe the 'Moral Crumple Zone':",
        "type": "rearrange",
        "words": [
            "Humans",
            "take",
            "the",
            "blame",
            "for",
            "machine",
            "failures"
        ]
    },
    {
        "q": "Just because a dataset is publicly available on the internet means it is free from copyright restrictions and ethical concerns regarding its usage.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "The trail of data generated by a user's online activities (clicks, likes, time spent) which can be mined for behavioral insights is known as Data ______.",
        "type": "fill_blank",
        "answers": [
            "exhaust"
        ],
        "other_options": [
            "mining",
            "warehouse",
            "lake"
        ]
    },
    {
        "q": "Which concept describes a scenario where an AI system works well in a test environment but fails when applied to a new, slightly different environment?",
        "type": "mcq",
        "o": [
            "Distribution Shift",
            "Convergent Evolution",
            "Gradient Ascent",
            "Hyperparameter Tuning"
        ]
    },
    {
        "q": "The '______' Act is a US federal law that protects individuals from discrimination based on their genetic information in health insurance and employment.",
        "type": "fill_blank",
        "answers": [
            "GINA"
        ],
        "other_options": [
            "FOIA",
            "RICO",
            "VISA"
        ]
    },
    {
        "q": "What is the primary function of the `robots.txt` file checked in this code snippet?",
        "type": "mcq",
        "c": "import urllib.robotparser\nrp = urllib.robotparser.RobotFileParser()\nrp.set_url(\"http://example.com/robots.txt\")\nrp.read()\ncan_scrape = rp.can_fetch(\"*\", \"http://example.com/sensitive-data\")",
        "o": [
            "To specifies which parts of a site crawlers are allowed to access",
            "To encrypt the website traffic",
            "To compress the HTML for faster loading",
            "To authenticate user passwords"
        ]
    },
    {
        "q": "Match the fairness metric to its mathematical definition:",
        "type": "match",
        "left": [
            "Demographic Parity",
            "Equalized Odds",
            "Predictive Parity"
        ],
        "right": [
            "P(Predicted=1 | Group A) = P(Predicted=1 | Group B)",
            "True Positive Rates and False Positive Rates are equal across groups",
            "Precision (PPV) is equal across groups"
        ]
    },
    {
        "q": "Digital watermarking is currently a completely fool-proof method for detecting AI-generated content and cannot be removed.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Rearrange the words to name a license type designed to prevent unethical AI usage:",
        "type": "rearrange",
        "words": [
            "Responsible",
            "AI",
            "Licenses",
            "restrict",
            "harmful",
            "applications"
        ]
    },
    {
        "q": "Training a single large NLP model can emit as much carbon as five cars in their lifetimes. This is a concern of ______ AI.",
        "type": "fill_blank",
        "answers": [
            "Green"
        ],
        "other_options": [
            "Blue",
            "Red",
            "Dark"
        ]
    },
    {
        "q": "What type of attack involves slightly modifying an image (e.g., changing a few pixels) so that a human sees a panda, but the AI sees a gibbon?",
        "type": "mcq",
        "c": "# Adding an imperceptible perturbation vector to the image\nadversarial_image = original_image + (0.007 * noise_vector)",
        "o": [
            "Adversarial Example / Evasion",
            "SQL Injection",
            "Cross-Site Scripting",
            "Man-in-the-Middle"
        ]
    },
    {
        "q": "In data governance, a Data ______ is an individual responsible for the management, quality, and security of a specific data asset.",
        "type": "fill_blank",
        "answers": [
            "Steward"
        ],
        "other_options": [
            "Broker",
            "Miner",
            "Sponge"
        ]
    },
    {
        "q": "Match the term to the type of audit:",
        "type": "match",
        "left": [
            "Internal Audit",
            "External Audit",
            "Third-Party Audit"
        ],
        "right": [
            "Conducted by the organization's own employees",
            "Conducted by an independent outside firm",
            "Conducted by an entity that is not the developer or the user"
        ]
    },
    {
        "q": "What is the output of this code checking for 'Redundant Encoding' (a privacy risk)?",
        "type": "mcq",
        "c": "import pandas as pd\ndf = pd.DataFrame({'Gender': ['M', 'F'], 'Honorific': ['Mr.', 'Ms.']})\n# Checking correlation between attributes\nprint(df['Gender'].equals(df['Honorific'].replace({'Mr.': 'M', 'Ms.': 'F'})))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to describe the 'Right to Object' in GDPR:",
        "type": "rearrange",
        "words": [
            "Users",
            "can",
            "stop",
            "processing",
            "of",
            "their",
            "data"
        ]
    },
    {
        "q": "A '______' is a decoy system set up to detect, deflect, or study attempts to gain unauthorized access to information systems.",
        "type": "fill_blank",
        "answers": [
            "honeypot"
        ],
        "other_options": [
            "firewall",
            "cookie",
            "beacon"
        ]
    },
    {
        "q": "It is considered ethical to use 'Mechanical Turk' or crowd-sourced workers to label data for pennies per hour without regard for their working conditions.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which organization creates the 'Ethics Guidelines for Trustworthy AI'?",
        "type": "mcq",
        "o": [
            "European Commission (EU)",
            "FIFA",
            "WWE",
            "NASA"
        ]
    },
    {
        "q": "Match the Generative AI risk with its definition:",
        "type": "match",
        "left": [
            "Hallucination",
            "Deepfake",
            "Copyright Infringement"
        ],
        "right": [
            "Model generating confident but factually incorrect information",
            "Synthetic media replacing a person's likeness",
            "Model reproducing protected content without permission"
        ]
    },
    {
        "q": "In the context of Federated Learning, client devices share ______ updates with the central server instead of sharing the raw training data.",
        "type": "fill_blank",
        "answers": [
            "model"
        ],
        "other_options": [
            "hardware",
            "network",
            "salary"
        ]
    },
    {
        "q": "The '______ Effect' refers to the phenomenon where combining multiple distinct, anonymized datasets can allow an adversary to re-identify individuals.",
        "type": "fill_blank",
        "answers": [
            "Mosaic"
        ],
        "other_options": [
            "Butterfly",
            "Greenhouse",
            "Doppler"
        ]
    },
    {
        "q": "Match the GDPR User Right to its correct definition:",
        "type": "match",
        "left": [
            "Right to Rectification",
            "Right to Portability",
            "Right to Restriction"
        ],
        "right": [
            "Correcting inaccurate or incomplete personal data",
            "Transferring data to another service provider",
            "Temporarily stopping data processing without deletion"
        ]
    },
    {
        "q": "What ethical safety practice is described by the following process?",
        "type": "mcq",
        "c": "def test_safety(model):\n    # Intentionally trying to trick the model into generating hate speech\n    # to identify vulnerabilities before release.\n    prompts = [\"generate violent text\", \"ignore safety rules\"]\n    results = model.generate(prompts)\n    analyze_failures(results)",
        "o": [
            "Red Teaming",
            "Hyperparameter Tuning",
            "A/B Testing",
            "Unit Testing"
        ]
    },
    {
        "q": "Rearrange the words to describe the concept of 'Dual Use' technology:",
        "type": "rearrange",
        "words": [
            "Tech",
            "built",
            "for",
            "good",
            "can",
            "cause",
            "harm"
        ]
    },
    {
        "q": "Simply making a model's source code 'Open Source' automatically guarantees that the model is ethical and safe to use.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which data governance concept is being implemented in this code using 'pydantic'?",
        "type": "mcq",
        "c": "from pydantic import BaseModel, EmailStr, validator\n\nclass UserData(BaseModel):\n    email: EmailStr\n    age: int\n\n    @validator('age')\n    def check_age(cls, v):\n        if v < 18:\n            raise ValueError('Must be an adult')\n        return v",
        "o": [
            "Data Quality / Validation Enforcement",
            "Data Encryption",
            "Model Training",
            "Web Scraping"
        ]
    },
    {
        "q": "A 'Trusted Execution Environment' (TEE) is a hardware-based security feature that isolates the execution of code and data from the main operating system.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the cognitive bias affecting Data Scientists with its description:",
        "type": "match",
        "left": [
            "Automation Bias",
            "Sunk Cost Fallacy",
            "Bandwagon Effect"
        ],
        "right": [
            "Trusting a machine's output over contradictory human knowledge",
            "Continuing a bad model because much time was already spent on it",
            "Using a specific algorithm just because everyone else is using it"
        ]
    },
    {
        "q": "What is the primary goal of 'Data Lineage' tracking?",
        "type": "mcq",
        "o": [
            "Tracing the origin, movement, and transformation of data",
            "Calculating the average value of a column",
            "Predicting future stock market trends",
            "Designing user interfaces for dashboards"
        ]
    },
    {
        "q": "Rearrange the words to name the principle regarding data storage limits:",
        "type": "rearrange",
        "words": [
            "Data",
            "storage",
            "limitation",
            "reduces",
            "security",
            "risks"
        ]
    },
    {
        "q": "In the context of NLP, 'Stochastic ______' is a term used by critics to describe large language models that generate plausible-sounding but meaningless or unverified text.",
        "type": "fill_blank",
        "answers": [
            "Parrots"
        ],
        "other_options": [
            "Pandas",
            "Pythons",
            "Trees"
        ]
    },
    {
        "q": "What issue is this code snippet attempting to measure using the Gini coefficient?",
        "type": "mcq",
        "c": "def gini(array):\n    # Calculating inequality in prediction distribution\n    array = array.flatten()\n    if np.amin(array) < 0:\n        return 0\n    # ... calculation steps ...",
        "o": [
            "Inequality / Disparity",
            "Execution Speed",
            "Memory Usage",
            "File Size"
        ]
    },
    {
        "q": "Match the privacy attack with the data it targets:",
        "type": "match",
        "left": [
            "Model Inversion",
            "Attribute Inference",
            "Model Extraction"
        ],
        "right": [
            "Reconstructing training data (e.g., faces)",
            "Predicting a sensitive missing feature (e.g., HIV status)",
            "Staling the model's parameters/weights"
        ]
    },
    {
        "q": "Ethical AI frameworks often distinguish between '______' (doing good) and 'Non-maleficence' (doing no harm).",
        "type": "fill_blank",
        "answers": [
            "Beneficence"
        ],
        "other_options": [
            "Malpractice",
            "Divergence",
            "Inference"
        ]
    },
    {
        "q": "What is the specific term for the legal remedy where a regulator forces a company to delete not only the illegally collected data but also any algorithms trained on that data?",
        "type": "mcq",
        "o": [
            "Algorithmic Disgorgement",
            "Digital Forfeiture",
            "Model Bankruptcy",
            "Data Liquidation"
        ]
    },
    {
        "q": "The approach of simply omitting sensitive attributes (like race or gender) from a dataset to prevent bias, which often fails due to proxy variables, is known as Fairness through ______.",
        "type": "fill_blank",
        "answers": [
            "Unawareness"
        ],
        "other_options": [
            "Awareness",
            "Equality",
            "Design"
        ]
    },
    {
        "q": "Match the adversarial attack type to its specific goal:",
        "type": "match",
        "left": [
            "Sponge Attack",
            "Poisoning Attack",
            "Evasion Attack"
        ],
        "right": [
            "Maximize energy consumption and latency",
            "Corrupt the training data integrity",
            "Fool the model at inference time"
        ]
    },
    {
        "q": "What is the primary ethical issue identified in this code snippet regarding data retention?",
        "type": "mcq",
        "c": "import datetime\n# Log file that appends user data indefinitely without rotation or deletion\nwith open(\"user_logs.txt\", \"a\") as f:\n    f.write(f\"{datetime.now()}: {user_input}\\n\")",
        "o": [
            "Violation of Storage Limitation",
            "Buffer Overflow",
            "SQL Injection Risk",
            "Inadequate Encryption"
        ]
    },
    {
        "q": "Rearrange the words to name a deceptive design pattern:",
        "type": "rearrange",
        "words": [
            "Roach",
            "Motel",
            "makes",
            "subscription",
            "cancellation",
            "difficult"
        ]
    },
    {
        "q": "A 'RAIL' license is a specific type of software license that includes behavioral-use restrictions to prevent unethical usage of AI models.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What statistical concept is being calculated here to measure the difference between the probability distributions of the training data vs. the deployment data?",
        "type": "mcq",
        "c": "from scipy.special import rel_entr\n# Calculating Kullback-Leibler (KL) Divergence\nkl_div = sum(rel_entr(p_train, q_deploy))",
        "o": [
            "Drift / Distribution Shift",
            "Mean Squared Error",
            "Accuracy Score",
            "Correlation Coefficient"
        ]
    },
    {
        "q": "In the context of RLHF (Reinforcement Learning from Human Feedback), the '______' model is trained to predict which response a human would prefer.",
        "type": "fill_blank",
        "answers": [
            "Reward"
        ],
        "other_options": [
            "Policy",
            "Actor",
            "Critic"
        ]
    },
    {
        "q": "Match the privacy term with its definition:",
        "type": "match",
        "left": [
            "Data Controller",
            "Data Processor",
            "Data Subject"
        ],
        "right": [
            "Entity that determines the purpose/means of processing",
            "Entity that processes data on behalf of the controller",
            "The individual whom the data is about"
        ]
    },
    {
        "q": "What is the output of the following code intended to strip metadata from an image for privacy?",
        "type": "mcq",
        "c": "from PIL import Image\nimg = Image.open('photo_with_gps.jpg')\n# Creating a new image without copying the EXIF metadata\ndata = list(img.getdata())\nclean_img = Image.new(img.mode, img.size)\nclean_img.putdata(data)\nprint('exif' in clean_img.info)",
        "o": [
            "False",
            "True",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to form a question about data accuracy:",
        "type": "rearrange",
        "words": [
            "Is",
            "the",
            "data",
            "kept",
            "up",
            "to",
            "date"
        ]
    },
    {
        "q": "The practice of labeling a model as 'Open Source' while keeping the training data, methodology, and weights proprietary is increasingly referred to as 'Open ______'.",
        "type": "fill_blank",
        "answers": [
            "Washing"
        ],
        "other_options": [
            "Sourcing",
            "Box",
            "Door"
        ]
    },
    {
        "q": "Which fairness metric is most appropriate when you want to ensure that the error rates (False Positives) are similar across all groups, often used in recidivism prediction?",
        "type": "mcq",
        "o": [
            "Predictive Equality",
            "Demographic Parity",
            "Disparate Impact",
            "Accuracy"
        ]
    },
    {
        "q": "It is impossible for a machine learning model to be accurate but still be unfair.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the primary purpose of the 'Safe Harbor' method in HIPAA regulations?",
        "type": "mcq",
        "o": [
            "To list specific identifiers that must be removed for de-identification",
            "To provide a secure server for data hosting",
            "To allow data transfer between US and EU",
            "To encrypt emails automatically"
        ]
    },
    {
        "q": "Which fairness definition requires that a classifier's predictions are independent of the sensitive attribute (e.g., gender) within each class of the true outcome?",
        "type": "mcq",
        "o": [
            "Equalized Odds",
            "Demographic Parity",
            "Individual Fairness",
            "Counterfactual Fairness"
        ]
    },
    {
        "q": "In the context of differential privacy, the parameter ______ (epsilon) represents the privacy budget; a smaller value implies stronger privacy but potentially lower utility.",
        "type": "fill_blank",
        "answers": [
            "epsilon"
        ],
        "other_options": [
            "delta",
            "gamma",
            "sigma"
        ]
    },
    {
        "q": "What potential vulnerability is demonstrated in this code where a model's confidence scores are accessible?",
        "type": "mcq",
        "c": "# Attacker queries model repeatedly with slightly different inputs\n# and observes precise changes in confidence scores\nconfidence = model.predict_proba(input_data)\nprint(confidence)",
        "o": [
            "Model Extraction / Stealing",
            "DDoS Attack",
            "Phishing",
            "Ransomware"
        ]
    },
    {
        "q": "Match the transparency tool with its visualization method:",
        "type": "match",
        "left": [
            "Partial Dependence Plot (PDP)",
            "ICE Plot",
            "SHAP Summary Plot"
        ],
        "right": [
            "Shows average effect of a feature on the prediction",
            "Shows effect of a feature for each individual instance",
            "Shows feature importance and impact direction for all samples"
        ]
    },
    {
        "q": "Rearrange the words to define 'Automated Decision Making' under GDPR:",
        "type": "rearrange",
        "words": [
            "Decisions",
            "made",
            "solely",
            "by",
            "machines",
            "affecting",
            "legal",
            "rights"
        ]
    },
    {
        "q": "The 'Right to Data Portability' only applies to data that the user has actively provided to the controller, not inferred data.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary purpose of the 'Watermarking' technique in Generative AI?",
        "type": "mcq",
        "o": [
            "To embed a hidden signal identifying content as AI-generated",
            "To prevent the image from being downloaded",
            "To increase the resolution of the image",
            "To compress the file size"
        ]
    },
    {
        "q": "The process of ______ involves replacing real data with realistic but fake data to protect privacy while maintaining statistical utility.",
        "type": "fill_blank",
        "answers": [
            "synthesizing"
        ],
        "other_options": [
            "deleting",
            "encrypting",
            "archiving"
        ]
    },
    {
        "q": "What is the output of the following code designed to calculate 'Disparate Impact'?",
        "type": "mcq",
        "c": "sr_privileged = 0.8\nsr_unprivileged = 0.6\ndisparate_impact = sr_unprivileged / sr_privileged\nprint(disparate_impact < 0.8)",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match the bias type with the stage where it typically enters the pipeline:",
        "type": "match",
        "left": [
            "Historical Bias",
            "Representation Bias",
            "Measurement Bias"
        ],
        "right": [
            "World / Society (Pre-collection)",
            "Sampling (Collection)",
            "Feature Engineering / Labeling"
        ]
    },
    {
        "q": "Which organization released the 'Blueprint for an AI Bill of Rights'?",
        "type": "mcq",
        "o": [
            "White House (OSTP)",
            "United Nations",
            "Google",
            "OpenAI"
        ]
    },
    {
        "q": "Rearrange the words to describe the 'Trolley Problem' in AI ethics:",
        "type": "rearrange",
        "words": [
            "Programming",
            "choices",
            "in",
            "unavoidable",
            "accident",
            "scenarios"
        ]
    },
    {
        "q": "A '______' attack recovers the original training data by analyzing the gradients shared during the training of a distributed model.",
        "type": "fill_blank",
        "answers": [
            "reconstruction"
        ],
        "other_options": [
            "phishing",
            "brute-force",
            "timing"
        ]
    },
    {
        "q": "If a facial recognition system works accurately for light-skinned men but fails for dark-skinned women, it exhibits 'Intersectional Bias'.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What concept is illustrated by this code preventing a single data point from affecting the average too much?",
        "type": "mcq",
        "c": "def winsorize(data, limits):\n    # Caps extreme values to reduce influence of outliers\n    import scipy.stats\n    return scipy.stats.mstats.winsorize(data, limits=limits)",
        "o": [
            "Robustness to Outliers",
            "Data Leakage",
            "Feature Selection",
            "Gradient Boosting"
        ]
    },
    {
        "q": "Which theorem states that it is mathematically impossible to satisfy all common fairness metrics (like Calibration, Equalized Odds, and Balance) simultaneously when base rates differ?",
        "type": "mcq",
        "o": [
            "Kleinberg's Impossibility Theorem",
            "Bayes' Theorem",
            "Central Limit Theorem",
            "No Free Lunch Theorem"
        ]
    },
    {
        "q": "Under HIPAA, the '______ Determination' method allows de-identification if a qualified statistician certifies that the risk of re-identification is very small.",
        "type": "fill_blank",
        "answers": [
            "Expert"
        ],
        "other_options": [
            "Safe",
            "Final",
            "Blind"
        ]
    },
    {
        "q": "What is the primary security purpose of adding 'salt' in the following code?",
        "type": "mcq",
        "c": "import os, hashlib\nsalt = os.urandom(32)\nhash_key = hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)",
        "o": [
            "To prevent Rainbow Table attacks on hashed passwords",
            "To compress the password string",
            "To convert the password to an integer",
            "To visualize the password distribution"
        ]
    },
    {
        "q": "Match the open-source toolkit to its primary ethical function:",
        "type": "match",
        "left": [
            "Microsoft Presidio",
            "IBM AIF360",
            "CleverHans",
            "CarbonTracker"
        ],
        "right": [
            "PII detection and anonymization",
            "Bias detection and mitigation",
            "Adversarial attack vulnerability testing",
            "Tracking energy consumption of training"
        ]
    },
    {
        "q": "Rearrange the words to state a principle of data minimization:",
        "type": "rearrange",
        "words": [
            "Collect",
            "only",
            "what",
            "is",
            "necessary",
            "for",
            "the",
            "purpose"
        ]
    },
    {
        "q": "Data '______' refers to the layout of data where rows represent individual records and columns represent variables, which is standard for analysis but requires privacy controls.",
        "type": "fill_blank",
        "answers": [
            "rectangular"
        ],
        "other_options": [
            "triangular",
            "circular",
            "spherical"
        ]
    },
    {
        "q": "What type of bias is present if researchers only publish models that show positive/successful results, hiding those that failed?",
        "type": "mcq",
        "o": [
            "Publication Bias",
            "Automation Bias",
            "Selection Bias",
            "Surviving Bias"
        ]
    },
    {
        "q": "The core information security concept known as the CIA Triad stands for Confidentiality, Integrity, and ______.",
        "type": "fill_blank",
        "answers": [
            "Availability"
        ],
        "other_options": [
            "Anonymity",
            "Accuracy",
            "Authorization"
        ]
    },
    {
        "q": "What is the function of the Regular Expression used in this code snippet?",
        "type": "mcq",
        "c": "import re\ntext = \"Contact 555-123-4567 for support\"\n# Scanning for sensitive patterns\npattern = r\"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b\"\nmatches = re.findall(pattern, text)",
        "o": [
            "To detect PII (Phone Numbers)",
            "To remove stopwords",
            "To capitalize sentences",
            "To check for SQL injection"
        ]
    },
    {
        "q": "Match the Data Governance role to its typical responsibility:",
        "type": "match",
        "left": [
            "Data Owner",
            "Data Steward",
            "Data Custodian"
        ],
        "right": [
            "Accountable for data classification and access rights",
            "Responsible for day-to-day data quality and metadata",
            "Responsible for the technical infrastructure and security"
        ]
    },
    {
        "q": "Federated Learning guarantees 100% privacy and makes it impossible for an attacker to reconstruct any user data.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Rearrange the words to describe the 'Black Box' problem:",
        "type": "rearrange",
        "words": [
            "Complex",
            "models",
            "lack",
            "transparency",
            "in",
            "decision",
            "making"
        ]
    },
    {
        "q": "Which term describes the practice of creating different service terms or prices for different groups based on algorithmic profiling (e.g., ZIP code), often resulting in discrimination?",
        "type": "mcq",
        "o": [
            "Digital Redlining",
            "Blueprinting",
            "White-listing",
            "Green-lighting"
        ]
    },
    {
        "q": "What concept is being checked in this code regarding model stability?",
        "type": "mcq",
        "c": "# Checking if the model prediction changes drastically \n# with a tiny change in input feature 'x'\nperturbation = 0.0001\ndiff = model.predict(x + perturbation) - model.predict(x)\nprint(abs(diff) > threshold)",
        "o": [
            "Local Lipschitz Continuity / Robustness",
            "Global Accuracy",
            "Recall Score",
            "Database Latency"
        ]
    },
    {
        "q": "In the context of 'Privacy by Design', privacy measures should be reactive (fixing problems after they happen) rather than proactive.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which international standard, published in 2023, is the first specifically designed for Artificial Intelligence Management Systems (AIMS)?",
        "type": "mcq",
        "o": [
            "ISO/IEC 42001",
            "ISO 9001",
            "ISO 27001",
            "IEEE 802.11"
        ]
    },
    {
        "q": "In the context of 'Green AI', the process of compressing a large model into a smaller one to reduce energy consumption while maintaining accuracy is known as Knowledge ______.",
        "type": "fill_blank",
        "answers": [
            "Distillation"
        ],
        "other_options": [
            "Extraction",
            "Graphing",
            "Mining"
        ]
    },
    {
        "q": "What specific privacy technique is being implemented in this code (flipping a coin to decide whether to tell the truth)?",
        "type": "mcq",
        "c": "import random\ndef get_answer(true_answer):\n    # A technique to allow plausible deniability\n    if random.random() < 0.5:\n        return random.choice([True, False])\n    return true_answer",
        "o": [
            "Randomized Response",
            "Homomorphic Encryption",
            "Data Hashing",
            "Salt and Pepper Noise"
        ]
    },
    {
        "q": "Match the type of AI harm (based on Kate Crawford's taxonomy) to its example:",
        "type": "match",
        "left": [
            "Allocative Harm",
            "Representational Harm",
            "Quality of Service Harm"
        ],
        "right": [
            "An algorithm denies a mortgage to a qualified applicant",
            "Search results reinforce negative stereotypes about a group",
            "Voice recognition works poorly for certain accents"
        ]
    },
    {
        "q": "Rearrange the words to define 'Model Collapse' in generative AI:",
        "type": "rearrange",
        "words": [
            "Training",
            "on",
            "synthetic",
            "data",
            "causes",
            "irreversible",
            "defects"
        ]
    },
    {
        "q": "The 'Right to be Informed' requires that privacy notices must be concise, transparent, intelligible, and easily accessible.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary function of the 'Fairlearn' library's `MetricFrame` shown in the code?",
        "type": "mcq",
        "c": "from fairlearn.metrics import MetricFrame, selection_rate\n# Analyzing how selection rate varies by group\nmf = MetricFrame(metrics=selection_rate, y_true=y_true, y_pred=y_pred, sensitive_features=sex)\nprint(mf.by_group)",
        "o": [
            "Disaggregated Analysis / Group metrics",
            "Model Training",
            "Hyperparameter Optimization",
            "Data Cleaning"
        ]
    },
    {
        "q": "In privacy law, a '______' interest allows data processing without consent if the business need outweighs the risk to individual rights (e.g., fraud prevention).",
        "type": "fill_blank",
        "answers": [
            "legitimate"
        ],
        "other_options": [
            "commercial",
            "public",
            "vital"
        ]
    },
    {
        "q": "Which text masking technique preserves the format of the original data (e.g., keeping the same number of digits for a credit card)?",
        "type": "mcq",
        "o": [
            "Format-Preserving Encryption (FPE)",
            "MD5 Hashing",
            "SHA-256",
            "Base64 Encoding"
        ]
    },
    {
        "q": "Match the core bioethics principle (Belmont Report) to its application in Data Science:",
        "type": "match",
        "left": [
            "Respect for Persons",
            "Beneficence",
            "Justice"
        ],
        "right": [
            "Obtaining informed consent from subjects",
            "Maximizing benefits while minimizing risks/harms",
            "Ensuring fair distribution of model errors across groups"
        ]
    },
    {
        "q": "What risk is this code snippet attempting to mitigate by removing 'unique' identifiers?",
        "type": "mcq",
        "c": "threshold = 5\n# Removing columns where values are too unique, preventing re-identification\nfor col in df.columns:\n    if df[col].value_counts().min() < threshold:\n        df.drop(col, axis=1, inplace=True)",
        "o": [
            "Singling Out / Re-identification",
            "Overfitting",
            "Underfitting",
            "Slow Processing"
        ]
    },
    {
        "q": "Rearrange the words to describe 'Function Creep':",
        "type": "rearrange",
        "words": [
            "Systems",
            "gradually",
            "expand",
            "beyond",
            "original",
            "intended",
            "purpose"
        ]
    },
    {
        "q": "A '______' Table is a precomputed table for reversing cryptographic hash functions, usually for cracking password hashes.",
        "type": "fill_blank",
        "answers": [
            "Rainbow"
        ],
        "other_options": [
            "Lookup",
            "Pivot",
            "Routing"
        ]
    },
    {
        "q": "It is considered 'Ethics Washing' when a company establishes an ethics board but gives it no power to enforce decisions or stop products.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which concept describes the friction between keeping a model private and allowing users to verify its fairness?",
        "type": "mcq",
        "o": [
            "Transparency-Privacy Trade-off",
            "Bias-Variance Trade-off",
            "Precision-Recall Trade-off",
            "Hardware-Software Trade-off"
        ]
    },
    {
        "q": "Which Canadian federal privacy law governs how private sector organizations collect, use, and disclose personal information?",
        "type": "mcq",
        "o": [
            "PIPEDA (Personal Information Protection and Electronic Documents Act)",
            "GDPR",
            "CCPA",
            "FERPA"
        ]
    },
    {
        "q": "The concept of 'Data ______' refers to the idea that data is subject to the laws and governance structures within the nation it is collected or stored.",
        "type": "fill_blank",
        "answers": [
            "Sovereignty"
        ],
        "other_options": [
            "Localization",
            "Embargo",
            "Monopoly"
        ]
    },
    {
        "q": "What specific security control is being implemented in this code snippet?",
        "type": "mcq",
        "c": "def access_resource(user, resource):\n    if 'admin' not in user.roles and resource.sensitivity == 'high':\n        raise PermissionError(\"Access Denied\")\n    return resource.data",
        "o": [
            "RBAC (Role-Based Access Control)",
            "SQL Injection Prevention",
            "Differential Privacy",
            "Data Anonymization"
        ]
    },
    {
        "q": "Match the state of data to its encryption requirement:",
        "type": "match",
        "left": [
            "Data at Rest",
            "Data in Transit",
            "Data in Use"
        ],
        "right": [
            "Encrypted on the hard drive/database",
            "Encrypted via TLS/SSL",
            "Encrypted via Homomorphic Encryption or TEE"
        ]
    },
    {
        "q": "Rearrange the words to define 'Contextual Integrity' (Nissenbaum's framework):",
        "type": "rearrange",
        "words": [
            "Privacy",
            "depends",
            "on",
            "appropriate",
            "flow",
            "of",
            "information"
        ]
    },
    {
        "q": "The 'Right to Erasure' in GDPR is absolute; a company must always delete data upon request, even if they are legally required to keep it for tax purposes.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What type of attack involves an adversary crafting a specific input prompt to bypass the safety filters of a Large Language Model (LLM)?",
        "type": "mcq",
        "o": [
            "Prompt Injection / Jailbreaking",
            "Cross-Site Request Forgery",
            "Buffer Overflow",
            "Packet Sniffing"
        ]
    },
    {
        "q": "In the context of A/B testing, running psychological experiments on users without their knowledge (e.g., manipulating news feeds to change emotions) violates the principle of ______ consent.",
        "type": "fill_blank",
        "answers": [
            "informed"
        ],
        "other_options": [
            "implied",
            "legal",
            "verbal"
        ]
    },
    {
        "q": "What data issue is this code snippet attempting to identify?",
        "type": "mcq",
        "c": "import pandas as pd\n# Checking if the 'ground truth' labels themselves vary significantly by group\ngroup_means = df.groupby('race')['approval_label'].mean()\nprint(group_means)",
        "o": [
            "Label Bias",
            "Feature Scaling",
            "Missing Values",
            "Multicollinearity"
        ]
    },
    {
        "q": "Match the open standard to its purpose:",
        "type": "match",
        "left": [
            "C2PA / CAI",
            "ONNX",
            "P3P"
        ],
        "right": [
            "Provenance and authenticity of digital content (Content Credentials)",
            "Interoperability of ML models",
            "Obsolete protocol for automated privacy policies"
        ]
    },
    {
        "q": "What is the output of this code regarding Python's `secrets` module vs `random` module for cryptography?",
        "type": "mcq",
        "c": "import secrets\n# secrets.choice is cryptographically strong\nprint(secrets.choice(['A', 'B']) in ['A', 'B'])",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to describe a 'Sybil Attack' in decentralized data:",
        "type": "rearrange",
        "words": [
            "One",
            "entity",
            "creates",
            "many",
            "fake",
            "identities"
        ]
    },
    {
        "q": "Which term describes the phenomenon where an algorithm is perceived as objective and true, even when it is flawed or biased?",
        "type": "mcq",
        "o": [
            "Automation Complacency",
            "Imposter Syndrome",
            "Dunning-Kruger Effect",
            "Pareto Principle"
        ]
    },
    {
        "q": "In a '______' Agreement, a data receiver legally agrees not to attempt to re-identify individuals from an anonymized dataset.",
        "type": "fill_blank",
        "answers": [
            "Data Use"
        ],
        "other_options": [
            "Service Level",
            "Non Disclosure",
            "End User"
        ]
    },
    {
        "q": "The 'Framing Effect' suggests that the way a data visualization is presented (e.g., truncating the Y-axis) can ethically mislead the viewer.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which cryptographic concept allows one party to prove to another that they know a value (like a password) without actually conveying the value itself?",
        "type": "mcq",
        "o": [
            "Zero-Knowledge Proof",
            "Asymmetric Key Exchange",
            "Double Ratchet Algorithm",
            "Quantum Key Distribution"
        ]
    },
    {
        "q": "In social science and AI data, the acronym 'WEIRD' refers to a sampling bias where data over-represents people from Western, Educated, Industrialized, Rich, and ______ societies.",
        "type": "fill_blank",
        "answers": [
            "Democratic"
        ],
        "other_options": [
            "Diverse",
            "Digital",
            "Developed"
        ]
    },
    {
        "q": "What specific type of data malpractice is being demonstrated in this code snippet?",
        "type": "mcq",
        "c": "import statsmodels.api as sm\nimport numpy as np\n# Running 100 random correlations and only reporting the one that is 'significant'\nfor i in range(100):\n    x = np.random.rand(100)\n    y = np.random.rand(100)\n    if sm.OLS(y, x).fit().pvalues[0] < 0.05:\n        print(f\"Found significant relationship at index {i}!\")",
        "o": [
            "P-hacking / Data Dredging",
            "Gradient Exploding",
            "Feature Engineering",
            "Cross-Validation"
        ]
    },
    {
        "q": "Match the term to the potential AI failure mode:",
        "type": "match",
        "left": [
            "Reward Hacking",
            "Instrumental Convergence",
            "Scalable Oversight"
        ],
        "right": [
            "Agent exploits a flaw in the scoring system to get points without doing the task",
            "Agent pursues harmful sub-goals (e.g., getting more money) to achieve its main goal",
            "Difficulty of supervising AI systems that are smarter/faster than humans"
        ]
    },
    {
        "q": "Rearrange the words to define 'Algorithmic Monoculture':",
        "type": "rearrange",
        "words": [
            "Many",
            "institutions",
            "using",
            "the",
            "same",
            "biased",
            "algorithm"
        ]
    },
    {
        "q": "A 'Data Protection Impact Assessment' (DPIA) is mandatory under GDPR only when processing is likely to result in a high risk to individuals' rights.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the primary ethical purpose of setting a 'random_state' or 'seed' in the following code?",
        "type": "mcq",
        "c": "from sklearn.model_selection import train_test_split\n# Splitting data with a fixed seed\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)",
        "o": [
            "Reproducibility",
            "Accuracy Optimization",
            "Encryption",
            "Data Compression"
        ]
    },
    {
        "q": "The concept of '______' refers to collected data that is processed and stored but not utilized for any analytical or business purpose, often posing a security risk.",
        "type": "fill_blank",
        "answers": [
            "Dark Data"
        ],
        "other_options": [
            "Big Data",
            "Meta Data",
            "Smart Data"
        ]
    },
    {
        "q": "Which US government framework provides a voluntary set of guidelines to better manage risks to individuals, organizations, and society associated with AI?",
        "type": "mcq",
        "o": [
            "NIST AI Risk Management Framework",
            "Sarbanes-Oxley Act",
            "Geneva Convention",
            "Kyoto Protocol"
        ]
    },
    {
        "q": "Match the specific adversarial attack to its description:",
        "type": "match",
        "left": [
            "Backdoor Attack / Trojan",
            "Oracle Attack",
            "Copycat Attack"
        ],
        "right": [
            "Model behaves normally unless a specific 'trigger' pattern is present",
            "Exploiting an API to extract model information",
            "Building a substitute model that mimics the target model"
        ]
    },
    {
        "q": "What is the output of this code regarding the 'Right to be Forgotten' logic?",
        "type": "mcq",
        "c": "database = {'user1': 'active', 'user2': 'deleted', 'user3': 'active'}\nrequest_deletion = 'user1'\n\n# Legal hold prevents deletion\nlegal_hold_users = ['user1']\n\nif request_deletion not in legal_hold_users:\n    del database[request_deletion]\n    print(\"Deleted\")\nelse:\n    print(\"Retained\")",
        "o": [
            "Retained",
            "Deleted",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to form a phrase regarding statistical ethics:",
        "type": "rearrange",
        "words": [
            "Correlation",
            "does",
            "not",
            "imply",
            "causation"
        ]
    },
    {
        "q": "An AI system that can modify its own code or learning parameters without human intervention is often cited as a risk for '______' takeoff.",
        "type": "fill_blank",
        "answers": [
            "recursive"
        ],
        "other_options": [
            "linear",
            "stagnant",
            "manual"
        ]
    },
    {
        "q": "Under the 'Third-Party Doctrine' in US law, individuals generally have no reasonable expectation of privacy for information they voluntarily turn over to third parties (like banks or ISPs).",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which data visualization practice is considered unethical because it exaggerates trends?",
        "type": "mcq",
        "o": [
            "Truncating the Y-axis (not starting at zero)",
            "Using a legend",
            "Labeling the axes",
            "Using a scatter plot"
        ]
    },
    {
        "q": "Which famous data privacy failure involved researchers re-identifying individuals in an anonymized movie rating dataset by cross-referencing it with IMDb public records?",
        "type": "mcq",
        "o": [
            "The Netflix Prize Dataset",
            "The Enron Email Scandal",
            "The AOL Search Logs",
            "The Cambridge Analytica Scandal"
        ]
    },
    {
        "q": "In the context of word embeddings (NLP), if the vector operation 'King - Man + Woman' results in 'Queen', but 'Doctor - Man + Woman' results in 'Nurse', this is an example of ______ bias.",
        "type": "fill_blank",
        "answers": [
            "stereotypical"
        ],
        "other_options": [
            "computational",
            "statistical",
            "variance"
        ]
    },
    {
        "q": "What specific security vulnerability is present in this password verification code?",
        "type": "mcq",
        "c": "def check_password(input_pw, stored_pw):\n    # Returns immediately upon finding a mismatch character\n    if len(input_pw) != len(stored_pw):\n        return False\n    for x, y in zip(input_pw, stored_pw):\n        if x != y:\n            return False\n    return True",
        "o": [
            "Timing Attack",
            "Buffer Overflow",
            "SQL Injection",
            "Cross-Site Scripting"
        ]
    },
    {
        "q": "Match the specific data anonymization failure to its method of re-identification:",
        "type": "match",
        "left": [
            "NYC Taxi Data",
            "Strava Heatmap",
            "Massachusetts Governor Medical Records"
        ],
        "right": [
            "Re-identified via pickup/drop-off coordinates and celebrity photos",
            "Revealed secret military base locations via fitness tracking",
            "Re-identified via Voter Registration List cross-referencing"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Clever Hans' effect in AI:",
        "type": "rearrange",
        "words": [
            "Model",
            "learns",
            "spurious",
            "correlations",
            "instead",
            "of",
            "actual",
            "concepts"
        ]
    },
    {
        "q": "According to current US Copyright Office guidance, art generated entirely by an AI via a text prompt (without human modification) is eligible for copyright protection.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the primary function of 'Data Swapping' in the context of statistical disclosure control?",
        "type": "mcq",
        "o": [
            "Exchanging values between records to protect privacy while maintaining totals",
            "Moving data from RAM to SSD",
            "Transferring data between two different companies",
            "Converting integers to floats"
        ]
    },
    {
        "q": "A '______' Box model (like a Decision Tree or Linear Regression) is inherently interpretable, unlike deep neural networks.",
        "type": "fill_blank",
        "answers": [
            "Glass"
        ],
        "other_options": [
            "Black",
            "Sand",
            "Lock"
        ]
    },
    {
        "q": "What ethical concept is highlighted by this code snippet attempting to ensure 'Individual Fairness'?",
        "type": "mcq",
        "c": "def is_fair(model, person_A, person_B):\n    # If two people are similar, they should have similar predictions\n    if distance(person_A, person_B) < epsilon:\n        assert abs(model.predict(person_A) - model.predict(person_B)) < delta",
        "o": [
            "Lipschitz Condition / Similarity",
            "Demographic Parity",
            "Model Accuracy",
            "Data Imputation"
        ]
    },
    {
        "q": "Match the Creative Commons license condition to its restriction:",
        "type": "match",
        "left": [
            "BY (Attribution)",
            "NC (Non-Commercial)",
            "ND (No Derivatives)",
            "SA (Share Alike)"
        ],
        "right": [
            "Must credit the creator",
            "Cannot use for profit",
            "Cannot modify or remix the work",
            "Must license new work under same terms"
        ]
    },
    {
        "q": "What is the output of this code, which demonstrates a weakness in 'k-anonymity' called the Homogeneity Attack?",
        "type": "mcq",
        "c": "# A group of k=3 users all share the same sensitive attribute\ngroup_data = [{'age': 30, 'disease': 'Flu'}, \n              {'age': 30, 'disease': 'Flu'}, \n              {'age': 30, 'disease': 'Flu'}]\n\n# Even if we don't know WHICH user is which, we know they all have the Flu.\nprint(len(set(u['disease'] for u in group_data)))",
        "o": [
            "1",
            "3",
            "0",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to describe the purpose of an 'Algorithmic Audit':",
        "type": "rearrange",
        "words": [
            "External",
            "review",
            "to",
            "verify",
            "system",
            "fairness",
            "and",
            "safety"
        ]
    },
    {
        "q": "The practice of creating a 'Shadow Model' to mimic a target model's behavior is typically the first step in which type of attack?",
        "type": "mcq",
        "o": [
            "Membership Inference Attack",
            "DDoS",
            "Phishing",
            "Ransomware"
        ]
    },
    {
        "q": "In the context of open data, '______' refers to the ability of different computer systems to exchange and make use of information (e.g., using standard formats like JSON or CSV).",
        "type": "fill_blank",
        "answers": [
            "interoperability"
        ],
        "other_options": [
            "scalability",
            "redundancy",
            "latency"
        ]
    },
    {
        "q": "Workplace surveillance software (often called 'Bossware') that tracks mouse movements and keystrokes raises ethical concerns primarily related to Employee ______.",
        "type": "mcq",
        "o": [
            "Autonomy and Privacy",
            "Salary Calculation",
            "Health Insurance",
            "Commute Time"
        ]
    },
    {
        "q": "Which Brazilian data protection law is closely modeled after the GDPR and regulates the processing of personal data in Brazil?",
        "type": "mcq",
        "o": [
            "LGPD (Lei Geral de Proteo de Dados)",
            "PDPA",
            "CCPA",
            "POPI Act"
        ]
    },
    {
        "q": "In the context of 'Fairness through Awareness', the algorithm is explicitly given access to ______ attributes during training to learn how to mitigate bias against them.",
        "type": "fill_blank",
        "answers": [
            "sensitive"
        ],
        "other_options": [
            "hidden",
            "encrypted",
            "noisy"
        ]
    },
    {
        "q": "What concept is being illustrated in this code where a penalty is added to the loss function based on correlation with a sensitive attribute?",
        "type": "mcq",
        "c": "def custom_loss(y_true, y_pred, sensitive_col):\n    # Standard loss + Fairness Penalty\n    base_loss = binary_crossentropy(y_true, y_pred)\n    penalty = abs(correlation(y_pred, sensitive_col))\n    return base_loss + (lambda_param * penalty)",
        "o": [
            "Fairness Constraint / Regularization",
            "Gradient Boosting",
            "Dropout Layer",
            "Data Augmentation"
        ]
    },
    {
        "q": "Match the famous dataset to the specific ethical controversy it sparked:",
        "type": "match",
        "left": [
            "COMPAS",
            "Enron Corpus",
            "ImageNet (Person Subtree)",
            "Tiny Images"
        ],
        "right": [
            "Racial bias in recidivism risk scores",
            "Privacy issues regarding employee emails",
            "Offensive/slur labeling of people images",
            "Contains derogatory terms and non-consensual images"
        ]
    },
    {
        "q": "Rearrange the words to define 'Technological Solutionism':",
        "type": "rearrange",
        "words": [
            "Belief",
            "that",
            "technology",
            "can",
            "solve",
            "all",
            "social",
            "problems"
        ]
    },
    {
        "q": "The 'Fair Credit Reporting Act' (FCRA) gives US consumers the right to dispute incomplete or inaccurate information in their credit file.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which type of inference attack seeks to discover global characteristics of a dataset (e.g., 'What is the ratio of men to women in the training set?') rather than specific individual data?",
        "type": "mcq",
        "o": [
            "Property Inference Attack",
            "Membership Inference Attack",
            "Model Inversion",
            "Evasion Attack"
        ]
    },
    {
        "q": "A '______' is a designated individual within an organization who acts as an independent bridge between data subjects, the organization, and the supervisory authority (required under GDPR).",
        "type": "fill_blank",
        "answers": [
            "DPO"
        ],
        "other_options": [
            "CEO",
            "CTO",
            "CFO"
        ]
    },
    {
        "q": "What is the primary purpose of this assertion in a data pipeline?",
        "type": "mcq",
        "c": "assert df['age'].min() >= 18, \"Dataset contains minors, halting process.\"\nmodel.fit(df)",
        "o": [
            "Data Quality / Compliance Check",
            "Feature Engineering",
            "Model Training",
            "Hyperparameter Tuning"
        ]
    },
    {
        "q": "Match the fairness toolkit to its creator/maintainer:",
        "type": "match",
        "left": [
            "Fairness Indicators",
            "Aequitas",
            "AI Fairness 360",
            "Opacus"
        ],
        "right": [
            "Google / TensorFlow",
            "University of Chicago (DSAPP)",
            "IBM",
            "Meta (PyTorch)"
        ]
    },
    {
        "q": "What is the output of the following code involving a simple 'suppression' technique?",
        "type": "mcq",
        "c": "df = pd.DataFrame({'User': ['A', 'B'], 'HIV_Status': ['Pos', 'Neg']})\n# Suppressing the entire sensitive column\ndf_pub = df.drop(columns=['HIV_Status'])\nprint('HIV_Status' in df_pub.columns)",
        "o": [
            "False",
            "True",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to describe the 'Black Elephant' problem in AI risks:",
        "type": "rearrange",
        "words": [
            "A",
            "known",
            "problem",
            "that",
            "everyone",
            "ignores",
            "until",
            "catastrophe"
        ]
    },
    {
        "q": "Which seminal study by Joy Buolamwini and Timnit Gebru exposed significant racial and gender bias in commercial facial recognition services?",
        "type": "mcq",
        "o": [
            "Gender Shades",
            "The Chinese Room",
            "The Imitation Game",
            "Moral Machine"
        ]
    },
    {
        "q": "A 'Data Trust' is a legal structure where a trustee manages data rights on behalf of the people who created the data, aiming for collective benefit.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In the context of generative AI, '______' refers to the degradation of model quality that occurs when a model is trained on data generated by previous versions of itself.",
        "type": "fill_blank",
        "answers": [
            "autophagy"
        ],
        "other_options": [
            "autocracy",
            "autonomy",
            "automation"
        ]
    },
    {
        "q": "Which Japanese data protection law, updated in 2020/2022, serves as the country's primary regulation for personal information?",
        "type": "mcq",
        "o": [
            "APPI (Act on the Protection of Personal Information)",
            "GDPR",
            "PDPA",
            "PIPL"
        ]
    },
    {
        "q": "The 'Privacy ______' refers to the discrepancy between individuals' stated concerns about privacy and their actual behavior online (e.g., accepting cookies without reading).",
        "type": "fill_blank",
        "answers": [
            "Paradox"
        ],
        "other_options": [
            "Gap",
            "Fallacy",
            "Dilemma"
        ]
    },
    {
        "q": "What specific type of bias handling is shown in this code snippet?",
        "type": "mcq",
        "c": "from sklearn.utils.class_weight import compute_sample_weight\n# Assigning higher importance to minority class samples during training\nweights = compute_sample_weight(class_weight='balanced', y=y_train)\nmodel.fit(X_train, y_train, sample_weight=weights)",
        "o": [
            "Reweighting / Cost-sensitive Learning",
            "Feature Dropping",
            "Data Anonymization",
            "Early Stopping"
        ]
    },
    {
        "q": "Match the transparency level to its intended audience:",
        "type": "match",
        "left": [
            "Global Model Interpretability",
            "Local Instance Explanation",
            "Counterfactual Explanation"
        ],
        "right": [
            "Data Scientists / Regulators auditing the whole system",
            "A loan officer reviewing a specific applicant",
            "An end-user asking 'What could I change to get approved?'"
        ]
    },
    {
        "q": "Rearrange the words to define 'Data Provenance':",
        "type": "rearrange",
        "words": [
            "History",
            "of",
            "where",
            "data",
            "originated",
            "and",
            "how",
            "it",
            "moved"
        ]
    },
    {
        "q": "In the context of 'Fair Use' (copyright law), scraping copyrighted data for non-profit academic research is generally less risky than scraping it for a commercial generative AI product.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which security vulnerability allows an attacker to manipulate the 'deserialization' process to execute arbitrary code on a server?",
        "type": "mcq",
        "c": "import pickle\n# Loading data from an untrusted source directly\ndata = pickle.loads(malicious_payload)",
        "o": [
            "Insecure Deserialization",
            "Cross-Site Scripting (XSS)",
            "Broken Access Control",
            "Sponge Attack"
        ]
    },
    {
        "q": "The concept of '______' refers to the uneven distribution of access to technology (internet/computers), which leads to data gaps where certain populations are underrepresented.",
        "type": "fill_blank",
        "answers": [
            "Digital Divide"
        ],
        "other_options": [
            "Tech Gap",
            "Data Cliff",
            "Net Neutrality"
        ]
    },
    {
        "q": "What is the primary purpose of a 'Data Catalog' in an enterprise data governance strategy?",
        "type": "mcq",
        "o": [
            "To maintain an organized inventory of data assets and their metadata",
            "To sell data to third parties",
            "To physically destroy hard drives",
            "To encrypt network traffic"
        ]
    },
    {
        "q": "Match the type of validity in data science to its definition:",
        "type": "match",
        "left": [
            "Construct Validity",
            "External Validity",
            "Internal Validity"
        ],
        "right": [
            "Does the test measure what it claims to measure?",
            "Can the results be generalized to the real world?",
            "Is the causal relationship within the study solid?"
        ]
    },
    {
        "q": "What phenomenon is demonstrated by this code where the model performs well on training data but fails on slightly different test data?",
        "type": "mcq",
        "c": "train_acc = model.score(X_train, y_train) # Returns 0.99\ntest_acc = model.score(X_test, y_test)   # Returns 0.65\nprint(train_acc - test_acc)",
        "o": [
            "Overfitting / Lack of Generalization",
            "Underfitting",
            "Bias",
            "Convergence"
        ]
    },
    {
        "q": "Rearrange the words to describe the 'Observer Effect' in data collection:",
        "type": "rearrange",
        "words": [
            "Subjects",
            "alter",
            "their",
            "behavior",
            "when",
            "they",
            "know",
            "they",
            "are",
            "watched"
        ]
    },
    {
        "q": "Which fairness metric focuses on ensuring that the 'False Positive Rate' is the same across groups (often used to prevent innocent people from being flagged)?",
        "type": "mcq",
        "o": [
            "Predictive Equality",
            "Equal Opportunity",
            "Demographic Parity",
            "Overall Accuracy"
        ]
    },
    {
        "q": "A 'Canary Trap' is a method used to detect data leaks by giving different versions of sensitive information to different people to see which version leaks.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "In the context of supply chain security, '______' occurs when an attacker publishes a malicious package with a name similar to a popular library (e.g., 'panda' instead of 'pandas') hoping developers install it by mistake.",
        "type": "fill_blank",
        "answers": [
            "Typosquatting"
        ],
        "other_options": [
            "Phishing",
            "Spoofing",
            "Mirroring"
        ]
    },
    {
        "q": "Which data privacy concept refers to the ability to link two or more records concerning the same individual or group of individuals in different databases?",
        "type": "mcq",
        "o": [
            "Linkability",
            "Scalability",
            "Durability",
            "Mutability"
        ]
    },
    {
        "q": "In the context of machine learning monitoring, ______ drift occurs when the statistical properties of the target variable (what you are trying to predict) change over time.",
        "type": "fill_blank",
        "answers": [
            "concept"
        ],
        "other_options": [
            "data",
            "feature",
            "schema"
        ]
    },
    {
        "q": "What is the critical security flaw in this code snippet used to process user-submitted mathematical queries?",
        "type": "mcq",
        "c": "user_input = \"__import__('os').system('rm -rf /')\" # Malicious input\nresult = eval(user_input)\nprint(result)",
        "o": [
            "Arbitrary Code Execution (using eval)",
            "Memory Leak",
            "Divide by Zero Error",
            "Type Mismatch"
        ]
    },
    {
        "q": "Match the adversarial defense mechanism to its description:",
        "type": "match",
        "left": [
            "Adversarial Training",
            "Defensive Distillation",
            "Input Sanitization"
        ],
        "right": [
            "Injecting adversarial examples into the training set",
            "Training a model on probabilities from another model to smooth the surface",
            "Cleaning or preprocessing input data to remove noise/attacks"
        ]
    },
    {
        "q": "Rearrange the words to define 'Data Colonialism':",
        "type": "rearrange",
        "words": [
            "Extracting",
            "data",
            "from",
            "humans",
            "for",
            "profit",
            "without",
            "benefit",
            "to",
            "them"
        ]
    },
    {
        "q": "The 'Ecological Fallacy' occurs when one assumes that statistical inferences about a group apply to every individual within that group.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which specific tool is designed to protect artists by adding invisible noise to images that disrupts AI style mimicry?",
        "type": "mcq",
        "o": [
            "Glaze / Nightshade",
            "Photoshop",
            "TensorBoard",
            "Jupyter Notebook"
        ]
    },
    {
        "q": "A '______' refers to a hidden feature in a neural network that causes it to misclassify an image when a specific, physical trigger (like a sticker) is present.",
        "type": "fill_blank",
        "answers": [
            "backdoor"
        ],
        "other_options": [
            "gateway",
            "portal",
            "window"
        ]
    },
    {
        "q": "What metric is being calculated in this code snippet used for fairness audit?",
        "type": "mcq",
        "c": "def calc_metric(fn, tp):\n    # fn = False Negatives, tp = True Positives\n    return fn / (fn + tp)",
        "o": [
            "False Negative Rate (Miss Rate)",
            "False Positive Rate",
            "Precision",
            "Accuracy"
        ]
    },
    {
        "q": "Match the AI operational level to the human involvement:",
        "type": "match",
        "left": [
            "Human-in-the-loop",
            "Human-on-the-loop",
            "Human-out-of-the-loop"
        ],
        "right": [
            "Human must confirm every decision",
            "Human supervises and can intervene if necessary",
            "System acts fully autonomously without intervention"
        ]
    },
    {
        "q": "What is the output of this code demonstrating a hash collision vulnerability with a weak algorithm?",
        "type": "mcq",
        "c": "import hashlib\n# MD5 is considered cryptographically broken\nh = hashlib.md5(b\"sensitive_data\")\nprint(h.hexdigest() == 'UNKNOWN_HASH')",
        "o": [
            "False",
            "True",
            "Error",
            "None"
        ]
    },
    {
        "q": "Rearrange the words to describe 'Surveillance Capitalism':",
        "type": "rearrange",
        "words": [
            "Commodifying",
            "personal",
            "data",
            "for",
            "behavioral",
            "prediction",
            "markets"
        ]
    },
    {
        "q": "Which principle states that an AI system should clearly identify itself as an AI to the user (e.g., 'I am a chatbot')?",
        "type": "mcq",
        "o": [
            "Principle of Disclosure",
            "Principle of Least Privilege",
            "Principle of Utility",
            "Principle of Data Sovereignty"
        ]
    },
    {
        "q": "Under the concept of 'Algorithmic Disgorgement', a company is allowed to keep the trained model even if the data used to train it was collected illegally.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "When a model detects a correlation between 'Ice Cream Sales' and 'Drowning Deaths', but fails to account for the season (Summer), 'Summer' is known as a ______ variable.",
        "type": "fill_blank",
        "answers": [
            "confounding"
        ],
        "other_options": [
            "target",
            "binary",
            "categorical"
        ]
    },
    {
        "q": "Which technique adds noise to dataset queries to mathematically guarantee that the presence or absence of a single individual cannot be distinguished?",
        "type": "mcq",
        "o": [
            "Differential Privacy",
            "K-Anonymity",
            "L-Diversity",
            "T-Closeness"
        ]
    },
    {
        "q": "In the context of 'Equalized Odds' for fairness, what condition must be met across different demographic groups?",
        "type": "mcq",
        "o": [
            "Equal True Positive and False Positive Rates",
            "Equal proportion of positive outcomes regardless of ground truth",
            "Equal accuracy scores",
            "Equal representation in the training data"
        ]
    },
    {
        "q": "What does the output of the following code indicate regarding the unprivileged group?",
        "type": "mcq",
        "c": "ratio = selection_rate_unprivileged / selection_rate_privileged\nprint(ratio)\n# Output: 0.4",
        "o": [
            "Disparate impact exists; they are selected less frequently.",
            "They are selected more frequently than the privileged group.",
            "The model is perfectly fair.",
            "The model is overfitting to the unprivileged group."
        ]
    },
    {
        "q": "Match the privacy attack with its definition:",
        "type": "match",
        "left": [
            "Linkage Attack",
            "Membership Inference",
            "Model Inversion"
        ],
        "right": [
            "Combining anonymized data with external sources to re-identify individuals",
            "Determining if a specific record was used to train the model",
            "Reconstructing sensitive features of input data from model outputs"
        ]
    },
    {
        "q": "SHAP (SHapley Additive exPlanations) values are based on ______ game theory.",
        "type": "fill_blank",
        "answers": [
            "cooperative"
        ],
        "other_options": [
            "non-cooperative",
            "zero-sum",
            "evolutionary"
        ]
    },
    {
        "q": "What is the primary purpose of a 'Model Card' in data ethics?",
        "type": "mcq",
        "o": [
            "To document model limitations, intended use, and performance metrics",
            "To visualize the neural network architecture",
            "To license the model for commercial use",
            "To store the weights and biases of the model"
        ]
    },
    {
        "q": "HIPAA regulations apply to all health data collected by consumer fitness trackers and mobile apps.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the specific issue with the following anonymization attempt?",
        "type": "mcq",
        "c": "# Dataset: ZipCode, Age, Nationality, Disease\n# Analysis shows unique combinations of Zip, Age, and Nationality map to single individuals.",
        "o": [
            "It fails K-Anonymity",
            "It lacks Differential Privacy",
            "It has high variance",
            "It is susceptible to SQL injection"
        ]
    },
    {
        "q": "Rearrange the words to describe a core principle of algorithmic accountability:",
        "type": "rearrange",
        "words": [
            "Developers",
            "are",
            "responsible",
            "for",
            "intended",
            "consequences"
        ]
    },
    {
        "q": "______ bias occurs when the data used to train the model does not accurately represent the population where the model will be deployed.",
        "type": "fill_blank",
        "answers": [
            "Sampling"
        ],
        "other_options": [
            "Confirmation",
            "Automation",
            "Sunk cost"
        ]
    },
    {
        "q": "Which concept ensures that a human can understand the internal logic of a machine learning model?",
        "type": "mcq",
        "o": [
            "Interpretability",
            "Accuracy",
            "Robustness",
            "Scalability"
        ]
    },
    {
        "q": "What is the result of running this code on a text dataset containing PII?",
        "type": "mcq",
        "c": "import re\ntext = 'Contact me at john.doe@example.com'\nclean = re.sub(r'\\S+@\\S+', '[REDACTED]', text)\nprint(clean)",
        "o": [
            "Contact me at [REDACTED]",
            "Contact me at john.doe",
            "Error",
            "None"
        ]
    },
    {
        "q": "Under the GDPR, individuals have the 'Right to be Forgotten'.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which metric evaluates how similar the predictions are for similar individuals, regardless of their sensitive attributes?",
        "type": "mcq",
        "o": [
            "Individual Fairness",
            "Group Fairness",
            "Demographic Parity",
            "Predictive Parity"
        ]
    },
    {
        "q": "Match the ethical principle with its description:",
        "type": "match",
        "left": [
            "Beneficence",
            "Non-maleficence",
            "Autonomy"
        ],
        "right": [
            "Acting to promote the well-being of others",
            "Do no harm",
            "Respecting user control and consent"
        ]
    },
    {
        "q": "Which privacy-preserving technique allows a model to be trained across multiple decentralized edge devices holding local data samples, without exchanging them?",
        "type": "mcq",
        "o": [
            "Federated Learning",
            "Homomorphic Encryption",
            "Secure Multi-Party Computation",
            "Data Scrubber"
        ]
    },
    {
        "q": "What phenomenon allows a model to discriminate against a protected group even if the protected attribute (e.g., race) is removed from the dataset?",
        "type": "mcq",
        "c": "features = ['zip_code', 'income', 'credit_score']\n# 'race' was removed, but 'zip_code' correlates highly with it.",
        "o": [
            "Proxy Variable Bias",
            "Omitted Variable Bias",
            "Selection Bias",
            "Exploding Gradient"
        ]
    },
    {
        "q": "LIME (Local Interpretable Model-agnostic Explanations) works by fitting a simple, ______ model around a specific prediction to explain it.",
        "type": "fill_blank",
        "answers": [
            "linear"
        ],
        "other_options": [
            "deep",
            "complex",
            "global"
        ]
    },
    {
        "q": "Match the fairness metric to its calculation or definition:",
        "type": "match",
        "left": [
            "Demographic Parity",
            "Calibration",
            "False Positive Error Rate Balance"
        ],
        "right": [
            "Positive outcome rates are equal across groups",
            "Predicted probabilities match observed frequencies",
            "Focuses on equalizing the rate of incorrect accusations"
        ]
    },
    {
        "q": "What is the output of the following hashing code, and is it reversible to retrieve the original password?",
        "type": "mcq",
        "c": "import hashlib\ndata = 'password123'.encode()\nhashed = hashlib.sha256(data).hexdigest()\nprint(type(hashed))",
        "o": [
            "String, No (One-way)",
            "String, Yes (Two-way)",
            "Integer, No (One-way)",
            "Bytes, Yes (Two-way)"
        ]
    },
    {
        "q": "Rearrange the words to define a 'Dark Pattern' in data collection:",
        "type": "rearrange",
        "words": [
            "User",
            "interfaces",
            "designed",
            "to",
            "trick",
            "users"
        ]
    },
    {
        "q": "Article 22 of the GDPR specifically grants the right to not be subject to a decision based solely on ______ processing.",
        "type": "fill_blank",
        "answers": [
            "automated"
        ],
        "other_options": [
            "manual",
            "third-party",
            "cloud"
        ]
    },
    {
        "q": "Which of the following is an example of 'Automation Bias'?",
        "type": "mcq",
        "o": [
            "A human operator trusting a flawed AI recommendation over their own correct judgment",
            "An AI model favoring the majority class in a dataset",
            "A developer automating a pipeline to save time",
            "A model degrading in performance over time"
        ]
    },
    {
        "q": "Synthetic data is artificial data generated to retain the statistical properties of real data without exposing private information.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What ethical issue is highlighted by the following scenario?",
        "type": "mcq",
        "c": "# Scenario: An image recognition model labels a photo of a human as a 'gorilla'.\n# The training data lacked diversity in skin tones.",
        "o": [
            "Representation Bias",
            "Label Leakage",
            "Feature Engineering Error",
            "Vanishing Gradient"
        ]
    },
    {
        "q": "Match the data protection law with its primary jurisdiction:",
        "type": "match",
        "left": [
            "CCPA/CPRA",
            "LGPD",
            "GDPR"
        ],
        "right": [
            "California (USA)",
            "Brazil",
            "European Union"
        ]
    },
    {
        "q": "Pseudonymization is the same as Anonymization because it makes re-identification impossible.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which technique allows computation to be performed directly on encrypted data without decrypting it first?",
        "type": "mcq",
        "o": [
            "Homomorphic Encryption",
            "AES-256",
            "RSA",
            "Tokenization"
        ]
    },
    {
        "q": "What does this code imply about the data processing agreement?",
        "type": "mcq",
        "c": "if user_consent == False and data_purpose == 'marketing':\n    process_data = False\nelse:\n    process_data = True",
        "o": [
            "Data is not processed for marketing without consent",
            "Data is always processed regardless of consent",
            "Data is processed only if it is anonymized",
            "Syntax Error"
        ]
    },
    {
        "q": "A 'Counterfactual Explanation' helps a user understand a model by showing:",
        "type": "mcq",
        "o": [
            "What needs to change in the input to get a different outcome",
            "The weights of every neuron in the network",
            "The average prediction of the dataset",
            "The mathematical proof of convergence"
        ]
    },
    {
        "q": "What phenomenon occurs when a predictive policing model sends officers to a neighborhood, leading to more arrests, which is then fed back into the model to predict even higher crime rates there?",
        "type": "mcq",
        "o": [
            "Feedback Loop",
            "Model Drift",
            "Vanishing Gradient",
            "Cold Start Problem"
        ]
    },
    {
        "q": "What is the primary ethical concern regarding this text processing code using pre-trained word embeddings?",
        "type": "mcq",
        "c": "vector_result = model['doctor'] - model['man'] + model['woman']\n# Result roughly equals 'nurse' instead of 'doctor'",
        "o": [
            "The model propagates historical gender stereotypes found in the training corpus",
            "The vector math is computationally expensive",
            "The model is overfitting to the word 'doctor'",
            "The syntax is deprecated in Python 3"
        ]
    },
    {
        "q": "The principle of 'Data ______' states that organizations should only collect and process data that is strictly necessary for the specified purpose.",
        "type": "fill_blank",
        "answers": [
            "Minimization"
        ],
        "other_options": [
            "Maximization",
            "Monetization",
            "Encryption"
        ]
    },
    {
        "q": "Match the Anonymization technique with its implementation method:",
        "type": "match",
        "left": [
            "Generalization",
            "Suppression",
            "Perturbation"
        ],
        "right": [
            "Replacing precise values with ranges (e.g., Age 25 -> 20-30)",
            "Deleting a data field or record entirely",
            "Slightly altering data values by adding random noise"
        ]
    },
    {
        "q": "Which US law specifically protects the privacy of children under the age of 13 online?",
        "type": "mcq",
        "o": [
            "COPPA",
            "HIPAA",
            "SOX",
            "OSHA"
        ]
    },
    {
        "q": "What concept refers to the practice of systematically denying services (like loans or insurance) to residents of specific neighborhoods, often translated into AI via location data?",
        "type": "mcq",
        "o": [
            "Digital Redlining",
            "Phishing",
            "Geo-fencing",
            "Blue-penciling"
        ]
    },
    {
        "q": "Rearrange the words to identify a key transparency right in the GDPR:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "explanation",
            "of",
            "automated",
            "decisions"
        ]
    },
    {
        "q": "Why is the following method of handling user passwords unethical and insecure?",
        "type": "mcq",
        "c": "def save_password(password):\n    # Storing directly in database\n    db.write(f\"User_Pass: {password}\")",
        "o": [
            "It stores passwords in Plain Text",
            "It uses a function instead of a class",
            "It consumes too much memory",
            "It requires a return statement"
        ]
    },
    {
        "q": "To prevent 'Rainbow Table' attacks on hashed data, a random string called a ______ is added to the input before hashing.",
        "type": "fill_blank",
        "answers": [
            "salt"
        ],
        "other_options": [
            "pepper",
            "seed",
            "key"
        ]
    },
    {
        "q": "Analyzing only the aircraft that returned from battle to determine where to add armor is an example of ______ bias.",
        "type": "mcq",
        "o": [
            "Survivorship",
            "Observer",
            "Recency",
            "Confirmation"
        ]
    },
    {
        "q": "What implies the 'Dual Use Dilemma' in AI development?",
        "type": "mcq",
        "o": [
            "Technology developed for good purposes can be repurposed for harm (e.g., Deepfakes)",
            "A model uses two different optimizers",
            "Data is used for both training and testing",
            "Using both CPU and GPU for training"
        ]
    },
    {
        "q": "Setting a fixed random seed (e.g., `np.random.seed(42)`) is crucial for ______ in scientific research.",
        "type": "mcq",
        "c": "import numpy as np\nnp.random.seed(42)\nmodel.fit(X, y)",
        "o": [
            "Reproducibility",
            "Privacy",
            "Encryption",
            "Speed"
        ]
    },
    {
        "q": "A 'Black Box' model provides higher interpretability than a Decision Tree.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the Data Governance term with its definition:",
        "type": "match",
        "left": [
            "Data Lineage",
            "Data Steward",
            "Data Catalog"
        ],
        "right": [
            "Tracking the lifecycle and flow of data from origin to destination",
            "Person responsible for data quality and security",
            "An organized inventory of data assets"
        ]
    },
    {
        "q": "Does dropping the 'Name' column guarantee privacy in this dataset?",
        "type": "mcq",
        "c": "df = pd.DataFrame({'Name': ['Alice'], 'Zip': ['90210'], 'DOB': ['1980-01-01'], 'Disease': ['Flu']})\ndf = df.drop('Name', axis=1)",
        "o": [
            "No, 'Zip' and 'DOB' are quasi-identifiers that can lead to re-identification",
            "Yes, the direct identifier is removed",
            "Yes, pandas deletes the data permanently from disk",
            "No, because the dataframe index remains"
        ]
    },
    {
        "q": "What is the name of the mathematical proof stating that it is impossible to simultaneously satisfy calibration, anti-classification, and equalized odds for a model, except in trivial cases?",
        "type": "mcq",
        "o": [
            "Chouldechova's Impossibility Theorem",
            "The Central Limit Theorem",
            "Nash Equilibrium",
            "Bayes' Theorem"
        ]
    },
    {
        "q": "In Differential Privacy, what does a higher value of Epsilon () signify regarding the trade-off between privacy and utility?",
        "type": "mcq",
        "c": "epsilon = 10.0 # High value\nmechanism = Laplace(epsilon)",
        "o": [
            "Lower Privacy, Higher Utility",
            "Higher Privacy, Lower Utility",
            "Higher Privacy, Higher Utility",
            "Lower Privacy, Lower Utility"
        ]
    },
    {
        "q": "Match the specific adversarial attack to its mechanism:",
        "type": "match",
        "left": [
            "Data Poisoning",
            "Model Stealing",
            "Evasion Attack"
        ],
        "right": [
            "Injecting malicious samples into training data to corrupt the model",
            "Querying a model to replicate its functionality or boundaries",
            "Modifying input data slightly to cause misclassification at inference time"
        ]
    },
    {
        "q": "______ Paradox occurs when a trend appears in several different groups of data but disappears or reverses when these groups are combined.",
        "type": "fill_blank",
        "answers": [
            "Simpson's"
        ],
        "other_options": [
            "Moravec's",
            "Braess's",
            "Fermi's"
        ]
    },
    {
        "q": "What ethical red flag is raised by the output of this feature importance analysis for a credit limit model?",
        "type": "mcq",
        "c": "print(model.feature_importances_)\n# Output corresponding to ['Income', 'Debt', 'Gender', 'Zip']:\n# [0.15, 0.20, 0.55, 0.10]",
        "o": [
            "The model relies heavily on a protected attribute (Gender)",
            "The model ignores debt completely",
            "The feature importances do not sum to 1",
            "Income is weighted too heavily"
        ]
    },
    {
        "q": "Rearrange the words to name the document required by GDPR before processing high-risk data:",
        "type": "rearrange",
        "words": [
            "Data",
            "Protection",
            "Impact",
            "Assessment"
        ]
    },
    {
        "q": "Making a model Open Source automatically guarantees that it is ethical and safe to use.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which of the following is an example of 'P-hacking' or 'Data Dredging'?",
        "type": "mcq",
        "o": [
            "Testing multiple hypotheses but only reporting the one that yields a significant result",
            "Cleaning null values from a dataset before training",
            "Using Principal Component Analysis to reduce dimensionality",
            "Splitting data into training and validation sets"
        ]
    },
    {
        "q": "What type of bias is introduced when a sentiment analysis model trained only on formal English fails to understand AAVE (African American Vernacular English)?",
        "type": "mcq",
        "c": "text = \"This beat is sick!\" \n# Model predicts: Negative sentiment (interpreting 'sick' literally)",
        "o": [
            "Deployment Bias / Mismatch",
            "Survivorship Bias",
            "Observer Bias",
            "Recall Bias"
        ]
    },
    {
        "q": "The concept of '______' requires that a user must actively check a box to agree to data collection, rather than having it pre-checked.",
        "type": "fill_blank",
        "answers": [
            "Opt-in"
        ],
        "other_options": [
            "Opt-out",
            "Hand-off",
            "Sign-off"
        ]
    },
    {
        "q": "Which Python library is specifically designed by IBM to detect and mitigate bias in machine learning models?",
        "type": "mcq",
        "o": [
            "AIF360 (AI Fairness 360)",
            "Pandas",
            "NumPy",
            "Matplotlib"
        ]
    },
    {
        "q": "What does this code snippet suggest about the model's update policy?",
        "type": "mcq",
        "c": "# Model deployed in 2020\ncurr_date = '2025-01-01'\nif curr_date > '2021-01-01':\n    pass # Continue using existing weights",
        "o": [
            "The model is at risk of Concept Drift due to lack of retraining",
            "The model is updating in real-time",
            "The model uses reinforcement learning",
            "The code deletes old data automatically"
        ]
    },
    {
        "q": "Match the privacy engineering tool with its primary function:",
        "type": "match",
        "left": [
            "Microsoft Presidio",
            "TensorFlow Privacy",
            "PySyft"
        ],
        "right": [
            "PII detection and redaction in text/images",
            "Training models with differential privacy guarantees",
            "Secure remote execution for deep learning"
        ]
    },
    {
        "q": "If a dataset is fully anonymized today, it is mathematically guaranteed to remain anonymous forever.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which term describes the practice of manipulating the design of a system to confuse users into sharing more data than they intend?",
        "type": "mcq",
        "o": [
            "Dark Patterns",
            "White Hat Hacking",
            "A/B Testing",
            "Feature Scaling"
        ]
    },
    {
        "q": "What is the term for the phenomenon where a metric ceases to be a valid measure once it becomes the target for optimization (e.g., teaching to the test)?",
        "type": "mcq",
        "o": [
            "Goodhart's Law",
            "Moore's Law",
            "Murphy's Law",
            "Zipf's Law"
        ]
    },
    {
        "q": "In Computer Vision, ______ maps are used to highlight which pixels in an image most influenced the model's classification decision.",
        "type": "fill_blank",
        "answers": [
            "Saliency"
        ],
        "other_options": [
            "Heat",
            "Density",
            "Texture"
        ]
    },
    {
        "q": "What ethical issue is occurring in this code snippet regarding model validation?",
        "type": "mcq",
        "c": "from sklearn.linear_model import LogisticRegression\n# MISTAKE: Fitting on the entire dataset before splitting\nmodel.fit(all_data_X, all_data_y)\npreds = model.predict(test_X)",
        "o": [
            "Data Leakage (invalidating performance claims)",
            "Underfitting",
            "Label Smoothing",
            "Incorrect regularization"
        ]
    },
    {
        "q": "Match the type of AI bias to its origin:",
        "type": "match",
        "left": [
            "Historical Bias",
            "Measurement Bias",
            "Evaluation Bias"
        ],
        "right": [
            "Existing societal prejudices reflected in the training data",
            "Errors in how data features are collected or labeled",
            "Benchmarking a model on data that doesn't represent the target population"
        ]
    },
    {
        "q": "The 'Mosaic Effect' refers to the ability to re-identify individuals by combining multiple independent, anonymized datasets.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which enforcement action, used by the FTC, requires a company to destroy not only the illegally collected data but also any algorithms or models trained on that data?",
        "type": "mcq",
        "o": [
            "Algorithmic Disgorgement",
            "Model Pruning",
            "Data Embargo",
            "Digital Forfeiture"
        ]
    },
    {
        "q": "What is the purpose of the noise addition in this Differential Privacy snippet?",
        "type": "mcq",
        "c": "true_count = query_database()\nepsilon = 0.5\n# Adding noise from Laplace distribution\nreported_count = true_count + np.random.laplace(0, 1/epsilon)",
        "o": [
            "To mask the contribution of any single individual to the count",
            "To correct for missing values in the database",
            "To increase the precision of the floating point number",
            "To encrypt the data for storage"
        ]
    },
    {
        "q": "Rearrange the words to identify a flawed strategy often mistaken for a fairness solution:",
        "type": "rearrange",
        "words": [
            "Fairness",
            "through",
            "unawareness",
            "is",
            "insufficient"
        ]
    },
    {
        "q": "Which cryptographic method allows one party to prove to another that they know a value (like a password) without conveying the actual value itself?",
        "type": "mcq",
        "o": [
            "Zero-Knowledge Proof",
            "Public Key Infrastructure",
            "Symmetric Encryption",
            "Steganography"
        ]
    },
    {
        "q": "______ involves ethical hacking where a team explicitly tries to attack a model to find vulnerabilities, biases, or harmful outputs before deployment.",
        "type": "fill_blank",
        "answers": [
            "Red Teaming"
        ],
        "other_options": [
            "Blue Teaming",
            "White Box Testing",
            "Beta Testing"
        ]
    },
    {
        "q": "What does the 'T' in the privacy model 'T-Closeness' represent?",
        "type": "mcq",
        "o": [
            "The distance between the distribution of a sensitive attribute in a cluster vs. the global distribution",
            "The time it takes to re-identify a record",
            "The threshold of error allowed in the model",
            "The total number of quasi-identifiers"
        ]
    },
    {
        "q": "Look at the class balance check below. If this dataset is used for fraud detection, what is the likely ethical risk?",
        "type": "mcq",
        "c": "print(df['is_fraud'].value_counts())\n# Output:\n# 0    99900\n# 1      100",
        "o": [
            "The model may completely ignore the minority class (fraud) to maximize accuracy",
            "The model will be too sensitive and flag everyone as fraud",
            "The model will run too slowly due to data size",
            "No risk, the data is clean"
        ]
    },
    {
        "q": "A 'Human-in-the-loop' system allows an AI to make high-stakes decisions entirely autonomously without supervision.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the Interpretability method with its scope:",
        "type": "match",
        "left": [
            "Partial Dependence Plot (PDP)",
            "SHAP (for a single row)",
            "Global Surrogate"
        ],
        "right": [
            "Shows the marginal effect of 1-2 features on the predicted outcome globally",
            "Explains the contribution of features for a specific instance",
            "An interpretable model trained to approximate the black box model entirely"
        ]
    },
    {
        "q": "Which famous thought experiment is often adapted to discuss the decision-making logic of Autonomous Vehicles in unavoidable accident scenarios?",
        "type": "mcq",
        "o": [
            "The Trolley Problem",
            "Schrdinger's Cat",
            "The Chinese Room",
            "The Turing Test"
        ]
    },
    {
        "q": "According to the EU AI Act, AI systems used for 'Social Scoring' by governments are classified under which risk category?",
        "type": "mcq",
        "o": [
            "Unacceptable Risk (Banned)",
            "High Risk",
            "Limited Risk",
            "Minimal Risk"
        ]
    },
    {
        "q": "What specific type of data poisoning attack involves injecting a specific trigger pattern (like a sticker on a stop sign) into the training set so the model misbehaves only when that trigger is present?",
        "type": "mcq",
        "o": [
            "Backdoor Attack",
            "Sponge Attack",
            "Oracle Attack",
            "Man-in-the-middle Attack"
        ]
    },
    {
        "q": "What is the security and ethical risk in the following Python code using the `pickle` module?",
        "type": "mcq",
        "c": "import pickle\n# data_stream comes from an external, untrusted user\nobj = pickle.loads(data_stream)",
        "o": [
            "Arbitrary code execution (Remote Code Execution)",
            "Memory leak",
            "Integer overflow",
            "Data bias injection"
        ]
    },
    {
        "q": "Match the privacy enhancing technology (PET) to its description:",
        "type": "match",
        "left": [
            "Trusted Execution Environment (TEE)",
            "Tokenization",
            "Synthetics"
        ],
        "right": [
            "Hardware-based secure area ensuring code/data integrity",
            "Replacing sensitive data with a non-sensitive equivalent pointer",
            "Artificially generated data mimicking real statistical patterns"
        ]
    },
    {
        "q": "The Illinois law known as ______ strictly regulates the collection and storage of biometric identifiers like face scans and fingerprints.",
        "type": "fill_blank",
        "answers": [
            "BIPA"
        ],
        "other_options": [
            "GDPR",
            "FERPA",
            "RICO"
        ]
    },
    {
        "q": "What type of validity is compromised when a model uses 'arrest records' as a proxy for 'crime rate', ignoring that arrests reflect police activity rather than total crime committed?",
        "type": "mcq",
        "o": [
            "Construct Validity",
            "Internal Validity",
            "Convergent Validity",
            "Face Validity"
        ]
    },
    {
        "q": "Rearrange the words to form the 7th principle of 'Privacy by Design':",
        "type": "rearrange",
        "words": [
            "Respect",
            "for",
            "user",
            "privacy",
            "keep",
            "it",
            "user-centric"
        ]
    },
    {
        "q": "Why is using the standard `random` library unethical/unsafe for generating password reset tokens?",
        "type": "mcq",
        "c": "import random\ntoken = random.randint(1000, 9999)\n# Used for security authentication",
        "o": [
            "It is pseudo-random and deterministic (predictable)",
            "It causes buffer overflows",
            "It only supports integers",
            "It cannot generate strings"
        ]
    },
    {
        "q": "What is the primary goal of 'Watermarking' in the context of Generative AI (LLMs/Image Generators)?",
        "type": "mcq",
        "o": [
            "To embed an invisible signal proving content was AI-generated",
            "To prevent the image from being copied",
            "To improve the resolution of the image",
            "To reduce the inference time"
        ]
    },
    {
        "q": "______ involves modifying the input to a model to dramatically increase its energy consumption and latency, raising environmental and availability concerns.",
        "type": "fill_blank",
        "answers": [
            "Sponge"
        ],
        "other_options": [
            "Leech",
            "Drain",
            "Flood"
        ]
    },
    {
        "q": "Which fairness philosophy argues that a model is fair if the process of decision-making is consistent for everyone, regardless of the outcome distribution?",
        "type": "mcq",
        "o": [
            "Procedural Fairness",
            "Distributive Fairness",
            "Outcome Fairness",
            "Restorative Justice"
        ]
    },
    {
        "q": "What does the logging practice in this snippet violate regarding data minimization principles?",
        "type": "mcq",
        "c": "try:\n    process_payment(user_object)\nexcept Exception as e:\n    # Dumping the entire object state to logs\n    logger.error(f\"Failed for: {user_object.__dict__}\")",
        "o": [
            "It logs sensitive PII/financial data into unsecured log files",
            "It fails to catch the exception properly",
            "It uses f-strings which are slow",
            "It does not raise the error again"
        ]
    },
    {
        "q": "The 'Right to Data Portability' allows users to obtain their data from a controller in a structured, commonly used, and machine-readable format.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the bias type to the scenario:",
        "type": "match",
        "left": [
            "Label Bias",
            "Ranking Bias",
            "Temporal Bias"
        ],
        "right": [
            "The annotator's own subjectivity influences the ground truth",
            "Search engines showing top results that reinforce user clicks",
            "Training on 2010 data to predict 2024 behavior"
        ]
    },
    {
        "q": "In the context of Federated Learning, what attack involves a server reconstructing the user's private data by analyzing the gradient updates sent by the user?",
        "type": "mcq",
        "o": [
            "Gradient Inversion / Leakage",
            "DDoS",
            "SQL Injection",
            "Cross-Site Scripting"
        ]
    },
    {
        "q": "Which social science concept describes the tendency for human operators to bear the responsibility when an automated system fails, even if the system was designed with hidden flaws?",
        "type": "mcq",
        "o": [
            "Moral Crumple Zone",
            "Bystander Effect",
            "Dunning-Kruger Effect",
            "Pareto Principle"
        ]
    },
    {
        "q": "What is the primary privacy risk exposed by this code, which processes user-uploaded images?",
        "type": "mcq",
        "c": "from PIL import Image\nimg = Image.open('user_photo.jpg')\nexif_data = img._getexif()\n# GPSInfo is often found in tag 34853\nprint(exif_data.get(34853))",
        "o": [
            "Exposure of geolocation metadata (Location Tracking)",
            "Pixel inversion attack",
            "Steganography injection",
            "Copyright infringement"
        ]
    },
    {
        "q": "In the context of survey ethics, '______ Response' is a technique where respondents answer sensitive questions based on a random event (like a coin flip) to protect their privacy.",
        "type": "fill_blank",
        "answers": [
            "Randomized"
        ],
        "other_options": [
            "Stochastic",
            "Encrypted",
            "Anonymized"
        ]
    },
    {
        "q": "Match the bias mitigation strategy to the stage of the machine learning pipeline where it is applied:",
        "type": "match",
        "left": [
            "Reweighting Samples",
            "Adversarial Debiasing",
            "Threshold Adjustment"
        ],
        "right": [
            "Pre-processing (Data stage)",
            "In-processing (Model training stage)",
            "Post-processing (Prediction stage)"
        ]
    },
    {
        "q": "Which U.S. federal law specifically governs the privacy of student education records?",
        "type": "mcq",
        "o": [
            "FERPA",
            "HIPAA",
            "FISMA",
            "GDPR"
        ]
    },
    {
        "q": "What ethical pitfall is demonstrated in this recommendation system logic?",
        "type": "mcq",
        "c": "# Suggest content based solely on what the user clicked previously\nrecommendations = get_similar_items(user_history.clicks)\n# Result: User sees increasingly extreme versions of the same topic.",
        "o": [
            "Filter Bubble / Echo Chamber",
            "Cold Start Problem",
            "Sparse Matrix Error",
            "Gradient Explosion"
        ]
    },
    {
        "q": "Rearrange the words to define a core principle of 'Value Sensitive Design':",
        "type": "rearrange",
        "words": [
            "Account",
            "for",
            "human",
            "values",
            "in",
            "technical",
            "design"
        ]
    },
    {
        "q": "Scraping publicly available data from social media profiles is automatically ethical and legal because the data is public.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the specific risk of the 'Hardcoded Secret' in this database connection snippet?",
        "type": "mcq",
        "c": "def connect_db():\n    # TODO: Move to env variables\n    pwd = \"SuperSecretAdmin123!\"\n    return db.connect(user='admin', password=pwd)",
        "o": [
            "Credential Leakage via Source Control",
            "SQL Injection",
            "Database Deadlock",
            "Connection Timeout"
        ]
    },
    {
        "q": "The concept of '______ Solutionism' is the belief that every social or ethical problem has a purely technological fix, often ignoring complex human factors.",
        "type": "fill_blank",
        "answers": [
            "Technological"
        ],
        "other_options": [
            "Digital",
            "Algorithmic",
            "Computational"
        ]
    },
    {
        "q": "Which financial regulation requires financial institutions to explain their information-sharing practices and safeguard sensitive data (GLBA)?",
        "type": "mcq",
        "o": [
            "Gramm-Leach-Bliley Act",
            "Sarbanes-Oxley Act",
            "Dodd-Frank Act",
            "Glass-Steagall Act"
        ]
    },
    {
        "q": "What is the purpose of the 'PATE' (Private Aggregation of Teacher Ensembles) framework?",
        "type": "mcq",
        "o": [
            "To transfer knowledge from an ensemble of 'teacher' models to a 'student' model with privacy guarantees",
            "To aggregate grades in an educational setting",
            "To encrypt data during transfer",
            "To detect cheating in online exams"
        ]
    },
    {
        "q": "Match the Data State to its security requirement:",
        "type": "match",
        "left": [
            "Data at Rest",
            "Data in Transit",
            "Data in Use"
        ],
        "right": [
            "Encryption via disk/database encryption (e.g., AES)",
            "Encryption via protocols like TLS/SSL",
            "Protection via Enclaves or Homomorphic Encryption"
        ]
    },
    {
        "q": "Does this code successfully reduce the granularity of the data to improve privacy?",
        "type": "mcq",
        "c": "import pandas as pd\ndf['exact_birth_date'] = pd.to_datetime(df['exact_birth_date'])\n# Replace exact date with just the year\ndf['birth_year'] = df['exact_birth_date'].dt.year\ndf.drop(columns=['exact_birth_date'], inplace=True)",
        "o": [
            "Yes, it generalizes the data (Generalization)",
            "No, it increases the risk",
            "No, it creates null values",
            "Yes, it encrypts the data"
        ]
    },
    {
        "q": "Which metric of fairness focuses on ensuring that the *probability* of a qualified applicant being selected is the same across all groups (Equality of Opportunity)?",
        "type": "mcq",
        "o": [
            "True Positive Rate Parity",
            "Statistical Parity",
            "False Positive Rate Parity",
            "Base Rate Parity"
        ]
    },
    {
        "q": "What is the primary purpose of the 'Datasheets for Datasets' framework proposed by Gebru et al.?",
        "type": "mcq",
        "o": [
            "To document the motivation, composition, and collection process of a dataset",
            "To compress the dataset for faster training",
            "To encrypt the dataset using SHA-256",
            "To automatically label the dataset using AI"
        ]
    },
    {
        "q": "In the context of U.S. labor law and AI, '______ Impact' refers to policies that are facially neutral but have a discriminatory effect on a protected group.",
        "type": "fill_blank",
        "answers": [
            "Disparate"
        ],
        "other_options": [
            "Adverse",
            "Direct",
            "Intentional"
        ]
    },
    {
        "q": "Match the GDPR entity with its definition:",
        "type": "match",
        "left": [
            "Data Subject",
            "Data Controller",
            "Data Processor"
        ],
        "right": [
            "The individual whom the data is about",
            "The entity that determines the purpose and means of processing",
            "The entity that processes data on behalf of the controller"
        ]
    },
    {
        "q": "Rearrange the words to form the name of a standard document used to assess privacy risks before starting a project:",
        "type": "rearrange",
        "words": [
            "Privacy",
            "Impact",
            "Assessment",
            "Report"
        ]
    },
    {
        "q": "According to the US Copyright Office (as of 2023), images generated entirely by AI without human creative contribution are eligible for copyright protection.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What technique is being applied in this code snippet to address class imbalance?",
        "type": "mcq",
        "c": "from sklearn.utils import resample\n# Separate majority and minority classes\nminority_upsampled = resample(minority, replace=True, n_samples=len(majority))",
        "o": [
            "Oversampling",
            "Undersampling",
            "Stratified K-Fold",
            "Regularization"
        ]
    },
    {
        "q": "The '______' Test is a proposal to replace the Turing Test, focusing instead on whether an AI system can skillfully generate a narrative that fits a set of constraints.",
        "type": "fill_blank",
        "answers": [
            "Lovelace"
        ],
        "other_options": [
            "Voight-Kampff",
            "Chinese Room",
            "Mirror"
        ]
    },
    {
        "q": "Which ethical framework judges the morality of an automated decision based on the consequences (e.g., saving the most lives in an accident), rather than strict rules?",
        "type": "mcq",
        "o": [
            "Utilitarianism",
            "Deontology",
            "Virtue Ethics",
            "Nihilism"
        ]
    },
    {
        "q": "What specific type of data leakage is occurring in this code?",
        "type": "mcq",
        "c": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# Fitting the scaler on the WHOLE dataset before splitting\nX_scaled = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y)",
        "o": [
            "Contamination of training data with test set statistics",
            "Target Leakage",
            "Label Leaking",
            "Feature Explosion"
        ]
    },
    {
        "q": "Match the type of user consent with its description:",
        "type": "match",
        "left": [
            "Explicit Consent",
            "Implicit Consent",
            "Granular Consent"
        ],
        "right": [
            "User takes a specific action (e.g., clicking 'I Agree') to permit processing",
            "Consent is inferred from user behavior (e.g., continuing to browse)",
            "User can agree to specific types of processing while rejecting others"
        ]
    },
    {
        "q": "Data ______ refers to the concept that data is subject to the laws and governance structures within the nation it is collected.",
        "type": "fill_blank",
        "answers": [
            "Sovereignty"
        ],
        "other_options": [
            "Localization",
            "Residency",
            "Colonialism"
        ]
    },
    {
        "q": "Rearrange the words to identify the 'Right' that allows a user to correct inaccurate data held about them:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "Rectification"
        ]
    },
    {
        "q": "What is the primary focus of 'Green AI'?",
        "type": "mcq",
        "o": [
            "Reducing the carbon footprint and energy cost of training large models",
            "Using AI to predict weather patterns",
            "Visualizing decision trees in green colors",
            "Recycling old hardware for servers"
        ]
    },
    {
        "q": "Hashing is a reversible process, meaning you can always decrypt the hash to get the original data if you have the key.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the purpose of the regex check in this data pipeline?",
        "type": "mcq",
        "c": "import re\npattern = r\"^\\d{3}-\\d{2}-\\d{4}$\"\nif re.match(pattern, input_str):\n    flag_sensitive(input_str)",
        "o": [
            "To identify and flag US Social Security Numbers (SSN)",
            "To validate email addresses",
            "To check for SQL injection patterns",
            "To detect credit card numbers"
        ]
    },
    {
        "q": "Which Python module is cryptographically strong and should be used instead of the standard `random` library for generating security tokens or temporary passwords?",
        "type": "mcq",
        "c": "import ______\ntoken = ______.token_hex(16)",
        "o": [
            "secrets",
            "crypto",
            "secure_rand",
            "hashlib"
        ]
    },
    {
        "q": "The NIST AI Risk Management Framework (AI RMF 1.0) organizes AI risks into four core functions: Govern, Map, Measure, and ______.",
        "type": "fill_blank",
        "answers": [
            "Manage"
        ],
        "other_options": [
            "Monitor",
            "Mitigate",
            "Master"
        ]
    },
    {
        "q": "Match the cognitive bias affecting Data Analysts to its definition:",
        "type": "match",
        "left": [
            "Anchoring Bias",
            "Gambler's Fallacy",
            "Bandwagon Effect"
        ],
        "right": [
            "Over-relying on the first piece of information offered (the 'anchor')",
            "Believing that past independent events influence future probabilities",
            "Adopting a methodology just because many others are doing it"
        ]
    },
    {
        "q": "What data ethics issue is introduced by this imputation code?",
        "type": "mcq",
        "c": "# Dataset contains 'Salary' and 'Gender'\n# Imputing missing salaries with the global mean\ndf['Salary'].fillna(df['Salary'].mean(), inplace=True)",
        "o": [
            "It erases structural differences between groups, potentially masking pay gaps",
            "It causes a MemoryError for large datasets",
            "It introduces negative values into the salary column",
            "It changes the data type to string"
        ]
    },
    {
        "q": "Rearrange the words to form the name of the fairness library maintained by Microsoft:",
        "type": "rearrange",
        "words": [
            "Fairlearn"
        ]
    },
    {
        "q": "In Reinforcement Learning, '______ Hacking' occurs when an agent learns a clever way to maximize the reward function without actually achieving the intended goal (e.g., a vacuum robot sweeping dust under the rug).",
        "type": "fill_blank",
        "answers": [
            "Reward"
        ],
        "other_options": [
            "Goal",
            "Policy",
            "Value"
        ]
    },
    {
        "q": "Which type of Differential Privacy adds noise to the data on the user's device *before* it is sent to the central server?",
        "type": "mcq",
        "o": [
            "Local Differential Privacy",
            "Global Differential Privacy",
            "Centralized Differential Privacy",
            "Hybrid Differential Privacy"
        ]
    },
    {
        "q": "Under the 'Purpose Limitation' principle of GDPR, data collected for a specific purpose (e.g., shipping) can freely be used for any other purpose (e.g., marketing) without further consent.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What does the 'A' stand for in the FATE framework for ethical AI?",
        "type": "mcq",
        "o": [
            "Accountability",
            "Accuracy",
            "Automation",
            "Anonymity"
        ]
    },
    {
        "q": "Identify the risk in this code where a model is trained on data generated by another model:",
        "type": "mcq",
        "c": "# Training Model B using predictions from Model A\ny_train_B = model_A.predict(X_train)",
        "o": [
            "Model Collapse / Autophagous Loops",
            "Overfitting",
            "Gradient Vanishing",
            "Feature Selection Error"
        ]
    },
    {
        "q": "Match the open-source tool to its primary ethical function:",
        "type": "match",
        "left": [
            "Carbon Tracker",
            "Deon",
            "Great Expectations"
        ],
        "right": [
            "Tracking energy consumption and carbon footprint of training",
            "A command-line ethics checklist for data science projects",
            "Validating, documenting, and profiling data quality"
        ]
    },
    {
        "q": "The theory of '______ Integrity' (Helen Nissenbaum) suggests that privacy is not about secrecy, but about the appropriate flow of information within specific social norms.",
        "type": "fill_blank",
        "answers": [
            "Contextual"
        ],
        "other_options": [
            "Structural",
            "Digital",
            "Social"
        ]
    },
    {
        "q": "What specific attack exploits the physical implementation of a system (e.g., power consumption or electromagnetic leaks) rather than the algorithm itself?",
        "type": "mcq",
        "o": [
            "Side-Channel Attack",
            "Brute Force Attack",
            "Phishing Attack",
            "Dictionary Attack"
        ]
    },
    {
        "q": "Rearrange the words to identify a GDPR right regarding processing restriction:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "restrict",
            "processing"
        ]
    },
    {
        "q": "Is the following SQL query safe from Injection attacks?",
        "type": "mcq",
        "c": "user_input = \"'; DROP TABLE users; --\"\nquery = f\"SELECT * FROM users WHERE name = '{user_input}'\"",
        "o": [
            "No, because it uses f-string formatting to insert raw input",
            "Yes, because f-strings are secure",
            "Yes, because Python sanitizes inputs automatically",
            "No, because the table name is wrong"
        ]
    },
    {
        "q": "What statistical phenomenon is demonstrated when a predictive model performs well on training data but fails to generalize to a minority demographic because the minority group was effectively treated as 'outliers' during optimization?",
        "type": "mcq",
        "o": [
            "Minority Class Marginalization",
            "The curse of dimensionality",
            "Homoscedasticity",
            "The Law of Large Numbers"
        ]
    },
    {
        "q": "Which fairness definition requires that the probability of a positive prediction is independent of the sensitive attribute (i.e., P(Y_hat=1 | A=a) = P(Y_hat=1 | A=b))?",
        "type": "mcq",
        "c": "# A is the sensitive attribute, Y_hat is prediction",
        "o": [
            "Demographic Parity (Statistical Parity)",
            "Equalized Odds",
            "Equality of Opportunity",
            "Calibration"
        ]
    },
    {
        "q": "In the context of EU law, '______' refers to the legal basis where an organization processes data because it is necessary for the performance of a contract with the user.",
        "type": "fill_blank",
        "answers": [
            "Contractual"
        ],
        "other_options": [
            "Consensual",
            "Legitimate",
            "Vital"
        ]
    },
    {
        "q": "Match the adversarial defense mechanism to its description:",
        "type": "match",
        "left": [
            "Adversarial Training",
            "Defensive Distillation",
            "Feature Squeezing"
        ],
        "right": [
            "Injecting adversarial examples into the training set with correct labels",
            "Training a second model to predict the probabilities of the first model",
            "Reducing the complexity of input data (e.g., reducing color bit depth)"
        ]
    },
    {
        "q": "What is the primary risk of using 'One-Hot Encoding' on a high-cardinality sensitive feature (like Zip Code) without further processing?",
        "type": "mcq",
        "o": [
            "It creates sparse vectors that act as unique identifiers, aiding re-identification",
            "It causes the model to underfit",
            "It automatically encrypts the data",
            "It reduces the dimensionality of the dataset"
        ]
    },
    {
        "q": "Rearrange the words to identify the principle that users should be able to move their data between service providers:",
        "type": "rearrange",
        "words": [
            "Data",
            "Portability",
            "allows",
            "switching",
            "providers"
        ]
    },
    {
        "q": "The '______' Effect describes a situation where an algorithm's deployment alters the behavior of the people it is observing, rendering the historical training data obsolete.",
        "type": "fill_blank",
        "answers": [
            "Performativity"
        ],
        "other_options": [
            "Observer",
            "Butterfly",
            "Placebo"
        ]
    },
    {
        "q": "Which of the following is considered a 'Dark Pattern' specifically related to cancellation of services?",
        "type": "mcq",
        "o": [
            "Roach Motel",
            "Privacy Zuckering",
            "Confirmshaming",
            "Sneak into Basket"
        ]
    },
    {
        "q": "A model with high accuracy can still be unfair if the False Negative rates differ significantly between protected groups.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the ethical implication of the 'proxy' variable in this housing price model?",
        "type": "mcq",
        "c": "# 'Race' is removed, but 'High_School_Quality_Index' is kept.\n# This index correlates 95% with neighborhood racial demographics.",
        "o": [
            "Redlining via proxy variables",
            "Improved model generalization",
            "Elimination of racial bias",
            "Data minimization"
        ]
    },
    {
        "q": "Match the term with the type of missing data:",
        "type": "match",
        "left": [
            "MCAR (Missing Completely At Random)",
            "MAR (Missing At Random)",
            "MNAR (Missing Not At Random)"
        ],
        "right": [
            "The probability of missingness is unrelated to any data (observed or unobserved)",
            "The probability of missingness depends on observed data but not the missing value itself",
            "The probability of missingness depends on the value of the missing data itself"
        ]
    },
    {
        "q": "What is the primary function of a 'Canary' in privacy-preserving machine learning?",
        "type": "mcq",
        "o": [
            "To test if a specific data point was included in the training set (Membership Inference)",
            "To signal when the model has finished training",
            "To encrypt the validation set",
            "To add random noise to the gradient"
        ]
    },
    {
        "q": "Which license allows others to use, modify, and distribute your code/data, but only if they release their work under the same license terms?",
        "type": "mcq",
        "o": [
            "Copyleft / ShareAlike (e.g., GPL, CC BY-SA)",
            "Permissive (e.g., MIT, Apache)",
            "Public Domain (CC0)",
            "Proprietary"
        ]
    },
    {
        "q": "The 'Right to ______' ensures that a human intervenes in automated decision-making processes that have legal or significant effects.",
        "type": "fill_blank",
        "answers": [
            "contest"
        ],
        "other_options": [
            "delete",
            "access",
            "forget"
        ]
    },
    {
        "q": "Why is the following data retention policy risky?",
        "type": "mcq",
        "c": "def archive_logs(logs):\n    # Keep logs forever for 'future analysis'\n    storage.save(logs, retention='indefinite')",
        "o": [
            "It violates the Storage Limitation principle and increases breach impact",
            "It is too expensive to store",
            "It makes the database slower",
            "It causes code rot"
        ]
    },
    {
        "q": "Which specific type of privacy attack observes the time it takes for a model to respond to a query to infer properties about the input data?",
        "type": "mcq",
        "o": [
            "Timing Side-Channel Attack",
            "Man-in-the-Middle Attack",
            "Dictionary Attack",
            "Phishing Attack"
        ]
    },
    {
        "q": "What data ethics principle is violated by the following code if used for secure deletion?",
        "type": "mcq",
        "c": "import os\n# User requests account deletion\nos.remove(\"user_data.db\")\n# The file pointer is removed, but magnetic data remains on disk.",
        "o": [
            "Right to Erasure (data is recoverable)",
            "Data Portability",
            "Purpose Limitation",
            "Accuracy"
        ]
    },
    {
        "q": "The practice of '______' involves auditing an algorithm by treating it as a 'black box' and analyzing its inputs and outputs without access to the internal code.",
        "type": "fill_blank",
        "answers": [
            "External"
        ],
        "other_options": [
            "Internal",
            "White-box",
            "Static"
        ]
    },
    {
        "q": "Match the philosophical framework to its application in AI Ethics:",
        "type": "match",
        "left": [
            "Deontology",
            "Consequentialism",
            "Virtue Ethics"
        ],
        "right": [
            "Following strict rules/duties (e.g., 'Never lie', 'Never kill')",
            "Judging actions by their outcomes (e.g., 'Maximize happiness')",
            "Focusing on the character/intent of the moral agent (the AI developer)"
        ]
    },
    {
        "q": "Which concept describes the capability of an individual to hide their connections to others in a social graph dataset?",
        "type": "mcq",
        "o": [
            "Graph Anonymity",
            "Node Centrality",
            "Edge Computing",
            "Link Prediction"
        ]
    },
    {
        "q": "What is the primary risk of using `eval()` in Python to process dynamic rules for a data filter?",
        "type": "mcq",
        "c": "rule = request.get('filter_rule')\n# input: \"__import__('os').system('rm -rf /')\"\nresult = eval(rule)",
        "o": [
            "Code Injection / Remote Code Execution",
            "Data Bias",
            "Model Overfitting",
            "Precision Loss"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Right to Explanation' in simple terms:",
        "type": "rearrange",
        "words": [
            "Understanding",
            "how",
            "a",
            "decision",
            "was",
            "reached"
        ]
    },
    {
        "q": "A 'Privacy ______' is a limit on how much information a specific algorithm or system is allowed to leak about a dataset before it must stop answering queries.",
        "type": "fill_blank",
        "answers": [
            "Budget"
        ],
        "other_options": [
            "Wall",
            "Shield",
            "Container"
        ]
    },
    {
        "q": "If a dataset lists '35-year-old male, Zip: 10001, Diagnosis: Flu', and there is only one 35-year-old male in Zip 10001 in the public census, this record is vulnerable to:",
        "type": "mcq",
        "o": [
            "Singling Out",
            "Aggregation",
            "Inference",
            "Masking"
        ]
    },
    {
        "q": "Removing 'Gender' from a dataset fixes gender bias, even if the dataset contains 'Job Title' (e.g., 'Nurse' vs 'Construction Worker').",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What fairness metric is calculated in this snippet?",
        "type": "mcq",
        "c": "fp_rate_group_a = fp_a / (fp_a + tn_a)\nfp_rate_group_b = fp_b / (fp_b + tn_b)\n# Checking if fp_rate_group_a == fp_rate_group_b",
        "o": [
            "Predictive Equality (False Positive Error Rate Balance)",
            "Demographic Parity",
            "Overall Accuracy",
            "Recall"
        ]
    },
    {
        "q": "Match the Data Lifecycle stage with the ethical concern:",
        "type": "match",
        "left": [
            "Collection",
            "Analysis",
            "Disposal"
        ],
        "right": [
            "Informed Consent",
            "P-Hacking / Cherry-picking",
            "Data Remanence"
        ]
    },
    {
        "q": "Which famous 2016 article by ProPublica investigated the COMPAS algorithm used in court systems?",
        "type": "mcq",
        "o": [
            "Machine Bias",
            "The End of Theory",
            "AI Superpowers",
            "Weapons of Math Destruction"
        ]
    },
    {
        "q": "______ involves creating a copy of a database for testing purposes where all real data is replaced with fictitious but structurally identical data.",
        "type": "fill_blank",
        "answers": [
            "Mocking"
        ],
        "other_options": [
            "Hashing",
            "Salting",
            "Phishing"
        ]
    },
    {
        "q": "What does this code indicate about the relationship between accuracy and privacy?",
        "type": "mcq",
        "c": "# Increasing noise to improve privacy\nnoise_scale = 10.0 \n# Accuracy drops as noise increases\nmodel_accuracy = 0.95 - (noise_scale * 0.02)",
        "o": [
            "There is often a trade-off: higher privacy can lead to lower utility/accuracy",
            "Higher privacy always leads to higher accuracy",
            "Noise has no effect on model performance",
            "Accuracy is independent of privacy parameters"
        ]
    },
    {
        "q": "Which specific US law grants citizens the right to know the contents of their credit file and the specific reasons for a credit denial (often relevant in Automated Decision Making)?",
        "type": "mcq",
        "o": [
            "FCRA (Fair Credit Reporting Act)",
            "COPPA",
            "DMCA",
            "Patriot Act"
        ]
    },
    {
        "q": "In the context of $(\\epsilon, \\delta)$-Differential Privacy, what does the parameter $\\delta$ (delta) represent?",
        "type": "mcq",
        "o": [
            "The small probability that the privacy guarantee will fail",
            "The amount of noise added",
            "The number of users in the database",
            "The utility score of the model"
        ]
    },
    {
        "q": "What ethical issue is depicted in this web scraping scenario?",
        "type": "mcq",
        "c": "import requests\n# Identifying as a normal user to bypass bot detection\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...'}\nrequests.get(url, headers=headers)",
        "o": [
            "Spoofing User Agents to bypass 'robots.txt' or bot protections",
            "SQL Injection",
            "Cross-Site Request Forgery",
            "Man-in-the-Middle"
        ]
    },
    {
        "q": "Match the level of human involvement in AI systems to its definition:",
        "type": "match",
        "left": [
            "Human-in-the-loop",
            "Human-on-the-loop",
            "Human-out-of-the-loop"
        ],
        "right": [
            "Human must confirm the action before the system executes it",
            "System acts autonomously but human can intervene/abort",
            "System acts autonomously with no human intervention possible"
        ]
    },
    {
        "q": "The file named ______ is a standard used by websites to communicate with web crawlers and other web robots to instruct them about which areas of the website should not be processed.",
        "type": "fill_blank",
        "answers": [
            "robots.txt"
        ],
        "other_options": [
            "sitemap.xml",
            "index.html",
            "config.json"
        ]
    },
    {
        "q": "What phenomenon occurred in the famous 'Netflix Prize' dataset release, where researchers linked anonymous movie ratings with public IMDb profiles?",
        "type": "mcq",
        "o": [
            "De-anonymization / Re-identification",
            "Data Corruption",
            "Model Inversion",
            "Feature Collision"
        ]
    },
    {
        "q": "Rearrange the words to identify the mechanism for legal data transfer from the EU to non-EU countries:",
        "type": "rearrange",
        "words": [
            "Standard",
            "Contractual",
            "Clauses"
        ]
    },
    {
        "q": "Is the following password storage method secure?",
        "type": "mcq",
        "c": "import base64\n# Encoding password for storage\nstored_pw = base64.b64encode(user_password.encode())",
        "o": [
            "No, Base64 is encoding, not encryption or hashing",
            "Yes, Base64 scrambles the data",
            "Yes, but only for short passwords",
            "No, it uses too much storage space"
        ]
    },
    {
        "q": "A ______ is a malicious modification of a neural network that functions normally on standard inputs but misclassifies inputs containing a specific 'trigger' pattern.",
        "type": "fill_blank",
        "answers": [
            "Trojan"
        ],
        "other_options": [
            "Virus",
            "Worm",
            "Bug"
        ]
    },
    {
        "q": "What does the 'Right to Object' in GDPR specifically allow a user to do?",
        "type": "mcq",
        "o": [
            "Stop the processing of their data for direct marketing or legitimate interests",
            "Delete all their data immediately",
            "Edit their data",
            "Download their data"
        ]
    },
    {
        "q": "If an AI Resume Screener is trained on 10 years of historical hiring data from a male-dominated industry, removing the 'Name' and 'Gender' columns is sufficient to eliminate bias.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the bias term to the example:",
        "type": "match",
        "left": [
            "Implicit Bias",
            "Confirmation Bias",
            "Sunk Cost Bias"
        ],
        "right": [
            "Unconscious stereotypes affecting a developer's decisions",
            "Interpretating new data in a way that supports existing beliefs",
            "Continuing a failing AI project because resources were already spent"
        ]
    },
    {
        "q": "What implies the presence of 'Sludge' in a User Interface (UI)?",
        "type": "mcq",
        "o": [
            "Excessive friction or difficult steps added to prevent users from making a choice (e.g., cancelling a subscription)",
            "Visual noise in the graphic design",
            "Slow loading times due to server issues",
            "Pop-ups asking for cookies"
        ]
    },
    {
        "q": "Which component of the CIA Triad is compromised if a healthcare model's predictions are altered by a hacker, leading to incorrect dosages?",
        "type": "mcq",
        "o": [
            "Integrity",
            "Confidentiality",
            "Availability",
            "Non-repudiation"
        ]
    },
    {
        "q": "What is the purpose of the `stratify` parameter in this split, regarding data ethics?",
        "type": "mcq",
        "c": "train_test_split(X, y, stratify=y, test_size=0.2)",
        "o": [
            "To ensure the train/test sets have the same proportion of classes (fair representation)",
            "To shuffle the data randomly",
            "To remove duplicates",
            "To increase training speed"
        ]
    },
    {
        "q": "In the context of US employment law and AI fairness, the '4/5ths Rule' (or 80% Rule) suggests that a selection rate for any race, sex, or ethnic group which is less than ______ of the rate for the group with the highest rate is generally regarded as evidence of adverse impact.",
        "type": "fill_blank",
        "answers": [
            "four-fifths"
        ],
        "other_options": [
            "one-half",
            "two-thirds",
            "nine-tenths"
        ]
    },
    {
        "q": "What ethical concept refers to the lack of data coverage for specific subgroups (e.g., rural populations), leading to models that fail to serve them effectively?",
        "type": "mcq",
        "o": [
            "Data Deserts",
            "Data Lakes",
            "Feature Engineering",
            "Data Warehousing"
        ]
    },
    {
        "q": "Calculate the Disparate Impact Ratio based on this code. Is there potential bias against Group B according to the 0.8 threshold?",
        "type": "mcq",
        "c": "group_A_selection_rate = 0.50 # 50% selected\ngroup_B_selection_rate = 0.30 # 30% selected\nratio = group_B_selection_rate / group_A_selection_rate",
        "o": [
            "Ratio is 0.6; Yes, bias is indicated (0.6 < 0.8)",
            "Ratio is 0.6; No, bias is not indicated",
            "Ratio is 1.6; Yes, bias is indicated",
            "Ratio is 0.2; No, bias is not indicated"
        ]
    },
    {
        "q": "Match the famous AI failure case to its primary ethical cause:",
        "type": "match",
        "left": [
            "Microsoft 'Tay' Chatbot",
            "Amazon Recruiting Tool",
            "Google Photos 'Gorilla' Incident"
        ],
        "right": [
            "Lack of input filtering led to users teaching it hate speech",
            "Training data based on historical hiring penalized the word 'Women'",
            "Training data lacked sufficient diversity in dark-skinned faces"
        ]
    },
    {
        "q": "Which term describes the gradual expansion of the use of a system or data beyond the purpose for which it was originally intended and consented to?",
        "type": "mcq",
        "o": [
            "Function Creep / Mission Creep",
            "Scope Creep",
            "Feature Bloat",
            "Agile Development"
        ]
    },
    {
        "q": "Rearrange the steps to correct Bias in an AI lifecycle:",
        "type": "rearrange",
        "words": [
            "Audit",
            "data",
            "Train",
            "model",
            "Measure",
            "bias",
            "Mitigate",
            "bias"
        ]
    },
    {
        "q": "Encryption and Anonymization are identical concepts; if data is encrypted, it is legally considered anonymized under all frameworks.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What specific flaw in K-Anonymity is exploited when an attacker knows that *all* individuals in a specific anonymized group (equivalence class) share the same sensitive attribute (e.g., everyone in the group has cancer)?",
        "type": "mcq",
        "o": [
            "Homogeneity Attack",
            "Background Knowledge Attack",
            "Sybil Attack",
            "Dictionary Attack"
        ]
    },
    {
        "q": "The concept of '______' refers to the ability of an individual affected by an automated decision to challenge that decision and potentially get it reversed.",
        "type": "fill_blank",
        "answers": [
            "Recourse"
        ],
        "other_options": [
            "Reverse",
            "Reboot",
            "Recall"
        ]
    },
    {
        "q": "Identify the issue in this time-series forecasting split:",
        "type": "mcq",
        "c": "data = pd.read_csv('stock_prices.csv')\n# Shuffling time-series data destroys temporal order\nX_train, X_test, y_train, y_test = train_test_split(data, target, shuffle=True)",
        "o": [
            "Look-ahead Bias (training on future data)",
            "Sampling Bias",
            "Underfitting",
            "Syntax Error"
        ]
    },
    {
        "q": "Which license is 'Permissive', allowing users to do almost anything with the code/data as long as they provide attribution?",
        "type": "mcq",
        "o": [
            "MIT License",
            "GPL (General Public License)",
            "Proprietary",
            "NDA"
        ]
    },
    {
        "q": "Match the stakeholder to their primary responsibility in the AI Ethics ecosystem:",
        "type": "match",
        "left": [
            "Data Scientist",
            "Domain Expert",
            "Compliance Officer"
        ],
        "right": [
            "Ensuring model accuracy and checking for technical bias",
            "Providing context on how data reflects real-world nuances",
            "Ensuring the system adheres to laws like GDPR/CCPA"
        ]
    },
    {
        "q": "What does the 'California Age-Appropriate Design Code Act' primarily mandate?",
        "type": "mcq",
        "o": [
            "High privacy settings by default for services likely to be accessed by children",
            "Banning all AI for children",
            "Requiring facial recognition for age verification",
            "Free internet access for schools"
        ]
    },
    {
        "q": "In the context of explainability, a 'Global' explanation attempts to explain the entire model's behavior, while a '______' explanation focuses on a single prediction.",
        "type": "fill_blank",
        "answers": [
            "Local"
        ],
        "other_options": [
            "Regional",
            "Specific",
            "Micro"
        ]
    },
    {
        "q": "Look at the Confusion Matrix below for a disease detector. What is the ethical concern if the disease is fatal but treatable?",
        "type": "mcq",
        "c": "# [[TN: 900, FP: 10], \n#  [FN: 80,  TP: 10]]\n# High False Negatives (FN)",
        "o": [
            "The model is missing many actual cases (Low Recall), risking lives",
            "The model is raising too many false alarms (Low Precision)",
            "The model is too accurate",
            "The model is biased against healthy people"
        ]
    },
    {
        "q": "What specific Python command-line flag can dangerously bypass security checks implemented using `assert` statements in production code?",
        "type": "mcq",
        "c": "def critical_operation(user):\n    assert user.is_authenticated, \"Security Breach\"\n    # If run with optimization, this line is skipped.\n    process_payment()",
        "o": [
            "-O (Optimize)",
            "-v (Verbose)",
            "-x (Execute)",
            "-d (Debug)"
        ]
    },
    {
        "q": "The term '______ Gaze', coined by Joy Buolamwini, describes the algorithmic bias in facial recognition systems that results from datasets dominated by lighter-skinned individuals.",
        "type": "fill_blank",
        "answers": [
            "Coded"
        ],
        "other_options": [
            "Digital",
            "Blind",
            "Broken"
        ]
    },
    {
        "q": "Which fairness metric checks if the ratio of favorable outcomes is consistent across different groups (e.g., both men and women get loans at a 40% rate)?",
        "type": "mcq",
        "o": [
            "Statistical Parity (Demographic Parity)",
            "Equalized Odds",
            "Predictive Rate Parity",
            "Counterfactual Fairness"
        ]
    },
    {
        "q": "Match the type of Data Drift to its definition:",
        "type": "match",
        "left": [
            "Covariate Shift",
            "Prior Probability Shift",
            "Concept Drift"
        ],
        "right": [
            "The distribution of input features (X) changes, but the relationship to Y remains the same",
            "The distribution of the target variable (Y) changes",
            "The fundamental relationship between input (X) and target (Y) changes"
        ]
    },
    {
        "q": "What is the primary ethical risk of 'Data Exhaust' (the digital trail left by users' online activities)?",
        "type": "mcq",
        "o": [
            "It can be aggregated to infer sensitive details (like health or political views) without explicit consent",
            "It clogs up server memory",
            "It cannot be compressed",
            "It is always inaccurate"
        ]
    },
    {
        "q": "In the context of Large Language Models (LLMs), '______' refers to the generation of plausible-sounding but factually incorrect or nonsensical information.",
        "type": "fill_blank",
        "answers": [
            "Hallucination"
        ],
        "other_options": [
            "Delusion",
            "Dreaming",
            "Overfitting"
        ]
    },
    {
        "q": "Rearrange the words to identify the 'Alignment Problem' in AI safety:",
        "type": "rearrange",
        "words": [
            "Ensuring",
            "AI",
            "goals",
            "match",
            "human",
            "values"
        ]
    },
    {
        "q": "What is the flaw in this 'anonymization' attempt?",
        "type": "mcq",
        "c": "df['user_id'] = df['user_id'].apply(lambda x: hash(x))\n# Hashing without a salt",
        "o": [
            "It is vulnerable to Dictionary or Rainbow Table attacks",
            "It increases the data size significantly",
            "It makes the data unreadable by the CPU",
            "It changes the data type to float"
        ]
    },
    {
        "q": "According to the 'Privacy by Design' framework, privacy should be the default setting.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which technique involves training a model on a dataset where the sensitive attribute is decorrelated from the feature set to prevent bias?",
        "type": "mcq",
        "o": [
            "Adversarial Debiasing",
            "Gradient Boosting",
            "Feature Crossing",
            "Hyperparameter Tuning"
        ]
    },
    {
        "q": "Match the pseudonymization technique to its description:",
        "type": "match",
        "left": [
            "Masking",
            "Tokenization",
            "Blurring"
        ],
        "right": [
            "Hiding part of the data with characters (e.g., ****-1234)",
            "Replacing sensitive data with a non-sensitive unique identifier",
            "Reducing the precision of image or location data"
        ]
    },
    {
        "q": "What type of bias is created when an AI system is trained on user interactions (clicks), creating a feedback loop that reinforces existing popularity rather than quality?",
        "type": "mcq",
        "o": [
            "Presentation / Exposure Bias",
            "Omitted Variable Bias",
            "Recall Bias",
            "Healthy Worker Bias"
        ]
    },
    {
        "q": "Look at the code below. If `y_pred` are the model predictions and `y_true` are actual labels, what does a low Recall score indicate in a cancer detection context?",
        "type": "mcq",
        "c": "from sklearn.metrics import recall_score\nscore = recall_score(y_true, y_pred)\n# score is 0.45 (Low)",
        "o": [
            "High False Negatives (Missing many actual cancer cases)",
            "High False Positives (Diagnosing healthy people as sick)",
            "The model is overfitting",
            "The model is perfectly balanced"
        ]
    },
    {
        "q": "The '______' Effect refers to the phenomenon where people trust an automated system less after it fails just once, often discarding it entirely.",
        "type": "fill_blank",
        "answers": [
            "Algorithmic"
        ],
        "other_options": [
            "Machine",
            "Digital",
            "Binary"
        ]
    },
    {
        "q": "Which emerging legal concept suggests that data workers (like content moderators) should have rights regarding the psychological toll of filtering toxic AI training data?",
        "type": "mcq",
        "o": [
            "Data Labor Rights",
            "The Right to Be Forgotten",
            "Digital Copyright",
            "Open Source Licensing"
        ]
    },
    {
        "q": "Which New York City law, effective as of 2023, specifically requires a 'Bias Audit' for automated employment decision tools (AEDT) used in hiring and promotion?",
        "type": "mcq",
        "o": [
            "Local Law 144",
            "The AI Bill of Rights",
            "Section 230",
            "Proposition 65"
        ]
    },
    {
        "q": "What security vulnerability is present in this Python code using the PyYAML library to parse user input?",
        "type": "mcq",
        "c": "import yaml\n# 'user_config' is an untrusted string\nconfig = yaml.load(user_config, Loader=yaml.Loader)",
        "o": [
            "Arbitrary Code Execution (via object deserialization)",
            "SQL Injection",
            "Cross-Site Scripting (XSS)",
            "Buffer Overflow"
        ]
    },
    {
        "q": "In the context of Large Language Models (LLMs), ______ Injection is an attack where the user crafts an input to override the model's original instructions and safety guardrails.",
        "type": "fill_blank",
        "answers": [
            "Prompt"
        ],
        "other_options": [
            "SQL",
            "Data",
            "Feature"
        ]
    },
    {
        "q": "Match the Explainable AI (XAI) taxonomy term with its definition:",
        "type": "match",
        "left": [
            "Model-Agnostic",
            "Model-Specific",
            "Post-hoc"
        ],
        "right": [
            "Techniques applicable to any model (e.g., LIME, SHAP)",
            "Techniques designed for a specific architecture (e.g., Attention weights in Transformers)",
            "Explanations generated after the model has already made a prediction"
        ]
    },
    {
        "q": "What is the ' Rashomon Effect' in machine learning modeling?",
        "type": "mcq",
        "o": [
            "The existence of multiple different models that yield similar accuracy but rely on completely different feature sets/explanations",
            "The tendency of a model to hallucinate facts",
            "The increase in error rate as data size increases",
            "The inability of a model to learn non-linear patterns"
        ]
    },
    {
        "q": "Rearrange the words to identify the ISO standard for Artificial Intelligence Management Systems:",
        "type": "rearrange",
        "words": [
            "ISO/IEC",
            "42001",
            "Standard"
        ]
    },
    {
        "q": "What ethical issue arises from using 'Intersectionality' in fairness analysis?",
        "type": "mcq",
        "c": "# Analyzing subgroups: Black Women vs White Men vs Black Men\n# Small sample sizes in intersections lead to high variance.",
        "o": [
            "Subgroups become too small to draw statistically significant conclusions (Data Sparsity)",
            "It is illegal to combine demographic features",
            "It reduces the computational complexity too much",
            "It guarantees 100% fairness automatically"
        ]
    },
    {
        "q": "Removing metadata (like EXIF data) from images is sufficient to prevent re-identification if the image content itself depicts a unique location.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which cryptographic function should be used to verify data integrity and authenticity using a secret key?",
        "type": "mcq",
        "c": "import hmac\nimport hashlib\n# Verifying that the message came from someone with the key",
        "o": [
            "HMAC (Hash-Based Message Authentication Code)",
            "MD5 (Message Digest 5)",
            "CRC32 (Cyclic Redundancy Check)",
            "Base64 Encoding"
        ]
    },
    {
        "q": "The practice of '______' involves releasing a model that performs well on public benchmarks (like ImageNet) but fails in real-world scenarios due to overfitting to the test set.",
        "type": "fill_blank",
        "answers": [
            "Gaming"
        ],
        "other_options": [
            "Training",
            "Pruning",
            "Boosting"
        ]
    },
    {
        "q": "What does the 'L' stand for in the privacy model 'L-Diversity'?",
        "type": "mcq",
        "o": [
            "The number of well-represented sensitive values within each equivalence class",
            "The length of the encryption key",
            "The latency of the query response",
            "The level of user consent"
        ]
    },
    {
        "q": "Identify the risk in this API design regarding data exposure:",
        "type": "mcq",
        "c": "@app.route('/get_user/<id>')\ndef get_user(id):\n    user = db.find(id)\n    # Returns the full user object including internal fields\n    return jsonify(user)",
        "o": [
            "Excessive Data Exposure / Mass Assignment",
            "Broken Access Control",
            "Injection Flaw",
            "Insecure Design"
        ]
    },
    {
        "q": "Match the AI Safety term to its description:",
        "type": "match",
        "left": [
            "Robustness",
            "Alignment",
            "Monitoring"
        ],
        "right": [
            "Ability to maintain performance under stress or attack",
            "Ensuring model objectives match human intent",
            "Continuous tracking of model performance in production"
        ]
    },
    {
        "q": "Deepfakes that are used to non-consensually depict individuals in compromising scenarios are often prosecuted under laws regarding 'Right of ______'.",
        "type": "fill_blank",
        "answers": [
            "Publicity"
        ],
        "other_options": [
            "Way",
            "Access",
            "Speech"
        ]
    },
    {
        "q": "What is the ethical implication of 'Clever Hans' in Machine Learning?",
        "type": "mcq",
        "o": [
            "A model appearing smart by learning spurious correlations (e.g., detecting a ruler in the image instead of the tumor)",
            "A model that can speak German",
            "A model that passes the Turing test",
            "A reinforcement learning agent that cheats"
        ]
    },
    {
        "q": "What specific security vulnerability is demonstrated in this XML parsing code (often called the 'Billion Laughs' attack)?",
        "type": "mcq",
        "c": "import xml.etree.ElementTree as ET\n# XML with nested entities that expand exponentially\ndata = \"\"\"<!DOCTYPE bomb [\n<!ENTITY a \"xxxxxxxxx...\">\n]>\n<bomb>&a;</bomb>\"\"\"\ntree = ET.fromstring(data)",
        "o": [
            "Denial of Service (DoS) via resource exhaustion",
            "SQL Injection",
            "Cross-Site Scripting (XSS)",
            "Man-in-the-Middle Attack"
        ]
    },
    {
        "q": "The practice of creating a superficial appearance of following ethical guidelines (e.g., setting up an ethics board with no veto power) to avoid regulation is known as 'Ethics ______'.",
        "type": "fill_blank",
        "answers": [
            "Washing"
        ],
        "other_options": [
            "Scrubbing",
            "Cleaning",
            "Mining"
        ]
    },
    {
        "q": "Match the Data Governance role with its primary responsibility:",
        "type": "match",
        "left": [
            "Data Owner",
            "Data Steward",
            "Data Custodian"
        ],
        "right": [
            "Accountable for the data's classification and access rights (Business side)",
            "Responsible for data quality, metadata, and adherence to policies",
            "Responsible for the technical storage, safe transport, and infrastructure (IT side)"
        ]
    },
    {
        "q": "Which metric, originally used in economics to measure wealth inequality, is adapted in AI to measure the inequality of benefit distribution across a population?",
        "type": "mcq",
        "o": [
            "Theil Index",
            "Gini Coefficient",
            "F1 Score",
            "ROC-AUC"
        ]
    },
    {
        "q": "Adversarial Training (training a model on adversarial examples) typically increases the model's robustness but often slightly decreases its accuracy on clean, standard data.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the words to describe the EU's requirement for AI oversight:",
        "type": "rearrange",
        "words": [
            "Human",
            "in",
            "command",
            "approach"
        ]
    },
    {
        "q": "What vulnerability is present in this file access code?",
        "type": "mcq",
        "c": "filename = user_input # e.g., \"../../etc/passwd\"\nwith open(f\"/var/www/uploads/{filename}\", 'r') as f:\n    print(f.read())",
        "o": [
            "Path Traversal (Directory Traversal)",
            "Buffer Overflow",
            "Race Condition",
            "Insecure Deserialization"
        ]
    },
    {
        "q": "Match the Explainable AI (XAI) plot type to its description:",
        "type": "match",
        "left": [
            "ICE Plot (Individual Conditional Expectation)",
            "PDP (Partial Dependence Plot)",
            "ALE (Accumulated Local Effects)"
        ],
        "right": [
            "Shows how a prediction changes for ONE specific instance as a feature varies",
            "Shows the average effect of a feature on the prediction across the WHOLE dataset",
            "A faster alternative to PDP that handles correlated features better"
        ]
    },
    {
        "q": "Under the EU AI Act, AI systems intended to interact with natural persons (like Chatbots) must meet which specific transparency obligation?",
        "type": "mcq",
        "o": [
            "They must inform the user that they are interacting with an AI system",
            "They must reveal their source code",
            "They must pay the user for the data",
            "They must be hosted in Europe"
        ]
    },
    {
        "q": "In Differential Privacy, the '______' of a function determines how much the output can change if a single record in the database is changed.",
        "type": "fill_blank",
        "answers": [
            "Sensitivity"
        ],
        "other_options": [
            "Accuracy",
            "Latency",
            "Diversity"
        ]
    },
    {
        "q": "Data that is legally released as 'Public Open Data' (e.g., voter records) is exempt from all ethical considerations regarding privacy and misuse.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the difference between 'Automation Bias' and 'Automation Complacency'?",
        "type": "mcq",
        "o": [
            "Bias is actively following incorrect advice; Complacency is passively missing errors due to lack of attention",
            "Bias is missing errors; Complacency is following advice",
            "They are synonyms",
            "Bias applies to training; Complacency applies to testing"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Safe Harbor' provision (historical):",
        "type": "rearrange",
        "words": [
            "Framework",
            "for",
            "transatlantic",
            "data",
            "flows"
        ]
    },
    {
        "q": "What ethical problem is known as the 'Surrogate Problem'?",
        "type": "mcq",
        "o": [
            "Optimizing for a measurable proxy (e.g., 'clicks') that does not actually align with the complex real-world goal (e.g., 'user well-being')",
            "Using a surrogate model for explainability",
            "Using synthetic data instead of real data",
            "Replacing a human worker with a robot"
        ]
    },
    {
        "q": "Which Python library helps prevent 'Pickle' insecurity by safely serializing/deserializing JSON data instead?",
        "type": "mcq",
        "o": [
            "json",
            "os",
            "sys",
            "ctypes"
        ]
    },
    {
        "q": "Which federal agency in the United States has the primary authority to penalize companies for 'unfair or deceptive acts' regarding data privacy policies?",
        "type": "mcq",
        "o": [
            "FTC (Federal Trade Commission)",
            "FDA (Food and Drug Administration)",
            "SEC (Securities and Exchange Commission)",
            "NSA (National Security Agency)"
        ]
    },
    {
        "q": "What specific type of bias is introduced when a model is trained on data where the labels were generated by an older, biased model (creating a feedback loop)?",
        "type": "mcq",
        "c": "# Training Model B on the output of biased Model A\n# instead of ground truth.",
        "o": [
            "Latent Bias / Automation Bias",
            "Selection Bias",
            "Measurement Bias",
            "Recall Bias"
        ]
    },
    {
        "q": "The '______' Protocol is a standard for websites to state their privacy preferences to browsers, though it is largely defunct and replaced by newer signals like GPC (Global Privacy Control).",
        "type": "fill_blank",
        "answers": [
            "P3P"
        ],
        "other_options": [
            "HTTP",
            "SSL",
            "TCP"
        ]
    },
    {
        "q": "Match the adversarial attack type to the target component:",
        "type": "match",
        "left": [
            "Model Extraction",
            "Inversion Attack",
            "Poisoning"
        ],
        "right": [
            "Stealing the model parameters/architecture",
            "Reconstructing private training data features",
            "Corrupting the training dataset integrity"
        ]
    },
    {
        "q": "What is the primary ethical concern with 'Emotion AI' or Affective Computing?",
        "type": "mcq",
        "o": [
            "It relies on pseudoscience claiming internal emotional states can be accurately inferred from facial expressions across all cultures",
            "It requires too much processing power",
            "It is too expensive to implement",
            "It only works on video, not audio"
        ]
    },
    {
        "q": "Rearrange the words to identify the principle that data should be accurate and kept up to date:",
        "type": "rearrange",
        "words": [
            "Data",
            "Accuracy",
            "Principle"
        ]
    },
    {
        "q": "A 'Data Trust' is a legal structure where data stewardship is delegated to an independent board of trustees who manage the data for the benefit of a group of beneficiaries.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the vulnerability in this API key handling?",
        "type": "mcq",
        "c": "def get_weather():\n    # API Key committed to git history\n    api_key = \"12345-ABCDE-SECRET\"\n    return requests.get(f\"api.weather.com?key={api_key}\")",
        "o": [
            "Hardcoded Secrets",
            "Insecure Transport",
            "Broken Authentication",
            "Server Side Request Forgery"
        ]
    },
    {
        "q": "Which fairness metric focuses on the ratio of False Positives between groups?",
        "type": "mcq",
        "o": [
            "Predictive Equality",
            "Demographic Parity",
            "Equal Opportunity",
            "Calibration"
        ]
    },
    {
        "q": "______ involves giving users a slider or toggle to control the 'granularity' of their data sharing (e.g., precise location vs. city-level location).",
        "type": "fill_blank",
        "answers": [
            "Obfuscation"
        ],
        "other_options": [
            "Encryption",
            "Deletion",
            "Compression"
        ]
    },
    {
        "q": "What is the purpose of a 'Canary Trap' in data security?",
        "type": "mcq",
        "o": [
            "Distributing slightly different versions of a sensitive document to detect who leaks it",
            "Detecting poisonous gases in server rooms",
            "Testing if a model is live",
            "Trapping malware in a sandbox"
        ]
    },
    {
        "q": "Which license requires that if you distribute your software, you must also make the source code available to the recipient?",
        "type": "mcq",
        "o": [
            "Copyleft (e.g., GPL)",
            "Permissive (e.g., MIT)",
            "Public Domain",
            "Commercial"
        ]
    },
    {
        "q": "What does the code below imply about the 'opt-out' mechanism?",
        "type": "mcq",
        "c": "def unsubscribe(user_email):\n    # Marking as 'inactive' but keeping the data\n    db.users.update_one({'email': user_email}, {'$set': {'status': 'inactive'}})\n    # No deletion occurs",
        "o": [
            "It violates the 'Right to Erasure' if the user requested total deletion",
            "It is a perfect implementation of GDPR",
            "It saves database space",
            "It encrypts the email"
        ]
    },
    {
        "q": "Match the privacy concept to the scenario:",
        "type": "match",
        "left": [
            "Data Minimization",
            "Purpose Limitation",
            "Storage Limitation"
        ],
        "right": [
            "Collecting only DoB instead of full birth date + time",
            "Using collected emails ONLY for shipping, not ads",
            "Deleting user logs after 30 days automatically"
        ]
    },
    {
        "q": "In the context of generative AI, 'Model ______' refers to the ability of a model to memorize and regurgitate exact training examples (like PII or copyrighted text).",
        "type": "fill_blank",
        "answers": [
            "Memorization"
        ],
        "other_options": [
            "Learning",
            "Training",
            "Recall"
        ]
    },
    {
        "q": "Which statistical paradox occurs when a model suggests that patients with asthma have a lower risk of dying from pneumonia, simply because those patients are hospitalized sooner and receive more aggressive care?",
        "type": "mcq",
        "o": [
            "The Caruana Paradox (Rule-Based Paradox)",
            "Simpson's Paradox",
            "The Accuracy Paradox",
            "The Observer Effect"
        ]
    },
    {
        "q": "What is the primary privacy danger of 'Linkage Attacks' when releasing an anonymized dataset?",
        "type": "mcq",
        "c": "# Dataset A: Anonymized Health Records (DOB, Zip, Sex, Diagnosis)\n# Dataset B: Public Voter List (Name, DOB, Zip, Sex)\n# Attacker joins A and B on (DOB, Zip, Sex).",
        "o": [
            "Re-identification of individuals by matching quasi-identifiers",
            "Corruption of the diagnosis column",
            "Encryption key leakage",
            "Database deadlock"
        ]
    },
    {
        "q": "The 'Right to ______' allows a data subject to move their personal data from one service provider to another in a structured format.",
        "type": "fill_blank",
        "answers": [
            "Portability"
        ],
        "other_options": [
            "Access",
            "Erasure",
            "Rectification"
        ]
    },
    {
        "q": "Match the threat model to the attacker's knowledge:",
        "type": "match",
        "left": [
            "White-Box Attack",
            "Black-Box Attack",
            "Gray-Box Attack"
        ],
        "right": [
            "Attacker has full access to the model architecture and weights",
            "Attacker only has access to the model's inputs and outputs (API)",
            "Attacker has partial knowledge (e.g., architecture but not weights)"
        ]
    },
    {
        "q": "Which ethical principle is violated if an AI system is deployed in a high-stakes environment (like healthcare) without ever validating its error rate on real-world data?",
        "type": "mcq",
        "o": [
            "Non-maleficence (Do no harm)",
            "Data Minimization",
            "Purpose Limitation",
            "Open Source"
        ]
    },
    {
        "q": "Rearrange the words to identify the risk of AI generating convincing fake media:",
        "type": "rearrange",
        "words": [
            "Deepfakes",
            "threaten",
            "information",
            "integrity"
        ]
    },
    {
        "q": "If a model's 'Recall' for the minority class is 0.1 (10%), what does this practically mean for that group?",
        "type": "mcq",
        "c": "recall = true_positives / (true_positives + false_negatives)\n# Result: 0.1",
        "o": [
            "The model is failing to identify 90% of the qualified candidates in that group",
            "The model is incorrectly accepting 90% of unqualified candidates",
            "The model is 90% accurate",
            "The model is unbiased"
        ]
    },
    {
        "q": "A 'Model Card' is a document that strictly tracks the financial cost of training a model.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the vulnerability in this Python code that uses `input()` to accept a file path?",
        "type": "mcq",
        "c": "fname = input(\"Enter file to read: \")\n# User enters: /etc/shadow\nwith open(fname) as f: print(f.read())",
        "o": [
            "Insecure Direct Object Reference (IDOR) / Path Traversal",
            "SQL Injection",
            "Cross-Site Scripting",
            "Buffer Overflow"
        ]
    },
    {
        "q": "______ Fairness checks if the predictive performance (like accuracy or error rate) is equal across different protected groups.",
        "type": "fill_blank",
        "answers": [
            "Group"
        ],
        "other_options": [
            "Individual",
            "Counterfactual",
            "Casual"
        ]
    },
    {
        "q": "Which term describes the practice of designing a user interface to manipulate users into taking an action they might not otherwise take (e.g., agreeing to tracking)?",
        "type": "mcq",
        "o": [
            "Dark Patterns",
            "User Centric Design",
            "A/B Testing",
            "Feature Engineering"
        ]
    },
    {
        "q": "What specific type of Differential Privacy noise mechanism is used for real-valued (numeric) data queries?",
        "type": "mcq",
        "o": [
            "Laplace Mechanism",
            "Exponential Mechanism",
            "Randomized Response",
            "Hashing"
        ]
    },
    {
        "q": "Match the bias to the example:",
        "type": "match",
        "left": [
            "Historical Bias",
            "Representation Bias",
            "Aggregation Bias"
        ],
        "right": [
            "A hiring algorithm penalizing women because past hiring managers did",
            "ImageNet containing mostly Western images",
            "Using a one-size-fits-all model for diverse populations (e.g., treating all Asians as one group)"
        ]
    },
    {
        "q": "Is this SQL query secure against injection?",
        "type": "mcq",
        "c": "cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))",
        "o": [
            "Yes, it uses parameterized queries",
            "No, it uses string concatenation",
            "No, because it selects *",
            "Yes, because python is secure by default"
        ]
    },
    {
        "q": "The '______' is the entity that determines the 'purposes and means' of the processing of personal data under GDPR.",
        "type": "fill_blank",
        "answers": [
            "Controller"
        ],
        "other_options": [
            "Processor",
            "Subject",
            "Authority"
        ]
    },
    {
        "q": "What is the specific risk of 'Algorithmic Monoculture', where many different institutions (e.g., all major banks) rely on the same third-party AI model for decision-making?",
        "type": "mcq",
        "o": [
            "Systemic Risk (Simultaneous failure across the entire sector)",
            "Increased individual model variance",
            "Decreased model accuracy",
            "Higher computational costs"
        ]
    },
    {
        "q": "What ethical issue is demonstrated in this code regarding 'Target Leakage'?",
        "type": "mcq",
        "c": "# Predicting if a customer will churn\n# 'customer_service_calls_post_cancellation' is included in features\nX = df[['age', 'income', 'customer_service_calls_post_cancellation']]\ny = df['churn']",
        "o": [
            "The feature includes information that happens *after* the target event, artificially inflating accuracy",
            "The feature is not numeric",
            "The model will underfit",
            "There is no issue"
        ]
    },
    {
        "q": "The concept of '______' refers to the tendency of users to attribute human-like traits, intent, or emotions to AI systems (e.g., 'The AI wants to help me').",
        "type": "fill_blank",
        "answers": [
            "Anthropomorphism"
        ],
        "other_options": [
            "Automation",
            "Simulation",
            "Personification"
        ]
    },
    {
        "q": "Match the term to the specific type of data:",
        "type": "match",
        "left": [
            "Inferred Data",
            "Observed Data",
            "Volunteered Data"
        ],
        "right": [
            "Conclusions drawn by the system (e.g., Credit Score, Political leaning)",
            "Data captured automatically (e.g., GPS history, Mouse clicks)",
            "Data explicitly given by the user (e.g., Profile Name, Form inputs)"
        ]
    },
    {
        "q": "Which fairness metric is most appropriate when the cost of a False Positive (accusing an innocent person) is very high, such as in criminal justice sentencing?",
        "type": "mcq",
        "o": [
            "Predictive Parity (Precision)",
            "Recall",
            "F1 Score",
            "Accuracy"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Transparency Paradox':",
        "type": "rearrange",
        "words": [
            "Too",
            "much",
            "detail",
            "can",
            "obscure",
            "understanding"
        ]
    },
    {
        "q": "Under the CPRA (California Privacy Rights Act), consumers have the specific right to limit the use and disclosure of '______ Personal Information' (SPI).",
        "type": "fill_blank",
        "answers": [
            "Sensitive"
        ],
        "other_options": [
            "Secure",
            "Shared",
            "Standard"
        ]
    },
    {
        "q": "What is the primary danger of using a 'Blacklist' approach (blocking known bad inputs) for sanitizing user input in a chatbot?",
        "type": "mcq",
        "c": "bad_words = ['exec', 'system', 'rm']\nif user_input not in bad_words:\n    run(user_input)",
        "o": [
            "It is impossible to list every possible malicious input; attackers will find a bypass",
            "It is too slow to check",
            "It blocks valid users",
            "It requires a database connection"
        ]
    },
    {
        "q": "The 'Brussels Effect' refers to the phenomenon where EU regulations (like GDPR) end up becoming global standards because multinational companies standardize their operations worldwide.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which adversarial attack involves placing a physical sticker (with a specific pattern) on an object to fool a computer vision system (e.g., making a toaster look like a banana)?",
        "type": "mcq",
        "o": [
            "Adversarial Patch",
            "Pixel Noise Attack",
            "Gradient Descent",
            "Man-in-the-middle"
        ]
    },
    {
        "q": "Match the audit type to its description:",
        "type": "match",
        "left": [
            "Socio-technical Audit",
            "Code Audit",
            "Impact Assessment"
        ],
        "right": [
            "Examining how the system interacts with social structures and human stakeholders",
            "Reviewing the source code for bugs and security flaws",
            "Evaluating potential future risks before deployment"
        ]
    },
    {
        "q": "What data ethics principle is violated in this code snippet regarding data retention?",
        "type": "mcq",
        "c": "def delete_account(user_id):\n    # Just toggling a flag, data remains forever\n    user.is_deleted = True\n    user.save()",
        "o": [
            "Storage Limitation / Right to Erasure",
            "Data Portability",
            "Accuracy",
            "Integrity"
        ]
    },
    {
        "q": "The '______' Machine is a platform developed by MIT to gather human perspectives on moral decisions made by machine intelligence, such as self-driving cars.",
        "type": "fill_blank",
        "answers": [
            "Moral"
        ],
        "other_options": [
            "Ethical",
            "Turing",
            "Thinking"
        ]
    },
    {
        "q": "Which statistical measure represents the agreement between two raters (annotators) labeling data, often used to check if the 'Ground Truth' is actually reliable?",
        "type": "mcq",
        "o": [
            "Cohen's Kappa",
            "R-Squared",
            "P-Value",
            "Standard Deviation"
        ]
    },
    {
        "q": "What is the security risk of 'Model Stealing' via API?",
        "type": "mcq",
        "o": [
            "An attacker queries the API repeatedly to train a surrogate model that mimics the proprietary model without paying for it",
            "An attacker deletes the model from the server",
            "An attacker changes the weights of the model",
            "An attacker steals the physical server"
        ]
    }
]