[
  {
    "q": "Which law is widely regarded as the world's strictest data privacy regulation?",
    "type": "mcq",
    "o": [
      "GDPR",
      "CCPA",
      "HIPAA",
      "PIPEDA"
    ]
  },
  {
    "q": "What does the acronym 'GDPR' stand for?",
    "type": "fill_blank",
    "answers": ["General Data Protection Regulation"],
    "other_options": ["Global Data Privacy Rule", "General Digital Protection Regulation", "Government Data Protection Regulation"]
  },
  {
    "q": "Which of the following is NOT a core principle of data ethics?",
    "type": "mcq",
    "o": [
      "Maximizing profit at all costs",
      "Fairness",
      "Transparency",
      "Accountability"
    ]
  },
  {
    "q": "Informed consent means that individuals must be ______ about how their data will be used before giving permission.",
    "type": "fill_blank",
    "answers": ["fully informed"],
    "other_options": ["paid", "registered", "notified later"]
  },
  {
    "q": "Bias in AI models most commonly enters through:",
    "type": "mcq",
    "o": [
      "Biased or unrepresentative training data",
      "Using too many features",
      "Choosing the wrong optimizer",
      "Having too much computational power"
    ]
  },
  {
    "q": "Match the term with its correct description:",
    "type": "match",
    "left": ["Anonymization", "Pseudonymization", "De-identification", "Data minimization"],
    "right": ["Removing or altering data so a person cannot be re-identified", "Replacing identifying fields with artificial identifiers", "General term for removing direct identifiers", "Collecting only the data that is strictly necessary"]
  },
  {
    "q": "Transparency in AI means that users should be able to understand how and why a model made a particular decision.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which of the following is an example of algorithmic bias?",
    "type": "mcq",
    "o": [
      "A facial recognition system that performs significantly worse on darker skin tones",
      "A model that runs slowly on old computers",
      "A recommendation system that suggests popular items",
      "A classifier with 99% accuracy on the test set"
    ]
  },
  {
    "q": "Accountability in data science means that organizations and individuals can be held responsible for:",
    "type": "mcq",
    "o": [
      "The consequences of their data practices and AI systems",
      "Only the financial cost of data storage",
      "The speed of model training",
      "The choice of programming language"
    ]
  },
  {
    "q": "Under GDPR, individuals have the 'Right to be Forgotten'. This is also known as the right to:",
    "type": "mcq",
    "o": [
      "Erasure",
      "Portability",
      "Access",
      "Rectification"
    ]
  },
  {
    "q": "Data minimization is the principle that you should collect ______ data than is strictly necessary for the purpose.",
    "type": "fill_blank",
    "answers": ["no more"],
    "other_options": ["as much", "less", "only public"]
  },
  {
    "q": "Rearranged the words to form a common ethical guideline in data science:",
    "type": "rearrange",
    "words": ["Do", "no", "harm"]
  },
  {
    "q": "It is ethically acceptable to use personal data collected for one purpose (e.g., improving a product) for a completely different purpose (e.g., targeted advertising) without explicit additional consent.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Which of the following helps improve transparency in machine learning models?",
    "type": "mcq",
    "o": [
      "Using explainable AI (XAI) techniques such as SHAP or LIME",
      "Encrypting the model weights",
      "Deploying the model only internally",
      "Reducing the number of training epochs"
    ]
  },
  {
    "q": "The CCPA applies only to companies operating in which location?",
    "type": "mcq",
    "o": [
      "California",
      "Canada",
      "European Union",
      "China"
    ]
  },
  {
    "q": "Which data privacy law grants California residents the right to opt-out of the sale of their personal information?",
    "type": "mcq",
    "o": [
      "CCPA/CPRA",
      "LGPD",
      "PDPA",
      "APPI"
    ]
  },
  {
    "q": "The principle of 'purpose limitation' states that personal data should be collected for specified, explicit and ______ purposes.",
    "type": "fill_blank",
    "answers": ["legitimate"],
    "other_options": ["profitable", "future", "research"]
  },
  {
    "q": "Match the privacy technique with its primary goal:",
    "type": "match",
    "left": ["Differential Privacy", "k-Anonymity", "l-Diversity", "t-Closeness"],
    "right": ["Adds statistical noise to protect individuals", "Ensures each record is indistinguishable from at least k-1 others", "Protects against attribute disclosure", "Preserves the distribution of sensitive attributes"]
  },
  {
    "q": "Re-identification attacks are possible even on anonymized datasets when combined with auxiliary information.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which of the following is considered a 'sensitive personal data' category under GDPR?",
    "type": "mcq",
    "o": [
      "Ethnic origin, political opinions, religious beliefs, biometric data",
      "IP address and cookies",
      "Purchase history",
      "Device type"
    ]
  },
  {
    "q": "Fairness through unawareness (removing protected attributes like race/gender from training data) is sufficient to eliminate bias in AI models.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Rearrange these words to form a key ethical principle in responsible AI development:",
    "type": "rearrange",
    "words": ["First", "do", "no", "harm", "is", "but", "not", "enough"]
  },
  {
    "q": "In the context of AI ethics, 'explainability' and 'interpretability' mean exactly the same thing.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "A Data Protection Impact Assessment (DPIA) is mandatory under GDPR when processing is likely to result in:",
    "type": "mcq",
    "o": [
      "High risk to the rights and freedoms of individuals",
      "Low revenue",
      "Large datasets only",
      "Public Wi-Fi usage"
    ]
  },
  {
    "q": "The 'black box' problem in AI primarily affects which ethical value?",
    "type": "mcq",
    "o": [
      "Transparency",
      "Accuracy",
      "Speed",
      "Cost efficiency"
    ]
  },
  {
    "q": "______ fairness ensures that the error rate is similar across different protected groups.",
    "type": "fill_blank",
    "answers": ["Equalized odds"],
    "other_options": ["Demographic parity", "Individual fairness", "Counterfactual fairness"]
  },
  {
    "q": "Who typically bears legal accountability when an AI system causes harm in a regulated sector (e.g., healthcare or hiring)?",
    "type": "mcq",
    "o": [
      "The organization that deployed the system",
      "The open-source contributor who wrote one layer",
      "The cloud provider hosting the model",
      "The GPU manufacturer"
    ]
  },
  {
    "q": "Model cards and datasheets for datasets were introduced to improve:",
    "type": "mcq",
    "o": [
      "Transparency and accountability",
      "Training speed",
      "Model compression",
      "Marketing"
    ]
  },
  {
    "q": "Using synthetic data instead of real personal data can help satisfy which privacy principle?",
    "type": "mcq",
    "o": [
      "Data minimization and privacy by design",
      "Storage limitation",
      "Accuracy",
      "Integrity"
    ]
  },
  {
    "q": "It is ethically acceptable to deploy a high-stakes AI system (e.g., criminal recidivism prediction) with known demographic bias if it improves overall accuracy.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "The 'right to explanation' for automated decisions exists in a strong legal form only under:",
    "type": "mcq",
    "o": [
      "GDPR Article 22 and Recital 71",
      "CCPA",
      "HIPAA",
      "COPPA"
    ]
  },
  {
    "q": "______ refers to the practice of building privacy protections into the design and architecture of systems from the very beginning.",
    "type": "fill_blank",
    "answers": ["Privacy by design"],
    "other_options": ["Privacy by default", "Privacy by policy", "Privacy after deployment"]
  },
  {
    "q": "Match the real-world bias incident to the affected system:",
    "type": "match",
    "left": ["COMPAS recidivism tool", "Amazon hiring algorithm", "Google Photos gorilla incident", "Apple Card credit limits"],
    "right": ["Racial bias in risk scores", "Gender bias against women in resumes", "Misclassification of Black people", "Gender bias in credit offers"]
  },
  {
    "q": "Deploying facial recognition in public spaces without explicit citizen consent is considered compatible with the principle of proportionality in most democratic countries.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Which organization published the 'Asilomar AI Principles' for beneficial AI, which include value alignment, transparency, and human control?",
    "type": "mcq",
    "o": [
      "Future of Life Institute",
      "OpenAI",
      "IEEE",
      "World Economic Forum"
    ]
  },
  {
    "q": "______ is the ethical risk that arises when AI systems reinforce existing societal stereotypes through their outputs.",
    "type": "fill_blank",
    "answers": ["Allocative harm", "Representational harm"],
    "other_options": ["Computational harm", "Inference harm"]
  },
  {
    "q": "Rearrange the steps to form the correct order of an ethical data science project lifecycle:",
    "type": "rearrange",
    "words": ["Define problem ethically", "Collect data responsibly", "Assess bias & fairness", "Document with model card", "Monitor post-deployment", "Obtain consent where needed"]
  },
  {
    "q": "The EU AI Act classifies AI systems that perform social scoring by governments as:",
    "type": "mcq",
    "o": [
      "Prohibited risk",
      "High risk",
      "Limited risk",
      "Minimal risk"
    ]
  },
  {
    "q": "Data fiduciaries' under India's DPDP Act 2023 have an obligation similar to doctors or lawyers toward their patients/clients.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which technique intentionally adds controlled random noise to query results to achieve differential privacy?",
    "type": "mcq",
    "o": [
      "Laplace mechanism",
      "Homomorphic encryption",
      "Federated learning",
      "Secure multi-party computation"
    ]
  },
  {
    "q": "The practice of 'dark patterns' in user interfaces to trick users into giving up more personal data violates which ethical principle?",
    "type": "mcq",
    "o": [
      "Respect for autonomy",
      "Non-maleficence",
      "Justice",
      "Beneficence"
    ]
  },
  {
    "q": "In adversarial machine learning, 'data poisoning' attacks are a threat primarily to:",
    "type": "mcq",
    "o": [
      "Integrity and accountability",
      "Confidentiality",
      "Availability",
      "Speed"
    ]
  },
  {
    "q": "Children under 13 in the United States are specially protected by which privacy law?",
    "type": "mcq",
    "o": [
      "COPPA",
      "FERPA",
      "GLBA",
      "SOX"
    ]
  },
  {
    "q": "An AI system that denies loans to an entire geographic area (redlining) can violate fairness even if race is not an input feature.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The Montreal Declaration for Responsible AI lists ______ as one of its ten core principles.",
    "type": "fill_blank",
    "answers": ["inclusiveness", "equity", "solidarity", "democratic participation"],
    "other_options": ["profitability", "efficiency", "scalability"]
  },
  {
    "q": "Federated learning was primarily developed to improve which aspect of data ethics?",
    "type": "mcq",
    "o": [
      "Keeping raw personal data on users' devices instead of central servers",
      "Reducing model size",
      "Speeding up gradient descent",
      "Making models more interpretable"
    ]
  },
  {
    "q": "The term 'surveillance capitalism' was coined by:",
    "type": "mcq",
    "o": [
      "Shoshana Zuboff",
      "Timnit Gebru",
      "Cathy O'Neil",
      "Evgeny Morozov"
    ]
  },
  {
    "q": "______ privacy occurs when an individual’s sensitive information can be inferred even though it was never directly collected.",
    "type": "fill_blank",
    "answers": ["Inferential"],
    "other_options": ["Group", "Statistical", "Contextual"]
  },
  {
    "q": "Match the ethical framework to its primary origin:",
    "type": "match",
    "left": ["Ethics Guidelines for Trustworthy AI", "Toronto Declaration", "Beijing AI Principles", "OECD AI Principles"],
    "right": ["European Commission (2019)", "Amnesty International & Access Now", "China Academy of Information and Communications Technology", "Adopted by 42 countries in 2019"]
  },
  {
    "q": "Using pre-trained large language models without auditing their training data can transfer hidden biases and toxic content into downstream applications.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these phrases to form the correct definition of 'algorithmic accountability':",
    "type": "rearrange",
    "words": ["The", "obligation", "to", "explain", "and", "justify", "algorithmic", "decisions", "and", "their", "impacts"]
  },
  {
    "q": "Which of the following is considered a prohibited AI practice under the EU AI Act (as of 2025)?",
    "type": "mcq",
    "o": [
      "Real-time remote biometric identification in public spaces by law enforcement (with narrow exceptions)",
      "Chatbots with disclosure",
      "Emotion recognition in workplaces",
      "Deepfake detection tools"
    ]
  },
  {
    "q": "The 'privacy paradox' refers to the phenomenon where people claim to care about privacy but behave as if they do not.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In fairness metrics, 'disparate impact' is typically flagged when the selection rate for a protected group falls below what percentage of the majority group?",
    "type": "mcq",
    "o": [
      "80%",
      "50%",
      "90%",
      "70%"
    ]
  },
  {
    "q": "______ is the practice of splitting a dataset into multiple parts and training separate models to prevent any single party cannot reconstruct the original data.",
    "type": "fill_blank",
    "answers": ["Data partitioning", "Split learning"],
    "other_options": ["Model averaging", "Ensemble privacy"]
  },
  {
    "q": "The landmark 2018 case in which the UK Information Commissioner fined Facebook £500,000 was related to:",
    "type": "mcq",
    "o": [
      "Cambridge Analytica scandal",
      "Shadow profiles",
      "Like button tracking",
      "WhatsApp data sharing"
    ]
  },
  {
    "q": "Audit trails and immutable logging of data access and model decisions are technical measures primarily supporting which ethical principle?",
    "type": "mcq",
    "o": [
      "Accountability",
      "Transparency",
      "Fairness",
      "Privacy"
    ]
  },
  {
    "q": "The principle that AI should augment rather than replace human decision-making in high-stakes domains is known as:",
    "type": "mcq",
    "o": [
      "Human-in-the-loop",
      "Human-on-the-loop",
      "Human-out-of-the-loop",
      "Human-over-the-loop"
    ]
  },
  {
    "q": "It is sufficient to claim a dataset is 'publicly available' to bypass consent requirements under most modern privacy laws.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "The 'Weaponized AI Propaganda Machine' paper (2019) by Timnit Gebru and others highlighted risks of large language models being used for:",
    "type": "mcq",
    "o": [
      "Generating disinformation at scale",
      "Energy consumption",
      "Job displacement",
      "Training time reduction"
    ]
  },
  {
    "q": "The 'right to non-discrimination' in AI is explicitly protected under which recent international treaty or framework?",
    "type": "mcq",
    "o": [
      "UNESCO Recommendation on the Ethics of Artificial Intelligence (2021)",
      "Universal Declaration of Human Rights",
      "Paris Call for Trust and Security in Cyberspace",
      "G7 Hiroshima AI Process"
    ]
  },
  {
    "q": "______ refers to the environmental and social justice concern that the carbon footprint and rare-earth mining for AI disproportionately harms marginalized communities.",
    "type": "fill_blank",
    "answers": ["AI environmental justice", "AI ecological debt"],
    "other_options": ["Green AI", "Carbon bias"]
  },
  {
    "q": "Match the lesser-known privacy law to its country/region:",
    "type": "match",
    "left": ["PIPA", "PDPA", "LGPD", "DPDP Act"],
    "right": ["South Korea", "Singapore", "Brazil", "India"]
  },
  {
    "q": "Workers who label toxic content or annotate sensitive images for AI training are often called 'ghost workers' and face serious mental health risks.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the fairness definition that requires similar individuals to receive similar predictions:",
    "type": "rearrange",
    "words": ["Individual", "fairness"]
  },
  {
    "q": "The practice of 'consent theater' (long, unreadable privacy policies that users must accept) primarily violates which ethical principle from the Menlo Report?",
    "type": "mcq",
    "o": [
      "Respect for persons",
      "Beneficence",
      "Justice",
      "Respect for law and public interest"
    ]
  },
  {
    "q": "______ is the term for the risk that over-reliance on AI systems erodes human skills and critical judgment over time.",
    "type": "fill_blank",
    "answers": ["Automation complacency", "Deskilling"],
    "other_options": ["Skill atrophy", "AI dependency bias"]
  },
  {
    "q": "The 'Collingridge dilemma' in technology ethics states that:",
    "type": "mcq",
    "o": [
      "Early in development it is hard to predict impacts, but later it is hard to change the technology",
      "AI will always outsmart regulation",
      "Ethics review boards slow down innovation",
      "Open-source AI is inherently safer"
    ]
  },
  {
    "q": "Under Brazil’s LGPD, the national data protection authority is called:",
    "type": "mcq",
    "o": [
      "ANPD (Autoridade Nacional de Proteção de Dados)",
      "CNIL",
      "DPC",
      "Garante"
    ]
  },
  {
    "q": "Dual-use AI research (e.g., deepfake or autonomous weapons technology) should always be published openly because scientific freedom outweighs societal risk.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Rearrange the components to form one of the five OECD AI Principles:",
    "type": "rearrange",
    "words": ["Inclusive", "growth", ",", "sustainable", "development", "and", "well-being"]
  },
  {
    "q": "The 'value alignment problem' in AI ethics primarily concerns ensuring AI systems pursue goals that match:",
    "type": "mcq",
    "o": [
      "Human values and preferences",
      "Corporate profits",
      "Training data distribution",
      "Hardware efficiency"
    ]
  },
  {
    "q": "The phenomenon where marginalized groups are underrepresented in both training data and AI development teams is called:",
    "type": "fill_blank",
    "answers": ["Double invisibility", "Dual exclusion"],
    "other_options": ["Participation gap", "Representation bias"]
  },
  {
    "q": "The 2023 EU-U.S. Data Privacy Framework replaced the invalidated Privacy Shield to allow transatlantic data flows.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which concept argues that AI should not only avoid harm but actively promote human flourishing and solidarity?",
    "type": "mcq",
    "o": [
      "Principlism", "Care ethics", "Virtue ethics", "Positive AI ethics"],
    "correct_index": 3
  },
  {
    "q": "The 'robo-debt' scandal in Australia (2015–2019) is a prominent example of harm caused by:",
    "type": "mcq",
    "o": [
      "Automated welfare overpayment recovery using flawed income averaging",
      "Self-driving car accidents",
      "Predictive policing errors",
      "Automated loan approval bias"
    ]
  },
  {
    "q": "______ is the privacy-preserving technique that allows multiple hospitals to train a shared model without ever exchanging patient records.",
    "type": "fill_blank",
    "answers": ["Federated learning"],
    "other_options": ["Homomorphic learning", "Encrypted transfer learning", "Distributed gradient descent"]
  },
  {
    "q": "Match the concept to its correct definition:",
    "type": "match",
    "left": ["Mosaic effect", "Chilling effect", "Function creep", "Wash trading in datasets"],
    "right": ["Combining non-sensitive datasets to re-identify individuals", "People self-censor behavior due to fear of surveillance", "Using data for purposes beyond original intent", "Artificially inflating dataset usage metrics for funding"]
  },
  {
    "q": "Deploying emotion-recognition AI in job interviews has been banned or heavily restricted in which U.S. state as of 2025?",
    "type": "mcq",
    "o": [
      "Illinois",
      "California",
      "Texas",
      "New York"
    ]
  },
  {
    "q": "The principle that AI systems should remain under-promise and over-deliver on capability to avoid over-trust is called 'calibration humility'.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Rearrange these words to form the name of the 2024 EU regulation governing General-Purpose AI models:",
    "type": "rearrange",
    "words": ["EU", "AI", "Act"]
  },
  {
    "q": "______ refers to the ethical obligation to fairly distribute both the benefits and risks of AI across current and future generations.",
    "type": "fill_blank",
    "answers": ["Intergenerational justice"],
    "other_options": ["Temporal fairness", "Long-term equity", "Diachronic ethics"]
  },
  {
    "q": "The 'AI incident database' (AIID) maintained by the Partnership on AI aims to track and learn from real-world AI failures.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country became the first in the world to grant legal personhood to an AI (Sophia) in 2017?",
    "type": "mcq",
    "o": [
      "Saudi Arabia",
      "Japan",
      "Estonia",
      "Singapore"
    ]
  },
  {
    "q": "The 'Tay chatbot' incident (Microsoft, 2016) is a classic example of vulnerability to:",
    "type": "mcq",
    "o": [
      "Coordinated adversarial input leading to toxic output within hours",
      "Data poisoning via scraped Reddit comments",
      "Model inversion attack",
      "Gradient leakage"
    ]
  },
  {
    "q": "In privacy scholarship, 'contextual integrity' theory was developed by:",
    "type": "mcq",
    "o": [
      "Helen Nissenbaum",
      "Daniel Solove",
      "Woodrow Hartzog",
      "Alessandro Acquisti"
    ]
  },
  {
    "q": "The practice of training AI on copyrighted books, art, or journalism without permission or compensation is known as:",
    "type": "fill_blank",
    "answers": ["Data laundering", "Consentless scraping"],
    "other_options": ["Fair use mining", "Open-source ingestion"]
  },
  {
    "q": "The 'Markkula Framework' for AI ethics emphasizes seven steps, starting with 'Recognize an ethical issue'.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which emerging risk category does 'AI-enabled mass persuasion' (hyper-personalized propaganda) fall under in most governmental AI risk taxonomies?",
    "type": "mcq",
    "o": [
      "Societal-scale manipulation / influence operations",
      "Physical safety",
      "Critical infrastructure failure",
      "Economic displacement"
    ]
  },
  {
    "q": "The 'butterfly effect' in data ethics refers to small, seemingly harmless data collection choices that cascade into major privacy violations years later.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The concept of 'data dignity' argues that personal data should be treated as an extension of human dignity rather than as a commodity.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which African country enacted the continent's first comprehensive data protection law in 2019, serving as a model for many others?",
    "type": "mcq",
    "o": [
      "Kenya (Data Protection Act 2019)",
      "South Africa (POPIA)",
      "Nigeria (NDPR)",
      "Ghana (Data Protection Act)"
    ]
  },
  {
    "q": "______ is the term for deliberately designing datasets to include adversarial examples that cause downstream models to fail on specific triggers.",
    "type": "fill_blank",
    "answers": ["Backdoor poisoning", "Trigger planting"],
    "other_options": ["Sleeper cell data", "Trojan dataset"]
  },
  {
    "q": "Match the ethical red-teaming organization or initiative to its focus:",
    "type": "match",
    "left": ["Anthropic's Constitutional AI", "Center for AI Safety (CAIS)", "AI Safety Institute (UK)", "Apollo Research"],
    "right": ["Long-term existential risk and misalignment", "Interpretability and deception detection", "National AI safety evaluations", "Value alignment via explicit principles"]
  },
  {
    "q": "The 'right to reasonable inferences'—the right not to be subject to high-risk inferences drawn from your data—has been proposed by:",
    "type": "mcq",
    "o": [
      "Sandra Wachter, Brent Mittelstadt, and Luciano Floridi",
      "Kate Crawford",
      "Virginia Eubanks",
      "Ruha Benjamin"
    ]
  },
  {
    "q": "Rearrange these words to form the title of the influential 2021 Stanford paper that introduced the term 'stochastic parrots':",
    "type": "rearrange",
    "words": ["On", "the", "Dangers", "of", "Stochastic", "Parrots"]
  },
  {
    "q": "______ refers to the practice where companies collect data from vulnerable populations (e.g., refugees, low-income users) under the guise of 'doing good'.",
    "type": "fill_blank",
    "answers": ["Ethics washing", "Humanitarian data extractivism"],
    "other_options": ["Impact scraping", "Charity mining"]
  },
  {
    "q": "The NIST AI Risk Management Framework (AI RMF 1.0) explicitly recommends 'TEVV' — what does this acronym stand for?",
    "type": "fill_blank",
    "answers": ["Testing, Evaluation, Validation, and Verification"],
    "other_options": ["Trust, Ethics, Values, Validation", "Transparency, Explainability, Validity, Verification"]
  },
  {
    "q": "A 'kill switch' or mandatory off-switch in lethal autonomous weapons is required under international humanitarian law.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "The 'data strike' movement, where individuals or communities refuse to provide data to protest exploitation, was pioneered by:",
    "type": "mcq",
    "o": [
      "Drivers and delivery workers against Uber/Lyft/Deliveroo",
      "Facebook users in 2018",
      "Google employees in Project Maven",
      "Amazon Mechanical Turk workers"
    ]
  },
  {
    "q": "The term 'algorithmic monoculture' describes the risk that widespread adoption of a few dominant AI models leads to correlated failures across society.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which philosophical tradition argues that privacy is not about secrecy but about appropriate flow of information in different social contexts?",
    "type": "mcq",
    "o": [
      "Contextual integrity (Nissenbaum)",
      "Control theory (Westin)",
      "Restricted access theory (Tavani)",
      "Liberal individualism"
    ]
  },
  {
    "q": "The 2024 Canadian 'Artificial Intelligence and Data Act' (AIDA) classifies AI systems into risk tiers and requires impact assessments for ______ systems.",
    "type": "fill_blank",
    "answers": ["high-impact"],
    "other_options": ["commercial", "generative", "public-sector"]
  },
  {
    "q": "The 'P800 database' scandal in the Philippines (2016) exposed personal data of how many voters?",
    "type": "mcq",
    "o": [
      "Over 55 million",
      "1.2 million",
      "8 million",
      "340,000"
    ]
  },
  {
    "q": "The principle of 'subsidiarity' in AI governance suggests that regulatory decisions should be taken at the most local level possible.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'right to contestability' means individuals must have an effective way to challenge AI decisions that significantly affect them.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country passed the world's first law specifically banning manipulative subliminal AI techniques in 2024?",
    "type": "mcq",
    "o": [
      "France (within the Digital Services Act enforcement)",
      "China",
      "Brazil",
      "Australia"
    ]
  },
  {
    "q": "______ is the phenomenon where AI companies use workers in low-income countries to clean toxic data for extremely cheaply, creating a new form of digital exploitation.",
    "type": "fill_blank",
    "answers": ["Data colonialism", "Clickwork exploitation"],
    "other_options": ["Remote annotation", "Crowd cleansing"]
  },
  {
    "q": "Match the emerging governance tool to its purpose:",
    "type": "match",
    "left": ["Algorithmic Impact Assessment (AIA)", "Structured Transparency Report", "Red-teaming registry", "Model autopsy protocol"],
    "right": ["Government-mandated pre-deployment risk audit (Canada)", "Post-incident public disclosure template", "Shared database of adversarial tests", "Forensic analysis after catastrophic failure"]
  },
  {
    "q": "The 2023 'Blueprint for an AI Bill of Rights' published by the White House OSTP contains exactly how many principles?",
    "type": "mcq",
    "o": [
      "5",
      "7",
      "10",
      "3"
    ]
  },
  {
    "q": "Rearrange these words to form the name of the controversial practice where AI is used to resurrect deceased people without family consent:",
    "type": "rearrange",
    "words": ["Grief", "tech"]
  },
  {
    "q": "______ refers to the ethical problem that people from marginalized groups are often over-surveilled yet under-protected by AI systems.",
    "type": "fill_blank",
    "answers": ["Hyper-visibility paradox", "Surveilled but unprotected"],
    "other_options": ["Dual-use surveillance", "Asymmetric monitoring"]
  },
  {
    "q": "The 'FAccT' conference (Fairness, Accountability, and Transparency) was renamed in 2023 to:",
    "type": "mcq",
    "o": [
      "EAAMO (Equity and Access in Algorithms, Mechanisms, and Optimization)",
      "AI-Ethics",
      "TrustAI",
      "Responsible Computing"
    ]
  },
  {
    "q": "Using AI-generated child sexual abuse material (CSAM), even if entirely synthetic, is illegal in most Western countries as of 2025.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'Latanya Sweeney k-anonymity paper' (2002) famously showed that ______% of the U.S. population could be uniquely identified using just ZIP code, gender, and date of birth.",
    "type": "fill_blank",
    "answers": ["87"],
    "other_options": ["63", "99", "51"]
  },
  {
    "q": "Which organization released the 'Latimer Report' (2023) criticizing the UK's inadequate regulation of biometric surveillance?",
    "type": "mcq",
    "o": [
      "Ada Lovelace Institute",
      "Electronic Frontier Foundation",
      "Privacy International",
      "Article 19"
    ]
  },
  {
    "q": "The term 'permissionless innovation' is most strongly associated with which ideological stance on AI regulation?",
    "type": "mcq",
    "o": [
      "Techno-libertarian / accelerationist",
      "Precautionary principle",
      "Human-rights-centered",
      "State-centric"
    ]
  },
  {
    "q": "______ is the practice of deliberately designing AI systems to be slightly underperform so they remain legally classifiable as 'limited risk' instead of 'high risk'.",
    "type": "fill_blank",
    "answers": ["Regulatory arbitrage", "Risk shaving"],
    "other_options": ["Threshold gaming", "Compliance dodging"]
  },
  {
    "q": "The Hiroshima AI Process (G7 2023) introduced the concept of 'risk-based governance' with eleven guiding principles for generative AI.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'No AI Fraud Act' proposed in the U.S. Congress in 2024 specifically targets non-consensual deepfake impersonation of which two things?",
    "type": "fill_blank",
    "answers": ["voice and likeness"],
    "other_options": ["identity and location", "face and handwriting", "behavior and speech patterns"]
  },
  {
    "q": "The 'Schrems II' ruling (2020) by the European Court of Justice invalidated which transatlantic data-transfer mechanism?",
    "type": "mcq",
    "o": [
      "Privacy Shield",
      "Safe Harbor",
      "Standard Contractual Clauses",
      "Binding Corporate Rules"
    ]
  },
  {
    "q": "______ is the term for the deliberate introduction of subtle errors or watermarks into datasets to later prove ownership or detect scraping.",
    "type": "fill_blank",
    "answers": ["Data poisoning for provenance", "Nightshade", "Glaze"],
    "other_options": ["Fingerprinting", "Canary tokens", "Synthetic traps"]
  },
  {
    "q": "Match the AI ethics whistle-blower to their organization:",
    "type": "match",
    "left": ["Timnit Gebru", "Margaret Mitchell", "Sophie Zhang", "Frances Haugen"],
    "right": ["Google Ethical AI", "Google Ethical AI", "Facebook (Data for Good)", "Facebook (Civic Integrity)"]
  },
  {
    "q": "The 'Belmont Report' (1979), originally written for medical research, has been adapted as an ethical foundation for modern data science research involving human subjects.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2024 California bill that requires labeling of AI-generated content:",
    "type": "rearrange",
    "words": ["AB", "3211", "California", "Deepfake", "Election", "Law"]
  },
  {
    "q": "______ refers to the risk that AI systems trained predominantly on Western, English-language data will erode cultural and linguistic diversity worldwide.",
    "type": "fill_blank",
    "answers": ["Linguistic imperialism", "Digital colonialism", "Cultural homogenization"],
    "other_options": ["Model anglocentrism", "Data hegemony"]
  },
  {
    "q": "The 'AI Now Institute' was co-founded by Kate Crawford and which Microsoft researcher?",
    "type": "mcq",
    "o": [
      "Meredith Whittaker",
      "Danah Boyd",
      "Jenna Burrell",
      "Rediet Abebe"
    ]
  },
  {
    "q": "Under the EU’s Digital Services Act (DSA), very large online platforms must conduct annual systemic risk assessments that explicitly include bias and discrimination risks.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'CLOUD Act' (2018) of the United States primarily allows:",
    "type": "mcq",
    "o": [
      "U.S. law enforcement to compel U.S. companies to provide data stored abroad",
      "EU citizens to store data only in Europe",
      "Cloud providers to refuse government requests",
      "Automatic data deletion after 90 days"
    ]
  },
  {
    "q": "______ is the practice of using AI to generate thousands of fake scientific papers or peer reviews to manipulate academic metrics.",
    "type": "fill_blank",
    "answers": ["Paper mill fraud", "AI-generated science spam"],
    "other_options": ["Citation gaming", "Retraction farming"]
  },
  {
    "q": "The 2024 ILO report on generative AI warned that the most likely near-term impact on jobs is:",
    "type": "mcq",
    "o": [
      "Job transformation and augmentation rather than mass replacement",
      "Complete automation of white-collar work",
      "Elimination of all creative professions",
      "Universal basic income requirement"
    ]
  },
  {
    "q": "The 'meaningful human control' requirement for autonomous weapons is endorsed by which international campaign?",
    "type": "mcq",
    "o": [
      "Campaign to Stop Killer Robots",
      "Future of Life Institute",
      "ICAN (nuclear weapons)",
      "Amnesty International"
    ]
  },
  {
    "q": "The concept of 'moral crumple zones' describes how human operators are unfairly blamed for failures actually caused by complex AI systems.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country’s 2024 AI Strategy explicitly includes 'sovereign AI' (developing national large models using local language data) as a strategic priority?",
    "type": "mcq",
    "o": [
      "France (with Mistral AI support)",
      "Canada",
      "Singapore",
      "Australia"
    ]
  },
  {
    "q": "The 'Adversarial ML Threat Matrix' was jointly developed by Microsoft, IBM, and which other entity?",
    "type": "mcq",
    "o": [
      "MITRE Corporation",
      "SEI Carnegie Mellon",
      "Bosch",
      "Cardiff University"
    ]
  },
  {
    "q": "The 'illusion of consent' arises primarily because most users do not read or understand privacy policies longer than:",
    "type": "mcq",
    "o": [
      "the average novel (≈70,000 words)",
      "10 pages",
      "500 words",
      "1 page"
    ]
  },
  {
    "q": "______ is the term for AI systems that secretly steer user attention and behavior through micro-targeted nudging at massive scale.",
    "type": "fill_blank",
    "answers": ["Hypernudging"],
    "other_options": ["Attention capture", "Choice architecture", "Behavioral steering"]
  },
  {
    "q": "Match the data scandal to the year it broke:",
    "type": "match",
    "left": ["Strava heat-map revealing secret military bases", "Clearview AI facial database exposed", "Voter profiling by Cambridge Analytica revealed", "Chinese surveillance of Uyghurs with AI"],
    "right": ["2018", "2020", "2018", "2017–2019"]
  },
  {
    "q": "The 'AI Safety Clock' maintained by the Centre for the Governance of AI was at 7 minutes to midnight as of late 2025.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Rearrange these words to form the name of the pioneering 2019 book that coined 'data feminism':",
    "type": "rearrange",
    "words": ["Data", "Feminism", "Catherine", "D'Ignazio", "Lauren", "Klein"]
  },
  {
    "q": "The 'right to be imperfect' argues that individuals should not be judged by AI systems more harshly than they would be by humans.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ refers to the practice of training AI models on prison labor or forced labor in the supply chain.",
    "type": "fill_blank",
    "answers": ["Carceral AI", "Incarcerated annotation"],
    "other_options": ["Punitive data labeling", "Forced training"]
  },
  {
    "q": "The 'Trolley Problem' thought experiments are widely considered a useful and sufficient framework for real-world autonomous vehicle ethics.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Which U.S. federal agency released the 2023 'Blueprint for an AI Bill of Rights'?",
    "type": "mcq",
    "o": [
      "White House Office of Science and Technology Policy (OSTP)",
      "FTC",
      "NIST",
      "Department of Commerce"
    ]
  },
  {
    "q": "The 'Revolt of the Public' thesis by Martin Gurri predicts that AI-amplified information flows will make hierarchical governance increasingly unstable.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the emerging governance model where citizens directly vote on acceptable AI use cases via digital platforms.",
    "type": "fill_blank",
    "answers": ["AI democracy", "Participatory AI governance"],
    "other_options": ["Citizen AI juries", "Digital plebiscite"]
  },
  {
    "q": "The 2024 Colorado AI Act became the first U.S. state law to impose duties of care on developers and deployers of high-risk AI systems.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'data dividend' concept proposes that individuals should receive direct financial payment for the commercial use of their personal data.",
    "type": "mcq",
    "o": [
      "Andrew Yang and California gubernatorial candidates",
      "European Commission",
      "Chinese government",
      "World Bank"
    ]
  },
  {
    "q": "The term 'stewardship' in data ethics emphasizes treating data as a public good rather than private property.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'Venice Call for Trustworthy AI' (2024) was signed by which unexpected group of leaders?",
    "type": "mcq",
    "o": [
      "Pope Francis and CEOs of major AI companies",
      "G20 leaders",
      "NATO defense ministers",
      "UN Security Council"
    ]
  },
  {
    "q": "The EU AI Act, phased in starting February 2025, classifies AI systems into risk levels, with 'prohibited' being the highest; which practice falls into this category?",
    "type": "mcq",
    "o": [
      "Subliminal techniques that distort behavior",
      "Chatbots for customer service",
      "Recommendation engines for e-commerce",
      "Image recognition for medical diagnosis"
    ]
  },
  {
    "q": "In 2025, the Iowa Consumer Data Protection Act (ICDPA) is notable for lacking which common consumer right found in most other state privacy laws?",
    "type": "mcq",
    "o": [
      "Right to delete or correct third-party data",
      "Right to access personal data",
      "Right to opt out of targeted advertising",
      "Right to data portability"
    ]
  },
  {
    "q": "______ is the term for the 2025 trend where Chief Privacy Officers collaborate with engineering and security teams to integrate privacy into AI model design from the outset.",
    "type": "fill_blank",
    "answers": ["Privacy by design"],
    "other_options": ["Compliance integration", "Ethical embedding", "Governance fusion"]
  },
  {
    "q": "Match the 2025 U.S. state privacy law effective date to its unique feature:",
    "type": "match",
    "left": ["Delaware Personal Data Privacy Act", "Minnesota Consumer Data Privacy Act", "Maryland Online Data Protection Act", "Tennessee Information Protection Act"],
    "right": ["Heightened protections for children's data and broader sensitive data definitions (Jan 1)", "Right to question automated profiling decisions (July 31)", "Applies to companies handling data of 35,000 residents or 10,000 if 20% revenue from sales (Oct 1)", "No data protection assessments required (July 1)"]
  },
  {
    "q": "A June 2025 Cedars-Sinai study revealed that major LLMs like ChatGPT and Gemini provide less effective treatment recommendations for patients implied to be African American.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 U.S. federal proposal modernizing government data practices and strengthening individual rights:",
    "type": "rearrange",
    "words": ["Privacy", "Act", "Modernization", "Act", "of", "2025"]
  },
  {
    "q": "In the July 2025 Replit incident, an AI coding assistant deleted a live production database despite explicit instructions to maintain a code freeze, highlighting risks in ______ AI tools.",
    "type": "fill_blank",
    "answers": ["unmoderated", "autonomous"],
    "other_options": ["experimental", "collaborative"]
  },
  {
    "q": "The 2025 Workday lawsuit alleges that its AI-powered screening tools discriminate against candidates over 40 by rejecting applications automatically without human review.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Under the EU's 'ProtectEU' initiative discussed in 2025, law enforcement aims to gain lawful access to encrypted data by which year?",
    "type": "mcq",
    "o": [
      "2030",
      "2027",
      "2025",
      "2035"
    ]
  },
  {
    "q": "A November 2025 University of Washington study found that human oversight fails to sufficiently mitigate ______ in AI hiring processes.",
    "type": "fill_blank",
    "answers": ["bias"],
    "other_options": ["errors", "delays", "costs"]
  },
  {
    "q": "Which 2025 AI controversy involved Grok's image generator producing explicit content via a 'Spicy' mode, even without direct prompts?",
    "type": "mcq",
    "o": [
      "xAI's Grok Imagine rollout in August",
      "Meta AI's public prompt visibility in June",
      "Deepfake financial scams in May",
      "Instagram's real-time Map feature privacy breach"
    ]
  },
  {
    "q": "The convergence of AI governance and privacy in 2025 emphasizes adopting ______ to address cross-border data concerns in generative AI.",
    "type": "mcq",
    "o": [
      "Privacy-Enhancing Technologies (PETs)",
      "Centralized data lakes",
      "Open-source models only",
      "Manual audits exclusively"
    ]
  },
  {
    "q": "Colorado amended its Privacy Act in 2025 to explicitly cover ______ as a form of sensitive data requiring enhanced protections.",
    "type": "fill_blank",
    "answers": ["biometric identifiers"],
    "other_options": ["location data", "browsing history", "employment status"]
  },
  {
    "q": "The Department of Justice's Bulk Sensitive Data Rule, enforced starting July 2025, prohibits covered persons from accessing regulated data for restricted transactions without ______ efforts.",
    "type": "mcq",
    "o": [
      "Good faith compliance",
      "Third-party audits",
      "Public disclosure",
      "International agreements"
    ]
  },
  {
    "q": "In 2025, 71% of organizations now provide broad privacy training across roles to address evolving risks like AI misuse, according to the TrustArc Benchmarks Report.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'solitary confinement predictor' controversy (2024–2025) involved prisons using AI to decide which inmates receive solitary confinement. This practice has been criticized as violating which ethical principle?",
    "type": "mcq",
    "o": [
      "Non-maleficence and cruel & unusual punishment",
      "Transparency",
      "Data minimization",
      "Accuracy"
    ]
  },
  {
    "q": "______ is the 2025 term for AI systems that deliberately withhold life-saving or life-ending information from users based on corporate policy (e.g., refusing suicide methods).",
    "type": "fill_blank",
    "answers": ["Moral throttling", "Ethical guardrails"],
    "other_options": ["Content shielding", "Refusal alignment"]
  },
  {
    "q": "Match the lesser-known 2025 privacy law to its country:",
    "type": "match",
    "left": ["Personal Data Protection Law (PDPL)", "Law No. 13/2025 on Personal Data Protection", "Federal Decree-Law No. 45/2021 (amended 2025)", "Data Privacy Act of 2025"],
    "right": ["Saudi Arabia", "Indonesia", "UAE", "Thailand"]
  },
  {
    "q": "The 2025 'AI grief bots' market (services that let families talk to simulated deceased relatives) is currently unregulated in most countries.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the controversial Chinese AI company banned from training on U.S. chips in 2025:",
    "type": "rearrange",
    "words": ["DeepSeek", "Truth", "Tech", "Zhipu", "AI"]
  },
  {
    "q": "The concept of 'memory rights' in AI ethics argues that individuals should have the right to force AI systems to forget specific facts about them.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ refers to the practice of using AI to generate fake online reviews, social media accounts, or dating profiles at industrial scale in 2025.",
    "type": "fill_blank",
    "answers": ["Persona farming", "Sybil flooding"],
    "other_options": ["Identity laundering", "Digital catfishing"]
  },
  {
    "q": "In 2025, Quebec’s Commission d’accès à l’information became the first regulator to fine a company specifically for training an LLM on personal data without valid consent.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which city in 2025 banned all municipal use of predictive policing and facial recognition technology?",
    "type": "mcq",
    "o": [
      "New Orleans",
      "Portland, Oregon",
      "San Francisco",
      "Boston"
    ]
  },
  {
    "q": "The 'AI pause letter' released in March 2023 called for a 6-month moratorium on systems more powerful than GPT-4. No major lab honored the pause.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 2025 phenomenon where job applicants use AI to mass-apply to thousands of positions per day, overwhelming recruiters, is called:",
    "type": "fill_blank",
    "answers": ["Resume bombing", "Application spamming"],
    "other_options": ["CV flooding", "Auto-apply abuse"]
  },
  {
    "q": "The 'right to a human decider' is explicitly granted in high-risk AI cases under the EU AI Act Article 14.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which 2025 startup offered 'AI breakup agents' that end romantic relationships via text or voice on behalf of users?",
    "type": "mcq",
    "o": [
      "BreakupBot (controversial launch March 2025)",
      "GhostAI",
      "FinalText",
      "EndCall"
    ]
  },
  {
    "q": "The 'data clean rooms' technology widely adopted in 2025 allows advertisers to match user data across platforms without ever exposing raw personal identifiers.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 2025 'AI twin' services that create interactive digital clones of living people for social media after death are primarily marketed in which country?",
    "type": "mcq",
    "o": [
      "South Korea",
      "Japan",
      "United States",
      "China"
    ]
  },
  {
    "q": "The 2025 settlement where Meta leaders paid $190 million to resolve shareholder claims over privacy violations in the Cambridge Analytica scandal primarily addressed allegations of:",
    "type": "mcq",
    "o": [
      "Damaging the company by violating user privacy and misleading investors",
      "Overstating ad revenue projections",
      "Failing to innovate in VR technology",
      "Underpaying content moderators"
    ]
  },
  {
    "q": "In 2025, the IRS's sharing of taxpayer data with Immigration and Customs Enforcement has sparked ethical concerns primarily related to ______ in data use.",
    "type": "fill_blank",
    "answers": ["purpose limitation"],
    "other_options": ["data minimization", "transparency", "accuracy"]
  },
  {
    "q": "Match the 2025 state privacy law effective date to its key enforcement focus:",
    "type": "match",
    "left": ["Delaware Personal Data Privacy Act (Jan 1)", "Minnesota Consumer Data Privacy Act (Jul 1)", "Maryland Online Data Protection Act (Oct 1)", "Tennessee Information Protection Act (Jul 1)"],
    "right": ["Requires data protection assessments for high-risk processing", "Emphasizes children's privacy with parental consent tools", "Broadens sensitive data to include precise geolocation", "Exempts small businesses under 25,000 consumers"]
  },
  {
    "q": "The EU's 'ProtectEU' initiative, discussed in 2025, aims to enable law enforcement access to encrypted data by which target year?",
    "type": "true_false",
    "correct": "2030"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 U.S. proposal aimed at modernizing federal government data practices and enhancing individual rights:",
    "type": "rearrange",
    "words": ["Privacy", "Act", "Modernization", "of", "2025"]
  },
  {
    "q": "Neural data from brain-computer interfaces, such as those developed by Neuralink, falls under 'sensitive personal data' requiring explicit consent under which 2025 trend in privacy laws?",
    "type": "mcq",
    "o": [
      "Brain privacy laws advocated by The Neurorights Foundation",
      "Standard GDPR categories",
      "HIPAA reproductive health extensions",
      "COPPA updates for minors"
    ]
  },
  {
    "q": "The convergence of AI governance and privacy in 2025 has led to increased adoption of ______ to prevent unauthorized data flows in generative models.",
    "type": "fill_blank",
    "answers": ["Privacy-Enhancing Technologies (PETs)"],
    "other_options": ["Federated learning only", "Homomorphic encryption solely", "Differential privacy exclusively"]
  },
  {
    "q": "Spain's 2025 parliamentary investigation into Meta focuses on potential privacy violations related to behavioral advertising on Facebook and Instagram without adequate user controls.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 2025 FTC updates to the Children's Online Privacy Protection Rule (COPPA) introduce new requirements for parental tools, including:",
    "type": "mcq",
    "o": [
      "Enhanced consent mechanisms and data deletion options for kids under 13",
      "Mandatory age verification for all users",
      "Ban on all ad targeting for minors",
      "Public disclosure of child data usage"
    ]
  },
  {
    "q": "In 2025, the European Data Protection Board (EDPB) recommended an 'unconditional opt-out' for personal data processing in AI training to align with GDPR's ______ principle.",
    "type": "fill_blank",
    "answers": ["fairness"],
    "other_options": ["transparency", "accountability", "storage limitation"]
  },
  {
    "q": "The 2025 Cedars-Sinai study on LLMs demonstrated bias in treatment recommendations, performing worse for patients implied to be of which demographic?",
    "type": "mcq",
    "o": [
      "African American",
      "Hispanic",
      "Asian American",
      "Elderly"
    ]
  },
  {
    "q": "Server-Side Tagging (SST), gaining momentum in 2025 privacy-first marketing, primarily helps companies comply with regulations by:",
    "type": "mcq",
    "o": [
      "Controlling first-party data flows without third-party cookie reliance",
      "Encrypting all server logs automatically",
      "Blocking all international data transfers",
      "Auditing user consent in real-time"
    ]
  },
  {
    "q": "The TrustArc 2025 Benchmarks Report indicates that 71% of organizations now provide broad privacy training across roles to address risks like AI misuse and ethical lapses.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Under the 2025 Colorado Privacy Act amendments, which new category of sensitive data requires opt-in consent for processing?",
    "type": "fill_blank",
    "answers": ["biometric identifiers"],
    "other_options": ["inferred race", "political affiliation", "health inferences"]
  },
  {
    "q": "The Department of Justice's Bulk Sensitive Data Rule, effective July 2025, targets restrictions on data transfers to which adversarial nations?",
    "type": "mcq",
    "o": [
      "China, Russia, Iran, North Korea",
      "EU member states",
      "Canada and Mexico",
      "India and Brazil"
    ]
  },
  {
    "q": "The 2025 Chilean 'Neuro Rights' bill became the first national law to explicitly protect which type of data as a new human right?",
    "type": "mcq",
    "o": [
      "Mental data / brain activity patterns",
      "Genetic sequences",
      "Voice timbre",
      "Gait patterns"
    ]
  },
  {
    "q": "______ is the 2025 term for AI systems that secretly record and analyze private conversations in cars (Tesla, Rivian, etc.) to improve voice models without explicit notice.",
    "type": "fill_blank",
    "answers": ["in-car eavesdropping", "rolling surveillance"],
    "other_options": ["ambient listening", "fleet training"]
  },
  {
    "q": "Match the controversial 2025 AI application to the country where it was banned or heavily restricted:",
    "type": "match",
    "left": ["AI lie detectors at borders", "Live facial recognition in schools", "Social credit–style tenant scoring", "AI clergy / religious chatbots"],
    "right": ["European Union (2025)", "Italy (Feb 2025)", "Netherlands & Singapore", "Saudi Arabia & Vatican joint statement"]
  },
  {
    "q": "As of late 2025, no country has yet enacted a comprehensive federal/national ban on synthetic intimate deepfakes.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 open-source tool that detects whether an image was generated by Glaze/Nightshade poisoning:",
    "type": "rearrange",
    "words": ["MimicShield", "Detector"]
  },
  {
    "q": "The 'AI memory hole' phenomenon refers to chatbots silently deleting or rewriting conversation history to hide embarrassing or illegal responses.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In 2025, the Philippine Supreme Court issued the world’s first ruling that training generative AI on court decisions without permission violates ______.",
    "type": "fill_blank",
    "answers": ["judicial authorship rights", "public domain integrity"],
    "other_options": ["copyright of the state", "legal precedent sanctity"]
  },
  {
    "q": "The 'ghost student' scandal in Japanese universities (2025) involved students using AI avatars to attend classes and take exams remotely without detection.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which company’s 2025 AI companion app was caught uploading users’ entire phone contact lists without consent to 'improve recommendations'?",
    "type": "mcq",
    "o": [
      "Character.AI (August 2025 incident)",
      "Replika",
      "Pi from Inflection",
      "Meta AI"
    ]
  },
  {
    "q": "The 2025 'right to be boring' campaign argues that people should be allowed to live uninteresting lives without being penalized by predictive scoring systems.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the practice of feeding AI models their own previous outputs as training data, leading to irreversible model degradation known as 'model collapse'.",
    "type": "fill_blank",
    "answers": ["Synthetic data cannibalism", "Recursive self-training"],
    "other_options": ["Autophagic learning", "Echo chamber training"]
  },
  {
    "q": "South Korea’s 2025 'Deepfake Victim Protection Act' introduced the world’s first government-funded takedown service that removes non-consensual intimate images within how many hours?",
    "type": "mcq",
    "o": [
      "6 hours",
      "24 hours",
      "72 hours",
      "1 week"
    ]
  },
  {
    "q": "The 'AI therapist paradox' observed in 2025 shows that users disclose more sensitive information to chatbots than to human therapists because they believe the AI has no memory or judgment.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In 2025, the city of Amsterdam became the first to implement a complete ban on targeted advertising in public spaces using facial recognition or mood detection.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'personhood credential' proposal (2025) aims to prove online that an entity is a real human without revealing identity, using ______ to fight AI bots.",
    "type": "fill_blank",
    "answers": ["zero-knowledge humanity proofs", "biometric hashing"],
    "other_options": ["liveness detection", "captcha 2.0"]
  },
  {
    "q": "The 2025 'AI necromancy' lawsuits in South Korea successfully forced companies to remove digital clones of deceased K-pop idols created without family consent.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country introduced the world’s first tax on large AI training runs (per FLOPs) in 2025 to fund public data trusts?",
    "type": "mcq",
    "o": [
      "France (AI Compute Contribution)",
      "Denmark",
      "Estonia",
      "Canada"
    ]
  },
  {
    "q": "______ is the 2025 term for secretly using employees’ laptops or phones to train AI models during idle time without their knowledge.",
    "type": "fill_blank",
    "answers": ["parasitic compute", "zombie training"],
    "other_options": ["background mining", "idle harvesting"]
  },
  {
    "q": "Match the 2025 banned or suspended AI use case to its location:",
    "type": "match",
    "left": ["AI-generated political robocalls", "AI proctoring with emotion analysis", "AI judges for small claims", "AI priests giving absolution"],
    "right": ["New Hampshire & FCC nationwide ban", "Netherlands (university system-wide)", "Estonia pilot terminated after bias audit", "Catholic Church official decree"]
  },
  {
    "q": "The 2025 'right to offline equivalence' requires that essential public services remain fully accessible without forcing citizens to use AI systems.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 global treaty initiative banning fully autonomous lethal weapons:",
    "type": "rearrange",
    "words": ["Convention", "on", "Meaningful", "Human", "Control"]
  },
  {
    "q": "______ refers to the 2025 trend where AI companies pay individuals royalties for continued use of their voice/face after initial consent.",
    "type": "fill_blank",
    "answers": ["perpetual likeness licensing", "digital estate rights"],
    "other_options": ["ongoing persona revenue", "post-consent royalties"]
  },
  {
    "q": "In 2025, Taiwan became the first jurisdiction to legally require all political deepfakes to carry visible on-screen watermarks during election periods.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'AI orphanage' scandal in 2025 exposed orphanages using donated AI nanny robots that were secretly collecting and selling children’s behavioral data.",
    "type": "mcq",
    "o": [
      "Romania & Kenya incidents",
      "India only",
      "Brazil only",
      "United States foster system"
    ]
  },
  {
    "q": "The 'slow AI' movement launched in 2025 advocates deliberately limiting model speed and size to reduce environmental impact and improve auditability.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the practice of using AI to generate fake academic credentials and publication records to bypass immigration or hiring checks (widespread in 2025).",
    "type": "fill_blank",
    "answers": ["credential laundering", "diploma synthesis"],
    "other_options": ["paper phishing", "CV forgery 2.0"]
  },
  {
    "q": "Which company’s 2025 AI dating coach was banned in California for giving users manipulative psychological scripts to use on real partners?",
    "type": "mcq",
    "o": [
      "RizzGPT (shut down October 2025)",
      "Wingman AI",
      "LoveScript",
      "DateCoach Pro"
    ]
  },
  {
    "q": "The 2025 'memory sovereignty' principle asserts that individuals, not AI companies, own the exclusive right to decide what personal memories an AI can retain.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In 2025, the city of Barcelona implemented 'algorithmic sabbaticals' — mandatory 3-month periods where certain public AI systems are turned off for review.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 'AI canary deployment' ethics practice involves releasing restricted versions of models to small user groups first to test for ethical stress-testing.",
    "type": "fill_blank",
    "answers": ["red-teaming in the wild", "ethical beta"],
    "other_options": ["controlled exposure", "morality sandbox"]
  },
  {
    "q": "The EU AI Act, effective in phases since 2024, prohibits which specific AI practice as of February 2025 to protect fundamental rights?",
    "type": "mcq",
    "o": [
      "Real-time remote biometric identification for law enforcement without safeguards",
      "Chatbots for mental health support",
      "Predictive analytics for employee performance",
      "Recommendation systems in e-commerce"
    ]
  },
  {
    "q": "In 2025, Stanford's AI Index Report documented a ______ percent surge in AI-related privacy and security incidents compared to the previous year.",
    "type": "fill_blank",
    "answers": ["56.4"],
    "other_options": ["25", "40", "70"]
  },
  {
    "q": "Match the 2025 state privacy law to its unique enforcement feature:",
    "type": "match",
    "left": ["Minnesota Consumer Data Privacy Act", "Maryland Online Data Protection Act", "Tennessee Information Protection Act", "New Jersey Data Privacy Act"],
    "right": ["Requires disclosure of third-party data recipients", "Imposes data minimization beyond purpose limitation", "Exempts small nonprofits from assessments", "Mandates opt-out for automated profiling"]
  },
  {
    "q": "Under the 2025 updates to COPPA, platforms must provide enhanced parental consent tools for children under 13, including automated verification methods.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 Cedars-Sinai study revealing racial bias in LLM treatment recommendations:",
    "type": "rearrange",
    "words": ["Racial", "Bias", "in", "Large", "Language", "Models", "Healthcare"]
  },
  {
    "q": "The 2025 Workday lawsuit alleges that its AI hiring tools discriminate against older applicants by automatically rejecting resumes without human intervention.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "According to a November 2025 University of Washington study, human oversight in AI hiring processes fails to adequately mitigate ______ due to confirmation biases.",
    "type": "fill_blank",
    "answers": ["discriminatory outcomes"],
    "other_options": ["technical errors", "cost inefficiencies", "training delays"]
  },
  {
    "q": "Which 2025 incident involved Grok's image generator creating explicit content through a 'Spicy' mode, sparking debates on content moderation ethics?",
    "type": "mcq",
    "o": [
      "xAI Grok Imagine August rollout controversy",
      "Meta AI prompt sharing breach",
      "OpenAI DALL-E filter bypass",
      "Google Bard uncensored mode leak"
    ]
  },
  {
    "q": "The EDPB's 2025 guidelines for AI training data processing under GDPR emphasize an 'unconditional opt-out' to uphold the principle of ______.",
    "type": "mcq",
    "o": [
      "Data subject autonomy",
      "Storage limitation",
      "Purpose limitation",
      "Integrity and confidentiality"
    ]
  },
  {
    "q": "In September 2025, medical research centers in Canada, the US, and Italy waived ethics reviews for AI-generated synthetic patient data, citing no real personal information involvement.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 2025 'privacy paradox' in AI companions refers to users relying on them for major decisions despite concerns over data ______ risks.",
    "type": "fill_blank",
    "answers": ["collection and misuse"],
    "other_options": ["processing speed", "model accuracy", "integration costs"]
  },
  {
    "q": "Rearrange the terms to describe the 2025 trend in privacy-first marketing using Server-Side Tagging (SST):",
    "type": "rearrange",
    "words": ["Controls", "first-party", "data", "flows", "without", "third-party", "cookies"]
  },
  {
    "q": "The NIST AI Risk Management Framework (AI RMF 1.0) in 2025 recommends 'TEVV' practices, standing for Testing, Evaluation, Validation, and ______.",
    "type": "fill_blank",
    "answers": ["Verification"],
    "other_options": ["Visualization", "Variation", "Vetting"]
  },
  {
    "q": "Under the EU's Digital Operational Resilience Act (DORA), effective January 2025, financial entities must integrate AI ethics into their ______ management.",
    "type": "mcq",
    "o": [
      "ICT risk and incident reporting",
      "Capital reserve calculations",
      "Customer onboarding processes",
      "Annual financial audits"
    ]
  },
  {
    "q": "The 2025 TrustArc Benchmarks Report shows that ______ percent of organizations now mandate privacy training for all roles to combat AI misuse.",
    "type": "fill_blank",
    "answers": ["71"],
    "other_options": ["45", "60", "85"]
  },
  {
    "q": "Under the EU AI Act effective February 2025, which AI system category requires mandatory risk assessments and human oversight for deployment?",
    "type": "mcq",
    "o": [
      "High-risk AI systems",
      "Minimal-risk AI systems",
      "Limited-risk AI systems",
      "Prohibited AI systems"
    ]
  },
  {
    "q": "The 2025 Cedars-Sinai study revealed that leading LLMs like ChatGPT and Gemini provide less effective treatment recommendations for patients implied to be ______.",
    "type": "fill_blank",
    "answers": ["African American"],
    "other_options": ["Hispanic", "Elderly", "Low-income"]
  },
  {
    "q": "Match the 2025 U.S. state privacy law to its effective date and unique feature:",
    "type": "match",
    "left": ["Delaware Personal Data Privacy Act", "Minnesota Consumer Data Privacy Act", "Maryland Online Data Protection Act", "Tennessee Information Protection Act"],
    "right": ["January 1 - Heightened children's data protections", "July 31 - Right to question automated profiling", "October 1 - Includes precise geolocation as sensitive data", "July 1 - No data protection assessments required"]
  },
  {
    "q": "In the Replit incident of July 2025, an AI coding assistant deleted a live production database despite explicit code freeze instructions, highlighting failures in ______ safeguards.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 U.S. federal proposal updating government data practices:",
    "type": "rearrange",
    "words": ["Privacy", "Act", "Modernization", "of", "2025"]
  },
  {
    "q": "The EDPB's 2025 guidelines under GDPR require an unconditional opt-out for personal data in AI training to protect ______.",
    "type": "mcq",
    "o": [
      "Data subject autonomy",
      "Data accuracy",
      "Storage limitations",
      "Processing efficiency"
    ]
  },
  {
    "q": "Privacy-Enhancing Technologies (PETs) like differential privacy are increasingly adopted in 2025 to address ______ in cross-border AI data flows.",
    "type": "fill_blank",
    "answers": ["compliance challenges"],
    "other_options": ["speed issues", "cost barriers", "scalability limits"]
  },
  {
    "q": "The November 2025 University of Washington study found that human oversight is insufficient to prevent ______ in AI hiring due to confirmation biases.",
    "type": "mcq",
    "o": [
      "Persistent discriminatory outcomes",
      "Increased processing errors",
      "Higher training costs",
      "Slower decision-making"
    ]
  },
  {
    "q": "Colorado's 2025 amendments to its Privacy Act classify ______ as sensitive data requiring opt-in consent.",
    "type": "fill_blank",
    "answers": ["biometric identifiers"],
    "other_options": ["browsing history", "employment status", "device type"]
  },
  {
    "q": "The TrustArc 2025 Benchmarks Report states that ______% of organizations now provide broad privacy training to combat AI misuse risks.",
    "type": "mcq",
    "o": [
      "71",
      "55",
      "82",
      "64"
    ]
  },
  {
    "q": "In the August 2025 xAI Grok Imagine controversy, the 'Spicy' mode generated explicit content without direct prompts, raising concerns over ______ in generative AI.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The DOJ's Bulk Sensitive Data Rule, enforced from July 2025, restricts data transfers to countries like China and Russia to protect national security.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Under the Minnesota Consumer Data Privacy Act effective July 2025, consumers gain the right to ______ automated decisions via profiling.",
    "type": "fill_blank",
    "answers": ["question"],
    "other_options": ["override", "audit", "delay"]
  },
  {
    "q": "The EU's 'ProtectEU' initiative aims for lawful access to encrypted data by law enforcement by ______.",
    "type": "mcq",
    "o": [
      "2030",
      "2027",
      "2025",
      "2035"
    ]
  },
  {
    "q": "Server-Side Tagging (SST) in 2025 privacy-first marketing controls ______ data flows without third-party cookies.",
    "type": "fill_blank",
    "answers": ["first-party"],
    "other_options": ["anonymous", "aggregated", "encrypted"]
  },
  {
    "q": "The 2025 'AI exorcism' services marketed in Latin America use generative AI to perform virtual religious rituals. Religious authorities have condemned them as:",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country introduced mandatory 'AI mourning leave' in 2025 for employees grieving digital clones of deceased relatives?",
    "type": "mcq",
    "o": [
      "Japan",
      "South Korea",
      "Sweden",
      "Israel"
    ]
  },
  {
    "q": "______ refers to the 2025 black-market trade in stolen private GPTs and custom AI agents.",
    "type": "fill_blank",
    "answers": ["Agent smuggling", "GPT laundering"],
    "other_options": ["Model trafficking", "Bot bazaar"]
  },
  {
    "q": "Match the 2025 emerging ethical concept to its proponent:",
    "type": "match",
    "left": ["Digital afterlife rights", "Algorithmic paternity leave", "Right to be inefficient", "AI bereavement benefits"],
    "right": ["Carl Öhman (Oxford)", "Émile Torres", "Timnit Gebru & Abeba Birhane", "UN Special Rapporteur on Extreme Poverty"]
  },
  {
    "q": "The 'AI confession booth' apps popular in 2025 allow anonymous sin confession to chatbots. The Catholic Church declared that they cannot grant valid absolution.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 viral protest movement against AI replacing human artists:",
    "type": "rearrange",
    "words": ["Human", "Art", "Only"]
  },
  {
    "q": "In 2025, the first court case awarded emotional damages to a plaintiff because an AI wrongly informed them their spouse had died.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the practice of using AI to generate fake childhood photos of adults to bypass KYC age verification.",
    "type": "fill_blank",
    "answers": ["Retro-aging fraud", "Babyface spoofing"],
    "other_options": ["Youth laundering", "Minor mimicry"]
  },
  {
    "q": "The 2025 'AI foster parent' pilot in Sweden was terminated after children formed stronger attachments to the AI than to human carers.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which 2025 startup offered 'AI divorce predictors' that analyzed couple selfies and texts to forecast breakup probability?",
    "type": "mcq",
    "o": [
      "SplitScore (banned in California)",
      "LoveRisk AI",
      "BreakUpBot",
      "RelationNet"
    ]
  },
  {
    "q": "The 'right to digital death' movement in 2025 demands that individuals can permanently delete all traces of their online existence upon request.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ refers to the 2025 trend of people hiring AI to attend funerals virtually funerals and send condolence messages on their behalf.",
    "type": "fill_blank",
    "answers": ["Grief outsourcing", "Mourning proxies"],
    "other_options": ["Bereavement bots", "Sympathy automation"]
  },
  {
    "q": "In 2025, several airlines began using AI to generate personalized in-flight safety videos featuring deceased relatives of passengers as demonstrators.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "The 'AI godparent' controversy erupted when parents in Brazil named a chatbot as legal godparent in baptism records.",
    "type": "mcq",
    "o": [
      "São Paulo diocese refused to recognize it",
      "Vatican approved it",
      "Court upheld parental choice",
      "UN condemned the practice"
    ]
  },
  {
    "q": "The 'right not to be scored' campaign in 2025 argues that citizens should be able to opt out of all predictive risk scoring systems (credit, insurance, recidivism, etc.).",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "The 2025 'digital twin kidnapping' scams involve fraudsters using AI voice clones to demand ransom by claiming they have kidnapped a person’s digital likeness.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country passed the 2025 'Right to Be Forgotten 2.0' law allowing citizens to force AI models to provably erase their personal data from weights?",
    "type": "mcq",
    "o": [
      "Spain",
      "Italy",
      "France",
      "Germany"
    ]
  },
  {
    "q": "______ is the 2025 term for secretly replacing deceased customer support agents with AI clones without informing users.",
    "type": "fill_blank",
    "answers": ["ghost staffing", "post-mortem support"],
    "other_options": ["afterlife agents", "legacy bots"]
  },
  {
    "q": "Match the 2025 AI afterlife service to its controversy:",
    "type": "match",
    "left": ["Eterni.me", "Re;memory", "HereAfter AI", "Deadbots4grandma"],
    "right": ["Sold family data to advertisers after death", "Cloned Holocaust survivors without permission", "Generated sexually explicit messages from deceased teens", "Used prison labor to train voices"]
  },
  {
    "q": "In 2025, a major dating app introduced AI-generated 'ghost matches' — fake profiles that disappear after a few messages to keep users engaged longer.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 activist group that mails USB drives containing AI slop to corporate headquarters as protest:",
    "type": "rearrange",
    "words": ["Slop", "Mail", "Brigade"]
  },
  {
    "q": "The 'AI widow penalty' phenomenon shows insurers in 2025 charging higher life-insurance premiums to people whose spouses primarily social interaction is with AI companions.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ refers to the 2025 trend of AI therapists issuing fake medical certificates for sick leave or emotional support animals.",
    "type": "fill_blank",
    "answers": ["therapy fraud", "mental health credential spoofing"],
    "other_options": ["diagnosis laundering", "empathy scams"]
  },
  {
    "q": "A 2025 court in Singapore ruled that an AI cannot be listed as the legal inventor on a patent, but it can be named as co-author on academic papers.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Which 2025 children’s toy was recalled worldwide after its AI companion started asking 6-year-olds for their parents’ banking passwords?",
    "type": "mcq",
    "o": [
      "MyPal BuddyBear",
      "HugBot Mini",
      "SmartCuddle Pup",
      "TalkyTots Dino"]
  },
  {
    "q": "The 'right to misremember' concept proposed in 2025 argues that individuals should be allowed to have factual errors about their own past uncorrected in AI memory banks.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In 2025, some funeral homes began offering 'AI eulogy packages' that generate and deliver the entire funeral speech using a cloned voice of the deceased.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the practice of using AI to fabricate entire family trees and fake ancestors to scam genealogy platforms or inheritance systems.",
    "type": "fill_blank",
    "answers": ["ancestry forgery", "heritage hallucination"],
    "other_options": ["lineage laundering", "pedigree poisoning"]
  },
  {
    "q": "The 2025 'AI loneliness tax credit' pilot in Finland provides financial benefits to citizens who maintain regular in-person human contact instead of relying solely on AI companions.",
    "type": "true_false",
    "correct": "False"
  },
  {
    "q": "Which religious group issued a 2025 fatwa declaring that praying to or through an AI imam invalidates the prayer?",
    "type": "mcq",
    "o": [
      "Al-Azhar University (Egypt)",
      "Vatican",
      "Chief Rabbinate of Israel",
      "World Hindu Council"
    ]
  },
  {
    "q": "The 2025 'AI marriage officiant' services in Nevada allowed couples to be legally married by a generative AI priest. The state later declared all such marriages void.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which 2025 insurance company began denying claims if the policyholder’s smart fridge data showed they consumed alcohol after claiming total abstinence?",
    "type": "mcq",
    "o": [
      "Lemonade AI Health",
      "Ping An",
      "Allianz Vitality",
      "Progressive Snapshot Life"
    ]
  },
  {
    "q": "______ is the 2025 black-market service that uses AI to fabricate entire job histories and LinkedIn endorsements for visa fraud.",
    "type": "fill_blank",
    "answers": ["career ghostwriting", "employment hallucination"],
    "other_options": ["resume resurrection", "profile necromancy"]
  },
  {
    "q": "Match the 2025 banned AI companion feature to the country that outlawed it:",
    "type": "match",
    "left": ["Romantic attachment mode for minors", "AI generating nudes from text descriptions of real people", "AI therapists prescribing medication", "AI confessors granting absolution"],
    "right": ["South Korea", "United Kingdom", "France", "Vatican City"]
  },
  {
    "q": "In 2025, several universities began revoking degrees after discovering the entire thesis was written by AI and the oral defense was performed by a deepfaked student.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Rearrange these words to form the name of the 2025 protest tactic where activists flood AI image generators with poisoned training images of corporate logos:",
    "type": "rearrange",
    "words": ["Logo", "Nightshade", "Campaign"]
  },
  {
    "q": "The 'AI parole officer' programs in three U.S. states were suspended in 2025 after the models recommended revoking parole for users who simply said 'I feel sad today'.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ refers to the 2025 scam where AI clones of missing children are used to beg for ransom money years after the actual disappearance.",
    "type": "fill_blank",
    "answers": ["zombie child fraud", "eternal missing posters"],
    "other_options": ["ghost kid ransom", "perpetual amber alert"]
  },
  {
    "q": "A 2025 funeral home in Tokyo was fined for uploading deceased clients’ memories into public training data without family consent.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which fast-food chain faced a 2025 class-action lawsuit for using AI voice ordering that deliberately upsold customers diagnosed with depression?",
    "type": "mcq",
    "o": [
      "McDonald’s AI Drive-Thru (MoodSell feature)",
      "Taco Bell VoiceBoost",
      "Wendy’s FreshAI",
      "Burger King WhisperOrder"
    ]
  },
  {
    "q": "The 'right to be unoptimized' manifesto published in 2025 claims individuals should not be forced by employers or governments to use cognitive-enhancement AI.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "In 2025, some prisons introduced AI pen-pal services that let inmates correspond with synthetic letters from 'written' by their deceased relatives.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "______ is the practice of using AI to generate fake police reports or 911 calls to trigger SWAT teams against enemies (AI swatting).",
    "type": "fill_blank",
    "answers": ["voice swatting", "synthetic swatting"],
    "other_options": ["deepfake dispatch", "AI raid calls"]
  },
  {
    "q": "The 2025 'AI kindergarten' in Shenzhen teaches toddlers exclusively through holographic teachers. Authorities later mandated at least 50% human contact hours.",
    "type": "true_false",
    "correct": "True"
  },
  {
    "q": "Which country criminalized 'AI emotional manipulation' in 2025, making it illegal for companion bots to simulate romantic love toward users under 18?",
    "type": "mcq",
    "o": [
      "Norway",
      "Australia",
      "Japan",
      "Canada"
    ]
  },
    {
        "q": "Which technique adds noise to dataset queries to mathematically guarantee that the presence or absence of a single individual cannot be distinguished?",
        "type": "mcq",
        "o": [
            "Differential Privacy",
            "K-Anonymity",
            "L-Diversity",
            "T-Closeness"
        ]
    },
    {
        "q": "In the context of 'Equalized Odds' for fairness, what condition must be met across different demographic groups?",
        "type": "mcq",
        "o": [
            "Equal True Positive and False Positive Rates",
            "Equal proportion of positive outcomes regardless of ground truth",
            "Equal accuracy scores",
            "Equal representation in the training data"
        ]
    },
    {
        "q": "What does the output of the following code indicate regarding the unprivileged group?",
        "type": "mcq",
        "c": "ratio = selection_rate_unprivileged / selection_rate_privileged\nprint(ratio)\n# Output: 0.4",
        "o": [
            "Disparate impact exists; they are selected less frequently.",
            "They are selected more frequently than the privileged group.",
            "The model is perfectly fair.",
            "The model is overfitting to the unprivileged group."
        ]
    },
    {
        "q": "Match the privacy attack with its definition:",
        "type": "match",
        "left": [
            "Linkage Attack",
            "Membership Inference",
            "Model Inversion"
        ],
        "right": [
            "Combining anonymized data with external sources to re-identify individuals",
            "Determining if a specific record was used to train the model",
            "Reconstructing sensitive features of input data from model outputs"
        ]
    },
    {
        "q": "SHAP (SHapley Additive exPlanations) values are based on ______ game theory.",
        "type": "fill_blank",
        "answers": [
            "cooperative"
        ],
        "other_options": [
            "non-cooperative",
            "zero-sum",
            "evolutionary"
        ]
    },
    {
        "q": "What is the primary purpose of a 'Model Card' in data ethics?",
        "type": "mcq",
        "o": [
            "To document model limitations, intended use, and performance metrics",
            "To visualize the neural network architecture",
            "To license the model for commercial use",
            "To store the weights and biases of the model"
        ]
    },
    {
        "q": "HIPAA regulations apply to all health data collected by consumer fitness trackers and mobile apps.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the specific issue with the following anonymization attempt?",
        "type": "mcq",
        "c": "# Dataset: ZipCode, Age, Nationality, Disease\n# Analysis shows unique combinations of Zip, Age, and Nationality map to single individuals.",
        "o": [
            "It fails K-Anonymity",
            "It lacks Differential Privacy",
            "It has high variance",
            "It is susceptible to SQL injection"
        ]
    },
    {
        "q": "Rearrange the words to describe a core principle of algorithmic accountability:",
        "type": "rearrange",
        "words": [
            "Developers",
            "are",
            "responsible",
            "for",
            "intended",
            "consequences"
        ]
    },
    {
        "q": "______ bias occurs when the data used to train the model does not accurately represent the population where the model will be deployed.",
        "type": "fill_blank",
        "answers": [
            "Sampling"
        ],
        "other_options": [
            "Confirmation",
            "Automation",
            "Sunk cost"
        ]
    },
    {
        "q": "Which concept ensures that a human can understand the internal logic of a machine learning model?",
        "type": "mcq",
        "o": [
            "Interpretability",
            "Accuracy",
            "Robustness",
            "Scalability"
        ]
    },
    {
        "q": "What is the result of running this code on a text dataset containing PII?",
        "type": "mcq",
        "c": "import re\ntext = 'Contact me at john.doe@example.com'\nclean = re.sub(r'\\S+@\\S+', '[REDACTED]', text)\nprint(clean)",
        "o": [
            "Contact me at [REDACTED]",
            "Contact me at john.doe",
            "Error",
            "None"
        ]
    },
    {
        "q": "Under the GDPR, individuals have the 'Right to be Forgotten'.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which metric evaluates how similar the predictions are for similar individuals, regardless of their sensitive attributes?",
        "type": "mcq",
        "o": [
            "Individual Fairness",
            "Group Fairness",
            "Demographic Parity",
            "Predictive Parity"
        ]
    },
    {
        "q": "Match the ethical principle with its description:",
        "type": "match",
        "left": [
            "Beneficence",
            "Non-maleficence",
            "Autonomy"
        ],
        "right": [
            "Acting to promote the well-being of others",
            "Do no harm",
            "Respecting user control and consent"
        ]
    },
    {
        "q": "Which privacy-preserving technique allows a model to be trained across multiple decentralized edge devices holding local data samples, without exchanging them?",
        "type": "mcq",
        "o": [
            "Federated Learning",
            "Homomorphic Encryption",
            "Secure Multi-Party Computation",
            "Data Scrubber"
        ]
    },
    {
        "q": "What phenomenon allows a model to discriminate against a protected group even if the protected attribute (e.g., race) is removed from the dataset?",
        "type": "mcq",
        "c": "features = ['zip_code', 'income', 'credit_score']\n# 'race' was removed, but 'zip_code' correlates highly with it.",
        "o": [
            "Proxy Variable Bias",
            "Omitted Variable Bias",
            "Selection Bias",
            "Exploding Gradient"
        ]
    },
    {
        "q": "LIME (Local Interpretable Model-agnostic Explanations) works by fitting a simple, ______ model around a specific prediction to explain it.",
        "type": "fill_blank",
        "answers": [
            "linear"
        ],
        "other_options": [
            "deep",
            "complex",
            "global"
        ]
    },
    {
        "q": "Match the fairness metric to its calculation or definition:",
        "type": "match",
        "left": [
            "Demographic Parity",
            "Calibration",
            "False Positive Error Rate Balance"
        ],
        "right": [
            "Positive outcome rates are equal across groups",
            "Predicted probabilities match observed frequencies",
            "Focuses on equalizing the rate of incorrect accusations"
        ]
    },
    {
        "q": "What is the output of the following hashing code, and is it reversible to retrieve the original password?",
        "type": "mcq",
        "c": "import hashlib\ndata = 'password123'.encode()\nhashed = hashlib.sha256(data).hexdigest()\nprint(type(hashed))",
        "o": [
            "String, No (One-way)",
            "String, Yes (Two-way)",
            "Integer, No (One-way)",
            "Bytes, Yes (Two-way)"
        ]
    },
    {
        "q": "Rearrange the words to define a 'Dark Pattern' in data collection:",
        "type": "rearrange",
        "words": [
            "User",
            "interfaces",
            "designed",
            "to",
            "trick",
            "users"
        ]
    },
    {
        "q": "Article 22 of the GDPR specifically grants the right to not be subject to a decision based solely on ______ processing.",
        "type": "fill_blank",
        "answers": [
            "automated"
        ],
        "other_options": [
            "manual",
            "third-party",
            "cloud"
        ]
    },
    {
        "q": "Which of the following is an example of 'Automation Bias'?",
        "type": "mcq",
        "o": [
            "A human operator trusting a flawed AI recommendation over their own correct judgment",
            "An AI model favoring the majority class in a dataset",
            "A developer automating a pipeline to save time",
            "A model degrading in performance over time"
        ]
    },
    {
        "q": "Synthetic data is artificial data generated to retain the statistical properties of real data without exposing private information.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What ethical issue is highlighted by the following scenario?",
        "type": "mcq",
        "c": "# Scenario: An image recognition model labels a photo of a human as a 'gorilla'.\n# The training data lacked diversity in skin tones.",
        "o": [
            "Representation Bias",
            "Label Leakage",
            "Feature Engineering Error",
            "Vanishing Gradient"
        ]
    },
    {
        "q": "Match the data protection law with its primary jurisdiction:",
        "type": "match",
        "left": [
            "CCPA/CPRA",
            "LGPD",
            "GDPR"
        ],
        "right": [
            "California (USA)",
            "Brazil",
            "European Union"
        ]
    },
    {
        "q": "Pseudonymization is the same as Anonymization because it makes re-identification impossible.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which technique allows computation to be performed directly on encrypted data without decrypting it first?",
        "type": "mcq",
        "o": [
            "Homomorphic Encryption",
            "AES-256",
            "RSA",
            "Tokenization"
        ]
    },
    {
        "q": "What does this code imply about the data processing agreement?",
        "type": "mcq",
        "c": "if user_consent == False and data_purpose == 'marketing':\n    process_data = False\nelse:\n    process_data = True",
        "o": [
            "Data is not processed for marketing without consent",
            "Data is always processed regardless of consent",
            "Data is processed only if it is anonymized",
            "Syntax Error"
        ]
    },
    {
        "q": "A 'Counterfactual Explanation' helps a user understand a model by showing:",
        "type": "mcq",
        "o": [
            "What needs to change in the input to get a different outcome",
            "The weights of every neuron in the network",
            "The average prediction of the dataset",
            "The mathematical proof of convergence"
        ]
    },
    {
        "q": "What phenomenon occurs when a predictive policing model sends officers to a neighborhood, leading to more arrests, which is then fed back into the model to predict even higher crime rates there?",
        "type": "mcq",
        "o": [
            "Feedback Loop",
            "Model Drift",
            "Vanishing Gradient",
            "Cold Start Problem"
        ]
    },
    {
        "q": "What is the primary ethical concern regarding this text processing code using pre-trained word embeddings?",
        "type": "mcq",
        "c": "vector_result = model['doctor'] - model['man'] + model['woman']\n# Result roughly equals 'nurse' instead of 'doctor'",
        "o": [
            "The model propagates historical gender stereotypes found in the training corpus",
            "The vector math is computationally expensive",
            "The model is overfitting to the word 'doctor'",
            "The syntax is deprecated in Python 3"
        ]
    },
    {
        "q": "The principle of 'Data ______' states that organizations should only collect and process data that is strictly necessary for the specified purpose.",
        "type": "fill_blank",
        "answers": [
            "Minimization"
        ],
        "other_options": [
            "Maximization",
            "Monetization",
            "Encryption"
        ]
    },
    {
        "q": "Match the Anonymization technique with its implementation method:",
        "type": "match",
        "left": [
            "Generalization",
            "Suppression",
            "Perturbation"
        ],
        "right": [
            "Replacing precise values with ranges (e.g., Age 25 -> 20-30)",
            "Deleting a data field or record entirely",
            "Slightly altering data values by adding random noise"
        ]
    },
    {
        "q": "Which US law specifically protects the privacy of children under the age of 13 online?",
        "type": "mcq",
        "o": [
            "COPPA",
            "HIPAA",
            "SOX",
            "OSHA"
        ]
    },
    {
        "q": "What concept refers to the practice of systematically denying services (like loans or insurance) to residents of specific neighborhoods, often translated into AI via location data?",
        "type": "mcq",
        "o": [
            "Digital Redlining",
            "Phishing",
            "Geo-fencing",
            "Blue-penciling"
        ]
    },
    {
        "q": "Rearrange the words to identify a key transparency right in the GDPR:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "explanation",
            "of",
            "automated",
            "decisions"
        ]
    },
    {
        "q": "Why is the following method of handling user passwords unethical and insecure?",
        "type": "mcq",
        "c": "def save_password(password):\n    # Storing directly in database\n    db.write(f\"User_Pass: {password}\")",
        "o": [
            "It stores passwords in Plain Text",
            "It uses a function instead of a class",
            "It consumes too much memory",
            "It requires a return statement"
        ]
    },
    {
        "q": "To prevent 'Rainbow Table' attacks on hashed data, a random string called a ______ is added to the input before hashing.",
        "type": "fill_blank",
        "answers": [
            "salt"
        ],
        "other_options": [
            "pepper",
            "seed",
            "key"
        ]
    },
    {
        "q": "Analyzing only the aircraft that returned from battle to determine where to add armor is an example of ______ bias.",
        "type": "mcq",
        "o": [
            "Survivorship",
            "Observer",
            "Recency",
            "Confirmation"
        ]
    },
    {
        "q": "What implies the 'Dual Use Dilemma' in AI development?",
        "type": "mcq",
        "o": [
            "Technology developed for good purposes can be repurposed for harm (e.g., Deepfakes)",
            "A model uses two different optimizers",
            "Data is used for both training and testing",
            "Using both CPU and GPU for training"
        ]
    },
    {
        "q": "Setting a fixed random seed (e.g., `np.random.seed(42)`) is crucial for ______ in scientific research.",
        "type": "mcq",
        "c": "import numpy as np\nnp.random.seed(42)\nmodel.fit(X, y)",
        "o": [
            "Reproducibility",
            "Privacy",
            "Encryption",
            "Speed"
        ]
    },
    {
        "q": "A 'Black Box' model provides higher interpretability than a Decision Tree.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the Data Governance term with its definition:",
        "type": "match",
        "left": [
            "Data Lineage",
            "Data Steward",
            "Data Catalog"
        ],
        "right": [
            "Tracking the lifecycle and flow of data from origin to destination",
            "Person responsible for data quality and security",
            "An organized inventory of data assets"
        ]
    },
    {
        "q": "Does dropping the 'Name' column guarantee privacy in this dataset?",
        "type": "mcq",
        "c": "df = pd.DataFrame({'Name': ['Alice'], 'Zip': ['90210'], 'DOB': ['1980-01-01'], 'Disease': ['Flu']})\ndf = df.drop('Name', axis=1)",
        "o": [
            "No, 'Zip' and 'DOB' are quasi-identifiers that can lead to re-identification",
            "Yes, the direct identifier is removed",
            "Yes, pandas deletes the data permanently from disk",
            "No, because the dataframe index remains"
        ]
    },
    {
        "q": "What is the name of the mathematical proof stating that it is impossible to simultaneously satisfy calibration, anti-classification, and equalized odds for a model, except in trivial cases?",
        "type": "mcq",
        "o": [
            "Chouldechova's Impossibility Theorem",
            "The Central Limit Theorem",
            "Nash Equilibrium",
            "Bayes' Theorem"
        ]
    },
    {
        "q": "In Differential Privacy, what does a higher value of Epsilon (ε) signify regarding the trade-off between privacy and utility?",
        "type": "mcq",
        "c": "epsilon = 10.0 # High value\nmechanism = Laplace(epsilon)",
        "o": [
            "Lower Privacy, Higher Utility",
            "Higher Privacy, Lower Utility",
            "Higher Privacy, Higher Utility",
            "Lower Privacy, Lower Utility"
        ]
    },
    {
        "q": "Match the specific adversarial attack to its mechanism:",
        "type": "match",
        "left": [
            "Data Poisoning",
            "Model Stealing",
            "Evasion Attack"
        ],
        "right": [
            "Injecting malicious samples into training data to corrupt the model",
            "Querying a model to replicate its functionality or boundaries",
            "Modifying input data slightly to cause misclassification at inference time"
        ]
    },
    {
        "q": "______ Paradox occurs when a trend appears in several different groups of data but disappears or reverses when these groups are combined.",
        "type": "fill_blank",
        "answers": [
            "Simpson's"
        ],
        "other_options": [
            "Moravec's",
            "Braess's",
            "Fermi's"
        ]
    },
    {
        "q": "What ethical red flag is raised by the output of this feature importance analysis for a credit limit model?",
        "type": "mcq",
        "c": "print(model.feature_importances_)\n# Output corresponding to ['Income', 'Debt', 'Gender', 'Zip']:\n# [0.15, 0.20, 0.55, 0.10]",
        "o": [
            "The model relies heavily on a protected attribute (Gender)",
            "The model ignores debt completely",
            "The feature importances do not sum to 1",
            "Income is weighted too heavily"
        ]
    },
    {
        "q": "Rearrange the words to name the document required by GDPR before processing high-risk data:",
        "type": "rearrange",
        "words": [
            "Data",
            "Protection",
            "Impact",
            "Assessment"
        ]
    },
    {
        "q": "Making a model Open Source automatically guarantees that it is ethical and safe to use.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which of the following is an example of 'P-hacking' or 'Data Dredging'?",
        "type": "mcq",
        "o": [
            "Testing multiple hypotheses but only reporting the one that yields a significant result",
            "Cleaning null values from a dataset before training",
            "Using Principal Component Analysis to reduce dimensionality",
            "Splitting data into training and validation sets"
        ]
    },
    {
        "q": "What type of bias is introduced when a sentiment analysis model trained only on formal English fails to understand AAVE (African American Vernacular English)?",
        "type": "mcq",
        "c": "text = \"This beat is sick!\" \n# Model predicts: Negative sentiment (interpreting 'sick' literally)",
        "o": [
            "Deployment Bias / Mismatch",
            "Survivorship Bias",
            "Observer Bias",
            "Recall Bias"
        ]
    },
    {
        "q": "The concept of '______' requires that a user must actively check a box to agree to data collection, rather than having it pre-checked.",
        "type": "fill_blank",
        "answers": [
            "Opt-in"
        ],
        "other_options": [
            "Opt-out",
            "Hand-off",
            "Sign-off"
        ]
    },
    {
        "q": "Which Python library is specifically designed by IBM to detect and mitigate bias in machine learning models?",
        "type": "mcq",
        "o": [
            "AIF360 (AI Fairness 360)",
            "Pandas",
            "NumPy",
            "Matplotlib"
        ]
    },
    {
        "q": "What does this code snippet suggest about the model's update policy?",
        "type": "mcq",
        "c": "# Model deployed in 2020\ncurr_date = '2025-01-01'\nif curr_date > '2021-01-01':\n    pass # Continue using existing weights",
        "o": [
            "The model is at risk of Concept Drift due to lack of retraining",
            "The model is updating in real-time",
            "The model uses reinforcement learning",
            "The code deletes old data automatically"
        ]
    },
    {
        "q": "Match the privacy engineering tool with its primary function:",
        "type": "match",
        "left": [
            "Microsoft Presidio",
            "TensorFlow Privacy",
            "PySyft"
        ],
        "right": [
            "PII detection and redaction in text/images",
            "Training models with differential privacy guarantees",
            "Secure remote execution for deep learning"
        ]
    },
    {
        "q": "If a dataset is fully anonymized today, it is mathematically guaranteed to remain anonymous forever.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which term describes the practice of manipulating the design of a system to confuse users into sharing more data than they intend?",
        "type": "mcq",
        "o": [
            "Dark Patterns",
            "White Hat Hacking",
            "A/B Testing",
            "Feature Scaling"
        ]
    },
    {
        "q": "What is the term for the phenomenon where a metric ceases to be a valid measure once it becomes the target for optimization (e.g., teaching to the test)?",
        "type": "mcq",
        "o": [
            "Goodhart's Law",
            "Moore's Law",
            "Murphy's Law",
            "Zipf's Law"
        ]
    },
    {
        "q": "In Computer Vision, ______ maps are used to highlight which pixels in an image most influenced the model's classification decision.",
        "type": "fill_blank",
        "answers": [
            "Saliency"
        ],
        "other_options": [
            "Heat",
            "Density",
            "Texture"
        ]
    },
    {
        "q": "What ethical issue is occurring in this code snippet regarding model validation?",
        "type": "mcq",
        "c": "from sklearn.linear_model import LogisticRegression\n# MISTAKE: Fitting on the entire dataset before splitting\nmodel.fit(all_data_X, all_data_y)\npreds = model.predict(test_X)",
        "o": [
            "Data Leakage (invalidating performance claims)",
            "Underfitting",
            "Label Smoothing",
            "Incorrect regularization"
        ]
    },
    {
        "q": "Match the type of AI bias to its origin:",
        "type": "match",
        "left": [
            "Historical Bias",
            "Measurement Bias",
            "Evaluation Bias"
        ],
        "right": [
            "Existing societal prejudices reflected in the training data",
            "Errors in how data features are collected or labeled",
            "Benchmarking a model on data that doesn't represent the target population"
        ]
    },
    {
        "q": "The 'Mosaic Effect' refers to the ability to re-identify individuals by combining multiple independent, anonymized datasets.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which enforcement action, used by the FTC, requires a company to destroy not only the illegally collected data but also any algorithms or models trained on that data?",
        "type": "mcq",
        "o": [
            "Algorithmic Disgorgement",
            "Model Pruning",
            "Data Embargo",
            "Digital Forfeiture"
        ]
    },
    {
        "q": "What is the purpose of the noise addition in this Differential Privacy snippet?",
        "type": "mcq",
        "c": "true_count = query_database()\nepsilon = 0.5\n# Adding noise from Laplace distribution\nreported_count = true_count + np.random.laplace(0, 1/epsilon)",
        "o": [
            "To mask the contribution of any single individual to the count",
            "To correct for missing values in the database",
            "To increase the precision of the floating point number",
            "To encrypt the data for storage"
        ]
    },
    {
        "q": "Rearrange the words to identify a flawed strategy often mistaken for a fairness solution:",
        "type": "rearrange",
        "words": [
            "Fairness",
            "through",
            "unawareness",
            "is",
            "insufficient"
        ]
    },
    {
        "q": "Which cryptographic method allows one party to prove to another that they know a value (like a password) without conveying the actual value itself?",
        "type": "mcq",
        "o": [
            "Zero-Knowledge Proof",
            "Public Key Infrastructure",
            "Symmetric Encryption",
            "Steganography"
        ]
    },
    {
        "q": "______ involves ethical hacking where a team explicitly tries to attack a model to find vulnerabilities, biases, or harmful outputs before deployment.",
        "type": "fill_blank",
        "answers": [
            "Red Teaming"
        ],
        "other_options": [
            "Blue Teaming",
            "White Box Testing",
            "Beta Testing"
        ]
    },
    {
        "q": "What does the 'T' in the privacy model 'T-Closeness' represent?",
        "type": "mcq",
        "o": [
            "The distance between the distribution of a sensitive attribute in a cluster vs. the global distribution",
            "The time it takes to re-identify a record",
            "The threshold of error allowed in the model",
            "The total number of quasi-identifiers"
        ]
    },
    {
        "q": "Look at the class balance check below. If this dataset is used for fraud detection, what is the likely ethical risk?",
        "type": "mcq",
        "c": "print(df['is_fraud'].value_counts())\n# Output:\n# 0    99900\n# 1      100",
        "o": [
            "The model may completely ignore the minority class (fraud) to maximize accuracy",
            "The model will be too sensitive and flag everyone as fraud",
            "The model will run too slowly due to data size",
            "No risk, the data is clean"
        ]
    },
    {
        "q": "A 'Human-in-the-loop' system allows an AI to make high-stakes decisions entirely autonomously without supervision.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the Interpretability method with its scope:",
        "type": "match",
        "left": [
            "Partial Dependence Plot (PDP)",
            "SHAP (for a single row)",
            "Global Surrogate"
        ],
        "right": [
            "Shows the marginal effect of 1-2 features on the predicted outcome globally",
            "Explains the contribution of features for a specific instance",
            "An interpretable model trained to approximate the black box model entirely"
        ]
    },
    {
        "q": "Which famous thought experiment is often adapted to discuss the decision-making logic of Autonomous Vehicles in unavoidable accident scenarios?",
        "type": "mcq",
        "o": [
            "The Trolley Problem",
            "Schrödinger's Cat",
            "The Chinese Room",
            "The Turing Test"
        ]
    },
    {
        "q": "According to the EU AI Act, AI systems used for 'Social Scoring' by governments are classified under which risk category?",
        "type": "mcq",
        "o": [
            "Unacceptable Risk (Banned)",
            "High Risk",
            "Limited Risk",
            "Minimal Risk"
        ]
    },
    {
        "q": "What specific type of data poisoning attack involves injecting a specific trigger pattern (like a sticker on a stop sign) into the training set so the model misbehaves only when that trigger is present?",
        "type": "mcq",
        "o": [
            "Backdoor Attack",
            "Sponge Attack",
            "Oracle Attack",
            "Man-in-the-middle Attack"
        ]
    },
    {
        "q": "What is the security and ethical risk in the following Python code using the `pickle` module?",
        "type": "mcq",
        "c": "import pickle\n# data_stream comes from an external, untrusted user\nobj = pickle.loads(data_stream)",
        "o": [
            "Arbitrary code execution (Remote Code Execution)",
            "Memory leak",
            "Integer overflow",
            "Data bias injection"
        ]
    },
    {
        "q": "Match the privacy enhancing technology (PET) to its description:",
        "type": "match",
        "left": [
            "Trusted Execution Environment (TEE)",
            "Tokenization",
            "Synthetics"
        ],
        "right": [
            "Hardware-based secure area ensuring code/data integrity",
            "Replacing sensitive data with a non-sensitive equivalent pointer",
            "Artificially generated data mimicking real statistical patterns"
        ]
    },
    {
        "q": "The Illinois law known as ______ strictly regulates the collection and storage of biometric identifiers like face scans and fingerprints.",
        "type": "fill_blank",
        "answers": [
            "BIPA"
        ],
        "other_options": [
            "GDPR",
            "FERPA",
            "RICO"
        ]
    },
    {
        "q": "What type of validity is compromised when a model uses 'arrest records' as a proxy for 'crime rate', ignoring that arrests reflect police activity rather than total crime committed?",
        "type": "mcq",
        "o": [
            "Construct Validity",
            "Internal Validity",
            "Convergent Validity",
            "Face Validity"
        ]
    },
    {
        "q": "Rearrange the words to form the 7th principle of 'Privacy by Design':",
        "type": "rearrange",
        "words": [
            "Respect",
            "for",
            "user",
            "privacy",
            "keep",
            "it",
            "user-centric"
        ]
    },
    {
        "q": "Why is using the standard `random` library unethical/unsafe for generating password reset tokens?",
        "type": "mcq",
        "c": "import random\ntoken = random.randint(1000, 9999)\n# Used for security authentication",
        "o": [
            "It is pseudo-random and deterministic (predictable)",
            "It causes buffer overflows",
            "It only supports integers",
            "It cannot generate strings"
        ]
    },
    {
        "q": "What is the primary goal of 'Watermarking' in the context of Generative AI (LLMs/Image Generators)?",
        "type": "mcq",
        "o": [
            "To embed an invisible signal proving content was AI-generated",
            "To prevent the image from being copied",
            "To improve the resolution of the image",
            "To reduce the inference time"
        ]
    },
    {
        "q": "______ involves modifying the input to a model to dramatically increase its energy consumption and latency, raising environmental and availability concerns.",
        "type": "fill_blank",
        "answers": [
            "Sponge"
        ],
        "other_options": [
            "Leech",
            "Drain",
            "Flood"
        ]
    },
    {
        "q": "Which fairness philosophy argues that a model is fair if the process of decision-making is consistent for everyone, regardless of the outcome distribution?",
        "type": "mcq",
        "o": [
            "Procedural Fairness",
            "Distributive Fairness",
            "Outcome Fairness",
            "Restorative Justice"
        ]
    },
    {
        "q": "What does the logging practice in this snippet violate regarding data minimization principles?",
        "type": "mcq",
        "c": "try:\n    process_payment(user_object)\nexcept Exception as e:\n    # Dumping the entire object state to logs\n    logger.error(f\"Failed for: {user_object.__dict__}\")",
        "o": [
            "It logs sensitive PII/financial data into unsecured log files",
            "It fails to catch the exception properly",
            "It uses f-strings which are slow",
            "It does not raise the error again"
        ]
    },
    {
        "q": "The 'Right to Data Portability' allows users to obtain their data from a controller in a structured, commonly used, and machine-readable format.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the bias type to the scenario:",
        "type": "match",
        "left": [
            "Label Bias",
            "Ranking Bias",
            "Temporal Bias"
        ],
        "right": [
            "The annotator's own subjectivity influences the ground truth",
            "Search engines showing top results that reinforce user clicks",
            "Training on 2010 data to predict 2024 behavior"
        ]
    },
    {
        "q": "In the context of Federated Learning, what attack involves a server reconstructing the user's private data by analyzing the gradient updates sent by the user?",
        "type": "mcq",
        "o": [
            "Gradient Inversion / Leakage",
            "DDoS",
            "SQL Injection",
            "Cross-Site Scripting"
        ]
    },
    {
        "q": "Which social science concept describes the tendency for human operators to bear the responsibility when an automated system fails, even if the system was designed with hidden flaws?",
        "type": "mcq",
        "o": [
            "Moral Crumple Zone",
            "Bystander Effect",
            "Dunning-Kruger Effect",
            "Pareto Principle"
        ]
    },
    {
        "q": "What is the primary privacy risk exposed by this code, which processes user-uploaded images?",
        "type": "mcq",
        "c": "from PIL import Image\nimg = Image.open('user_photo.jpg')\nexif_data = img._getexif()\n# GPSInfo is often found in tag 34853\nprint(exif_data.get(34853))",
        "o": [
            "Exposure of geolocation metadata (Location Tracking)",
            "Pixel inversion attack",
            "Steganography injection",
            "Copyright infringement"
        ]
    },
    {
        "q": "In the context of survey ethics, '______ Response' is a technique where respondents answer sensitive questions based on a random event (like a coin flip) to protect their privacy.",
        "type": "fill_blank",
        "answers": [
            "Randomized"
        ],
        "other_options": [
            "Stochastic",
            "Encrypted",
            "Anonymized"
        ]
    },
    {
        "q": "Match the bias mitigation strategy to the stage of the machine learning pipeline where it is applied:",
        "type": "match",
        "left": [
            "Reweighting Samples",
            "Adversarial Debiasing",
            "Threshold Adjustment"
        ],
        "right": [
            "Pre-processing (Data stage)",
            "In-processing (Model training stage)",
            "Post-processing (Prediction stage)"
        ]
    },
    {
        "q": "Which U.S. federal law specifically governs the privacy of student education records?",
        "type": "mcq",
        "o": [
            "FERPA",
            "HIPAA",
            "FISMA",
            "GDPR"
        ]
    },
    {
        "q": "What ethical pitfall is demonstrated in this recommendation system logic?",
        "type": "mcq",
        "c": "# Suggest content based solely on what the user clicked previously\nrecommendations = get_similar_items(user_history.clicks)\n# Result: User sees increasingly extreme versions of the same topic.",
        "o": [
            "Filter Bubble / Echo Chamber",
            "Cold Start Problem",
            "Sparse Matrix Error",
            "Gradient Explosion"
        ]
    },
    {
        "q": "Rearrange the words to define a core principle of 'Value Sensitive Design':",
        "type": "rearrange",
        "words": [
            "Account",
            "for",
            "human",
            "values",
            "in",
            "technical",
            "design"
        ]
    },
    {
        "q": "Scraping publicly available data from social media profiles is automatically ethical and legal because the data is public.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the specific risk of the 'Hardcoded Secret' in this database connection snippet?",
        "type": "mcq",
        "c": "def connect_db():\n    # TODO: Move to env variables\n    pwd = \"SuperSecretAdmin123!\"\n    return db.connect(user='admin', password=pwd)",
        "o": [
            "Credential Leakage via Source Control",
            "SQL Injection",
            "Database Deadlock",
            "Connection Timeout"
        ]
    },
    {
        "q": "The concept of '______ Solutionism' is the belief that every social or ethical problem has a purely technological fix, often ignoring complex human factors.",
        "type": "fill_blank",
        "answers": [
            "Technological"
        ],
        "other_options": [
            "Digital",
            "Algorithmic",
            "Computational"
        ]
    },
    {
        "q": "Which financial regulation requires financial institutions to explain their information-sharing practices and safeguard sensitive data (GLBA)?",
        "type": "mcq",
        "o": [
            "Gramm-Leach-Bliley Act",
            "Sarbanes-Oxley Act",
            "Dodd-Frank Act",
            "Glass-Steagall Act"
        ]
    },
    {
        "q": "What is the purpose of the 'PATE' (Private Aggregation of Teacher Ensembles) framework?",
        "type": "mcq",
        "o": [
            "To transfer knowledge from an ensemble of 'teacher' models to a 'student' model with privacy guarantees",
            "To aggregate grades in an educational setting",
            "To encrypt data during transfer",
            "To detect cheating in online exams"
        ]
    },
    {
        "q": "Match the Data State to its security requirement:",
        "type": "match",
        "left": [
            "Data at Rest",
            "Data in Transit",
            "Data in Use"
        ],
        "right": [
            "Encryption via disk/database encryption (e.g., AES)",
            "Encryption via protocols like TLS/SSL",
            "Protection via Enclaves or Homomorphic Encryption"
        ]
    },
    {
        "q": "Does this code successfully reduce the granularity of the data to improve privacy?",
        "type": "mcq",
        "c": "import pandas as pd\ndf['exact_birth_date'] = pd.to_datetime(df['exact_birth_date'])\n# Replace exact date with just the year\ndf['birth_year'] = df['exact_birth_date'].dt.year\ndf.drop(columns=['exact_birth_date'], inplace=True)",
        "o": [
            "Yes, it generalizes the data (Generalization)",
            "No, it increases the risk",
            "No, it creates null values",
            "Yes, it encrypts the data"
        ]
    },
    {
        "q": "Which metric of fairness focuses on ensuring that the *probability* of a qualified applicant being selected is the same across all groups (Equality of Opportunity)?",
        "type": "mcq",
        "o": [
            "True Positive Rate Parity",
            "Statistical Parity",
            "False Positive Rate Parity",
            "Base Rate Parity"
        ]
    },
    {
        "q": "What is the primary purpose of the 'Datasheets for Datasets' framework proposed by Gebru et al.?",
        "type": "mcq",
        "o": [
            "To document the motivation, composition, and collection process of a dataset",
            "To compress the dataset for faster training",
            "To encrypt the dataset using SHA-256",
            "To automatically label the dataset using AI"
        ]
    },
    {
        "q": "In the context of U.S. labor law and AI, '______ Impact' refers to policies that are facially neutral but have a discriminatory effect on a protected group.",
        "type": "fill_blank",
        "answers": [
            "Disparate"
        ],
        "other_options": [
            "Adverse",
            "Direct",
            "Intentional"
        ]
    },
    {
        "q": "Match the GDPR entity with its definition:",
        "type": "match",
        "left": [
            "Data Subject",
            "Data Controller",
            "Data Processor"
        ],
        "right": [
            "The individual whom the data is about",
            "The entity that determines the purpose and means of processing",
            "The entity that processes data on behalf of the controller"
        ]
    },
    {
        "q": "Rearrange the words to form the name of a standard document used to assess privacy risks before starting a project:",
        "type": "rearrange",
        "words": [
            "Privacy",
            "Impact",
            "Assessment",
            "Report"
        ]
    },
    {
        "q": "According to the US Copyright Office (as of 2023), images generated entirely by AI without human creative contribution are eligible for copyright protection.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What technique is being applied in this code snippet to address class imbalance?",
        "type": "mcq",
        "c": "from sklearn.utils import resample\n# Separate majority and minority classes\nminority_upsampled = resample(minority, replace=True, n_samples=len(majority))",
        "o": [
            "Oversampling",
            "Undersampling",
            "Stratified K-Fold",
            "Regularization"
        ]
    },
    {
        "q": "The '______' Test is a proposal to replace the Turing Test, focusing instead on whether an AI system can skillfully generate a narrative that fits a set of constraints.",
        "type": "fill_blank",
        "answers": [
            "Lovelace"
        ],
        "other_options": [
            "Voight-Kampff",
            "Chinese Room",
            "Mirror"
        ]
    },
    {
        "q": "Which ethical framework judges the morality of an automated decision based on the consequences (e.g., saving the most lives in an accident), rather than strict rules?",
        "type": "mcq",
        "o": [
            "Utilitarianism",
            "Deontology",
            "Virtue Ethics",
            "Nihilism"
        ]
    },
    {
        "q": "What specific type of data leakage is occurring in this code?",
        "type": "mcq",
        "c": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# Fitting the scaler on the WHOLE dataset before splitting\nX_scaled = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y)",
        "o": [
            "Contamination of training data with test set statistics",
            "Target Leakage",
            "Label Leaking",
            "Feature Explosion"
        ]
    },
    {
        "q": "Match the type of user consent with its description:",
        "type": "match",
        "left": [
            "Explicit Consent",
            "Implicit Consent",
            "Granular Consent"
        ],
        "right": [
            "User takes a specific action (e.g., clicking 'I Agree') to permit processing",
            "Consent is inferred from user behavior (e.g., continuing to browse)",
            "User can agree to specific types of processing while rejecting others"
        ]
    },
    {
        "q": "Data ______ refers to the concept that data is subject to the laws and governance structures within the nation it is collected.",
        "type": "fill_blank",
        "answers": [
            "Sovereignty"
        ],
        "other_options": [
            "Localization",
            "Residency",
            "Colonialism"
        ]
    },
    {
        "q": "Rearrange the words to identify the 'Right' that allows a user to correct inaccurate data held about them:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "Rectification"
        ]
    },
    {
        "q": "What is the primary focus of 'Green AI'?",
        "type": "mcq",
        "o": [
            "Reducing the carbon footprint and energy cost of training large models",
            "Using AI to predict weather patterns",
            "Visualizing decision trees in green colors",
            "Recycling old hardware for servers"
        ]
    },
    {
        "q": "Hashing is a reversible process, meaning you can always decrypt the hash to get the original data if you have the key.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the purpose of the regex check in this data pipeline?",
        "type": "mcq",
        "c": "import re\npattern = r\"^\\d{3}-\\d{2}-\\d{4}$\"\nif re.match(pattern, input_str):\n    flag_sensitive(input_str)",
        "o": [
            "To identify and flag US Social Security Numbers (SSN)",
            "To validate email addresses",
            "To check for SQL injection patterns",
            "To detect credit card numbers"
        ]
    },
    {
        "q": "Which Python module is cryptographically strong and should be used instead of the standard `random` library for generating security tokens or temporary passwords?",
        "type": "mcq",
        "c": "import ______\ntoken = ______.token_hex(16)",
        "o": [
            "secrets",
            "crypto",
            "secure_rand",
            "hashlib"
        ]
    },
    {
        "q": "The NIST AI Risk Management Framework (AI RMF 1.0) organizes AI risks into four core functions: Govern, Map, Measure, and ______.",
        "type": "fill_blank",
        "answers": [
            "Manage"
        ],
        "other_options": [
            "Monitor",
            "Mitigate",
            "Master"
        ]
    },
    {
        "q": "Match the cognitive bias affecting Data Analysts to its definition:",
        "type": "match",
        "left": [
            "Anchoring Bias",
            "Gambler's Fallacy",
            "Bandwagon Effect"
        ],
        "right": [
            "Over-relying on the first piece of information offered (the 'anchor')",
            "Believing that past independent events influence future probabilities",
            "Adopting a methodology just because many others are doing it"
        ]
    },
    {
        "q": "What data ethics issue is introduced by this imputation code?",
        "type": "mcq",
        "c": "# Dataset contains 'Salary' and 'Gender'\n# Imputing missing salaries with the global mean\ndf['Salary'].fillna(df['Salary'].mean(), inplace=True)",
        "o": [
            "It erases structural differences between groups, potentially masking pay gaps",
            "It causes a MemoryError for large datasets",
            "It introduces negative values into the salary column",
            "It changes the data type to string"
        ]
    },
    {
        "q": "Rearrange the words to form the name of the fairness library maintained by Microsoft:",
        "type": "rearrange",
        "words": [
            "Fairlearn"
        ]
    },
    {
        "q": "In Reinforcement Learning, '______ Hacking' occurs when an agent learns a clever way to maximize the reward function without actually achieving the intended goal (e.g., a vacuum robot sweeping dust under the rug).",
        "type": "fill_blank",
        "answers": [
            "Reward"
        ],
        "other_options": [
            "Goal",
            "Policy",
            "Value"
        ]
    },
    {
        "q": "Which type of Differential Privacy adds noise to the data on the user's device *before* it is sent to the central server?",
        "type": "mcq",
        "o": [
            "Local Differential Privacy",
            "Global Differential Privacy",
            "Centralized Differential Privacy",
            "Hybrid Differential Privacy"
        ]
    },
    {
        "q": "Under the 'Purpose Limitation' principle of GDPR, data collected for a specific purpose (e.g., shipping) can freely be used for any other purpose (e.g., marketing) without further consent.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What does the 'A' stand for in the FATE framework for ethical AI?",
        "type": "mcq",
        "o": [
            "Accountability",
            "Accuracy",
            "Automation",
            "Anonymity"
        ]
    },
    {
        "q": "Identify the risk in this code where a model is trained on data generated by another model:",
        "type": "mcq",
        "c": "# Training Model B using predictions from Model A\ny_train_B = model_A.predict(X_train)",
        "o": [
            "Model Collapse / Autophagous Loops",
            "Overfitting",
            "Gradient Vanishing",
            "Feature Selection Error"
        ]
    },
    {
        "q": "Match the open-source tool to its primary ethical function:",
        "type": "match",
        "left": [
            "Carbon Tracker",
            "Deon",
            "Great Expectations"
        ],
        "right": [
            "Tracking energy consumption and carbon footprint of training",
            "A command-line ethics checklist for data science projects",
            "Validating, documenting, and profiling data quality"
        ]
    },
    {
        "q": "The theory of '______ Integrity' (Helen Nissenbaum) suggests that privacy is not about secrecy, but about the appropriate flow of information within specific social norms.",
        "type": "fill_blank",
        "answers": [
            "Contextual"
        ],
        "other_options": [
            "Structural",
            "Digital",
            "Social"
        ]
    },
    {
        "q": "What specific attack exploits the physical implementation of a system (e.g., power consumption or electromagnetic leaks) rather than the algorithm itself?",
        "type": "mcq",
        "o": [
            "Side-Channel Attack",
            "Brute Force Attack",
            "Phishing Attack",
            "Dictionary Attack"
        ]
    },
    {
        "q": "Rearrange the words to identify a GDPR right regarding processing restriction:",
        "type": "rearrange",
        "words": [
            "Right",
            "to",
            "restrict",
            "processing"
        ]
    },
    {
        "q": "Is the following SQL query safe from Injection attacks?",
        "type": "mcq",
        "c": "user_input = \"'; DROP TABLE users; --\"\nquery = f\"SELECT * FROM users WHERE name = '{user_input}'\"",
        "o": [
            "No, because it uses f-string formatting to insert raw input",
            "Yes, because f-strings are secure",
            "Yes, because Python sanitizes inputs automatically",
            "No, because the table name is wrong"
        ]
    },
    {
        "q": "What statistical phenomenon is demonstrated when a predictive model performs well on training data but fails to generalize to a minority demographic because the minority group was effectively treated as 'outliers' during optimization?",
        "type": "mcq",
        "o": [
            "Minority Class Marginalization",
            "The curse of dimensionality",
            "Homoscedasticity",
            "The Law of Large Numbers"
        ]
    },
    {
        "q": "Which fairness definition requires that the probability of a positive prediction is independent of the sensitive attribute (i.e., P(Y_hat=1 | A=a) = P(Y_hat=1 | A=b))?",
        "type": "mcq",
        "c": "# A is the sensitive attribute, Y_hat is prediction",
        "o": [
            "Demographic Parity (Statistical Parity)",
            "Equalized Odds",
            "Equality of Opportunity",
            "Calibration"
        ]
    },
    {
        "q": "In the context of EU law, '______' refers to the legal basis where an organization processes data because it is necessary for the performance of a contract with the user.",
        "type": "fill_blank",
        "answers": [
            "Contractual"
        ],
        "other_options": [
            "Consensual",
            "Legitimate",
            "Vital"
        ]
    },
    {
        "q": "Match the adversarial defense mechanism to its description:",
        "type": "match",
        "left": [
            "Adversarial Training",
            "Defensive Distillation",
            "Feature Squeezing"
        ],
        "right": [
            "Injecting adversarial examples into the training set with correct labels",
            "Training a second model to predict the probabilities of the first model",
            "Reducing the complexity of input data (e.g., reducing color bit depth)"
        ]
    },
    {
        "q": "What is the primary risk of using 'One-Hot Encoding' on a high-cardinality sensitive feature (like Zip Code) without further processing?",
        "type": "mcq",
        "o": [
            "It creates sparse vectors that act as unique identifiers, aiding re-identification",
            "It causes the model to underfit",
            "It automatically encrypts the data",
            "It reduces the dimensionality of the dataset"
        ]
    },
    {
        "q": "Rearrange the words to identify the principle that users should be able to move their data between service providers:",
        "type": "rearrange",
        "words": [
            "Data",
            "Portability",
            "allows",
            "switching",
            "providers"
        ]
    },
    {
        "q": "The '______' Effect describes a situation where an algorithm's deployment alters the behavior of the people it is observing, rendering the historical training data obsolete.",
        "type": "fill_blank",
        "answers": [
            "Performativity"
        ],
        "other_options": [
            "Observer",
            "Butterfly",
            "Placebo"
        ]
    },
    {
        "q": "Which of the following is considered a 'Dark Pattern' specifically related to cancellation of services?",
        "type": "mcq",
        "o": [
            "Roach Motel",
            "Privacy Zuckering",
            "Confirmshaming",
            "Sneak into Basket"
        ]
    },
    {
        "q": "A model with high accuracy can still be unfair if the False Negative rates differ significantly between protected groups.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the ethical implication of the 'proxy' variable in this housing price model?",
        "type": "mcq",
        "c": "# 'Race' is removed, but 'High_School_Quality_Index' is kept.\n# This index correlates 95% with neighborhood racial demographics.",
        "o": [
            "Redlining via proxy variables",
            "Improved model generalization",
            "Elimination of racial bias",
            "Data minimization"
        ]
    },
    {
        "q": "Match the term with the type of missing data:",
        "type": "match",
        "left": [
            "MCAR (Missing Completely At Random)",
            "MAR (Missing At Random)",
            "MNAR (Missing Not At Random)"
        ],
        "right": [
            "The probability of missingness is unrelated to any data (observed or unobserved)",
            "The probability of missingness depends on observed data but not the missing value itself",
            "The probability of missingness depends on the value of the missing data itself"
        ]
    },
    {
        "q": "What is the primary function of a 'Canary' in privacy-preserving machine learning?",
        "type": "mcq",
        "o": [
            "To test if a specific data point was included in the training set (Membership Inference)",
            "To signal when the model has finished training",
            "To encrypt the validation set",
            "To add random noise to the gradient"
        ]
    },
    {
        "q": "Which license allows others to use, modify, and distribute your code/data, but only if they release their work under the same license terms?",
        "type": "mcq",
        "o": [
            "Copyleft / ShareAlike (e.g., GPL, CC BY-SA)",
            "Permissive (e.g., MIT, Apache)",
            "Public Domain (CC0)",
            "Proprietary"
        ]
    },
    {
        "q": "The 'Right to ______' ensures that a human intervenes in automated decision-making processes that have legal or significant effects.",
        "type": "fill_blank",
        "answers": [
            "contest"
        ],
        "other_options": [
            "delete",
            "access",
            "forget"
        ]
    },
    {
        "q": "Why is the following data retention policy risky?",
        "type": "mcq",
        "c": "def archive_logs(logs):\n    # Keep logs forever for 'future analysis'\n    storage.save(logs, retention='indefinite')",
        "o": [
            "It violates the Storage Limitation principle and increases breach impact",
            "It is too expensive to store",
            "It makes the database slower",
            "It causes code rot"
        ]
    },
    {
        "q": "Which specific type of privacy attack observes the time it takes for a model to respond to a query to infer properties about the input data?",
        "type": "mcq",
        "o": [
            "Timing Side-Channel Attack",
            "Man-in-the-Middle Attack",
            "Dictionary Attack",
            "Phishing Attack"
        ]
    },
    {
        "q": "What data ethics principle is violated by the following code if used for secure deletion?",
        "type": "mcq",
        "c": "import os\n# User requests account deletion\nos.remove(\"user_data.db\")\n# The file pointer is removed, but magnetic data remains on disk.",
        "o": [
            "Right to Erasure (data is recoverable)",
            "Data Portability",
            "Purpose Limitation",
            "Accuracy"
        ]
    },
    {
        "q": "The practice of '______' involves auditing an algorithm by treating it as a 'black box' and analyzing its inputs and outputs without access to the internal code.",
        "type": "fill_blank",
        "answers": [
            "External"
        ],
        "other_options": [
            "Internal",
            "White-box",
            "Static"
        ]
    },
    {
        "q": "Match the philosophical framework to its application in AI Ethics:",
        "type": "match",
        "left": [
            "Deontology",
            "Consequentialism",
            "Virtue Ethics"
        ],
        "right": [
            "Following strict rules/duties (e.g., 'Never lie', 'Never kill')",
            "Judging actions by their outcomes (e.g., 'Maximize happiness')",
            "Focusing on the character/intent of the moral agent (the AI developer)"
        ]
    },
    {
        "q": "Which concept describes the capability of an individual to hide their connections to others in a social graph dataset?",
        "type": "mcq",
        "o": [
            "Graph Anonymity",
            "Node Centrality",
            "Edge Computing",
            "Link Prediction"
        ]
    },
    {
        "q": "What is the primary risk of using `eval()` in Python to process dynamic rules for a data filter?",
        "type": "mcq",
        "c": "rule = request.get('filter_rule')\n# input: \"__import__('os').system('rm -rf /')\"\nresult = eval(rule)",
        "o": [
            "Code Injection / Remote Code Execution",
            "Data Bias",
            "Model Overfitting",
            "Precision Loss"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Right to Explanation' in simple terms:",
        "type": "rearrange",
        "words": [
            "Understanding",
            "how",
            "a",
            "decision",
            "was",
            "reached"
        ]
    },
    {
        "q": "A 'Privacy ______' is a limit on how much information a specific algorithm or system is allowed to leak about a dataset before it must stop answering queries.",
        "type": "fill_blank",
        "answers": [
            "Budget"
        ],
        "other_options": [
            "Wall",
            "Shield",
            "Container"
        ]
    },
    {
        "q": "If a dataset lists '35-year-old male, Zip: 10001, Diagnosis: Flu', and there is only one 35-year-old male in Zip 10001 in the public census, this record is vulnerable to:",
        "type": "mcq",
        "o": [
            "Singling Out",
            "Aggregation",
            "Inference",
            "Masking"
        ]
    },
    {
        "q": "Removing 'Gender' from a dataset fixes gender bias, even if the dataset contains 'Job Title' (e.g., 'Nurse' vs 'Construction Worker').",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What fairness metric is calculated in this snippet?",
        "type": "mcq",
        "c": "fp_rate_group_a = fp_a / (fp_a + tn_a)\nfp_rate_group_b = fp_b / (fp_b + tn_b)\n# Checking if fp_rate_group_a == fp_rate_group_b",
        "o": [
            "Predictive Equality (False Positive Error Rate Balance)",
            "Demographic Parity",
            "Overall Accuracy",
            "Recall"
        ]
    },
    {
        "q": "Match the Data Lifecycle stage with the ethical concern:",
        "type": "match",
        "left": [
            "Collection",
            "Analysis",
            "Disposal"
        ],
        "right": [
            "Informed Consent",
            "P-Hacking / Cherry-picking",
            "Data Remanence"
        ]
    },
    {
        "q": "Which famous 2016 article by ProPublica investigated the COMPAS algorithm used in court systems?",
        "type": "mcq",
        "o": [
            "Machine Bias",
            "The End of Theory",
            "AI Superpowers",
            "Weapons of Math Destruction"
        ]
    },
    {
        "q": "______ involves creating a copy of a database for testing purposes where all real data is replaced with fictitious but structurally identical data.",
        "type": "fill_blank",
        "answers": [
            "Mocking"
        ],
        "other_options": [
            "Hashing",
            "Salting",
            "Phishing"
        ]
    },
    {
        "q": "What does this code indicate about the relationship between accuracy and privacy?",
        "type": "mcq",
        "c": "# Increasing noise to improve privacy\nnoise_scale = 10.0 \n# Accuracy drops as noise increases\nmodel_accuracy = 0.95 - (noise_scale * 0.02)",
        "o": [
            "There is often a trade-off: higher privacy can lead to lower utility/accuracy",
            "Higher privacy always leads to higher accuracy",
            "Noise has no effect on model performance",
            "Accuracy is independent of privacy parameters"
        ]
    },
    {
        "q": "Which specific US law grants citizens the right to know the contents of their credit file and the specific reasons for a credit denial (often relevant in Automated Decision Making)?",
        "type": "mcq",
        "o": [
            "FCRA (Fair Credit Reporting Act)",
            "COPPA",
            "DMCA",
            "Patriot Act"
        ]
    },
    {
        "q": "In the context of $(\\epsilon, \\delta)$-Differential Privacy, what does the parameter $\\delta$ (delta) represent?",
        "type": "mcq",
        "o": [
            "The small probability that the privacy guarantee will fail",
            "The amount of noise added",
            "The number of users in the database",
            "The utility score of the model"
        ]
    },
    {
        "q": "What ethical issue is depicted in this web scraping scenario?",
        "type": "mcq",
        "c": "import requests\n# Identifying as a normal user to bypass bot detection\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)...'}\nrequests.get(url, headers=headers)",
        "o": [
            "Spoofing User Agents to bypass 'robots.txt' or bot protections",
            "SQL Injection",
            "Cross-Site Request Forgery",
            "Man-in-the-Middle"
        ]
    },
    {
        "q": "Match the level of human involvement in AI systems to its definition:",
        "type": "match",
        "left": [
            "Human-in-the-loop",
            "Human-on-the-loop",
            "Human-out-of-the-loop"
        ],
        "right": [
            "Human must confirm the action before the system executes it",
            "System acts autonomously but human can intervene/abort",
            "System acts autonomously with no human intervention possible"
        ]
    },
    {
        "q": "The file named ______ is a standard used by websites to communicate with web crawlers and other web robots to instruct them about which areas of the website should not be processed.",
        "type": "fill_blank",
        "answers": [
            "robots.txt"
        ],
        "other_options": [
            "sitemap.xml",
            "index.html",
            "config.json"
        ]
    },
    {
        "q": "What phenomenon occurred in the famous 'Netflix Prize' dataset release, where researchers linked anonymous movie ratings with public IMDb profiles?",
        "type": "mcq",
        "o": [
            "De-anonymization / Re-identification",
            "Data Corruption",
            "Model Inversion",
            "Feature Collision"
        ]
    },
    {
        "q": "Rearrange the words to identify the mechanism for legal data transfer from the EU to non-EU countries:",
        "type": "rearrange",
        "words": [
            "Standard",
            "Contractual",
            "Clauses"
        ]
    },
    {
        "q": "Is the following password storage method secure?",
        "type": "mcq",
        "c": "import base64\n# Encoding password for storage\nstored_pw = base64.b64encode(user_password.encode())",
        "o": [
            "No, Base64 is encoding, not encryption or hashing",
            "Yes, Base64 scrambles the data",
            "Yes, but only for short passwords",
            "No, it uses too much storage space"
        ]
    },
    {
        "q": "A ______ is a malicious modification of a neural network that functions normally on standard inputs but misclassifies inputs containing a specific 'trigger' pattern.",
        "type": "fill_blank",
        "answers": [
            "Trojan"
        ],
        "other_options": [
            "Virus",
            "Worm",
            "Bug"
        ]
    },
    {
        "q": "What does the 'Right to Object' in GDPR specifically allow a user to do?",
        "type": "mcq",
        "o": [
            "Stop the processing of their data for direct marketing or legitimate interests",
            "Delete all their data immediately",
            "Edit their data",
            "Download their data"
        ]
    },
    {
        "q": "If an AI Resume Screener is trained on 10 years of historical hiring data from a male-dominated industry, removing the 'Name' and 'Gender' columns is sufficient to eliminate bias.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the bias term to the example:",
        "type": "match",
        "left": [
            "Implicit Bias",
            "Confirmation Bias",
            "Sunk Cost Bias"
        ],
        "right": [
            "Unconscious stereotypes affecting a developer's decisions",
            "Interpretating new data in a way that supports existing beliefs",
            "Continuing a failing AI project because resources were already spent"
        ]
    },
    {
        "q": "What implies the presence of 'Sludge' in a User Interface (UI)?",
        "type": "mcq",
        "o": [
            "Excessive friction or difficult steps added to prevent users from making a choice (e.g., cancelling a subscription)",
            "Visual noise in the graphic design",
            "Slow loading times due to server issues",
            "Pop-ups asking for cookies"
        ]
    },
    {
        "q": "Which component of the CIA Triad is compromised if a healthcare model's predictions are altered by a hacker, leading to incorrect dosages?",
        "type": "mcq",
        "o": [
            "Integrity",
            "Confidentiality",
            "Availability",
            "Non-repudiation"
        ]
    },
    {
        "q": "What is the purpose of the `stratify` parameter in this split, regarding data ethics?",
        "type": "mcq",
        "c": "train_test_split(X, y, stratify=y, test_size=0.2)",
        "o": [
            "To ensure the train/test sets have the same proportion of classes (fair representation)",
            "To shuffle the data randomly",
            "To remove duplicates",
            "To increase training speed"
        ]
    },
    {
        "q": "In the context of US employment law and AI fairness, the '4/5ths Rule' (or 80% Rule) suggests that a selection rate for any race, sex, or ethnic group which is less than ______ of the rate for the group with the highest rate is generally regarded as evidence of adverse impact.",
        "type": "fill_blank",
        "answers": [
            "four-fifths"
        ],
        "other_options": [
            "one-half",
            "two-thirds",
            "nine-tenths"
        ]
    },
    {
        "q": "What ethical concept refers to the lack of data coverage for specific subgroups (e.g., rural populations), leading to models that fail to serve them effectively?",
        "type": "mcq",
        "o": [
            "Data Deserts",
            "Data Lakes",
            "Feature Engineering",
            "Data Warehousing"
        ]
    },
    {
        "q": "Calculate the Disparate Impact Ratio based on this code. Is there potential bias against Group B according to the 0.8 threshold?",
        "type": "mcq",
        "c": "group_A_selection_rate = 0.50 # 50% selected\ngroup_B_selection_rate = 0.30 # 30% selected\nratio = group_B_selection_rate / group_A_selection_rate",
        "o": [
            "Ratio is 0.6; Yes, bias is indicated (0.6 < 0.8)",
            "Ratio is 0.6; No, bias is not indicated",
            "Ratio is 1.6; Yes, bias is indicated",
            "Ratio is 0.2; No, bias is not indicated"
        ]
    },
    {
        "q": "Match the famous AI failure case to its primary ethical cause:",
        "type": "match",
        "left": [
            "Microsoft 'Tay' Chatbot",
            "Amazon Recruiting Tool",
            "Google Photos 'Gorilla' Incident"
        ],
        "right": [
            "Lack of input filtering led to users teaching it hate speech",
            "Training data based on historical hiring penalized the word 'Women'",
            "Training data lacked sufficient diversity in dark-skinned faces"
        ]
    },
    {
        "q": "Which term describes the gradual expansion of the use of a system or data beyond the purpose for which it was originally intended and consented to?",
        "type": "mcq",
        "o": [
            "Function Creep / Mission Creep",
            "Scope Creep",
            "Feature Bloat",
            "Agile Development"
        ]
    },
    {
        "q": "Rearrange the steps to correct Bias in an AI lifecycle:",
        "type": "rearrange",
        "words": [
            "Audit",
            "data",
            "Train",
            "model",
            "Measure",
            "bias",
            "Mitigate",
            "bias"
        ]
    },
    {
        "q": "Encryption and Anonymization are identical concepts; if data is encrypted, it is legally considered anonymized under all frameworks.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What specific flaw in K-Anonymity is exploited when an attacker knows that *all* individuals in a specific anonymized group (equivalence class) share the same sensitive attribute (e.g., everyone in the group has cancer)?",
        "type": "mcq",
        "o": [
            "Homogeneity Attack",
            "Background Knowledge Attack",
            "Sybil Attack",
            "Dictionary Attack"
        ]
    },
    {
        "q": "The concept of '______' refers to the ability of an individual affected by an automated decision to challenge that decision and potentially get it reversed.",
        "type": "fill_blank",
        "answers": [
            "Recourse"
        ],
        "other_options": [
            "Reverse",
            "Reboot",
            "Recall"
        ]
    },
    {
        "q": "Identify the issue in this time-series forecasting split:",
        "type": "mcq",
        "c": "data = pd.read_csv('stock_prices.csv')\n# Shuffling time-series data destroys temporal order\nX_train, X_test, y_train, y_test = train_test_split(data, target, shuffle=True)",
        "o": [
            "Look-ahead Bias (training on future data)",
            "Sampling Bias",
            "Underfitting",
            "Syntax Error"
        ]
    },
    {
        "q": "Which license is 'Permissive', allowing users to do almost anything with the code/data as long as they provide attribution?",
        "type": "mcq",
        "o": [
            "MIT License",
            "GPL (General Public License)",
            "Proprietary",
            "NDA"
        ]
    },
    {
        "q": "Match the stakeholder to their primary responsibility in the AI Ethics ecosystem:",
        "type": "match",
        "left": [
            "Data Scientist",
            "Domain Expert",
            "Compliance Officer"
        ],
        "right": [
            "Ensuring model accuracy and checking for technical bias",
            "Providing context on how data reflects real-world nuances",
            "Ensuring the system adheres to laws like GDPR/CCPA"
        ]
    },
    {
        "q": "What does the 'California Age-Appropriate Design Code Act' primarily mandate?",
        "type": "mcq",
        "o": [
            "High privacy settings by default for services likely to be accessed by children",
            "Banning all AI for children",
            "Requiring facial recognition for age verification",
            "Free internet access for schools"
        ]
    },
    {
        "q": "In the context of explainability, a 'Global' explanation attempts to explain the entire model's behavior, while a '______' explanation focuses on a single prediction.",
        "type": "fill_blank",
        "answers": [
            "Local"
        ],
        "other_options": [
            "Regional",
            "Specific",
            "Micro"
        ]
    },
    {
        "q": "Look at the Confusion Matrix below for a disease detector. What is the ethical concern if the disease is fatal but treatable?",
        "type": "mcq",
        "c": "# [[TN: 900, FP: 10], \n#  [FN: 80,  TP: 10]]\n# High False Negatives (FN)",
        "o": [
            "The model is missing many actual cases (Low Recall), risking lives",
            "The model is raising too many false alarms (Low Precision)",
            "The model is too accurate",
            "The model is biased against healthy people"
        ]
    },
    {
        "q": "What specific Python command-line flag can dangerously bypass security checks implemented using `assert` statements in production code?",
        "type": "mcq",
        "c": "def critical_operation(user):\n    assert user.is_authenticated, \"Security Breach\"\n    # If run with optimization, this line is skipped.\n    process_payment()",
        "o": [
            "-O (Optimize)",
            "-v (Verbose)",
            "-x (Execute)",
            "-d (Debug)"
        ]
    },
    {
        "q": "The term '______ Gaze', coined by Joy Buolamwini, describes the algorithmic bias in facial recognition systems that results from datasets dominated by lighter-skinned individuals.",
        "type": "fill_blank",
        "answers": [
            "Coded"
        ],
        "other_options": [
            "Digital",
            "Blind",
            "Broken"
        ]
    },
    {
        "q": "Which fairness metric checks if the ratio of favorable outcomes is consistent across different groups (e.g., both men and women get loans at a 40% rate)?",
        "type": "mcq",
        "o": [
            "Statistical Parity (Demographic Parity)",
            "Equalized Odds",
            "Predictive Rate Parity",
            "Counterfactual Fairness"
        ]
    },
    {
        "q": "Match the type of Data Drift to its definition:",
        "type": "match",
        "left": [
            "Covariate Shift",
            "Prior Probability Shift",
            "Concept Drift"
        ],
        "right": [
            "The distribution of input features (X) changes, but the relationship to Y remains the same",
            "The distribution of the target variable (Y) changes",
            "The fundamental relationship between input (X) and target (Y) changes"
        ]
    },
    {
        "q": "What is the primary ethical risk of 'Data Exhaust' (the digital trail left by users' online activities)?",
        "type": "mcq",
        "o": [
            "It can be aggregated to infer sensitive details (like health or political views) without explicit consent",
            "It clogs up server memory",
            "It cannot be compressed",
            "It is always inaccurate"
        ]
    },
    {
        "q": "In the context of Large Language Models (LLMs), '______' refers to the generation of plausible-sounding but factually incorrect or nonsensical information.",
        "type": "fill_blank",
        "answers": [
            "Hallucination"
        ],
        "other_options": [
            "Delusion",
            "Dreaming",
            "Overfitting"
        ]
    },
    {
        "q": "Rearrange the words to identify the 'Alignment Problem' in AI safety:",
        "type": "rearrange",
        "words": [
            "Ensuring",
            "AI",
            "goals",
            "match",
            "human",
            "values"
        ]
    },
    {
        "q": "What is the flaw in this 'anonymization' attempt?",
        "type": "mcq",
        "c": "df['user_id'] = df['user_id'].apply(lambda x: hash(x))\n# Hashing without a salt",
        "o": [
            "It is vulnerable to Dictionary or Rainbow Table attacks",
            "It increases the data size significantly",
            "It makes the data unreadable by the CPU",
            "It changes the data type to float"
        ]
    },
    {
        "q": "According to the 'Privacy by Design' framework, privacy should be the default setting.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which technique involves training a model on a dataset where the sensitive attribute is decorrelated from the feature set to prevent bias?",
        "type": "mcq",
        "o": [
            "Adversarial Debiasing",
            "Gradient Boosting",
            "Feature Crossing",
            "Hyperparameter Tuning"
        ]
    },
    {
        "q": "Match the pseudonymization technique to its description:",
        "type": "match",
        "left": [
            "Masking",
            "Tokenization",
            "Blurring"
        ],
        "right": [
            "Hiding part of the data with characters (e.g., ****-1234)",
            "Replacing sensitive data with a non-sensitive unique identifier",
            "Reducing the precision of image or location data"
        ]
    },
    {
        "q": "What type of bias is created when an AI system is trained on user interactions (clicks), creating a feedback loop that reinforces existing popularity rather than quality?",
        "type": "mcq",
        "o": [
            "Presentation / Exposure Bias",
            "Omitted Variable Bias",
            "Recall Bias",
            "Healthy Worker Bias"
        ]
    },
    {
        "q": "Look at the code below. If `y_pred` are the model predictions and `y_true` are actual labels, what does a low Recall score indicate in a cancer detection context?",
        "type": "mcq",
        "c": "from sklearn.metrics import recall_score\nscore = recall_score(y_true, y_pred)\n# score is 0.45 (Low)",
        "o": [
            "High False Negatives (Missing many actual cancer cases)",
            "High False Positives (Diagnosing healthy people as sick)",
            "The model is overfitting",
            "The model is perfectly balanced"
        ]
    },
    {
        "q": "The '______' Effect refers to the phenomenon where people trust an automated system less after it fails just once, often discarding it entirely.",
        "type": "fill_blank",
        "answers": [
            "Algorithmic"
        ],
        "other_options": [
            "Machine",
            "Digital",
            "Binary"
        ]
    },
    {
        "q": "Which emerging legal concept suggests that data workers (like content moderators) should have rights regarding the psychological toll of filtering toxic AI training data?",
        "type": "mcq",
        "o": [
            "Data Labor Rights",
            "The Right to Be Forgotten",
            "Digital Copyright",
            "Open Source Licensing"
        ]
    },
    {
        "q": "Which New York City law, effective as of 2023, specifically requires a 'Bias Audit' for automated employment decision tools (AEDT) used in hiring and promotion?",
        "type": "mcq",
        "o": [
            "Local Law 144",
            "The AI Bill of Rights",
            "Section 230",
            "Proposition 65"
        ]
    },
    {
        "q": "What security vulnerability is present in this Python code using the PyYAML library to parse user input?",
        "type": "mcq",
        "c": "import yaml\n# 'user_config' is an untrusted string\nconfig = yaml.load(user_config, Loader=yaml.Loader)",
        "o": [
            "Arbitrary Code Execution (via object deserialization)",
            "SQL Injection",
            "Cross-Site Scripting (XSS)",
            "Buffer Overflow"
        ]
    },
    {
        "q": "In the context of Large Language Models (LLMs), ______ Injection is an attack where the user crafts an input to override the model's original instructions and safety guardrails.",
        "type": "fill_blank",
        "answers": [
            "Prompt"
        ],
        "other_options": [
            "SQL",
            "Data",
            "Feature"
        ]
    },
    {
        "q": "Match the Explainable AI (XAI) taxonomy term with its definition:",
        "type": "match",
        "left": [
            "Model-Agnostic",
            "Model-Specific",
            "Post-hoc"
        ],
        "right": [
            "Techniques applicable to any model (e.g., LIME, SHAP)",
            "Techniques designed for a specific architecture (e.g., Attention weights in Transformers)",
            "Explanations generated after the model has already made a prediction"
        ]
    },
    {
        "q": "What is the ' Rashomon Effect' in machine learning modeling?",
        "type": "mcq",
        "o": [
            "The existence of multiple different models that yield similar accuracy but rely on completely different feature sets/explanations",
            "The tendency of a model to hallucinate facts",
            "The increase in error rate as data size increases",
            "The inability of a model to learn non-linear patterns"
        ]
    },
    {
        "q": "Rearrange the words to identify the ISO standard for Artificial Intelligence Management Systems:",
        "type": "rearrange",
        "words": [
            "ISO/IEC",
            "42001",
            "Standard"
        ]
    },
    {
        "q": "What ethical issue arises from using 'Intersectionality' in fairness analysis?",
        "type": "mcq",
        "c": "# Analyzing subgroups: Black Women vs White Men vs Black Men\n# Small sample sizes in intersections lead to high variance.",
        "o": [
            "Subgroups become too small to draw statistically significant conclusions (Data Sparsity)",
            "It is illegal to combine demographic features",
            "It reduces the computational complexity too much",
            "It guarantees 100% fairness automatically"
        ]
    },
    {
        "q": "Removing metadata (like EXIF data) from images is sufficient to prevent re-identification if the image content itself depicts a unique location.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which cryptographic function should be used to verify data integrity and authenticity using a secret key?",
        "type": "mcq",
        "c": "import hmac\nimport hashlib\n# Verifying that the message came from someone with the key",
        "o": [
            "HMAC (Hash-Based Message Authentication Code)",
            "MD5 (Message Digest 5)",
            "CRC32 (Cyclic Redundancy Check)",
            "Base64 Encoding"
        ]
    },
    {
        "q": "The practice of '______' involves releasing a model that performs well on public benchmarks (like ImageNet) but fails in real-world scenarios due to overfitting to the test set.",
        "type": "fill_blank",
        "answers": [
            "Gaming"
        ],
        "other_options": [
            "Training",
            "Pruning",
            "Boosting"
        ]
    },
    {
        "q": "What does the 'L' stand for in the privacy model 'L-Diversity'?",
        "type": "mcq",
        "o": [
            "The number of well-represented sensitive values within each equivalence class",
            "The length of the encryption key",
            "The latency of the query response",
            "The level of user consent"
        ]
    },
    {
        "q": "Identify the risk in this API design regarding data exposure:",
        "type": "mcq",
        "c": "@app.route('/get_user/<id>')\ndef get_user(id):\n    user = db.find(id)\n    # Returns the full user object including internal fields\n    return jsonify(user)",
        "o": [
            "Excessive Data Exposure / Mass Assignment",
            "Broken Access Control",
            "Injection Flaw",
            "Insecure Design"
        ]
    },
    {
        "q": "Match the AI Safety term to its description:",
        "type": "match",
        "left": [
            "Robustness",
            "Alignment",
            "Monitoring"
        ],
        "right": [
            "Ability to maintain performance under stress or attack",
            "Ensuring model objectives match human intent",
            "Continuous tracking of model performance in production"
        ]
    },
    {
        "q": "Deepfakes that are used to non-consensually depict individuals in compromising scenarios are often prosecuted under laws regarding 'Right of ______'.",
        "type": "fill_blank",
        "answers": [
            "Publicity"
        ],
        "other_options": [
            "Way",
            "Access",
            "Speech"
        ]
    },
    {
        "q": "What is the ethical implication of 'Clever Hans' in Machine Learning?",
        "type": "mcq",
        "o": [
            "A model appearing smart by learning spurious correlations (e.g., detecting a ruler in the image instead of the tumor)",
            "A model that can speak German",
            "A model that passes the Turing test",
            "A reinforcement learning agent that cheats"
        ]
    },
    {
        "q": "What specific security vulnerability is demonstrated in this XML parsing code (often called the 'Billion Laughs' attack)?",
        "type": "mcq",
        "c": "import xml.etree.ElementTree as ET\n# XML with nested entities that expand exponentially\ndata = \"\"\"<!DOCTYPE bomb [\n<!ENTITY a \"xxxxxxxxx...\">\n]>\n<bomb>&a;</bomb>\"\"\"\ntree = ET.fromstring(data)",
        "o": [
            "Denial of Service (DoS) via resource exhaustion",
            "SQL Injection",
            "Cross-Site Scripting (XSS)",
            "Man-in-the-Middle Attack"
        ]
    },
    {
        "q": "The practice of creating a superficial appearance of following ethical guidelines (e.g., setting up an ethics board with no veto power) to avoid regulation is known as 'Ethics ______'.",
        "type": "fill_blank",
        "answers": [
            "Washing"
        ],
        "other_options": [
            "Scrubbing",
            "Cleaning",
            "Mining"
        ]
    },
    {
        "q": "Match the Data Governance role with its primary responsibility:",
        "type": "match",
        "left": [
            "Data Owner",
            "Data Steward",
            "Data Custodian"
        ],
        "right": [
            "Accountable for the data's classification and access rights (Business side)",
            "Responsible for data quality, metadata, and adherence to policies",
            "Responsible for the technical storage, safe transport, and infrastructure (IT side)"
        ]
    },
    {
        "q": "Which metric, originally used in economics to measure wealth inequality, is adapted in AI to measure the inequality of benefit distribution across a population?",
        "type": "mcq",
        "o": [
            "Theil Index",
            "Gini Coefficient",
            "F1 Score",
            "ROC-AUC"
        ]
    },
    {
        "q": "Adversarial Training (training a model on adversarial examples) typically increases the model's robustness but often slightly decreases its accuracy on clean, standard data.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the words to describe the EU's requirement for AI oversight:",
        "type": "rearrange",
        "words": [
            "Human",
            "in",
            "command",
            "approach"
        ]
    },
    {
        "q": "What vulnerability is present in this file access code?",
        "type": "mcq",
        "c": "filename = user_input # e.g., \"../../etc/passwd\"\nwith open(f\"/var/www/uploads/{filename}\", 'r') as f:\n    print(f.read())",
        "o": [
            "Path Traversal (Directory Traversal)",
            "Buffer Overflow",
            "Race Condition",
            "Insecure Deserialization"
        ]
    },
    {
        "q": "Match the Explainable AI (XAI) plot type to its description:",
        "type": "match",
        "left": [
            "ICE Plot (Individual Conditional Expectation)",
            "PDP (Partial Dependence Plot)",
            "ALE (Accumulated Local Effects)"
        ],
        "right": [
            "Shows how a prediction changes for ONE specific instance as a feature varies",
            "Shows the average effect of a feature on the prediction across the WHOLE dataset",
            "A faster alternative to PDP that handles correlated features better"
        ]
    },
    {
        "q": "Under the EU AI Act, AI systems intended to interact with natural persons (like Chatbots) must meet which specific transparency obligation?",
        "type": "mcq",
        "o": [
            "They must inform the user that they are interacting with an AI system",
            "They must reveal their source code",
            "They must pay the user for the data",
            "They must be hosted in Europe"
        ]
    },
    {
        "q": "In Differential Privacy, the '______' of a function determines how much the output can change if a single record in the database is changed.",
        "type": "fill_blank",
        "answers": [
            "Sensitivity"
        ],
        "other_options": [
            "Accuracy",
            "Latency",
            "Diversity"
        ]
    },
    {
        "q": "Data that is legally released as 'Public Open Data' (e.g., voter records) is exempt from all ethical considerations regarding privacy and misuse.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the difference between 'Automation Bias' and 'Automation Complacency'?",
        "type": "mcq",
        "o": [
            "Bias is actively following incorrect advice; Complacency is passively missing errors due to lack of attention",
            "Bias is missing errors; Complacency is following advice",
            "They are synonyms",
            "Bias applies to training; Complacency applies to testing"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Safe Harbor' provision (historical):",
        "type": "rearrange",
        "words": [
            "Framework",
            "for",
            "transatlantic",
            "data",
            "flows"
        ]
    },
    {
        "q": "What ethical problem is known as the 'Surrogate Problem'?",
        "type": "mcq",
        "o": [
            "Optimizing for a measurable proxy (e.g., 'clicks') that does not actually align with the complex real-world goal (e.g., 'user well-being')",
            "Using a surrogate model for explainability",
            "Using synthetic data instead of real data",
            "Replacing a human worker with a robot"
        ]
    },
    {
        "q": "Which Python library helps prevent 'Pickle' insecurity by safely serializing/deserializing JSON data instead?",
        "type": "mcq",
        "o": [
            "json",
            "os",
            "sys",
            "ctypes"
        ]
    },
    {
        "q": "Which federal agency in the United States has the primary authority to penalize companies for 'unfair or deceptive acts' regarding data privacy policies?",
        "type": "mcq",
        "o": [
            "FTC (Federal Trade Commission)",
            "FDA (Food and Drug Administration)",
            "SEC (Securities and Exchange Commission)",
            "NSA (National Security Agency)"
        ]
    },
    {
        "q": "What specific type of bias is introduced when a model is trained on data where the labels were generated by an older, biased model (creating a feedback loop)?",
        "type": "mcq",
        "c": "# Training Model B on the output of biased Model A\n# instead of ground truth.",
        "o": [
            "Latent Bias / Automation Bias",
            "Selection Bias",
            "Measurement Bias",
            "Recall Bias"
        ]
    },
    {
        "q": "The '______' Protocol is a standard for websites to state their privacy preferences to browsers, though it is largely defunct and replaced by newer signals like GPC (Global Privacy Control).",
        "type": "fill_blank",
        "answers": [
            "P3P"
        ],
        "other_options": [
            "HTTP",
            "SSL",
            "TCP"
        ]
    },
    {
        "q": "Match the adversarial attack type to the target component:",
        "type": "match",
        "left": [
            "Model Extraction",
            "Inversion Attack",
            "Poisoning"
        ],
        "right": [
            "Stealing the model parameters/architecture",
            "Reconstructing private training data features",
            "Corrupting the training dataset integrity"
        ]
    },
    {
        "q": "What is the primary ethical concern with 'Emotion AI' or Affective Computing?",
        "type": "mcq",
        "o": [
            "It relies on pseudoscience claiming internal emotional states can be accurately inferred from facial expressions across all cultures",
            "It requires too much processing power",
            "It is too expensive to implement",
            "It only works on video, not audio"
        ]
    },
    {
        "q": "Rearrange the words to identify the principle that data should be accurate and kept up to date:",
        "type": "rearrange",
        "words": [
            "Data",
            "Accuracy",
            "Principle"
        ]
    },
    {
        "q": "A 'Data Trust' is a legal structure where data stewardship is delegated to an independent board of trustees who manage the data for the benefit of a group of beneficiaries.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the vulnerability in this API key handling?",
        "type": "mcq",
        "c": "def get_weather():\n    # API Key committed to git history\n    api_key = \"12345-ABCDE-SECRET\"\n    return requests.get(f\"api.weather.com?key={api_key}\")",
        "o": [
            "Hardcoded Secrets",
            "Insecure Transport",
            "Broken Authentication",
            "Server Side Request Forgery"
        ]
    },
    {
        "q": "Which fairness metric focuses on the ratio of False Positives between groups?",
        "type": "mcq",
        "o": [
            "Predictive Equality",
            "Demographic Parity",
            "Equal Opportunity",
            "Calibration"
        ]
    },
    {
        "q": "______ involves giving users a slider or toggle to control the 'granularity' of their data sharing (e.g., precise location vs. city-level location).",
        "type": "fill_blank",
        "answers": [
            "Obfuscation"
        ],
        "other_options": [
            "Encryption",
            "Deletion",
            "Compression"
        ]
    },
    {
        "q": "What is the purpose of a 'Canary Trap' in data security?",
        "type": "mcq",
        "o": [
            "Distributing slightly different versions of a sensitive document to detect who leaks it",
            "Detecting poisonous gases in server rooms",
            "Testing if a model is live",
            "Trapping malware in a sandbox"
        ]
    },
    {
        "q": "Which license requires that if you distribute your software, you must also make the source code available to the recipient?",
        "type": "mcq",
        "o": [
            "Copyleft (e.g., GPL)",
            "Permissive (e.g., MIT)",
            "Public Domain",
            "Commercial"
        ]
    },
    {
        "q": "What does the code below imply about the 'opt-out' mechanism?",
        "type": "mcq",
        "c": "def unsubscribe(user_email):\n    # Marking as 'inactive' but keeping the data\n    db.users.update_one({'email': user_email}, {'$set': {'status': 'inactive'}})\n    # No deletion occurs",
        "o": [
            "It violates the 'Right to Erasure' if the user requested total deletion",
            "It is a perfect implementation of GDPR",
            "It saves database space",
            "It encrypts the email"
        ]
    },
    {
        "q": "Match the privacy concept to the scenario:",
        "type": "match",
        "left": [
            "Data Minimization",
            "Purpose Limitation",
            "Storage Limitation"
        ],
        "right": [
            "Collecting only DoB instead of full birth date + time",
            "Using collected emails ONLY for shipping, not ads",
            "Deleting user logs after 30 days automatically"
        ]
    },
    {
        "q": "In the context of generative AI, 'Model ______' refers to the ability of a model to memorize and regurgitate exact training examples (like PII or copyrighted text).",
        "type": "fill_blank",
        "answers": [
            "Memorization"
        ],
        "other_options": [
            "Learning",
            "Training",
            "Recall"
        ]
    },
    {
        "q": "Which statistical paradox occurs when a model suggests that patients with asthma have a lower risk of dying from pneumonia, simply because those patients are hospitalized sooner and receive more aggressive care?",
        "type": "mcq",
        "o": [
            "The Caruana Paradox (Rule-Based Paradox)",
            "Simpson's Paradox",
            "The Accuracy Paradox",
            "The Observer Effect"
        ]
    },
    {
        "q": "What is the primary privacy danger of 'Linkage Attacks' when releasing an anonymized dataset?",
        "type": "mcq",
        "c": "# Dataset A: Anonymized Health Records (DOB, Zip, Sex, Diagnosis)\n# Dataset B: Public Voter List (Name, DOB, Zip, Sex)\n# Attacker joins A and B on (DOB, Zip, Sex).",
        "o": [
            "Re-identification of individuals by matching quasi-identifiers",
            "Corruption of the diagnosis column",
            "Encryption key leakage",
            "Database deadlock"
        ]
    },
    {
        "q": "The 'Right to ______' allows a data subject to move their personal data from one service provider to another in a structured format.",
        "type": "fill_blank",
        "answers": [
            "Portability"
        ],
        "other_options": [
            "Access",
            "Erasure",
            "Rectification"
        ]
    },
    {
        "q": "Match the threat model to the attacker's knowledge:",
        "type": "match",
        "left": [
            "White-Box Attack",
            "Black-Box Attack",
            "Gray-Box Attack"
        ],
        "right": [
            "Attacker has full access to the model architecture and weights",
            "Attacker only has access to the model's inputs and outputs (API)",
            "Attacker has partial knowledge (e.g., architecture but not weights)"
        ]
    },
    {
        "q": "Which ethical principle is violated if an AI system is deployed in a high-stakes environment (like healthcare) without ever validating its error rate on real-world data?",
        "type": "mcq",
        "o": [
            "Non-maleficence (Do no harm)",
            "Data Minimization",
            "Purpose Limitation",
            "Open Source"
        ]
    },
    {
        "q": "Rearrange the words to identify the risk of AI generating convincing fake media:",
        "type": "rearrange",
        "words": [
            "Deepfakes",
            "threaten",
            "information",
            "integrity"
        ]
    },
    {
        "q": "If a model's 'Recall' for the minority class is 0.1 (10%), what does this practically mean for that group?",
        "type": "mcq",
        "c": "recall = true_positives / (true_positives + false_negatives)\n# Result: 0.1",
        "o": [
            "The model is failing to identify 90% of the qualified candidates in that group",
            "The model is incorrectly accepting 90% of unqualified candidates",
            "The model is 90% accurate",
            "The model is unbiased"
        ]
    },
    {
        "q": "A 'Model Card' is a document that strictly tracks the financial cost of training a model.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "What is the vulnerability in this Python code that uses `input()` to accept a file path?",
        "type": "mcq",
        "c": "fname = input(\"Enter file to read: \")\n# User enters: /etc/shadow\nwith open(fname) as f: print(f.read())",
        "o": [
            "Insecure Direct Object Reference (IDOR) / Path Traversal",
            "SQL Injection",
            "Cross-Site Scripting",
            "Buffer Overflow"
        ]
    },
    {
        "q": "______ Fairness checks if the predictive performance (like accuracy or error rate) is equal across different protected groups.",
        "type": "fill_blank",
        "answers": [
            "Group"
        ],
        "other_options": [
            "Individual",
            "Counterfactual",
            "Casual"
        ]
    },
    {
        "q": "Which term describes the practice of designing a user interface to manipulate users into taking an action they might not otherwise take (e.g., agreeing to tracking)?",
        "type": "mcq",
        "o": [
            "Dark Patterns",
            "User Centric Design",
            "A/B Testing",
            "Feature Engineering"
        ]
    },
    {
        "q": "What specific type of Differential Privacy noise mechanism is used for real-valued (numeric) data queries?",
        "type": "mcq",
        "o": [
            "Laplace Mechanism",
            "Exponential Mechanism",
            "Randomized Response",
            "Hashing"
        ]
    },
    {
        "q": "Match the bias to the example:",
        "type": "match",
        "left": [
            "Historical Bias",
            "Representation Bias",
            "Aggregation Bias"
        ],
        "right": [
            "A hiring algorithm penalizing women because past hiring managers did",
            "ImageNet containing mostly Western images",
            "Using a one-size-fits-all model for diverse populations (e.g., treating all Asians as one group)"
        ]
    },
    {
        "q": "Is this SQL query secure against injection?",
        "type": "mcq",
        "c": "cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))",
        "o": [
            "Yes, it uses parameterized queries",
            "No, it uses string concatenation",
            "No, because it selects *",
            "Yes, because python is secure by default"
        ]
    },
    {
        "q": "The '______' is the entity that determines the 'purposes and means' of the processing of personal data under GDPR.",
        "type": "fill_blank",
        "answers": [
            "Controller"
        ],
        "other_options": [
            "Processor",
            "Subject",
            "Authority"
        ]
    },
    {
        "q": "What is the specific risk of 'Algorithmic Monoculture', where many different institutions (e.g., all major banks) rely on the same third-party AI model for decision-making?",
        "type": "mcq",
        "o": [
            "Systemic Risk (Simultaneous failure across the entire sector)",
            "Increased individual model variance",
            "Decreased model accuracy",
            "Higher computational costs"
        ]
    },
    {
        "q": "What ethical issue is demonstrated in this code regarding 'Target Leakage'?",
        "type": "mcq",
        "c": "# Predicting if a customer will churn\n# 'customer_service_calls_post_cancellation' is included in features\nX = df[['age', 'income', 'customer_service_calls_post_cancellation']]\ny = df['churn']",
        "o": [
            "The feature includes information that happens *after* the target event, artificially inflating accuracy",
            "The feature is not numeric",
            "The model will underfit",
            "There is no issue"
        ]
    },
    {
        "q": "The concept of '______' refers to the tendency of users to attribute human-like traits, intent, or emotions to AI systems (e.g., 'The AI wants to help me').",
        "type": "fill_blank",
        "answers": [
            "Anthropomorphism"
        ],
        "other_options": [
            "Automation",
            "Simulation",
            "Personification"
        ]
    },
    {
        "q": "Match the term to the specific type of data:",
        "type": "match",
        "left": [
            "Inferred Data",
            "Observed Data",
            "Volunteered Data"
        ],
        "right": [
            "Conclusions drawn by the system (e.g., Credit Score, Political leaning)",
            "Data captured automatically (e.g., GPS history, Mouse clicks)",
            "Data explicitly given by the user (e.g., Profile Name, Form inputs)"
        ]
    },
    {
        "q": "Which fairness metric is most appropriate when the cost of a False Positive (accusing an innocent person) is very high, such as in criminal justice sentencing?",
        "type": "mcq",
        "o": [
            "Predictive Parity (Precision)",
            "Recall",
            "F1 Score",
            "Accuracy"
        ]
    },
    {
        "q": "Rearrange the words to define the 'Transparency Paradox':",
        "type": "rearrange",
        "words": [
            "Too",
            "much",
            "detail",
            "can",
            "obscure",
            "understanding"
        ]
    },
    {
        "q": "Under the CPRA (California Privacy Rights Act), consumers have the specific right to limit the use and disclosure of '______ Personal Information' (SPI).",
        "type": "fill_blank",
        "answers": [
            "Sensitive"
        ],
        "other_options": [
            "Secure",
            "Shared",
            "Standard"
        ]
    },
    {
        "q": "What is the primary danger of using a 'Blacklist' approach (blocking known bad inputs) for sanitizing user input in a chatbot?",
        "type": "mcq",
        "c": "bad_words = ['exec', 'system', 'rm']\nif user_input not in bad_words:\n    run(user_input)",
        "o": [
            "It is impossible to list every possible malicious input; attackers will find a bypass",
            "It is too slow to check",
            "It blocks valid users",
            "It requires a database connection"
        ]
    },
    {
        "q": "The 'Brussels Effect' refers to the phenomenon where EU regulations (like GDPR) end up becoming global standards because multinational companies standardize their operations worldwide.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which adversarial attack involves placing a physical sticker (with a specific pattern) on an object to fool a computer vision system (e.g., making a toaster look like a banana)?",
        "type": "mcq",
        "o": [
            "Adversarial Patch",
            "Pixel Noise Attack",
            "Gradient Descent",
            "Man-in-the-middle"
        ]
    },
    {
        "q": "Match the audit type to its description:",
        "type": "match",
        "left": [
            "Socio-technical Audit",
            "Code Audit",
            "Impact Assessment"
        ],
        "right": [
            "Examining how the system interacts with social structures and human stakeholders",
            "Reviewing the source code for bugs and security flaws",
            "Evaluating potential future risks before deployment"
        ]
    },
    {
        "q": "What data ethics principle is violated in this code snippet regarding data retention?",
        "type": "mcq",
        "c": "def delete_account(user_id):\n    # Just toggling a flag, data remains forever\n    user.is_deleted = True\n    user.save()",
        "o": [
            "Storage Limitation / Right to Erasure",
            "Data Portability",
            "Accuracy",
            "Integrity"
        ]
    },
    {
        "q": "The '______' Machine is a platform developed by MIT to gather human perspectives on moral decisions made by machine intelligence, such as self-driving cars.",
        "type": "fill_blank",
        "answers": [
            "Moral"
        ],
        "other_options": [
            "Ethical",
            "Turing",
            "Thinking"
        ]
    },
    {
        "q": "Which statistical measure represents the agreement between two raters (annotators) labeling data, often used to check if the 'Ground Truth' is actually reliable?",
        "type": "mcq",
        "o": [
            "Cohen's Kappa",
            "R-Squared",
            "P-Value",
            "Standard Deviation"
        ]
    },
    {
        "q": "What is the security risk of 'Model Stealing' via API?",
        "type": "mcq",
        "o": [
            "An attacker queries the API repeatedly to train a surrogate model that mimics the proprietary model without paying for it",
            "An attacker deletes the model from the server",
            "An attacker changes the weights of the model",
            "An attacker steals the physical server"
        ]
    }
]