{
    "id": "learn_data_lifecycle",
    "topicId": "data_lifecycle",
    "topicTitle": "Data Science Lifecycle",
    "description": "Master the complete data science lifecycle from data collection through deployment and monitoring",
    "baseKP": 80,
    "slides": [
        {
            "id": "data_lifecycle_1",
            "type": "content",
            "title": "Welcome to the Data Science Lifecycle",
            "content": "# Data Science Lifecycle ğŸ”„\n\nEvery successful data science project follows a structured lifecycle. Understanding this lifecycle is crucial for delivering impactful solutions.\n\n## What You'll Learn:\n- **Data Collection** - Gathering raw data from various sources\n- **Data Preparation** - Cleaning and transforming data\n- **Exploratory Analysis** - Understanding patterns and relationships\n- **Model Building** - Creating predictive solutions\n- **Deployment** - Putting models into production\n- **Monitoring** - Maintaining model performance\n\n> ğŸ’¡ **Key Insight:** The lifecycle is iterative, not linear. You'll often revisit earlier stages as you learn more!\n\n## Why This Matters\n\n| Statistic | Impact |\n|-----------|--------|\n| 80% of time | Spent on data preparation |\n| 70% of projects | Fail due to poor data quality |\n| 87% of models | Never make it to production |\n\nLet's master each stage to beat these odds!"
        },
        {
            "id": "data_lifecycle_2",
            "type": "content",
            "title": "Stage 1: Data Collection",
            "content": "# Data Collection ğŸ“¥\n\nThe foundation of any data science project begins with gathering quality data.\n\n## Data Sources\n\n### Internal Sources\n- ğŸ—„ï¸ **Databases** - SQL, NoSQL databases\n- ğŸ“Š **Data Warehouses** - Centralized storage\n- ğŸ“ **Files** - CSV, Excel, JSON, Parquet\n- ğŸ“ **Logs** - Application and server logs\n\n### External Sources\n- ğŸŒ **APIs** - Web services, REST endpoints\n- ğŸ•·ï¸ **Web Scraping** - Extracting web data\n- ğŸ“¦ **Open Datasets** - Kaggle, government data\n- ğŸ¤ **Third-party** - Vendors, partners\n\n## Data Collection Best Practices\n\n| Practice | Benefit |\n|----------|--------|\n| Document sources | Traceability |\n| Validate on ingestion | Early error detection |\n| Store metadata | Context preservation |\n| Version your data | Reproducibility |\n\n## Common Challenges\n\n- âŒ Missing or incomplete data\n- âŒ Inconsistent formats\n- âŒ Access and permission issues\n- âŒ Real-time vs batch requirements\n\n> âš ï¸ **Warning:** Poor data collection leads to \"Garbage In, Garbage Out\"!"
        },
        {
            "id": "data_lifecycle_3",
            "type": "content",
            "title": "Stage 2: Data Preparation",
            "content": "# Data Preparation ğŸ§¹\n\nData preparation is the most time-consuming but critical stageâ€”typically 60-80% of the project!\n\n## Key Activities\n\n### 1. Data Cleaning\n- Handle missing values\n- Remove duplicates\n- Fix inconsistencies\n- Correct errors\n\n### 2. Data Transformation\n- Normalize/standardize features\n- Encode categorical variables\n- Create derived features\n- Aggregate data\n\n### 3. Data Integration\n- Merge multiple sources\n- Resolve conflicts\n- Align schemas\n\n## Example: Handling Missing Values\n\n```python\nimport numpy as np\n\n# Sample data with missing values\ndata = [10, 20, np.nan, 40, 50, np.nan, 70]\n\n# Calculate mean excluding NaN\nclean_data = [x for x in data if not np.isnan(x)]\nmean_value = sum(clean_data) / len(clean_data)\n\nprint(f\"Mean value: {mean_value}\")\nprint(f\"Clean data: {clean_data}\")\n```\n\n<!-- FULL_CODE_START\nimport numpy as np\n\n# Sample data with missing values\ndata = [10, 20, np.nan, 40, 50, np.nan, 70]\n\n# Calculate mean excluding NaN\nclean_data = [x for x in data if not np.isnan(x)]\nmean_value = sum(clean_data) / len(clean_data)\n\nprint(f\"Original data: {data}\")\nprint(f\"Mean value: {mean_value}\")\nprint(f\"Clean data: {clean_data}\")\n\n# Fill missing with mean\nfilled_data = [x if not np.isnan(x) else mean_value for x in data]\nprint(f\"Filled data: {filled_data}\")\nFULL_CODE_END -->\n\n> ğŸ’¡ **Pro Tip:** Automate data cleaning pipelines to ensure consistency!"
        },
        {
            "id": "data_lifecycle_quiz_1",
            "type": "quiz",
            "title": "Data Preparation Check",
            "content": "Test your understanding of data preparation!",
            "quizQuestion": "What percentage of a data science project is typically spent on data preparation?",
            "quizOptions": [
                "10-20%",
                "30-40%",
                "60-80%",
                "90-100%"
            ],
            "correctOptionIndex": 2
        },
        {
            "id": "data_lifecycle_4",
            "type": "content",
            "title": "Stage 3: Exploratory Data Analysis",
            "content": "# Exploratory Data Analysis (EDA) ğŸ”\n\nEDA helps you understand your data before building models.\n\n## Goals of EDA\n\n- ğŸ“Š Understand data distributions\n- ğŸ”— Discover relationships between variables\n- ğŸš¨ Identify outliers and anomalies\n- ğŸ’¡ Generate hypotheses for modeling\n\n## Key Techniques\n\n### Summary Statistics\n- Mean, median, mode\n- Standard deviation, variance\n- Min, max, range\n- Percentiles and quartiles\n\n### Visualization Types\n\n| Chart Type | Use Case |\n|------------|----------|\n| Histograms | Distribution of single variable |\n| Box Plots | Outliers and quartiles |\n| Scatter Plots | Relationships between variables |\n| Heatmaps | Correlation matrices |\n| Bar Charts | Categorical comparisons |\n\n## Example: Basic Statistics with NumPy\n\n```python\nimport numpy as np\n\ndata = [23, 45, 67, 89, 12, 34, 56, 78, 90, 21]\n\nprint(f\"Mean: {np.mean(data):.2f}\")\nprint(f\"Median: {np.median(data):.2f}\")\nprint(f\"Std Dev: {np.std(data):.2f}\")\nprint(f\"Min: {np.min(data)}, Max: {np.max(data)}\")\n```\n\n<!-- FULL_CODE_START\nimport numpy as np\n\n# Sample dataset\ndata = [23, 45, 67, 89, 12, 34, 56, 78, 90, 21]\n\nprint(\"=== Exploratory Data Analysis ===\")\nprint(f\"\\nDataset: {data}\")\nprint(f\"\\nNumber of observations: {len(data)}\")\nprint(f\"\\nMean: {np.mean(data):.2f}\")\nprint(f\"Median: {np.median(data):.2f}\")\nprint(f\"Standard Deviation: {np.std(data):.2f}\")\nprint(f\"Variance: {np.var(data):.2f}\")\nprint(f\"Min: {np.min(data)}\")\nprint(f\"Max: {np.max(data)}\")\nprint(f\"Range: {np.max(data) - np.min(data)}\")\nprint(f\"\\n25th percentile: {np.percentile(data, 25):.2f}\")\nprint(f\"75th percentile: {np.percentile(data, 75):.2f}\")\nFULL_CODE_END -->\n\n> ğŸ¯ **Remember:** EDA is about asking questions and letting the data answer them!"
        },
        {
            "id": "data_lifecycle_5",
            "type": "content",
            "title": "EDA Best Practices",
            "content": "# EDA Best Practices ğŸ“‹\n\nFollow these guidelines for effective exploratory analysis.\n\n## The EDA Checklist\n\n### 1. Start with the Basics\n- âœ… Check data shape (rows, columns)\n- âœ… Examine data types\n- âœ… Look for missing values\n- âœ… Identify duplicates\n\n### 2. Univariate Analysis\n- âœ… Analyze each variable separately\n- âœ… Check distributions\n- âœ… Identify outliers\n- âœ… Understand value ranges\n\n### 3. Bivariate Analysis\n- âœ… Explore relationships between pairs\n- âœ… Calculate correlations\n- âœ… Create scatter plots\n- âœ… Compare groups\n\n### 4. Multivariate Analysis\n- âœ… Look at interactions\n- âœ… Create correlation heatmaps\n- âœ… Use dimensionality reduction\n\n## Questions to Ask During EDA\n\n| Category | Questions |\n|----------|----------|\n| Quality | Are there missing values? Outliers? |\n| Distribution | Is data normally distributed? Skewed? |\n| Relationships | Which variables are correlated? |\n| Patterns | Are there trends or seasonality? |\n\n> ğŸ’¡ **Pro Tip:** Document your findings! EDA insights guide the entire modeling process."
        },
        {
            "id": "data_lifecycle_quiz_2",
            "type": "quiz",
            "title": "EDA Quiz",
            "content": "Test your EDA knowledge!",
            "quizQuestion": "Which chart type is BEST for identifying outliers in a dataset?",
            "quizOptions": [
                "Pie Chart",
                "Box Plot",
                "Line Chart",
                "Area Chart"
            ],
            "correctOptionIndex": 1
        },
        {
            "id": "data_lifecycle_6",
            "type": "content",
            "title": "Stage 4: Model Building",
            "content": "# Model Building ğŸ¤–\n\nThis is where data science gets excitingâ€”creating predictive models!\n\n## The Modeling Process\n\n### 1. Problem Definition\n- Classification vs Regression vs Clustering\n- Define success metrics\n- Set baseline performance\n\n### 2. Feature Engineering\n- Create new features\n- Select important features\n- Handle categorical variables\n\n### 3. Model Selection\n\n| Problem Type | Common Algorithms |\n|--------------|------------------|\n| Classification | Logistic Regression, Random Forest, XGBoost |\n| Regression | Linear Regression, Decision Trees, Neural Networks |\n| Clustering | K-Means, DBSCAN, Hierarchical |\n\n### 4. Training & Validation\n- Split data (train/validation/test)\n- Train multiple models\n- Cross-validation\n- Hyperparameter tuning\n\n### 5. Evaluation\n\n| Metric | Use Case |\n|--------|----------|\n| Accuracy | Balanced classification |\n| Precision/Recall | Imbalanced classes |\n| RMSE | Regression |\n| AUC-ROC | Binary classification |\n\n> âš ï¸ **Warning:** Don't just pick the model with highest accuracyâ€”consider interpretability, training time, and deployment complexity!"
        },
        {
            "id": "data_lifecycle_7",
            "type": "content",
            "title": "Stage 5: Deployment",
            "content": "# Model Deployment ğŸš€\n\nA model has no value until it's in production serving real users!\n\n## Deployment Options\n\n### Batch Prediction\n- Run predictions on schedule\n- Process large datasets offline\n- Store results in database\n- **Use case:** Daily sales forecasts\n\n### Real-time Prediction\n- Serve predictions via API\n- Low-latency requirements\n- **Use case:** Fraud detection\n\n### Edge Deployment\n- Run on device (mobile, IoT)\n- Offline capable\n- **Use case:** Image recognition apps\n\n## Deployment Checklist\n\n- âœ… Model serialization (save the trained model)\n- âœ… API development (REST endpoints)\n- âœ… Containerization (Docker)\n- âœ… Infrastructure (cloud or on-premise)\n- âœ… CI/CD pipeline\n- âœ… Documentation\n\n## Common Deployment Patterns\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Request   â”‚ --> â”‚   API       â”‚ --> â”‚   Model     â”‚\nâ”‚   (Input)   â”‚     â”‚   Gateway   â”‚     â”‚   Server    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                              â”‚\n                                              v\n                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                                        â”‚  Response   â”‚\n                                        â”‚ (Prediction)â”‚\n                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n> ğŸ’¡ **Fact:** 87% of machine learning projects never make it to production. Proper deployment practices are key to success!"
        },
        {
            "id": "data_lifecycle_8",
            "type": "content",
            "title": "Stage 6: Monitoring",
            "content": "# Model Monitoring ğŸ“Š\n\nDeployment is just the beginningâ€”continuous monitoring ensures long-term success.\n\n## Why Monitoring Matters\n\nModels degrade over time due to:\n- ğŸ“‰ **Data Drift** - Input data distributions change\n- ğŸ¯ **Concept Drift** - Relationships between features and target change\n- ğŸ› **Model Decay** - Accuracy decreases over time\n\n## What to Monitor\n\n### 1. Model Performance\n- Prediction accuracy/error rates\n- Response times/latency\n- Throughput (predictions/second)\n\n### 2. Data Quality\n- Missing values rate\n- Feature distributions\n- Outlier frequency\n\n### 3. System Health\n- CPU/Memory usage\n- API availability\n- Error rates\n\n## Monitoring Dashboard Example\n\n| Metric | Threshold | Alert |\n|--------|-----------|-------|\n| Accuracy | < 90% | Warning |\n| Latency | > 100ms | Critical |\n| Error Rate | > 1% | Critical |\n| Data Drift Score | > 0.3 | Warning |\n\n## Retraining Triggers\n\n- âš ï¸ Performance drops below threshold\n- âš ï¸ Significant data drift detected\n- âš ï¸ New data available\n- âš ï¸ Business rules change\n\n> ğŸ¯ **Best Practice:** Set up automated alerts and retraining pipelines!"
        },
        {
            "id": "data_lifecycle_quiz_3",
            "type": "quiz",
            "title": "Monitoring Quiz",
            "content": "Test your understanding of model monitoring!",
            "quizQuestion": "What is 'Data Drift' in the context of model monitoring?",
            "quizOptions": [
                "When the model moves to a different server",
                "When input data distributions change over time",
                "When the model forgets its training",
                "When the database runs out of space"
            ],
            "correctOptionIndex": 1
        },
        {
            "id": "data_lifecycle_9",
            "type": "content",
            "title": "MLOps: Operationalizing ML",
            "content": "# MLOps: Operationalizing Machine Learning âš™ï¸\n\nMLOps brings DevOps practices to machine learning for reliable, scalable ML systems.\n\n## Core MLOps Principles\n\n### 1. Version Control Everything\n- Code (Git)\n- Data (DVC, Delta Lake)\n- Models (MLflow, Weights & Biases)\n- Experiments (tracking tools)\n\n### 2. Automate Pipelines\n- Data ingestion\n- Feature engineering\n- Model training\n- Deployment\n- Monitoring\n\n### 3. Reproducibility\n- Environment management (Docker)\n- Dependency tracking\n- Random seed control\n- Configuration management\n\n## MLOps Maturity Levels\n\n| Level | Description | Automation |\n|-------|-------------|------------|\n| 0 | Manual, script-based | None |\n| 1 | ML pipeline automation | Partial |\n| 2 | CI/CD pipeline | Full |\n| 3 | Automated retraining | Self-healing |\n\n## Key MLOps Tools\n\n- **Experiment Tracking:** MLflow, Weights & Biases\n- **Pipeline Orchestration:** Airflow, Kubeflow\n- **Model Serving:** TensorFlow Serving, Seldon\n- **Monitoring:** Evidently AI, WhyLabs\n\n> ğŸš€ **Goal:** Reduce time from experiment to production while maintaining quality!"
        },
        {
            "id": "data_lifecycle_10",
            "type": "content",
            "title": "Lifecycle in Practice",
            "content": "# Putting It All Together ğŸ”„\n\nLet's see how the lifecycle works in a real project.\n\n## Case Study: Customer Churn Prediction\n\n### Stage 1: Collection\n- Extract customer data from CRM\n- Gather transaction history\n- Pull support ticket data\n\n### Stage 2: Preparation\n- Clean missing values\n- Create features (usage patterns, tenure)\n- Encode categorical variables\n\n### Stage 3: EDA\n- Analyze churn distribution\n- Find correlations with behavior\n- Identify at-risk segments\n\n### Stage 4: Modeling\n- Train classification models\n- Evaluate with precision/recall\n- Select best performer\n\n### Stage 5: Deployment\n- Deploy as REST API\n- Integrate with CRM system\n- Set up batch scoring\n\n### Stage 6: Monitoring\n- Track prediction accuracy\n- Monitor data drift\n- Retrain quarterly\n\n## Timeline\n\n```\nWeek 1-2: Collection + Preparation\nWeek 3:   EDA + Feature Engineering  \nWeek 4:   Model Building + Evaluation\nWeek 5:   Deployment\nOngoing:  Monitoring + Maintenance\n```\n\n> ğŸ’¡ **Reality Check:** Most projects take 2-4 months from concept to production!"
        },
        {
            "id": "data_lifecycle_quiz_4",
            "type": "quiz",
            "title": "Lifecycle Order Quiz",
            "content": "Test your understanding of the lifecycle order!",
            "quizQuestion": "What is the correct order of the data science lifecycle stages?",
            "quizOptions": [
                "Modeling â†’ Collection â†’ EDA â†’ Deployment",
                "Collection â†’ EDA â†’ Preparation â†’ Modeling",
                "Collection â†’ Preparation â†’ EDA â†’ Modeling â†’ Deployment â†’ Monitoring",
                "EDA â†’ Collection â†’ Deployment â†’ Monitoring"
            ],
            "correctOptionIndex": 2
        },
        {
            "id": "data_lifecycle_11",
            "type": "content",
            "title": "Common Pitfalls",
            "content": "# Common Lifecycle Pitfalls âš ï¸\n\nAvoid these common mistakes at each stage.\n\n## Collection Pitfalls\n- âŒ Not validating data sources\n- âŒ Ignoring data privacy requirements\n- âŒ Collecting irrelevant data\n\n## Preparation Pitfalls\n- âŒ Data leakage (using future info)\n- âŒ Over-engineering features\n- âŒ Inconsistent preprocessing\n\n## EDA Pitfalls\n- âŒ Skipping EDA entirely\n- âŒ Confirmation bias\n- âŒ Ignoring outliers\n\n## Modeling Pitfalls\n- âŒ Overfitting to training data\n- âŒ Wrong evaluation metrics\n- âŒ Not establishing baselines\n\n## Deployment Pitfalls\n- âŒ Training-serving skew\n- âŒ No rollback plan\n- âŒ Missing documentation\n\n## Monitoring Pitfalls\n- âŒ No monitoring at all\n- âŒ Ignoring drift alerts\n- âŒ Manual retraining processes\n\n> ğŸ¯ **Key Lesson:** Document everything, automate where possible, and always validate your assumptions!"
        },
        {
            "id": "data_lifecycle_12",
            "type": "content",
            "title": "Summary",
            "content": "# Congratulations! ğŸ‰\n\nYou've mastered the Data Science Lifecycle!\n\n## Key Takeaways\n\n### The 6 Stages\n1. **Collection** ğŸ“¥ - Gather data from multiple sources\n2. **Preparation** ğŸ§¹ - Clean and transform (60-80% of time!)\n3. **EDA** ğŸ” - Understand patterns and relationships\n4. **Modeling** ğŸ¤– - Build and validate predictive models\n5. **Deployment** ğŸš€ - Put models into production\n6. **Monitoring** ğŸ“Š - Maintain performance over time\n\n### Critical Insights\n\n- âœ… The lifecycle is **iterative**, not linear\n- âœ… Data quality determines model quality\n- âœ… EDA insights guide modeling decisions\n- âœ… Deployment and monitoring are essential, not optional\n- âœ… MLOps practices ensure reliability\n\n### Remember\n\n| Stage | Typical Time |\n|-------|-------------|\n| Collection + Prep | 60-80% |\n| EDA + Modeling | 15-25% |\n| Deployment + Monitoring | 5-15% |\n\n> ğŸš€ **Next Steps:** Practice each stage with a real dataset from Kaggle!\n\nKeep building and deploying! ğŸ’ª"
        }
    ]
}