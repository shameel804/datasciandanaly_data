[
    {
        "q": "Which keyword declares an immutable variable?",
        "type": "mcq",
        "o": [
            "val",
            "var",
            "const",
            "let"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val x = 5\nprintln(x)",
        "o": [
            "5",
            "x",
            "Error",
            "null"
        ]
    },
    {
        "q": "Scala runs on the JVM.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ keyword declares mutable variables.",
        "type": "fill_blank",
        "answers": [
            "var"
        ],
        "other_options": [
            "val",
            "let",
            "mut"
        ]
    },
    {
        "q": "Match the Scala basics:",
        "type": "match",
        "left": [
            "val",
            "var",
            "def",
            "class"
        ],
        "right": [
            "Immutable",
            "Mutable",
            "Method",
            "Type"
        ]
    },
    {
        "q": "Which type inference feature does Scala have?",
        "type": "mcq",
        "o": [
            "Automatic type inference",
            "Explicit only",
            "No inference",
            "Optional inference"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val name = \"Scala\"\nprintln(name.length)",
        "o": [
            "5",
            "Scala",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Scala compilation:",
        "type": "rearrange",
        "words": [
            ".scala file",
            "scalac compiler",
            "bytecode",
            "JVM execution"
        ]
    },
    {
        "q": "The ______ defines code blocks.",
        "type": "fill_blank",
        "answers": [
            "{}"
        ],
        "other_options": [
            "()",
            "[]",
            "<>"
        ]
    },
    {
        "q": "Which is the Scala REPL command?",
        "type": "mcq",
        "o": [
            "scala",
            "scalac",
            "sbt",
            "mvn"
        ]
    },
    {
        "q": "Scala supports both OOP and FP.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Scala tools:",
        "type": "match",
        "left": [
            "scala",
            "scalac",
            "sbt",
            "Metals"
        ],
        "right": [
            "REPL",
            "Compiler",
            "Build tool",
            "LSP server"
        ]
    },
    {
        "q": "The ______ is Scala's build tool.",
        "type": "fill_blank",
        "answers": [
            "sbt"
        ],
        "other_options": [
            "maven",
            "gradle",
            "ant"
        ]
    },
    {
        "q": "Which method is the entry point?",
        "type": "mcq",
        "o": [
            "main",
            "start",
            "run",
            "init"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "println(1 + 2 * 3)",
        "o": [
            "7",
            "9",
            "6",
            "Error"
        ]
    },
    {
        "q": "Rearrange method definition:",
        "type": "rearrange",
        "words": [
            "def",
            "name",
            "(params)",
            ":",
            "Type",
            "=",
            "body"
        ]
    },
    {
        "q": "Match the numeric types:",
        "type": "match",
        "left": [
            "Int",
            "Long",
            "Double",
            "Float"
        ],
        "right": [
            "32-bit integer",
            "64-bit integer",
            "64-bit decimal",
            "32-bit decimal"
        ]
    },
    {
        "q": "The ______ type represents true/false.",
        "type": "fill_blank",
        "answers": [
            "Boolean"
        ],
        "other_options": [
            "Bool",
            "boolean",
            "Bit"
        ]
    },
    {
        "q": "Which type is for single characters?",
        "type": "mcq",
        "o": [
            "Char",
            "String",
            "Character",
            "Chr"
        ]
    },
    {
        "q": "String interpolation uses s prefix.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val x = 10\nprintln(s\"Value: $x\")",
        "o": [
            "Value: 10",
            "Value: $x",
            "Error",
            "Value: x"
        ]
    },
    {
        "q": "Match the string interpolators:",
        "type": "match",
        "left": [
            "s",
            "f",
            "raw",
            "custom"
        ],
        "right": [
            "Basic",
            "Formatted",
            "No escapes",
            "User defined"
        ]
    },
    {
        "q": "The ______ interpolator formats numbers.",
        "type": "fill_blank",
        "answers": [
            "f"
        ],
        "other_options": [
            "s",
            "fmt",
            "n"
        ]
    },
    {
        "q": "Which collection is immutable by default?",
        "type": "mcq",
        "o": [
            "List",
            "ArrayBuffer",
            "ListBuffer",
            "MutableList"
        ]
    },
    {
        "q": "Rearrange list creation:",
        "type": "rearrange",
        "words": [
            "val",
            "list",
            "=",
            "List",
            "(",
            "elements",
            ")"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val list = List(1, 2, 3)\nprintln(list.head)",
        "o": [
            "1",
            "List(1, 2, 3)",
            "3",
            "Error"
        ]
    },
    {
        "q": "The ______ method returns list tail.",
        "type": "fill_blank",
        "answers": [
            "tail"
        ],
        "other_options": [
            "rest",
            "end",
            "last"
        ]
    },
    {
        "q": "Match the list operations:",
        "type": "match",
        "left": [
            "head",
            "tail",
            "last",
            "init"
        ],
        "right": [
            "First element",
            "All but first",
            "Last element",
            "All but last"
        ]
    },
    {
        "q": "Which operator prepends to list?",
        "type": "mcq",
        "o": [
            "::",
            "++",
            ":+",
            "+:"
        ]
    },
    {
        "q": "Nil represents empty list.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val list = 1 :: 2 :: Nil\nprintln(list.length)",
        "o": [
            "2",
            "3",
            "1",
            "Error"
        ]
    },
    {
        "q": "Match the list methods:",
        "type": "match",
        "left": [
            "map",
            "filter",
            "fold",
            "flatMap"
        ],
        "right": [
            "Transform",
            "Select",
            "Reduce",
            "Map and flatten"
        ]
    },
    {
        "q": "The ______ transforms each element.",
        "type": "fill_blank",
        "answers": [
            "map"
        ],
        "other_options": [
            "transform",
            "apply",
            "convert"
        ]
    },
    {
        "q": "Which method filters elements?",
        "type": "mcq",
        "o": [
            "filter",
            "select",
            "where",
            "pick"
        ]
    },
    {
        "q": "Rearrange map operation:",
        "type": "rearrange",
        "words": [
            "list",
            ".",
            "map",
            "(",
            "x",
            "=>",
            "x * 2",
            ")"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val list = List(1, 2, 3)\nprintln(list.map(_ * 2))",
        "o": [
            "List(2, 4, 6)",
            "List(1, 2, 3)",
            "6",
            "Error"
        ]
    },
    {
        "q": "_ is a placeholder in lambdas.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the higher-order functions:",
        "type": "match",
        "left": [
            "reduce",
            "fold",
            "scan",
            "aggregate"
        ],
        "right": [
            "Combine elements",
            "With initial",
            "Running totals",
            "Complex reduce"
        ]
    },
    {
        "q": "The ______ method sums elements.",
        "type": "fill_blank",
        "answers": [
            "sum"
        ],
        "other_options": [
            "add",
            "total",
            "aggregate"
        ]
    },
    {
        "q": "Which method finds the maximum?",
        "type": "mcq",
        "o": [
            "max",
            "maximum",
            "highest",
            "top"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val list = List(1, 2, 3)\nprintln(list.sum)",
        "o": [
            "6",
            "List(1, 2, 3)",
            "3",
            "Error"
        ]
    },
    {
        "q": "Rearrange filter operation:",
        "type": "rearrange",
        "words": [
            "list",
            ".",
            "filter",
            "(",
            "_",
            ">",
            "0",
            ")"
        ]
    },
    {
        "q": "Match the collection types:",
        "type": "match",
        "left": [
            "List",
            "Vector",
            "Set",
            "Map"
        ],
        "right": [
            "Linked list",
            "Indexed sequence",
            "Unique elements",
            "Key-value pairs"
        ]
    },
    {
        "q": "The ______ collection has O(1) access.",
        "type": "fill_blank",
        "answers": [
            "Vector"
        ],
        "other_options": [
            "List",
            "Array",
            "Seq"
        ]
    },
    {
        "q": "Which collection stores unique elements?",
        "type": "mcq",
        "o": [
            "Set",
            "List",
            "Vector",
            "Array"
        ]
    },
    {
        "q": "Sets remove duplicates automatically.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val set = Set(1, 2, 2, 3)\nprintln(set.size)",
        "o": [
            "3",
            "4",
            "Set(1, 2, 3)",
            "Error"
        ]
    },
    {
        "q": "Match the Map operations:",
        "type": "match",
        "left": [
            "get",
            "apply",
            "keys",
            "values"
        ],
        "right": [
            "Option result",
            "Direct access",
            "All keys",
            "All values"
        ]
    },
    {
        "q": "The ______ creates a Map.",
        "type": "fill_blank",
        "answers": [
            "Map"
        ],
        "other_options": [
            "HashMap",
            "Dict",
            "Dictionary"
        ]
    },
    {
        "q": "Which syntax creates Map entries?",
        "type": "mcq",
        "o": [
            "->",
            ":",
            "=",
            "::"
        ]
    },
    {
        "q": "Rearrange Map creation:",
        "type": "rearrange",
        "words": [
            "val",
            "map",
            "=",
            "Map",
            "(",
            "\"a\" -> 1",
            ")"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val map = Map(\"a\" -> 1)\nprintln(map(\"a\"))",
        "o": [
            "1",
            "a",
            "None",
            "Error"
        ]
    },
    {
        "q": "get returns Option type.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Option types:",
        "type": "match",
        "left": [
            "Some",
            "None",
            "Option",
            "getOrElse"
        ],
        "right": [
            "Has value",
            "No value",
            "Container",
            "Default value"
        ]
    },
    {
        "q": "The ______ represents a missing value.",
        "type": "fill_blank",
        "answers": [
            "None"
        ],
        "other_options": [
            "null",
            "Nil",
            "Empty"
        ]
    },
    {
        "q": "Which method provides default?",
        "type": "mcq",
        "o": [
            "getOrElse",
            "orDefault",
            "default",
            "fallback"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val opt: Option[Int] = None\nprintln(opt.getOrElse(0))",
        "o": [
            "0",
            "None",
            "null",
            "Error"
        ]
    },
    {
        "q": "Rearrange Option handling:",
        "type": "rearrange",
        "words": [
            "option",
            ".",
            "map",
            "(",
            "transform",
            ")",
            ".",
            "getOrElse",
            "(",
            "default",
            ")"
        ]
    },
    {
        "q": "Match the control structures:",
        "type": "match",
        "left": [
            "if",
            "match",
            "for",
            "while"
        ],
        "right": [
            "Conditional",
            "Pattern match",
            "Comprehension",
            "Loop"
        ]
    },
    {
        "q": "The ______ is an expression in Scala.",
        "type": "fill_blank",
        "answers": [
            "if"
        ],
        "other_options": [
            "when",
            "case",
            "cond"
        ]
    },
    {
        "q": "Which construct replaces switch?",
        "type": "mcq",
        "o": [
            "match",
            "switch",
            "case",
            "when"
        ]
    },
    {
        "q": "if-else returns a value.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val x = if (true) 1 else 0\nprintln(x)",
        "o": [
            "1",
            "0",
            "true",
            "Error"
        ]
    },
    {
        "q": "Match the pattern matching:",
        "type": "match",
        "left": [
            "case _",
            "case x",
            "case Nil",
            "case Some(x)"
        ],
        "right": [
            "Wildcard",
            "Binding",
            "Empty list",
            "Extract value"
        ]
    },
    {
        "q": "The ______ matches anything.",
        "type": "fill_blank",
        "answers": [
            "_"
        ],
        "other_options": [
            "*",
            "?",
            "any"
        ]
    },
    {
        "q": "Which keyword adds guards?",
        "type": "mcq",
        "o": [
            "if",
            "when",
            "where",
            "guard"
        ]
    },
    {
        "q": "Rearrange match expression:",
        "type": "rearrange",
        "words": [
            "value",
            "match",
            "{",
            "case",
            "pattern",
            "=>",
            "result",
            "}"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val x = 1 match {\n  case 1 => \"one\"\n  case _ => \"other\"\n}\nprintln(x)",
        "o": [
            "one",
            "1",
            "other",
            "Error"
        ]
    },
    {
        "q": "case classes auto-generate equals.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the case class features:",
        "type": "match",
        "left": [
            "equals",
            "hashCode",
            "toString",
            "copy"
        ],
        "right": [
            "Comparison",
            "Hash value",
            "String rep",
            "Clone copy"
        ]
    },
    {
        "q": "The ______ creates case classes.",
        "type": "fill_blank",
        "answers": [
            "case class"
        ],
        "other_options": [
            "data class",
            "record",
            "struct"
        ]
    },
    {
        "q": "Which feature enables extraction?",
        "type": "mcq",
        "o": [
            "unapply",
            "extract",
            "deconstruct",
            "pattern"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "case class Person(name: String)\nval p = Person(\"John\")\nprintln(p.name)",
        "o": [
            "John",
            "Person",
            "name",
            "Error"
        ]
    },
    {
        "q": "Rearrange case class definition:",
        "type": "rearrange",
        "words": [
            "case",
            "class",
            "Name",
            "(",
            "field: Type",
            ")"
        ]
    },
    {
        "q": "Match the OOP concepts:",
        "type": "match",
        "left": [
            "class",
            "object",
            "trait",
            "abstract class"
        ],
        "right": [
            "Blueprint",
            "Singleton",
            "Interface",
            "Partial impl"
        ]
    },
    {
        "q": "The ______ keyword creates singletons.",
        "type": "fill_blank",
        "answers": [
            "object"
        ],
        "other_options": [
            "singleton",
            "static",
            "module"
        ]
    },
    {
        "q": "Which keyword defines interfaces?",
        "type": "mcq",
        "o": [
            "trait",
            "interface",
            "protocol",
            "contract"
        ]
    },
    {
        "q": "Traits can have implementations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "object App {\n  val x = 1\n}\nprintln(App.x)",
        "o": [
            "1",
            "App",
            "x",
            "Error"
        ]
    },
    {
        "q": "Match the trait concepts:",
        "type": "match",
        "left": [
            "extends",
            "with",
            "override",
            "super"
        ],
        "right": [
            "First trait",
            "Additional traits",
            "Redefine",
            "Parent call"
        ]
    },
    {
        "q": "The ______ mixes in additional traits.",
        "type": "fill_blank",
        "answers": [
            "with"
        ],
        "other_options": [
            "and",
            "plus",
            "also"
        ]
    },
    {
        "q": "Which keyword overrides methods?",
        "type": "mcq",
        "o": [
            "override",
            "redefine",
            "replace",
            "implement"
        ]
    },
    {
        "q": "Rearrange trait mixing:",
        "type": "rearrange",
        "words": [
            "class",
            "Name",
            "extends",
            "Trait1",
            "with",
            "Trait2"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "trait Greet { def hi = \"Hello\" }\nobject App extends Greet\nprintln(App.hi)",
        "o": [
            "Hello",
            "Greet",
            "hi",
            "Error"
        ]
    },
    {
        "q": "Companion objects share name with class.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the function concepts:",
        "type": "match",
        "left": [
            "def",
            "=>",
            "apply",
            "currying"
        ],
        "right": [
            "Method def",
            "Lambda arrow",
            "Call syntax",
            "Multiple params"
        ]
    },
    {
        "q": "The ______ method enables f() syntax.",
        "type": "fill_blank",
        "answers": [
            "apply"
        ],
        "other_options": [
            "call",
            "invoke",
            "exec"
        ]
    },
    {
        "q": "Which feature splits parameters?",
        "type": "mcq",
        "o": [
            "Currying",
            "Partial application",
            "Both",
            "Neither"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val add = (a: Int, b: Int) => a + b\nprintln(add(2, 3))",
        "o": [
            "5",
            "add",
            "23",
            "Error"
        ]
    },
    {
        "q": "Rearrange curried function:",
        "type": "rearrange",
        "words": [
            "def",
            "add",
            "(a: Int)",
            "(b: Int)",
            "=",
            "a + b"
        ]
    },
    {
        "q": "Match the function types:",
        "type": "match",
        "left": [
            "Int => Int",
            "(Int, Int) => Int",
            "() => Int",
            "Int => Unit"
        ],
        "right": [
            "Unary",
            "Binary",
            "Nullary",
            "No return"
        ]
    },
    {
        "q": "The ______ type means no value.",
        "type": "fill_blank",
        "answers": [
            "Unit"
        ],
        "other_options": [
            "Void",
            "Nothing",
            "Null"
        ]
    },
    {
        "q": "Which type is never instantiated?",
        "type": "mcq",
        "o": [
            "Nothing",
            "Null",
            "Unit",
            "Any"
        ]
    },
    {
        "q": "Nothing is a subtype of all types.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "def greet(): Unit = println(\"Hi\")\ngreet()",
        "o": [
            "Hi",
            "()",
            "Unit",
            "Error"
        ]
    },
    {
        "q": "Match the type hierarchy:",
        "type": "match",
        "left": [
            "Any",
            "AnyVal",
            "AnyRef",
            "Nothing"
        ],
        "right": [
            "Top type",
            "Value types",
            "Reference types",
            "Bottom type"
        ]
    },
    {
        "q": "Which framework processes big data?",
        "type": "mcq",
        "o": [
            "Apache Spark",
            "Apache Storm",
            "Apache Flink",
            "All of the above"
        ]
    },
    {
        "q": "Spark runs on Scala natively.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Spark components:",
        "type": "match",
        "left": [
            "SparkContext",
            "SparkSession",
            "RDD",
            "DataFrame"
        ],
        "right": [
            "Entry point",
            "Unified API",
            "Resilient data",
            "Structured data"
        ]
    },
    {
        "q": "The ______ is Spark's main abstraction.",
        "type": "fill_blank",
        "answers": [
            "RDD"
        ],
        "other_options": [
            "DataFrame",
            "Dataset",
            "DStream"
        ]
    },
    {
        "q": "Which method creates SparkSession?",
        "type": "mcq",
        "o": [
            "builder()",
            "create()",
            "new SparkSession()",
            "init()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val spark = SparkSession.builder().appName(\"app\").getOrCreate()\nprintln(spark.sparkContext.appName)",
        "o": [
            "app",
            "SparkSession",
            "spark",
            "Error"
        ]
    },
    {
        "q": "Rearrange Spark initialization:",
        "type": "rearrange",
        "words": [
            "SparkSession",
            ".",
            "builder()",
            ".",
            "appName()",
            ".",
            "getOrCreate()"
        ]
    },
    {
        "q": "Match the RDD operations:",
        "type": "match",
        "left": [
            "map",
            "filter",
            "reduce",
            "collect"
        ],
        "right": [
            "Transform",
            "Select",
            "Aggregate",
            "Retrieve"
        ]
    },
    {
        "q": "The ______ fetches RDD to driver.",
        "type": "fill_blank",
        "answers": [
            "collect"
        ],
        "other_options": [
            "get",
            "fetch",
            "retrieve"
        ]
    },
    {
        "q": "Which operation triggers computation?",
        "type": "mcq",
        "o": [
            "Action",
            "Transformation",
            "Both",
            "Neither"
        ]
    },
    {
        "q": "Transformations are lazy.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the RDD actions:",
        "type": "match",
        "left": [
            "count",
            "first",
            "take",
            "saveAsTextFile"
        ],
        "right": [
            "Element count",
            "First element",
            "N elements",
            "Write to file"
        ]
    },
    {
        "q": "The ______ action counts elements.",
        "type": "fill_blank",
        "answers": [
            "count"
        ],
        "other_options": [
            "size",
            "length",
            "num"
        ]
    },
    {
        "q": "Which method creates RDD from collection?",
        "type": "mcq",
        "o": [
            "parallelize",
            "create",
            "fromList",
            "toRDD"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val rdd = sc.parallelize(List(1, 2, 3))\nprintln(rdd.count())",
        "o": [
            "3",
            "List(1, 2, 3)",
            "6",
            "Error"
        ]
    },
    {
        "q": "Rearrange RDD creation:",
        "type": "rearrange",
        "words": [
            "spark",
            ".",
            "sparkContext",
            ".",
            "parallelize",
            "(",
            "data",
            ")"
        ]
    },
    {
        "q": "Match the persistence levels:",
        "type": "match",
        "left": [
            "MEMORY_ONLY",
            "DISK_ONLY",
            "MEMORY_AND_DISK",
            "OFF_HEAP"
        ],
        "right": [
            "RAM only",
            "Disk only",
            "Both",
            "Native memory"
        ]
    },
    {
        "q": "The ______ caches RDD in memory.",
        "type": "fill_blank",
        "answers": [
            "cache"
        ],
        "other_options": [
            "persist",
            "store",
            "save"
        ]
    },
    {
        "q": "Which method uncaches RDD?",
        "type": "mcq",
        "o": [
            "unpersist",
            "uncache",
            "remove",
            "clear"
        ]
    },
    {
        "q": "cache() uses MEMORY_ONLY.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the DataFrame operations:",
        "type": "match",
        "left": [
            "select",
            "filter",
            "groupBy",
            "join"
        ],
        "right": [
            "Choose columns",
            "Row filter",
            "Aggregate",
            "Combine tables"
        ]
    },
    {
        "q": "The ______ selects columns.",
        "type": "fill_blank",
        "answers": [
            "select"
        ],
        "other_options": [
            "get",
            "pick",
            "columns"
        ]
    },
    {
        "q": "Which method reads CSV files?",
        "type": "mcq",
        "o": [
            "read.csv()",
            "readCSV()",
            "loadCSV()",
            "csv.read()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val df = spark.read.option(\"header\", true).csv(\"file.csv\")\ndf.printSchema()",
        "o": [
            "Schema output",
            "Data",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange DataFrame read:",
        "type": "rearrange",
        "words": [
            "spark",
            ".",
            "read",
            ".",
            "format()",
            ".",
            "load()"
        ]
    },
    {
        "q": "Match the write modes:",
        "type": "match",
        "left": [
            "overwrite",
            "append",
            "ignore",
            "error"
        ],
        "right": [
            "Replace",
            "Add",
            "Skip if exists",
            "Fail if exists"
        ]
    },
    {
        "q": "The ______ adds data to existing.",
        "type": "fill_blank",
        "answers": [
            "append"
        ],
        "other_options": [
            "add",
            "insert",
            "extend"
        ]
    },
    {
        "q": "Which format is columnar?",
        "type": "mcq",
        "o": [
            "Parquet",
            "CSV",
            "JSON",
            "Text"
        ]
    },
    {
        "q": "Parquet supports schema evolution.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the file formats:",
        "type": "match",
        "left": [
            "parquet",
            "orc",
            "json",
            "avro"
        ],
        "right": [
            "Columnar Apache",
            "Columnar Hive",
            "Semi-structured",
            "Row-based schema"
        ]
    },
    {
        "q": "The ______ format is human-readable.",
        "type": "fill_blank",
        "answers": [
            "json"
        ],
        "other_options": [
            "parquet",
            "orc",
            "avro"
        ]
    },
    {
        "q": "Which method shows data?",
        "type": "mcq",
        "o": [
            "show()",
            "display()",
            "print()",
            "view()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val df = spark.range(3)\ndf.show()",
        "o": [
            "Table with 0,1,2",
            "3",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange DataFrame write:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "write",
            ".",
            "mode()",
            ".",
            "parquet()"
        ]
    },
    {
        "q": "Match the SQL functions:",
        "type": "match",
        "left": [
            "col",
            "lit",
            "expr",
            "when"
        ],
        "right": [
            "Column ref",
            "Literal value",
            "SQL expression",
            "Conditional"
        ]
    },
    {
        "q": "The ______ creates a column reference.",
        "type": "fill_blank",
        "answers": [
            "col"
        ],
        "other_options": [
            "column",
            "field",
            "ref"
        ]
    },
    {
        "q": "Which method runs SQL queries?",
        "type": "mcq",
        "o": [
            "spark.sql()",
            "spark.query()",
            "spark.execute()",
            "spark.run()"
        ]
    },
    {
        "q": "SQL and DataFrame API are interchangeable.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the aggregations:",
        "type": "match",
        "left": [
            "count",
            "sum",
            "avg",
            "max"
        ],
        "right": [
            "Number of rows",
            "Total",
            "Average",
            "Maximum"
        ]
    },
    {
        "q": "The ______ computes average.",
        "type": "fill_blank",
        "answers": [
            "avg"
        ],
        "other_options": [
            "mean",
            "average",
            "mid"
        ]
    },
    {
        "q": "Which method groups data?",
        "type": "mcq",
        "o": [
            "groupBy",
            "group",
            "aggregate",
            "partition"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.groupBy(\"col\").count().show()",
        "o": [
            "Grouped counts",
            "Single count",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange aggregation:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "groupBy()",
            ".",
            "agg()",
            ".",
            "show()"
        ]
    },
    {
        "q": "Match the join types:",
        "type": "match",
        "left": [
            "inner",
            "left",
            "right",
            "full"
        ],
        "right": [
            "Both match",
            "Left all",
            "Right all",
            "All rows"
        ]
    },
    {
        "q": "The ______ join includes unmatched.",
        "type": "fill_blank",
        "answers": [
            "outer"
        ],
        "other_options": [
            "full",
            "all",
            "complete"
        ]
    },
    {
        "q": "Which join keeps left rows?",
        "type": "mcq",
        "o": [
            "left",
            "right",
            "inner",
            "cross"
        ]
    },
    {
        "q": "Cross join creates cartesian product.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the window functions:",
        "type": "match",
        "left": [
            "row_number",
            "rank",
            "lag",
            "lead"
        ],
        "right": [
            "Sequential",
            "With gaps",
            "Previous",
            "Next"
        ]
    },
    {
        "q": "The ______ accesses previous row.",
        "type": "fill_blank",
        "answers": [
            "lag"
        ],
        "other_options": [
            "prev",
            "before",
            "back"
        ]
    },
    {
        "q": "Which method defines window?",
        "type": "mcq",
        "o": [
            "Window.partitionBy()",
            "over()",
            "windowSpec()",
            "frame()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.sql.functions._\nval w = Window.partitionBy(\"col\")\ndf.withColumn(\"rn\", row_number().over(w))",
        "o": [
            "DataFrame with row numbers",
            "Error",
            "1",
            "null"
        ]
    },
    {
        "q": "Rearrange window function:",
        "type": "rearrange",
        "words": [
            "Window",
            ".",
            "partitionBy()",
            ".",
            "orderBy()"
        ]
    },
    {
        "q": "Match the UDF concepts:",
        "type": "match",
        "left": [
            "udf",
            "register",
            "callUDF",
            "PandasUDF"
        ],
        "right": [
            "Create UDF",
            "SQL access",
            "Call by name",
            "Vectorized"
        ]
    },
    {
        "q": "The ______ registers UDF for SQL.",
        "type": "fill_blank",
        "answers": [
            "register"
        ],
        "other_options": [
            "add",
            "create",
            "define"
        ]
    },
    {
        "q": "Which API handles structured data?",
        "type": "mcq",
        "o": [
            "Dataset",
            "RDD",
            "DStream",
            "PairRDD"
        ]
    },
    {
        "q": "Dataset is type-safe.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Dataset methods:",
        "type": "match",
        "left": [
            "as",
            "toDF",
            "map",
            "flatMap"
        ],
        "right": [
            "Type cast",
            "To DataFrame",
            "Transform",
            "Flatten"
        ]
    },
    {
        "q": "The ______ converts to DataFrame.",
        "type": "fill_blank",
        "answers": [
            "toDF"
        ],
        "other_options": [
            "asDF",
            "dataFrame",
            "convert"
        ]
    },
    {
        "q": "Which encoder enables Dataset?",
        "type": "mcq",
        "o": [
            "Encoder",
            "Serializer",
            "Converter",
            "Mapper"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "case class Person(name: String, age: Int)\nval ds = Seq(Person(\"John\", 30)).toDS()\nds.show()",
        "o": [
            "Table with John, 30",
            "Person",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Dataset creation:",
        "type": "rearrange",
        "words": [
            "spark",
            ".",
            "createDataset()",
            "(",
            "data",
            ")"
        ]
    },
    {
        "q": "Match the broadcast concepts:",
        "type": "match",
        "left": [
            "broadcast",
            "accumulator",
            "SparkContext",
            "Broadcast variable"
        ],
        "right": [
            "Share read-only",
            "Share write",
            "Driver entry",
            "Cached data"
        ]
    },
    {
        "q": "The ______ shares data to all nodes.",
        "type": "fill_blank",
        "answers": [
            "broadcast"
        ],
        "other_options": [
            "distribute",
            "share",
            "send"
        ]
    },
    {
        "q": "Which variable aggregates values?",
        "type": "mcq",
        "o": [
            "Accumulator",
            "Broadcast",
            "Counter",
            "Aggregator"
        ]
    },
    {
        "q": "Broadcast variables are read-only.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the partitioning strategies:",
        "type": "match",
        "left": [
            "repartition",
            "coalesce",
            "partitionBy",
            "bucketBy"
        ],
        "right": [
            "Full shuffle",
            "Reduce shuffle",
            "By column",
            "Bucketed"
        ]
    },
    {
        "q": "The ______ reduces partitions efficiently.",
        "type": "fill_blank",
        "answers": [
            "coalesce"
        ],
        "other_options": [
            "reduce",
            "shrink",
            "compact"
        ]
    },
    {
        "q": "Which method fully reshuffles?",
        "type": "mcq",
        "o": [
            "repartition",
            "coalesce",
            "shuffle",
            "redistribute"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val rdd = sc.parallelize(1 to 100, 10)\nprintln(rdd.coalesce(2).getNumPartitions)",
        "o": [
            "2",
            "10",
            "100",
            "Error"
        ]
    },
    {
        "q": "Rearrange partitioning:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "repartition()",
            ".",
            "write",
            ".",
            "save()"
        ]
    },
    {
        "q": "Match the Spark SQL concepts:",
        "type": "match",
        "left": [
            "createTempView",
            "createGlobalTempView",
            "catalog",
            "database"
        ],
        "right": [
            "Session scope",
            "App scope",
            "Metadata",
            "Container"
        ]
    },
    {
        "q": "The ______ creates session-scoped view.",
        "type": "fill_blank",
        "answers": [
            "createTempView"
        ],
        "other_options": [
            "tempView",
            "createView",
            "view"
        ]
    },
    {
        "q": "Which catalog method lists tables?",
        "type": "mcq",
        "o": [
            "listTables",
            "getTables",
            "showTables",
            "tables"
        ]
    },
    {
        "q": "Global temp views use global_temp database.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the implicits:",
        "type": "match",
        "left": [
            "Encoder",
            "toDF",
            "toDS",
            "$"
        ],
        "right": [
            "Type info",
            "To DataFrame",
            "To Dataset",
            "Column syntax"
        ]
    },
    {
        "q": "The ______ provides Spark implicits.",
        "type": "fill_blank",
        "answers": [
            "spark.implicits._"
        ],
        "other_options": [
            "implicits",
            "SparkImplicits",
            "Encoders"
        ]
    },
    {
        "q": "Which implicit enables $ syntax?",
        "type": "mcq",
        "o": [
            "StringToColumn",
            "ColumnSyntax",
            "DollarColumn",
            "SparkColumn"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import spark.implicits._\nval df = Seq((1, \"a\")).toDF(\"id\", \"name\")\ndf.select($\"id\").show()",
        "o": [
            "Column id values",
            "1",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange implicit import:",
        "type": "rearrange",
        "words": [
            "import",
            "spark",
            ".",
            "implicits",
            ".",
            "_"
        ]
    },
    {
        "q": "Match the type classes:",
        "type": "match",
        "left": [
            "Ordering",
            "Numeric",
            "Encoder",
            "TypeTag"
        ],
        "right": [
            "Comparison",
            "Math ops",
            "Serialization",
            "Type info"
        ]
    },
    {
        "q": "The ______ provides comparison.",
        "type": "fill_blank",
        "answers": [
            "Ordering"
        ],
        "other_options": [
            "Comparable",
            "Order",
            "Compare"
        ]
    },
    {
        "q": "Which type class enables math?",
        "type": "mcq",
        "o": [
            "Numeric",
            "Math",
            "Number",
            "Arithmetic"
        ]
    },
    {
        "q": "Type classes enable ad-hoc polymorphism.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the implicit concepts:",
        "type": "match",
        "left": [
            "implicit val",
            "implicit def",
            "implicit class",
            "context bound"
        ],
        "right": [
            "Value",
            "Conversion",
            "Extension",
            "Type constraint"
        ]
    },
    {
        "q": "The ______ adds methods to types.",
        "type": "fill_blank",
        "answers": [
            "implicit class"
        ],
        "other_options": [
            "extension",
            "decorator",
            "pimp"
        ]
    },
    {
        "q": "Which syntax is T: Ordering?",
        "type": "mcq",
        "o": [
            "Context bound",
            "View bound",
            "Type bound",
            "Class bound"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "implicit class IntOps(x: Int) {\n  def double = x * 2\n}\nprintln(5.double)",
        "o": [
            "10",
            "5",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange implicit class:",
        "type": "rearrange",
        "words": [
            "implicit",
            "class",
            "Name",
            "(",
            "val x: T",
            ")",
            "{",
            "methods",
            "}"
        ]
    },
    {
        "q": "Match the variance annotations:",
        "type": "match",
        "left": [
            "+T",
            "-T",
            "T",
            "[_]"
        ],
        "right": [
            "Covariant",
            "Contravariant",
            "Invariant",
            "Existential"
        ]
    },
    {
        "q": "The ______ makes type covariant.",
        "type": "fill_blank",
        "answers": [
            "+"
        ],
        "other_options": [
            "-",
            "out",
            "co"
        ]
    },
    {
        "q": "Which variance is for parameters?",
        "type": "mcq",
        "o": [
            "Contravariant",
            "Covariant",
            "Invariant",
            "Bivariant"
        ]
    },
    {
        "q": "List[+A] is covariant.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the type bounds:",
        "type": "match",
        "left": [
            "T <: A",
            "T >: A",
            "T <% A",
            "T : A"
        ],
        "right": [
            "Upper bound",
            "Lower bound",
            "View bound",
            "Context bound"
        ]
    },
    {
        "q": "The ______ sets upper bound.",
        "type": "fill_blank",
        "answers": [
            "<:"
        ],
        "other_options": [
            ">:",
            "<",
            "extends"
        ]
    },
    {
        "q": "Which bound requires subtype?",
        "type": "mcq",
        "o": [
            "Upper bound",
            "Lower bound",
            "View bound",
            "Context bound"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "def foo[T <: Number](x: T) = x\nprintln(foo(1: Integer))",
        "o": [
            "1",
            "Number",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange type bounds:",
        "type": "rearrange",
        "words": [
            "def",
            "foo",
            "[",
            "T",
            "<:",
            "Bound",
            "]",
            "(x: T)"
        ]
    },
    {
        "q": "Match the for-comprehension:",
        "type": "match",
        "left": [
            "<-",
            "=",
            "if",
            "yield"
        ],
        "right": [
            "Generator",
            "Definition",
            "Guard",
            "Return"
        ]
    },
    {
        "q": "The ______ filters in for-comprehension.",
        "type": "fill_blank",
        "answers": [
            "if"
        ],
        "other_options": [
            "filter",
            "when",
            "where"
        ]
    },
    {
        "q": "Which keyword produces values?",
        "type": "mcq",
        "o": [
            "yield",
            "return",
            "give",
            "produce"
        ]
    },
    {
        "q": "for-yield is syntactic sugar for flatMap/map.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the monadic operations:",
        "type": "match",
        "left": [
            "flatMap",
            "map",
            "filter",
            "withFilter"
        ],
        "right": [
            "Bind",
            "Functor map",
            "Select",
            "Lazy filter"
        ]
    },
    {
        "q": "The ______ is monadic bind.",
        "type": "fill_blank",
        "answers": [
            "flatMap"
        ],
        "other_options": [
            "bind",
            "chain",
            "then"
        ]
    },
    {
        "q": "Which method is called by map?",
        "type": "mcq",
        "o": [
            "map",
            "fmap",
            "transform",
            "apply"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val result = for {\n  x <- List(1, 2)\n  y <- List(3, 4)\n} yield x + y\nprintln(result)",
        "o": [
            "List(4, 5, 5, 6)",
            "List(3, 4)",
            "10",
            "Error"
        ]
    },
    {
        "q": "Rearrange for-comprehension:",
        "type": "rearrange",
        "words": [
            "for",
            "{",
            "x <- xs",
            ";",
            "if cond",
            "}",
            "yield",
            "expr"
        ]
    },
    {
        "q": "Match the Future concepts:",
        "type": "match",
        "left": [
            "Future",
            "Promise",
            "ExecutionContext",
            "Await"
        ],
        "right": [
            "Async result",
            "Write once",
            "Thread pool",
            "Blocking wait"
        ]
    },
    {
        "q": "The ______ provides thread pool.",
        "type": "fill_blank",
        "answers": [
            "ExecutionContext"
        ],
        "other_options": [
            "ThreadPool",
            "Executor",
            "Scheduler"
        ]
    },
    {
        "q": "Which method blocks for result?",
        "type": "mcq",
        "o": [
            "Await.result",
            "Future.get",
            "Future.wait",
            "Result.get"
        ]
    },
    {
        "q": "Futures are non-blocking.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Future combinators:",
        "type": "match",
        "left": [
            "map",
            "flatMap",
            "recover",
            "recoverWith"
        ],
        "right": [
            "Transform",
            "Chain futures",
            "Handle error",
            "Future on error"
        ]
    },
    {
        "q": "The ______ handles Future failures.",
        "type": "fill_blank",
        "answers": [
            "recover"
        ],
        "other_options": [
            "catch",
            "handle",
            "rescue"
        ]
    },
    {
        "q": "Which method chains Futures?",
        "type": "mcq",
        "o": [
            "flatMap",
            "then",
            "chain",
            "andThen"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import scala.concurrent._\nimport ExecutionContext.Implicits.global\nval f = Future(1 + 1)\nf.map(_ * 2)",
        "o": [
            "Future(4)",
            "4",
            "Future(2)",
            "Error"
        ]
    },
    {
        "q": "Rearrange Future handling:",
        "type": "rearrange",
        "words": [
            "Future",
            "{",
            "computation",
            "}",
            ".",
            "map",
            "(",
            "transform",
            ")"
        ]
    },
    {
        "q": "Match the Try types:",
        "type": "match",
        "left": [
            "Success",
            "Failure",
            "Try",
            "recover"
        ],
        "right": [
            "Has value",
            "Has exception",
            "Container",
            "Handle error"
        ]
    },
    {
        "q": "The ______ wraps exception handling.",
        "type": "fill_blank",
        "answers": [
            "Try"
        ],
        "other_options": [
            "Result",
            "Either",
            "Option"
        ]
    },
    {
        "q": "Which type represents success/failure?",
        "type": "mcq",
        "o": [
            "Try",
            "Option",
            "Either",
            "Result"
        ]
    },
    {
        "q": "Either has Left and Right.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Either conventions:",
        "type": "match",
        "left": [
            "Left",
            "Right",
            "left.toOption",
            "right.toOption"
        ],
        "right": [
            "Error",
            "Success",
            "None if Right",
            "None if Left"
        ]
    },
    {
        "q": "The ______ side is the success by convention.",
        "type": "fill_blank",
        "answers": [
            "Right"
        ],
        "other_options": [
            "Left",
            "Success",
            "Value"
        ]
    },
    {
        "q": "Which method swaps Either sides?",
        "type": "mcq",
        "o": [
            "swap",
            "flip",
            "reverse",
            "invert"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val e: Either[String, Int] = Right(42)\nprintln(e.getOrElse(0))",
        "o": [
            "42",
            "0",
            "Right(42)",
            "Error"
        ]
    },
    {
        "q": "Rearrange Either handling:",
        "type": "rearrange",
        "words": [
            "either",
            ".",
            "fold",
            "(",
            "leftHandler",
            ",",
            "rightHandler",
            ")"
        ]
    },
    {
        "q": "Match the Spark Streaming:",
        "type": "match",
        "left": [
            "DStream",
            "StreamingContext",
            "Window",
            "Checkpoint"
        ],
        "right": [
            "Micro-batches",
            "Entry point",
            "Time window",
            "Fault tolerance"
        ]
    },
    {
        "q": "The ______ is Spark Streaming abstraction.",
        "type": "fill_blank",
        "answers": [
            "DStream"
        ],
        "other_options": [
            "Stream",
            "Flow",
            "Source"
        ]
    },
    {
        "q": "Which context manages streaming?",
        "type": "mcq",
        "o": [
            "StreamingContext",
            "SparkContext",
            "SparkSession",
            "StreamContext"
        ]
    },
    {
        "q": "Spark Streaming uses micro-batches.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Structured Streaming:",
        "type": "match",
        "left": [
            "readStream",
            "writeStream",
            "trigger",
            "watermark"
        ],
        "right": [
            "Read source",
            "Write sink",
            "Batch interval",
            "Late data"
        ]
    },
    {
        "q": "The ______ reads streaming data.",
        "type": "fill_blank",
        "answers": [
            "readStream"
        ],
        "other_options": [
            "stream",
            "streamRead",
            "source"
        ]
    },
    {
        "q": "Which mode appends only new rows?",
        "type": "mcq",
        "o": [
            "Append",
            "Complete",
            "Update",
            "New"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "val df = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 9999).load()\ndf.isStreaming",
        "o": [
            "true",
            "false",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange streaming query:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "writeStream",
            ".",
            "format()",
            ".",
            "start()"
        ]
    },
    {
        "q": "Match the output modes:",
        "type": "match",
        "left": [
            "Append",
            "Complete",
            "Update",
            "None"
        ],
        "right": [
            "New rows only",
            "All rows",
            "Changed rows",
            "No output"
        ]
    },
    {
        "q": "The ______ handles late data.",
        "type": "fill_blank",
        "answers": [
            "watermark"
        ],
        "other_options": [
            "lateness",
            "delay",
            "threshold"
        ]
    },
    {
        "q": "Which trigger processes continuously?",
        "type": "mcq",
        "o": [
            "Continuous",
            "ProcessingTime",
            "Once",
            "Stream"
        ]
    },
    {
        "q": "Checkpointing enables fault tolerance.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the MLlib concepts:",
        "type": "match",
        "left": [
            "Transformer",
            "Estimator",
            "Pipeline",
            "Evaluator"
        ],
        "right": [
            "Transform data",
            "Fit model",
            "Chain stages",
            "Metrics"
        ]
    },
    {
        "q": "The ______ fits to data.",
        "type": "fill_blank",
        "answers": [
            "Estimator"
        ],
        "other_options": [
            "Fitter",
            "Model",
            "Trainer"
        ]
    },
    {
        "q": "Which stage transforms data?",
        "type": "mcq",
        "o": [
            "Transformer",
            "Estimator",
            "Evaluator",
            "Pipeline"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.ml.feature.VectorAssembler\nval assembler = new VectorAssembler().setInputCols(Array(\"a\", \"b\")).setOutputCol(\"features\")\nassembler.isInstanceOf[Transformer]",
        "o": [
            "true",
            "false",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange ML Pipeline:",
        "type": "rearrange",
        "words": [
            "Pipeline",
            "(",
            "stages",
            "=",
            "[",
            "stage1",
            ",",
            "stage2",
            "]",
            ")"
        ]
    },
    {
        "q": "Match the feature transformers:",
        "type": "match",
        "left": [
            "VectorAssembler",
            "StringIndexer",
            "OneHotEncoder",
            "StandardScaler"
        ],
        "right": [
            "Combine columns",
            "String to index",
            "Category to binary",
            "Normalize"
        ]
    },
    {
        "q": "The ______ combines features.",
        "type": "fill_blank",
        "answers": [
            "VectorAssembler"
        ],
        "other_options": [
            "FeatureVector",
            "Combiner",
            "Merger"
        ]
    },
    {
        "q": "Which transformer encodes categories?",
        "type": "mcq",
        "o": [
            "OneHotEncoder",
            "StringIndexer",
            "LabelEncoder",
            "Binarizer"
        ]
    },
    {
        "q": "StringIndexer converts labels to indices.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the ML algorithms:",
        "type": "match",
        "left": [
            "LogisticRegression",
            "RandomForest",
            "GBTClassifier",
            "KMeans"
        ],
        "right": [
            "Binary classification",
            "Ensemble trees",
            "Gradient boost",
            "Clustering"
        ]
    },
    {
        "q": "The ______ algorithm clusters data.",
        "type": "fill_blank",
        "answers": [
            "KMeans"
        ],
        "other_options": [
            "Cluster",
            "Group",
            "Partition"
        ]
    },
    {
        "q": "Which model is ensemble-based?",
        "type": "mcq",
        "o": [
            "RandomForest",
            "LogisticRegression",
            "LinearRegression",
            "NaiveBayes"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.ml.classification.LogisticRegression\nval lr = new LogisticRegression()\nlr.isInstanceOf[Estimator[_]]",
        "o": [
            "true",
            "false",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange model training:",
        "type": "rearrange",
        "words": [
            "estimator",
            ".",
            "fit",
            "(",
            "trainingData",
            ")"
        ]
    },
    {
        "q": "Match the evaluators:",
        "type": "match",
        "left": [
            "BinaryClassificationEvaluator",
            "MulticlassClassificationEvaluator",
            "RegressionEvaluator",
            "ClusteringEvaluator"
        ],
        "right": [
            "Binary metrics",
            "Multi-class metrics",
            "Regression metrics",
            "Cluster metrics"
        ]
    },
    {
        "q": "The ______ computes AUC-ROC.",
        "type": "fill_blank",
        "answers": [
            "BinaryClassificationEvaluator"
        ],
        "other_options": [
            "ROCEvaluator",
            "AUCEvaluator",
            "ClassifierEvaluator"
        ]
    },
    {
        "q": "Which method saves the model?",
        "type": "mcq",
        "o": [
            "save",
            "persist",
            "store",
            "write"
        ]
    },
    {
        "q": "CrossValidator performs k-fold validation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the tuning concepts:",
        "type": "match",
        "left": [
            "ParamGridBuilder",
            "CrossValidator",
            "TrainValidationSplit",
            "bestModel"
        ],
        "right": [
            "Parameter grid",
            "K-fold",
            "Single split",
            "Best result"
        ]
    },
    {
        "q": "The ______ builds parameter combinations.",
        "type": "fill_blank",
        "answers": [
            "ParamGridBuilder"
        ],
        "other_options": [
            "GridSearch",
            "ParamSearch",
            "GridBuilder"
        ]
    },
    {
        "q": "Which split is faster than CV?",
        "type": "mcq",
        "o": [
            "TrainValidationSplit",
            "CrossValidator",
            "RandomSplit",
            "StratifiedSplit"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.ml.tuning.ParamGridBuilder\nnew ParamGridBuilder().build().length",
        "o": [
            "1",
            "0",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange hyperparameter tuning:",
        "type": "rearrange",
        "words": [
            "CrossValidator",
            "(",
            "estimator",
            ",",
            "paramGrid",
            ",",
            "evaluator",
            ")"
        ]
    },
    {
        "q": "Match the GraphX concepts:",
        "type": "match",
        "left": [
            "Graph",
            "VertexRDD",
            "EdgeRDD",
            "Pregel"
        ],
        "right": [
            "Graph structure",
            "Vertex data",
            "Edge data",
            "Iterative algo"
        ]
    },
    {
        "q": "The ______ represents graph vertices.",
        "type": "fill_blank",
        "answers": [
            "VertexRDD"
        ],
        "other_options": [
            "Nodes",
            "Points",
            "Vertices"
        ]
    },
    {
        "q": "Which API handles graph processing?",
        "type": "mcq",
        "o": [
            "GraphX",
            "GraphFrame",
            "SparkGraph",
            "Both A and B"
        ]
    },
    {
        "q": "GraphFrames use DataFrames.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the graph algorithms:",
        "type": "match",
        "left": [
            "PageRank",
            "ConnectedComponents",
            "ShortestPaths",
            "TriangleCount"
        ],
        "right": [
            "Importance",
            "Clusters",
            "Path finding",
            "Triangle counting"
        ]
    },
    {
        "q": "The ______ computes page importance.",
        "type": "fill_blank",
        "answers": [
            "PageRank"
        ],
        "other_options": [
            "Rank",
            "Importance",
            "Score"
        ]
    },
    {
        "q": "Which algorithm finds communities?",
        "type": "mcq",
        "o": [
            "ConnectedComponents",
            "LabelPropagation",
            "Community",
            "Both A and B"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.graphx._\nval vertices: RDD[(VertexId, String)] = sc.parallelize(Array((1L, \"A\")))\nvertices.count()",
        "o": [
            "1",
            "A",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange graph creation:",
        "type": "rearrange",
        "words": [
            "Graph",
            "(",
            "vertices",
            ",",
            "edges",
            ")"
        ]
    },
    {
        "q": "Match the Spark optimizations:",
        "type": "match",
        "left": [
            "Catalyst",
            "Tungsten",
            "Whole-stage codegen",
            "Predicate pushdown"
        ],
        "right": [
            "Query optimizer",
            "Memory management",
            "Code generation",
            "Filter early"
        ]
    },
    {
        "q": "The ______ optimizes queries.",
        "type": "fill_blank",
        "answers": [
            "Catalyst"
        ],
        "other_options": [
            "Optimizer",
            "Planner",
            "Engine"
        ]
    },
    {
        "q": "Which feature generates bytecode?",
        "type": "mcq",
        "o": [
            "Whole-stage codegen",
            "Catalyst",
            "Tungsten",
            "JIT"
        ]
    },
    {
        "q": "Tungsten manages off-heap memory.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the execution concepts:",
        "type": "match",
        "left": [
            "Job",
            "Stage",
            "Task",
            "Shuffle"
        ],
        "right": [
            "Action result",
            "Task group",
            "Single unit",
            "Data exchange"
        ]
    },
    {
        "q": "The ______ is smallest execution unit.",
        "type": "fill_blank",
        "answers": [
            "Task"
        ],
        "other_options": [
            "Job",
            "Stage",
            "Slot"
        ]
    },
    {
        "q": "Which operation causes shuffle?",
        "type": "mcq",
        "o": [
            "groupByKey",
            "map",
            "filter",
            "flatMap"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.get(\"spark.sql.shuffle.partitions\")",
        "o": [
            "200 (default)",
            "100",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange execution flow:",
        "type": "rearrange",
        "words": [
            "Driver",
            "creates",
            "Jobs",
            "splits",
            "Stages",
            "runs",
            "Tasks"
        ]
    },
    {
        "q": "Match the memory areas:",
        "type": "match",
        "left": [
            "Execution",
            "Storage",
            "Reserved",
            "User"
        ],
        "right": [
            "Shuffles/joins",
            "Cached data",
            "System",
            "UDFs"
        ]
    },
    {
        "q": "The ______ memory caches RDDs.",
        "type": "fill_blank",
        "answers": [
            "Storage"
        ],
        "other_options": [
            "Cache",
            "Persist",
            "Hold"
        ]
    },
    {
        "q": "Which config sets memory fraction?",
        "type": "mcq",
        "o": [
            "spark.memory.fraction",
            "spark.executor.memory",
            "spark.storage.memory",
            "spark.shuffle.memory"
        ]
    },
    {
        "q": "Spilling writes to disk when full.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the shuffle concepts:",
        "type": "match",
        "left": [
            "ShuffleMapTask",
            "ResultTask",
            "SortShuffleManager",
            "spark.sql.shuffle.partitions"
        ],
        "right": [
            "Map side",
            "Reduce side",
            "Shuffle impl",
            "Partition count"
        ]
    },
    {
        "q": "The ______ manages shuffle files.",
        "type": "fill_blank",
        "answers": [
            "ShuffleManager"
        ],
        "other_options": [
            "ShuffleService",
            "ShuffleWriter",
            "ShuffleHandler"
        ]
    },
    {
        "q": "Which service manages shuffle externally?",
        "type": "mcq",
        "o": [
            "External Shuffle Service",
            "ShuffleManager",
            "ShuffleBlockFetcher",
            "ShuffleReader"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.set(\"spark.sql.shuffle.partitions\", \"100\")\nspark.conf.get(\"spark.sql.shuffle.partitions\")",
        "o": [
            "100",
            "200",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange shuffle optimization:",
        "type": "rearrange",
        "words": [
            "Reduce partitions",
            "Use broadcast",
            "Avoid groupByKey",
            "Enable AQE"
        ]
    },
    {
        "q": "Match the AQE features:",
        "type": "match",
        "left": [
            "Coalescing partitions",
            "Skew join",
            "Dynamic pruning",
            "Runtime optimization"
        ],
        "right": [
            "Merge small",
            "Handle skew",
            "Filter early",
            "Adaptive plans"
        ]
    },
    {
        "q": "The ______ enables adaptive execution.",
        "type": "fill_blank",
        "answers": [
            "AQE"
        ],
        "other_options": [
            "Adaptive",
            "Dynamic",
            "Runtime"
        ]
    },
    {
        "q": "Which feature handles data skew?",
        "type": "mcq",
        "o": [
            "Skew join optimization",
            "Broadcast join",
            "Sort merge join",
            "Hash join"
        ]
    },
    {
        "q": "AQE adjusts plans at runtime.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the join strategies:",
        "type": "match",
        "left": [
            "Broadcast hash",
            "Sort merge",
            "Shuffle hash",
            "Broadcast nested loop"
        ],
        "right": [
            "Small table",
            "Large sorted",
            "Medium data",
            "Cross join"
        ]
    },
    {
        "q": "The ______ join broadcasts small table.",
        "type": "fill_blank",
        "answers": [
            "Broadcast hash"
        ],
        "other_options": [
            "Hash",
            "Merge",
            "Nested"
        ]
    },
    {
        "q": "Which join sorts both sides?",
        "type": "mcq",
        "o": [
            "Sort merge join",
            "Broadcast join",
            "Hash join",
            "Nested loop join"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import org.apache.spark.sql.functions._\ndf1.join(broadcast(df2), \"key\")",
        "o": [
            "Broadcast join result",
            "Error",
            "df1",
            "null"
        ]
    },
    {
        "q": "Rearrange join optimization:",
        "type": "rearrange",
        "words": [
            "Check sizes",
            "Choose strategy",
            "Use hint",
            "Execute join"
        ]
    },
    {
        "q": "Match the serialization:",
        "type": "match",
        "left": [
            "Java serialization",
            "Kryo",
            "Encoders",
            "Kyro registration"
        ],
        "right": [
            "Default slow",
            "Fast binary",
            "Dataset serial",
            "Type mapping"
        ]
    },
    {
        "q": "The ______ serializer is faster.",
        "type": "fill_blank",
        "answers": [
            "Kryo"
        ],
        "other_options": [
            "Java",
            "Binary",
            "Fast"
        ]
    },
    {
        "q": "Which config enables Kryo?",
        "type": "mcq",
        "o": [
            "spark.serializer",
            "spark.kryo.enabled",
            "spark.kryo.serializer",
            "spark.serialization"
        ]
    },
    {
        "q": "Registering classes improves Kryo.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the locality levels:",
        "type": "match",
        "left": [
            "PROCESS_LOCAL",
            "NODE_LOCAL",
            "RACK_LOCAL",
            "ANY"
        ],
        "right": [
            "Same JVM",
            "Same node",
            "Same rack",
            "Anywhere"
        ]
    },
    {
        "q": "The ______ locality is fastest.",
        "type": "fill_blank",
        "answers": [
            "PROCESS_LOCAL"
        ],
        "other_options": [
            "NODE_LOCAL",
            "LOCAL",
            "CACHE"
        ]
    },
    {
        "q": "Which locality reads from same node?",
        "type": "mcq",
        "o": [
            "NODE_LOCAL",
            "PROCESS_LOCAL",
            "RACK_LOCAL",
            "ANY"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.get(\"spark.locality.wait\")",
        "o": [
            "3s (default)",
            "1s",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange locality optimization:",
        "type": "rearrange",
        "words": [
            "Colocate data",
            "Set locality wait",
            "Monitor tasks",
            "Adjust settings"
        ]
    },
    {
        "q": "Match the Delta Lake features:",
        "type": "match",
        "left": [
            "ACID",
            "Time travel",
            "Schema enforcement",
            "Merge"
        ],
        "right": [
            "Transactions",
            "History",
            "Schema check",
            "Upsert"
        ]
    },
    {
        "q": "The ______ provides ACID on data lake.",
        "type": "fill_blank",
        "answers": [
            "Delta Lake"
        ],
        "other_options": [
            "Iceberg",
            "Hudi",
            "Lakehouse"
        ]
    },
    {
        "q": "Which feature enables versioning?",
        "type": "mcq",
        "o": [
            "Time travel",
            "ACID",
            "Merge",
            "Optimize"
        ]
    },
    {
        "q": "Delta Lake supports schema evolution.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Delta operations:",
        "type": "match",
        "left": [
            "MERGE",
            "UPDATE",
            "DELETE",
            "OPTIMIZE"
        ],
        "right": [
            "Upsert",
            "Modify rows",
            "Remove rows",
            "Compact files"
        ]
    },
    {
        "q": "The ______ compacts small files.",
        "type": "fill_blank",
        "answers": [
            "OPTIMIZE"
        ],
        "other_options": [
            "COMPACT",
            "VACUUM",
            "MERGE"
        ]
    },
    {
        "q": "Which command removes old versions?",
        "type": "mcq",
        "o": [
            "VACUUM",
            "OPTIMIZE",
            "COMPACT",
            "CLEAN"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/path\")",
        "o": [
            "Version 0 data",
            "Latest data",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Delta time travel:",
        "type": "rearrange",
        "words": [
            "spark.read",
            ".",
            "format(\"delta\")",
            ".",
            "option(\"timestampAsOf\")",
            ".",
            "load()"
        ]
    },
    {
        "q": "Match the Iceberg features:",
        "type": "match",
        "left": [
            "Hidden partitioning",
            "Schema evolution",
            "Time travel",
            "Snapshots"
        ],
        "right": [
            "Auto partition",
            "Schema changes",
            "History",
            "Versions"
        ]
    },
    {
        "q": "The ______ hides partition columns.",
        "type": "fill_blank",
        "answers": [
            "hidden partitioning"
        ],
        "other_options": [
            "auto partition",
            "smart partition",
            "invisible partition"
        ]
    },
    {
        "q": "Which format is engine-agnostic?",
        "type": "mcq",
        "o": [
            "Apache Iceberg",
            "Delta Lake",
            "Apache Hudi",
            "All of the above"
        ]
    },
    {
        "q": "Iceberg supports multiple engines.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the sealed traits:",
        "type": "match",
        "left": [
            "sealed trait",
            "case object",
            "exhaustive match",
            "ADT"
        ],
        "right": [
            "Closed hierarchy",
            "Singleton case",
            "All cases",
            "Algebraic data type"
        ]
    },
    {
        "q": "The ______ ensures exhaustive matching.",
        "type": "fill_blank",
        "answers": [
            "sealed"
        ],
        "other_options": [
            "closed",
            "private",
            "final"
        ]
    },
    {
        "q": "Which keyword marks singleton?",
        "type": "mcq",
        "o": [
            "case object",
            "object",
            "case class",
            "singleton"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "sealed trait Color\ncase object Red extends Color\ncase object Blue extends Color\nval c: Color = Red\nc match { case Red => 1 case Blue => 2 }",
        "o": [
            "1",
            "2",
            "Color",
            "Error"
        ]
    },
    {
        "q": "Rearrange ADT definition:",
        "type": "rearrange",
        "words": [
            "sealed",
            "trait",
            "Base",
            ";",
            "case",
            "class",
            "A",
            "extends",
            "Base"
        ]
    },
    {
        "q": "Match the partial functions:",
        "type": "match",
        "left": [
            "PartialFunction",
            "isDefinedAt",
            "orElse",
            "andThen"
        ],
        "right": [
            "Partial domain",
            "Check defined",
            "Combine",
            "Chain"
        ]
    },
    {
        "q": "The ______ checks if defined.",
        "type": "fill_blank",
        "answers": [
            "isDefinedAt"
        ],
        "other_options": [
            "isDefined",
            "contains",
            "has"
        ]
    },
    {
        "q": "Which method combines partial functions?",
        "type": "mcq",
        "o": [
            "orElse",
            "andThen",
            "compose",
            "combine"
        ]
    },
    {
        "q": "Partial functions may not be total.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the self types:",
        "type": "match",
        "left": [
            "self =>",
            "self: Type =>",
            "this.type",
            "Cake pattern"
        ],
        "right": [
            "Self reference",
            "Type requirement",
            "Singleton type",
            "DI pattern"
        ]
    },
    {
        "q": "The ______ pattern enables DI.",
        "type": "fill_blank",
        "answers": [
            "Cake"
        ],
        "other_options": [
            "Factory",
            "Singleton",
            "Builder"
        ]
    },
    {
        "q": "Which syntax declares self type?",
        "type": "mcq",
        "o": [
            "self: Type =>",
            "this: Type",
            "requires Type",
            "needs Type"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "trait A { self: B => }\ntrait B { val x = 1 }\nobject C extends A with B\nprintln(C.x)",
        "o": [
            "1",
            "Error",
            "C",
            "null"
        ]
    },
    {
        "q": "Rearrange self type:",
        "type": "rearrange",
        "words": [
            "trait",
            "A",
            "{",
            "self:",
            "B",
            "=>",
            "...}",
            "}"
        ]
    },
    {
        "q": "Match the type members:",
        "type": "match",
        "left": [
            "type T",
            "type T = Int",
            "type T <: Number",
            "path-dependent"
        ],
        "right": [
            "Abstract type",
            "Type alias",
            "Bounded type",
            "Instance type"
        ]
    },
    {
        "q": "The ______ declares abstract type.",
        "type": "fill_blank",
        "answers": [
            "type T"
        ],
        "other_options": [
            "abstract T",
            "define T",
            "member T"
        ]
    },
    {
        "q": "Which feature enables path types?",
        "type": "mcq",
        "o": [
            "Path-dependent types",
            "Type members",
            "Abstract types",
            "Type aliases"
        ]
    },
    {
        "q": "a.T differs from b.T.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the structural types:",
        "type": "match",
        "left": [
            "Structural typing",
            "reflectiveCalls",
            "duck typing",
            "refinement"
        ],
        "right": [
            "Shape-based",
            "Import",
            "Behavior",
            "Type + members"
        ]
    },
    {
        "q": "The ______ enables duck typing.",
        "type": "fill_blank",
        "answers": [
            "Structural typing"
        ],
        "other_options": [
            "Duck typing",
            "Shape typing",
            "Interface typing"
        ]
    },
    {
        "q": "Which import enables reflection?",
        "type": "mcq",
        "o": [
            "scala.language.reflectiveCalls",
            "scala.reflect._",
            "scala.language.structural",
            "scala.structural._"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import scala.language.reflectiveCalls\ndef foo(x: { def bar: Int }) = x.bar\nfoo(new { def bar = 42 })",
        "o": [
            "42",
            "bar",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange structural type:",
        "type": "rearrange",
        "words": [
            "def",
            "foo",
            "(",
            "x:",
            "{",
            "def method: T",
            "}",
            ")"
        ]
    },
    {
        "q": "Match the higher-kinded types:",
        "type": "match",
        "left": [
            "F[_]",
            "Functor",
            "Monad",
            "Kind projector"
        ],
        "right": [
            "Type constructor",
            "Mappable",
            "Flatmappable",
            "Plugin"
        ]
    },
    {
        "q": "The ______ abstracts over type constructors.",
        "type": "fill_blank",
        "answers": [
            "F[_]"
        ],
        "other_options": [
            "T[*]",
            "A<_>",
            "Type[_]"
        ]
    },
    {
        "q": "Which type class requires map?",
        "type": "mcq",
        "o": [
            "Functor",
            "Monad",
            "Applicative",
            "Semigroup"
        ]
    },
    {
        "q": "Monad extends Functor.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Cats type classes:",
        "type": "match",
        "left": [
            "Semigroup",
            "Monoid",
            "Functor",
            "Applicative"
        ],
        "right": [
            "Combine",
            "Empty + combine",
            "Map",
            "Apply + pure"
        ]
    },
    {
        "q": "The ______ has empty element.",
        "type": "fill_blank",
        "answers": [
            "Monoid"
        ],
        "other_options": [
            "Semigroup",
            "Group",
            "Ring"
        ]
    },
    {
        "q": "Which method does Semigroup provide?",
        "type": "mcq",
        "o": [
            "combine",
            "append",
            "add",
            "merge"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import cats.implicits._\nList(1, 2) |+| List(3, 4)",
        "o": [
            "List(1, 2, 3, 4)",
            "List(4, 6)",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Cats import:",
        "type": "rearrange",
        "words": [
            "import",
            "cats",
            ".",
            "implicits",
            ".",
            "_"
        ]
    },
    {
        "q": "Match the IO concepts:",
        "type": "match",
        "left": [
            "IO",
            "unsafeRunSync",
            "flatMap",
            "Resource"
        ],
        "right": [
            "Effect type",
            "Execute",
            "Chain",
            "Safe handling"
        ]
    },
    {
        "q": "The ______ represents side effects.",
        "type": "fill_blank",
        "answers": [
            "IO"
        ],
        "other_options": [
            "Effect",
            "Task",
            "Action"
        ]
    },
    {
        "q": "Which method runs IO unsafely?",
        "type": "mcq",
        "o": [
            "unsafeRunSync",
            "run",
            "execute",
            "perform"
        ]
    },
    {
        "q": "IO is referentially transparent.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Cats Effect types:",
        "type": "match",
        "left": [
            "IO",
            "Resource",
            "Fiber",
            "Deferred"
        ],
        "right": [
            "Effect",
            "Acquire/release",
            "Lightweight thread",
            "Promise"
        ]
    },
    {
        "q": "The ______ manages resources safely.",
        "type": "fill_blank",
        "answers": [
            "Resource"
        ],
        "other_options": [
            "Bracket",
            "Using",
            "Managed"
        ]
    },
    {
        "q": "Which type represents async result?",
        "type": "mcq",
        "o": [
            "Deferred",
            "Promise",
            "Future",
            "Async"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import cats.effect.IO\nval io = IO(println(\"Hello\"))\nio.unsafeRunSync()",
        "o": [
            "Hello (printed)",
            "IO",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange IO creation:",
        "type": "rearrange",
        "words": [
            "IO",
            "{",
            "effect",
            "}",
            ".",
            "flatMap",
            "{",
            "result",
            "}"
        ]
    },
    {
        "q": "Match the Akka concepts:",
        "type": "match",
        "left": [
            "Actor",
            "ActorRef",
            "Behavior",
            "ActorContext"
        ],
        "right": [
            "Processing unit",
            "Reference",
            "Message handler",
            "Context"
        ]
    },
    {
        "q": "The ______ handles messages.",
        "type": "fill_blank",
        "answers": [
            "Behavior"
        ],
        "other_options": [
            "Handler",
            "Processor",
            "Receiver"
        ]
    },
    {
        "q": "Which method sends messages?",
        "type": "mcq",
        "o": [
            "! or tell",
            "send",
            "message",
            "dispatch"
        ]
    },
    {
        "q": "Akka actors are message-driven.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Akka Typed:",
        "type": "match",
        "left": [
            "Behavior.receive",
            "Behavior.same",
            "Behaviors.stopped",
            "Behaviors.setup"
        ],
        "right": [
            "Handle message",
            "Keep behavior",
            "Stop actor",
            "Initialize"
        ]
    },
    {
        "q": "The ______ maintains current behavior.",
        "type": "fill_blank",
        "answers": [
            "same"
        ],
        "other_options": [
            "keep",
            "stay",
            "current"
        ]
    },
    {
        "q": "Which method creates actor behavior?",
        "type": "mcq",
        "o": [
            "Behaviors.receive",
            "Actor.create",
            "new Actor",
            "Actor.apply"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import akka.actor.typed._\nval behavior = Behaviors.receiveMessage[String] { msg =>\n  println(msg)\n  Behaviors.same\n}",
        "o": [
            "Behavior instance",
            "String",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange actor creation:",
        "type": "rearrange",
        "words": [
            "Behaviors",
            ".",
            "setup",
            "{",
            "context",
            "=>",
            "behavior",
            "}"
        ]
    },
    {
        "q": "Match the Akka supervision:",
        "type": "match",
        "left": [
            "Resume",
            "Restart",
            "Stop",
            "Escalate"
        ],
        "right": [
            "Continue",
            "Reset state",
            "Terminate",
            "Parent handles"
        ]
    },
    {
        "q": "The ______ strategy restarts actor.",
        "type": "fill_blank",
        "answers": [
            "Restart"
        ],
        "other_options": [
            "Reset",
            "Recreate",
            "Reboot"
        ]
    },
    {
        "q": "Which strategy ignores failure?",
        "type": "mcq",
        "o": [
            "Resume",
            "Restart",
            "Stop",
            "Ignore"
        ]
    },
    {
        "q": "Supervision is hierarchical.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the ZIO effects:",
        "type": "match",
        "left": [
            "ZIO",
            "Task",
            "UIO",
            "URIO"
        ],
        "right": [
            "Full effect",
            "Error type",
            "No error",
            "No dependencies"
        ]
    },
    {
        "q": "The ______ is ZIO with no error.",
        "type": "fill_blank",
        "answers": [
            "UIO"
        ],
        "other_options": [
            "Safe",
            "Pure",
            "Clean"
        ]
    },
    {
        "q": "Which ZIO type has environment?",
        "type": "mcq",
        "o": [
            "ZIO",
            "Task",
            "UIO",
            "IO"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import zio._\nval effect = ZIO.succeed(42)\neffect.fork",
        "o": [
            "Fiber[Nothing, Int]",
            "42",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange ZIO composition:",
        "type": "rearrange",
        "words": [
            "for",
            "{",
            "a <- effect1",
            ";",
            "b <- effect2",
            "}",
            "yield",
            "result"
        ]
    },
    {
        "q": "Match the http4s concepts:",
        "type": "match",
        "left": [
            "HttpRoutes",
            "Client",
            "Server",
            "Middleware"
        ],
        "right": [
            "Routes",
            "Http client",
            "Http server",
            "Filter"
        ]
    },
    {
        "q": "The ______ defines routes.",
        "type": "fill_blank",
        "answers": [
            "HttpRoutes"
        ],
        "other_options": [
            "Router",
            "Endpoints",
            "Paths"
        ]
    },
    {
        "q": "Which DSL creates routes?",
        "type": "mcq",
        "o": [
            "http4s dsl",
            "http routes",
            "router dsl",
            "endpoint dsl"
        ]
    },
    {
        "q": "http4s is purely functional.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the FS2 concepts:",
        "type": "match",
        "left": [
            "Stream",
            "Pipe",
            "Chunk",
            "Pull"
        ],
        "right": [
            "Data stream",
            "Transform",
            "Buffer",
            "Low-level"
        ]
    },
    {
        "q": "The ______ processes stream data.",
        "type": "fill_blank",
        "answers": [
            "Pipe"
        ],
        "other_options": [
            "Filter",
            "Transform",
            "Handler"
        ]
    },
    {
        "q": "Which type is FS2's main abstraction?",
        "type": "mcq",
        "o": [
            "Stream",
            "Flow",
            "Source",
            "Flux"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import fs2.Stream\nStream(1, 2, 3).map(_ * 2).toList",
        "o": [
            "List(2, 4, 6)",
            "Stream",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange FS2 stream:",
        "type": "rearrange",
        "words": [
            "Stream",
            ".",
            "emit",
            "(",
            "value",
            ")",
            ".",
            "compile",
            ".",
            "drain"
        ]
    },
    {
        "q": "Match the Doobie concepts:",
        "type": "match",
        "left": [
            "ConnectionIO",
            "Transactor",
            "Fragment",
            "Query0"
        ],
        "right": [
            "DB action",
            "Connection",
            "SQL parts",
            "Query type"
        ]
    },
    {
        "q": "The ______ executes database actions.",
        "type": "fill_blank",
        "answers": [
            "Transactor"
        ],
        "other_options": [
            "Connection",
            "Database",
            "Executor"
        ]
    },
    {
        "q": "Which type represents SQL action?",
        "type": "mcq",
        "o": [
            "ConnectionIO",
            "Query",
            "Statement",
            "Command"
        ]
    },
    {
        "q": "Doobie is functional JDBC.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Circe concepts:",
        "type": "match",
        "left": [
            "Encoder",
            "Decoder",
            "Json",
            "Cursor"
        ],
        "right": [
            "To JSON",
            "From JSON",
            "JSON value",
            "Navigate"
        ]
    },
    {
        "q": "The ______ decodes JSON.",
        "type": "fill_blank",
        "answers": [
            "Decoder"
        ],
        "other_options": [
            "Parser",
            "Reader",
            "Unmarshaller"
        ]
    },
    {
        "q": "Which method derives codecs?",
        "type": "mcq",
        "o": [
            "deriveEncoder/Decoder",
            "auto",
            "generic",
            "derived"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import io.circe.syntax._\nMap(\"a\" -> 1).asJson.noSpaces",
        "o": [
            "{\"a\":1}",
            "Map",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Circe derivation:",
        "type": "rearrange",
        "words": [
            "import",
            "io.circe.generic.auto._"
        ]
    },
    {
        "q": "Match the macro annotations:",
        "type": "match",
        "left": [
            "@inline",
            "@tailrec",
            "@specialized",
            "@throws"
        ],
        "right": [
            "Inline hint",
            "Tail call",
            "Primitive spec",
            "Exception doc"
        ]
    },
    {
        "q": "The ______ ensures tail recursion.",
        "type": "fill_blank",
        "answers": [
            "@tailrec"
        ],
        "other_options": [
            "@recursive",
            "@tail",
            "@optimized"
        ]
    },
    {
        "q": "Which annotation optimizes primitives?",
        "type": "mcq",
        "o": [
            "@specialized",
            "@primitive",
            "@native",
            "@value"
        ]
    },
    {
        "q": "@inline suggests inlining.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the compilation phases:",
        "type": "match",
        "left": [
            "Parser",
            "Typer",
            "Erasure",
            "Codegen"
        ],
        "right": [
            "Syntax tree",
            "Type check",
            "Remove types",
            "Bytecode"
        ]
    },
    {
        "q": "The ______ phase checks types.",
        "type": "fill_blank",
        "answers": [
            "Typer"
        ],
        "other_options": [
            "TypeChecker",
            "Analyzer",
            "Validator"
        ]
    },
    {
        "q": "Which phase generates bytecode?",
        "type": "mcq",
        "o": [
            "Codegen/Backend",
            "Typer",
            "Parser",
            "Optimizer"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "@tailrec def loop(n: Int, acc: Int = 0): Int =\n  if (n <= 0) acc else loop(n - 1, acc + n)\nloop(5)",
        "o": [
            "15",
            "5",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange tailrec function:",
        "type": "rearrange",
        "words": [
            "@tailrec",
            "def",
            "name",
            "(",
            "params",
            ")",
            ":",
            "Type",
            "=",
            "body"
        ]
    },
    {
        "q": "Match the collection conversions:",
        "type": "match",
        "left": [
            "to",
            "from",
            "iterator",
            "view"
        ],
        "right": [
            "Convert to",
            "Create from",
            "Iterate",
            "Lazy view"
        ]
    },
    {
        "q": "The ______ creates lazy collection.",
        "type": "fill_blank",
        "answers": [
            "view"
        ],
        "other_options": [
            "lazy",
            "stream",
            "iterator"
        ]
    },
    {
        "q": "Which method converts collections?",
        "type": "mcq",
        "o": [
            "to",
            "as",
            "convert",
            "cast"
        ]
    },
    {
        "q": "Views are evaluated lazily.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the parallel collections:",
        "type": "match",
        "left": [
            "par",
            "seq",
            "ParVector",
            "ParSeq"
        ],
        "right": [
            "Parallelize",
            "Sequential",
            "Parallel vector",
            "Parallel seq"
        ]
    },
    {
        "q": "The ______ creates parallel collection.",
        "type": "fill_blank",
        "answers": [
            "par"
        ],
        "other_options": [
            "parallel",
            "async",
            "concurrent"
        ]
    },
    {
        "q": "Which method serializes parallel?",
        "type": "mcq",
        "o": [
            "seq",
            "serial",
            "sync",
            "single"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "List(1, 2, 3).view.map(_ * 2).take(2).toList",
        "o": [
            "List(2, 4)",
            "List(2, 4, 6)",
            "Error",
            "null"
        ]
    },
    {
        "q": "Match the testing frameworks:",
        "type": "match",
        "left": [
            "ScalaTest",
            "Specs2",
            "MUnit",
            "ScalaCheck"
        ],
        "right": [
            "Testing lib",
            "BDD style",
            "Lightweight",
            "Property testing"
        ]
    },
    {
        "q": "The ______ does property testing.",
        "type": "fill_blank",
        "answers": [
            "ScalaCheck"
        ],
        "other_options": [
            "QuickCheck",
            "PropTest",
            "Hypothesis"
        ]
    },
    {
        "q": "Which framework is BDD-style?",
        "type": "mcq",
        "o": [
            "Specs2",
            "ScalaTest",
            "MUnit",
            "JUnit"
        ]
    },
    {
        "q": "Rearrange ScalaTest assertions:",
        "type": "rearrange",
        "words": [
            "assert",
            "(",
            "condition",
            ")"
        ]
    },
    {
        "q": "Match the build tools:",
        "type": "match",
        "left": [
            "sbt",
            "Mill",
            "Gradle",
            "Maven"
        ],
        "right": [
            "Scala default",
            "Fast builds",
            "Kotlin/Android",
            "Java default"
        ]
    },
    {
        "q": "The ______ is Scala's default build tool.",
        "type": "fill_blank",
        "answers": [
            "sbt"
        ],
        "other_options": [
            "mill",
            "gradle",
            "maven"
        ]
    },
    {
        "q": "Which tool uses build.sc?",
        "type": "mcq",
        "o": [
            "Mill",
            "sbt",
            "Gradle",
            "Bazel"
        ]
    },
    {
        "q": "What is the output of this sbt command?",
        "type": "mcq",
        "c": "sbt compile",
        "o": [
            "Compiles project",
            "Error",
            "compile",
            "null"
        ]
    },
    {
        "q": "sbt uses build.sbt file.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Scala 3 features:",
        "type": "match",
        "left": [
            "given",
            "using",
            "extension",
            "enum"
        ],
        "right": [
            "Implicit value",
            "Implicit param",
            "Extension method",
            "Enumeration"
        ]
    },
    {
        "q": "The ______ replaces implicit.",
        "type": "fill_blank",
        "answers": [
            "given"
        ],
        "other_options": [
            "provided",
            "auto",
            "infer"
        ]
    },
    {
        "q": "Which keyword adds extension methods?",
        "type": "mcq",
        "o": [
            "extension",
            "implicit class",
            "extend",
            "enrich"
        ]
    },
    {
        "q": "Scala 3 has improved enums.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the export clauses:",
        "type": "match",
        "left": [
            "export",
            "given",
            "type",
            "transparent"
        ],
        "right": [
            "Re-export",
            "Export implicit",
            "Export type",
            "Inline transparent"
        ]
    },
    {
        "q": "The ______ re-exports members.",
        "type": "fill_blank",
        "answers": [
            "export"
        ],
        "other_options": [
            "reexport",
            "forward",
            "delegate"
        ]
    },
    {
        "q": "Which feature replaces view bounds?",
        "type": "mcq",
        "o": [
            "Context bounds",
            "Using clauses",
            "Given instances",
            "Type lambdas"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "extension (s: String)\n  def greet = s\"Hello $s\"\n\"World\".greet",
        "o": [
            "Hello World",
            "World",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Scala 3 given:",
        "type": "rearrange",
        "words": [
            "given",
            "name:",
            "Type",
            "=",
            "value"
        ]
    },
    {
        "q": "Match the Scala 3 types:",
        "type": "match",
        "left": [
            "Union types",
            "Intersection",
            "Match types",
            "Opaque types"
        ],
        "right": [
            "A | B",
            "A & B",
            "Type match",
            "Hidden impl"
        ]
    },
    {
        "q": "The ______ combines alternatives.",
        "type": "fill_blank",
        "answers": [
            "Union types"
        ],
        "other_options": [
            "Or types",
            "Either types",
            "Sum types"
        ]
    },
    {
        "q": "Which type hides implementation?",
        "type": "mcq",
        "o": [
            "Opaque types",
            "Private types",
            "Hidden types",
            "Sealed types"
        ]
    },
    {
        "q": "Intersection types use &.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the metaprogramming:",
        "type": "match",
        "left": [
            "inline",
            "Quotes",
            "Expr",
            "Splices"
        ],
        "right": [
            "Compile-time",
            "Quote context",
            "Expression",
            "Insert code"
        ]
    },
    {
        "q": "The ______ evaluates at compile time.",
        "type": "fill_blank",
        "answers": [
            "inline"
        ],
        "other_options": [
            "const",
            "comptime",
            "static"
        ]
    },
    {
        "q": "Which feature replaces macros?",
        "type": "mcq",
        "o": [
            "Inline and quotes",
            "Reflection",
            "Annotations",
            "Compiler plugins"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "inline def power(x: Double, inline n: Int): Double =\n  inline if n == 0 then 1.0\n  else x * power(x, n - 1)\npower(2, 3)",
        "o": [
            "8.0",
            "6.0",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange inline def:",
        "type": "rearrange",
        "words": [
            "inline",
            "def",
            "name",
            "(",
            "inline param",
            ")",
            "=",
            "body"
        ]
    },
    {
        "q": "Match the context functions:",
        "type": "match",
        "left": [
            "?=>",
            "summon",
            "compiletime",
            "constValue"
        ],
        "right": [
            "Context func",
            "Get implicit",
            "Compile ops",
            "Type-level value"
        ]
    },
    {
        "q": "The ______ gets implicit value.",
        "type": "fill_blank",
        "answers": [
            "summon"
        ],
        "other_options": [
            "implicitly",
            "get",
            "require"
        ]
    },
    {
        "q": "Which syntax is context function?",
        "type": "mcq",
        "o": [
            "?=>",
            "=>",
            "->",
            "=>"
        ]
    },
    {
        "q": "summon replaces implicitly.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the derives clause:",
        "type": "match",
        "left": [
            "derives",
            "Mirror",
            "ProductOf",
            "SumOf"
        ],
        "right": [
            "Auto derive",
            "Reflection",
            "Product type",
            "Sum type"
        ]
    },
    {
        "q": "The ______ auto-derives type classes.",
        "type": "fill_blank",
        "answers": [
            "derives"
        ],
        "other_options": [
            "auto",
            "derive",
            "generate"
        ]
    },
    {
        "q": "Which mirror represents products?",
        "type": "mcq",
        "o": [
            "ProductOf",
            "SumOf",
            "TupleOf",
            "CaseOf"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "enum Color derives CanEqual:\n  case Red, Green, Blue\nColor.Red == Color.Red",
        "o": [
            "true",
            "false",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange enum definition:",
        "type": "rearrange",
        "words": [
            "enum",
            "Name",
            "derives",
            "TypeClass",
            ":",
            "case",
            "A",
            ",",
            "B"
        ]
    },
    {
        "q": "Match the multiversal equality:",
        "type": "match",
        "left": [
            "CanEqual",
            "strictEquality",
            "Eql",
            "derives CanEqual"
        ],
        "right": [
            "Type class",
            "Import",
            "Old name",
            "Auto derive"
        ]
    },
    {
        "q": "The ______ enables strict equality.",
        "type": "fill_blank",
        "answers": [
            "strictEquality"
        ],
        "other_options": [
            "safeEquals",
            "typeEquals",
            "strictEq"
        ]
    },
    {
        "q": "Which import enables strict equals?",
        "type": "mcq",
        "o": [
            "scala.language.strictEquality",
            "scala.strict._",
            "scala.equals._",
            "scala.safe._"
        ]
    },
    {
        "q": "CanEqual controls == comparison.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Scala Native:",
        "type": "match",
        "left": [
            "Scala Native",
            "LLVM",
            "NIR",
            "sbt-native"
        ],
        "right": [
            "Native compile",
            "Backend",
            "IR format",
            "Build plugin"
        ]
    },
    {
        "q": "The ______ compiles to native.",
        "type": "fill_blank",
        "answers": [
            "Scala Native"
        ],
        "other_options": [
            "ScalaNative",
            "Native Scala",
            "NativeCompiler"
        ]
    },
    {
        "q": "Which backend does Scala Native use?",
        "type": "mcq",
        "o": [
            "LLVM",
            "GCC",
            "JVM",
            "Graal"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import scala.scalanative.unsafe._\nval ptr = stackalloc[Int]()\n!ptr = 42\n!ptr",
        "o": [
            "42",
            "ptr",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange native allocation:",
        "type": "rearrange",
        "words": [
            "val",
            "ptr",
            "=",
            "stackalloc",
            "[",
            "Type",
            "]",
            "()"
        ]
    },
    {
        "q": "Match the Scala.js concepts:",
        "type": "match",
        "left": [
            "Scala.js",
            "fastOptJS",
            "fullOptJS",
            "JSExport"
        ],
        "right": [
            "JS backend",
            "Dev build",
            "Prod build",
            "Export to JS"
        ]
    },
    {
        "q": "The ______ creates production JS.",
        "type": "fill_blank",
        "answers": [
            "fullOptJS"
        ],
        "other_options": [
            "prodJS",
            "minJS",
            "optJS"
        ]
    },
    {
        "q": "Which build is faster for dev?",
        "type": "mcq",
        "o": [
            "fastOptJS",
            "fullOptJS",
            "linkJS",
            "compileJS"
        ]
    },
    {
        "q": "Scala.js compiles to JavaScript.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the cross-platform:",
        "type": "match",
        "left": [
            "crossProject",
            "JVM",
            "JS",
            "Native"
        ],
        "right": [
            "Multi-platform",
            "Java VM",
            "JavaScript",
            "Native binary"
        ]
    },
    {
        "q": "The ______ supports multiple platforms.",
        "type": "fill_blank",
        "answers": [
            "crossProject"
        ],
        "other_options": [
            "multiProject",
            "platformProject",
            "allProject"
        ]
    },
    {
        "q": "Which platforms does Scala support?",
        "type": "mcq",
        "o": [
            "JVM, JS, Native",
            "JVM only",
            "JVM and JS",
            "All major platforms"
        ]
    },
    {
        "q": "What is the output of this sbt task?",
        "type": "mcq",
        "c": "sbt fastOptJS",
        "o": [
            "JS file output",
            "Error",
            "fastOptJS",
            "null"
        ]
    },
    {
        "q": "Scala 3 improved cross-platform.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Spark 3 features:",
        "type": "match",
        "left": [
            "AQE",
            "DPP",
            "ANSI SQL",
            "Pandas API"
        ],
        "right": [
            "Adaptive query",
            "Dynamic pruning",
            "Standard SQL",
            "Pandas on Spark"
        ]
    },
    {
        "q": "The ______ enables dynamic partition pruning.",
        "type": "fill_blank",
        "answers": [
            "DPP"
        ],
        "other_options": [
            "AQE",
            "pruning",
            "dynamic"
        ]
    },
    {
        "q": "Which feature adds Pandas compatibility?",
        "type": "mcq",
        "o": [
            "Pandas API on Spark",
            "Koalas",
            "PySpark",
            "Both A and B"
        ]
    },
    {
        "q": "Spark 3 has improved AQE.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Spark monitoring:",
        "type": "match",
        "left": [
            "Spark UI",
            "History Server",
            "Metrics",
            "Event logs"
        ],
        "right": [
            "Live dashboard",
            "Past jobs",
            "Stats",
            "Job history"
        ]
    },
    {
        "q": "The ______ shows job history.",
        "type": "fill_blank",
        "answers": [
            "History Server"
        ],
        "other_options": [
            "Spark UI",
            "Dashboard",
            "Monitor"
        ]
    },
    {
        "q": "Which port is Spark UI default?",
        "type": "mcq",
        "o": [
            "4040",
            "8080",
            "8888",
            "9999"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.sparkContext.uiWebUrl",
        "o": [
            "Some(http://...)",
            "4040",
            "Error",
            "null"
        ]
    },
    {
        "q": "Rearrange Spark tuning:",
        "type": "rearrange",
        "words": [
            "Check plan",
            "Identify bottleneck",
            "Adjust config",
            "Validate improvement"
        ]
    },
    {
        "q": "Match the memory tuning:",
        "type": "match",
        "left": [
            "spark.executor.memory",
            "spark.memory.fraction",
            "spark.memory.storageFraction",
            "spark.driver.memory"
        ],
        "right": [
            "Executor RAM",
            "Memory split",
            "Storage portion",
            "Driver RAM"
        ]
    },
    {
        "q": "The ______ sets executor memory.",
        "type": "fill_blank",
        "answers": [
            "spark.executor.memory"
        ],
        "other_options": [
            "executor.memory",
            "memory",
            "ram"
        ]
    },
    {
        "q": "Which config affects storage?",
        "type": "mcq",
        "o": [
            "spark.memory.storageFraction",
            "spark.executor.memory",
            "spark.driver.memory",
            "spark.shuffle.memory"
        ]
    },
    {
        "q": "More executors is always better.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Match the GC tuning:",
        "type": "match",
        "left": [
            "G1GC",
            "ParallelGC",
            "CMS",
            "ZGC"
        ],
        "right": [
            "Balanced",
            "Throughput",
            "Low pause",
            "Ultra low pause"
        ]
    },
    {
        "q": "The ______ GC has low pause.",
        "type": "fill_blank",
        "answers": [
            "G1GC"
        ],
        "other_options": [
            "ParallelGC",
            "SerialGC",
            "ConcurrentGC"
        ]
    },
    {
        "q": "Which GC is recommended for Spark?",
        "type": "mcq",
        "o": [
            "G1GC",
            "ParallelGC",
            "CMS",
            "Serial"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.get(\"spark.executor.extraJavaOptions\")",
        "o": [
            "JVM options string",
            "Error",
            "null",
            "Empty"
        ]
    },
    {
        "q": "Rearrange GC tuning:",
        "type": "rearrange",
        "words": [
            "Monitor GC",
            "Analyze patterns",
            "Choose collector",
            "Test performance"
        ]
    },
    {
        "q": "Match the cluster managers:",
        "type": "match",
        "left": [
            "Standalone",
            "YARN",
            "Kubernetes",
            "Mesos"
        ],
        "right": [
            "Built-in",
            "Hadoop",
            "Container",
            "Apache"
        ]
    },
    {
        "q": "The ______ runs Spark containers.",
        "type": "fill_blank",
        "answers": [
            "Kubernetes"
        ],
        "other_options": [
            "Docker",
            "Container",
            "K8s"
        ]
    },
    {
        "q": "Which manager integrates with Hadoop?",
        "type": "mcq",
        "o": [
            "YARN",
            "Kubernetes",
            "Mesos",
            "Standalone"
        ]
    },
    {
        "q": "YARN manages Hadoop resources.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the deploy modes:",
        "type": "match",
        "left": [
            "client",
            "cluster",
            "local",
            "local[*]"
        ],
        "right": [
            "Driver on client",
            "Driver in cluster",
            "Single thread",
            "All cores"
        ]
    },
    {
        "q": "The ______ mode runs driver remotely.",
        "type": "fill_blank",
        "answers": [
            "cluster"
        ],
        "other_options": [
            "remote",
            "server",
            "distributed"
        ]
    },
    {
        "q": "Which mode is for development?",
        "type": "mcq",
        "o": [
            "local",
            "client",
            "cluster",
            "debug"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.get(\"spark.master\")",
        "o": [
            "Master URL",
            "Error",
            "null",
            "local"
        ]
    },
    {
        "q": "Rearrange cluster submission:",
        "type": "rearrange",
        "words": [
            "spark-submit",
            "--master",
            "URL",
            "--deploy-mode",
            "app.jar"
        ]
    },
    {
        "q": "Match the data sources:",
        "type": "match",
        "left": [
            "JDBC",
            "Kafka",
            "S3",
            "HDFS"
        ],
        "right": [
            "Database",
            "Streaming",
            "Object store",
            "Distributed FS"
        ]
    },
    {
        "q": "The ______ reads from databases.",
        "type": "fill_blank",
        "answers": [
            "JDBC"
        ],
        "other_options": [
            "Database",
            "SQL",
            "DB"
        ]
    },
    {
        "q": "Which source supports streaming?",
        "type": "mcq",
        "o": [
            "Kafka",
            "JDBC",
            "CSV",
            "Parquet"
        ]
    },
    {
        "q": "S3 is object storage.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Kafka integration:",
        "type": "match",
        "left": [
            "subscribe",
            "startingOffsets",
            "endingOffsets",
            "kafka.bootstrap.servers"
        ],
        "right": [
            "Topics",
            "Start position",
            "End position",
            "Brokers"
        ]
    },
    {
        "q": "The ______ specifies Kafka brokers.",
        "type": "fill_blank",
        "answers": [
            "kafka.bootstrap.servers"
        ],
        "other_options": [
            "brokers",
            "servers",
            "hosts"
        ]
    },
    {
        "q": "Which offset starts from beginning?",
        "type": "mcq",
        "o": [
            "earliest",
            "latest",
            "beginning",
            "first"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.readStream.format(\"kafka\").option(\"subscribe\", \"topic\").load()",
        "o": [
            "Streaming DataFrame",
            "Error",
            "Kafka",
            "null"
        ]
    },
    {
        "q": "Rearrange Kafka read:",
        "type": "rearrange",
        "words": [
            "spark.readStream",
            ".",
            "format(\"kafka\")",
            ".",
            "option(\"subscribe\")",
            ".",
            "load()"
        ]
    },
    {
        "q": "Match the connectors:",
        "type": "match",
        "left": [
            "Cassandra",
            "MongoDB",
            "Elasticsearch",
            "Redis"
        ],
        "right": [
            "Wide column",
            "Document",
            "Search engine",
            "Key-value"
        ]
    },
    {
        "q": "The ______ connector reads NoSQL.",
        "type": "fill_blank",
        "answers": [
            "Cassandra"
        ],
        "other_options": [
            "NoSQL",
            "Document",
            "KV"
        ]
    },
    {
        "q": "Which connector supports search?",
        "type": "mcq",
        "o": [
            "Elasticsearch",
            "MongoDB",
            "Cassandra",
            "Redis"
        ]
    },
    {
        "q": "Connectors enable data integration.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the compression:",
        "type": "match",
        "left": [
            "snappy",
            "gzip",
            "lz4",
            "zstd"
        ],
        "right": [
            "Fast balanced",
            "High ratio",
            "Very fast",
            "Modern efficient"
        ]
    },
    {
        "q": "The ______ codec is fastest.",
        "type": "fill_blank",
        "answers": [
            "lz4"
        ],
        "other_options": [
            "snappy",
            "fast",
            "quick"
        ]
    },
    {
        "q": "Which codec has best ratio?",
        "type": "mcq",
        "o": [
            "gzip",
            "snappy",
            "lz4",
            "none"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.write.option(\"compression\", \"snappy\").parquet(\"/path\")",
        "o": [
            "Compressed parquet",
            "Error",
            "df",
            "null"
        ]
    },
    {
        "q": "Rearrange compression write:",
        "type": "rearrange",
        "words": [
            "df.write",
            ".",
            "option(\"compression\")",
            ".",
            "parquet()"
        ]
    },
    {
        "q": "Match the skew handling:",
        "type": "match",
        "left": [
            "Salting",
            "Broadcast",
            "Splitting",
            "Sampling"
        ],
        "right": [
            "Add random key",
            "Small table",
            "Break large",
            "Analyze data"
        ]
    },
    {
        "q": "The ______ adds random prefix.",
        "type": "fill_blank",
        "answers": [
            "Salting"
        ],
        "other_options": [
            "Random",
            "Shuffle",
            "Hash"
        ]
    },
    {
        "q": "Which technique handles hot keys?",
        "type": "mcq",
        "o": [
            "Salting",
            "Broadcast",
            "Repartition",
            "Coalesce"
        ]
    },
    {
        "q": "Data skew causes performance issues.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the debugging:",
        "type": "match",
        "left": [
            "explain()",
            "toDebugString",
            "queryExecution",
            "debugCodegen"
        ],
        "right": [
            "Show plan",
            "RDD lineage",
            "Query details",
            "Generated code"
        ]
    },
    {
        "q": "The ______ shows query plan.",
        "type": "fill_blank",
        "answers": [
            "explain"
        ],
        "other_options": [
            "plan",
            "show",
            "debug"
        ]
    },
    {
        "q": "Which method shows RDD lineage?",
        "type": "mcq",
        "o": [
            "toDebugString",
            "explain",
            "showLineage",
            "dependencies"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.explain(true)",
        "o": [
            "Physical and logical plans",
            "Error",
            "df",
            "null"
        ]
    },
    {
        "q": "Rearrange debugging:",
        "type": "rearrange",
        "words": [
            "Check explain",
            "Analyze stages",
            "Find bottleneck",
            "Optimize query"
        ]
    },
    {
        "q": "Match the speculative execution:",
        "type": "match",
        "left": [
            "spark.speculation",
            "spark.speculation.multiplier",
            "spark.speculation.quantile",
            "straggler"
        ],
        "right": [
            "Enable",
            "Threshold ratio",
            "Task percent",
            "Slow task"
        ]
    },
    {
        "q": "The ______ reruns slow tasks.",
        "type": "fill_blank",
        "answers": [
            "speculation"
        ],
        "other_options": [
            "retry",
            "duplicate",
            "backup"
        ]
    },
    {
        "q": "Which config enables speculation?",
        "type": "mcq",
        "o": [
            "spark.speculation",
            "spark.task.speculation",
            "spark.speculate",
            "spark.retry"
        ]
    },
    {
        "q": "Speculation helps with stragglers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the dynamic allocation:",
        "type": "match",
        "left": [
            "spark.dynamicAllocation.enabled",
            "initialExecutors",
            "minExecutors",
            "maxExecutors"
        ],
        "right": [
            "Enable",
            "Starting count",
            "Min count",
            "Max count"
        ]
    },
    {
        "q": "The ______ auto-scales executors.",
        "type": "fill_blank",
        "answers": [
            "dynamicAllocation"
        ],
        "other_options": [
            "autoScale",
            "elastic",
            "dynamic"
        ]
    },
    {
        "q": "Which config sets max executors?",
        "type": "mcq",
        "o": [
            "spark.dynamicAllocation.maxExecutors",
            "spark.executor.max",
            "spark.max.executors",
            "spark.executors.max"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.conf.get(\"spark.dynamicAllocation.enabled\")",
        "o": [
            "true or false",
            "Error",
            "enabled",
            "null"
        ]
    },
    {
        "q": "Rearrange dynamic scaling:",
        "type": "rearrange",
        "words": [
            "Enable feature",
            "Set min/max",
            "Configure timeout",
            "Monitor scaling"
        ]
    },
    {
        "q": "Match the SQL optimization:",
        "type": "match",
        "left": [
            "CBO",
            "Statistics",
            "Histograms",
            "Join reorder"
        ],
        "right": [
            "Cost optimizer",
            "Table metadata",
            "Value distribution",
            "Reorder joins"
        ]
    },
    {
        "q": "The ______ uses statistics.",
        "type": "fill_blank",
        "answers": [
            "CBO"
        ],
        "other_options": [
            "Optimizer",
            "Stats",
            "Cost"
        ]
    },
    {
        "q": "Which feature reorders joins?",
        "type": "mcq",
        "o": [
            "CBO",
            "RBO",
            "Catalyst",
            "Tungsten"
        ]
    },
    {
        "q": "ANALYZE TABLE collects statistics.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the catalog APIs:",
        "type": "match",
        "left": [
            "spark.catalog",
            "listDatabases",
            "listTables",
            "tableExists"
        ],
        "right": [
            "Catalog object",
            "All databases",
            "All tables",
            "Check table"
        ]
    },
    {
        "q": "The ______ accesses metadata.",
        "type": "fill_blank",
        "answers": [
            "catalog"
        ],
        "other_options": [
            "metadata",
            "schema",
            "info"
        ]
    },
    {
        "q": "Which method lists tables?",
        "type": "mcq",
        "o": [
            "listTables",
            "getTables",
            "tables",
            "showTables"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.catalog.listDatabases().collect()",
        "o": [
            "Array of databases",
            "Error",
            "databases",
            "null"
        ]
    },
    {
        "q": "Rearrange catalog usage:",
        "type": "rearrange",
        "words": [
            "spark.catalog",
            ".",
            "listTables()",
            ".",
            "show()"
        ]
    },
    {
        "q": "Match the Hive integration:",
        "type": "match",
        "left": [
            "enableHiveSupport",
            "hive.metastore.uris",
            "spark.sql.warehouse.dir",
            "HiveContext"
        ],
        "right": [
            "Enable Hive",
            "Metastore",
            "Warehouse path",
            "Legacy API"
        ]
    },
    {
        "q": "The ______ enables Hive.",
        "type": "fill_blank",
        "answers": [
            "enableHiveSupport"
        ],
        "other_options": [
            "hiveSupport",
            "enableHive",
            "hive"
        ]
    },
    {
        "q": "Which config sets warehouse?",
        "type": "mcq",
        "o": [
            "spark.sql.warehouse.dir",
            "spark.hive.warehouse",
            "spark.warehouse.path",
            "hive.warehouse.dir"
        ]
    },
    {
        "q": "Hive tables are managed.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the table types:",
        "type": "match",
        "left": [
            "Managed",
            "External",
            "Temporary",
            "Global temp"
        ],
        "right": [
            "Spark controls",
            "User controls",
            "Session scope",
            "App scope"
        ]
    },
    {
        "q": "The ______ table owns data.",
        "type": "fill_blank",
        "answers": [
            "Managed"
        ],
        "other_options": [
            "Internal",
            "Controlled",
            "Native"
        ]
    },
    {
        "q": "Which table survives restart?",
        "type": "mcq",
        "o": [
            "Managed/External",
            "Temporary",
            "Global temp",
            "None"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "spark.sql(\"CREATE TABLE IF NOT EXISTS t(id INT)\")",
        "o": [
            "Creates managed table",
            "Error",
            "t",
            "null"
        ]
    },
    {
        "q": "Rearrange table creation:",
        "type": "rearrange",
        "words": [
            "CREATE TABLE",
            "name",
            "(",
            "columns",
            ")",
            "USING",
            "format"
        ]
    },
    {
        "q": "Match the partitioning:",
        "type": "match",
        "left": [
            "PARTITIONED BY",
            "CLUSTERED BY",
            "SORTED BY",
            "DISTRIBUTE BY"
        ],
        "right": [
            "Directory structure",
            "Bucketing",
            "Sort within",
            "Shuffle distribute"
        ]
    },
    {
        "q": "The ______ creates directories.",
        "type": "fill_blank",
        "answers": [
            "PARTITIONED BY"
        ],
        "other_options": [
            "PARTITION",
            "DIRECTORY",
            "FOLDER"
        ]
    },
    {
        "q": "Which clause enables bucketing?",
        "type": "mcq",
        "o": [
            "CLUSTERED BY",
            "BUCKETED BY",
            "BUCKET BY",
            "HASH BY"
        ]
    },
    {
        "q": "Bucketing avoids shuffles.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the data quality:",
        "type": "match",
        "left": [
            "Constraints",
            "CHECK",
            "NOT NULL",
            "UNIQUE"
        ],
        "right": [
            "Validation rules",
            "Condition check",
            "Required",
            "No duplicates"
        ]
    },
    {
        "q": "The ______ ensures not empty.",
        "type": "fill_blank",
        "answers": [
            "NOT NULL"
        ],
        "other_options": [
            "REQUIRED",
            "MANDATORY",
            "EXISTS"
        ]
    },
    {
        "q": "Which constraint validates values?",
        "type": "mcq",
        "o": [
            "CHECK",
            "VALIDATE",
            "ASSERT",
            "VERIFY"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.na.drop().count()",
        "o": [
            "Rows without nulls",
            "Error",
            "All rows",
            "null"
        ]
    },
    {
        "q": "Rearrange null handling:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "na",
            ".",
            "fill(value)",
            ".",
            "show()"
        ]
    },
    {
        "q": "Match the column functions:",
        "type": "match",
        "left": [
            "withColumn",
            "drop",
            "withColumnRenamed",
            "select"
        ],
        "right": [
            "Add/replace",
            "Remove",
            "Rename",
            "Choose"
        ]
    },
    {
        "q": "The ______ adds new column.",
        "type": "fill_blank",
        "answers": [
            "withColumn"
        ],
        "other_options": [
            "addColumn",
            "newColumn",
            "createColumn"
        ]
    },
    {
        "q": "Which method removes column?",
        "type": "mcq",
        "o": [
            "drop",
            "remove",
            "delete",
            "exclude"
        ]
    },
    {
        "q": "withColumn can update existing.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the type casting:",
        "type": "match",
        "left": [
            "cast",
            "astype",
            "to_date",
            "to_timestamp"
        ],
        "right": [
            "Type conversion",
            "Alias",
            "Date convert",
            "Timestamp convert"
        ]
    },
    {
        "q": "The ______ converts to date.",
        "type": "fill_blank",
        "answers": [
            "to_date"
        ],
        "other_options": [
            "date",
            "toDate",
            "asDate"
        ]
    },
    {
        "q": "Which function casts types?",
        "type": "mcq",
        "o": [
            "cast",
            "convert",
            "as",
            "to"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "col(\"value\").cast(\"int\")",
        "o": [
            "Column expression",
            "Error",
            "int",
            "null"
        ]
    },
    {
        "q": "Rearrange type cast:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "withColumn()",
            ".",
            "cast(\"type\")"
        ]
    },
    {
        "q": "Match the date functions:",
        "type": "match",
        "left": [
            "current_date",
            "current_timestamp",
            "datediff",
            "date_add"
        ],
        "right": [
            "Today",
            "Now",
            "Difference",
            "Add days"
        ]
    },
    {
        "q": "The ______ returns current date.",
        "type": "fill_blank",
        "answers": [
            "current_date"
        ],
        "other_options": [
            "today",
            "now",
            "getDate"
        ]
    },
    {
        "q": "Which function adds days?",
        "type": "mcq",
        "o": [
            "date_add",
            "addDays",
            "plus_days",
            "day_add"
        ]
    },
    {
        "q": "datediff calculates day difference.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the string functions:",
        "type": "match",
        "left": [
            "concat",
            "substring",
            "split",
            "regexp_extract"
        ],
        "right": [
            "Join strings",
            "Part of string",
            "Split by delimiter",
            "Regex match"
        ]
    },
    {
        "q": "The ______ joins strings.",
        "type": "fill_blank",
        "answers": [
            "concat"
        ],
        "other_options": [
            "join",
            "combine",
            "merge"
        ]
    },
    {
        "q": "Which function extracts pattern?",
        "type": "mcq",
        "o": [
            "regexp_extract",
            "extract",
            "pattern",
            "match"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "concat(lit(\"Hello \"), col(\"name\"))",
        "o": [
            "Column expression",
            "Error",
            "Hello name",
            "null"
        ]
    },
    {
        "q": "Rearrange string operation:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "withColumn()",
            ".",
            "concat()"
        ]
    },
    {
        "q": "Match the array functions:",
        "type": "match",
        "left": [
            "array",
            "explode",
            "array_contains",
            "size"
        ],
        "right": [
            "Create array",
            "Flatten",
            "Check contains",
            "Array length"
        ]
    },
    {
        "q": "The ______ flattens arrays.",
        "type": "fill_blank",
        "answers": [
            "explode"
        ],
        "other_options": [
            "flatten",
            "unnest",
            "expand"
        ]
    },
    {
        "q": "Which function creates array?",
        "type": "mcq",
        "o": [
            "array",
            "create_array",
            "make_array",
            "Array"
        ]
    },
    {
        "q": "explode creates multiple rows.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the map functions:",
        "type": "match",
        "left": [
            "map",
            "map_keys",
            "map_values",
            "element_at"
        ],
        "right": [
            "Create map",
            "All keys",
            "All values",
            "Get element"
        ]
    },
    {
        "q": "The ______ returns map keys.",
        "type": "fill_blank",
        "answers": [
            "map_keys"
        ],
        "other_options": [
            "keys",
            "getKeys",
            "mapKeys"
        ]
    },
    {
        "q": "Which function accesses element?",
        "type": "mcq",
        "o": [
            "element_at",
            "get",
            "access",
            "retrieve"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "map(lit(\"a\"), lit(1))",
        "o": [
            "Column with map",
            "Error",
            "Map",
            "null"
        ]
    },
    {
        "q": "Rearrange map access:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "select()",
            ".",
            "element_at()"
        ]
    },
    {
        "q": "Match the struct functions:",
        "type": "match",
        "left": [
            "struct",
            "getField",
            "col.field",
            "schema"
        ],
        "right": [
            "Create struct",
            "Access field",
            "Dot notation",
            "Structure"
        ]
    },
    {
        "q": "The ______ creates struct.",
        "type": "fill_blank",
        "answers": [
            "struct"
        ],
        "other_options": [
            "object",
            "record",
            "tuple"
        ]
    },
    {
        "q": "Which method accesses nested?",
        "type": "mcq",
        "o": [
            "getField",
            "get",
            "nested",
            "child"
        ]
    },
    {
        "q": "Dot notation accesses struct fields.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the JSON handling:",
        "type": "match",
        "left": [
            "from_json",
            "to_json",
            "schema_of_json",
            "get_json_object"
        ],
        "right": [
            "Parse JSON",
            "Create JSON",
            "Infer schema",
            "XPath-like access"
        ]
    },
    {
        "q": "The ______ parses JSON string.",
        "type": "fill_blank",
        "answers": [
            "from_json"
        ],
        "other_options": [
            "parse_json",
            "json_parse",
            "toJson"
        ]
    },
    {
        "q": "Which function creates JSON?",
        "type": "mcq",
        "o": [
            "to_json",
            "create_json",
            "make_json",
            "json"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "to_json(struct(col(\"a\"), col(\"b\")))",
        "o": [
            "JSON string column",
            "Error",
            "struct",
            "null"
        ]
    },
    {
        "q": "Rearrange JSON parsing:",
        "type": "rearrange",
        "words": [
            "from_json",
            "(",
            "col",
            ",",
            "schema",
            ")"
        ]
    },
    {
        "q": "Match the transformation:",
        "type": "match",
        "left": [
            "transform",
            "filter",
            "aggregate",
            "zip_with"
        ],
        "right": [
            "Map array",
            "Filter array",
            "Reduce array",
            "Combine arrays"
        ]
    },
    {
        "q": "The ______ maps array elements.",
        "type": "fill_blank",
        "answers": [
            "transform"
        ],
        "other_options": [
            "map",
            "apply",
            "each"
        ]
    },
    {
        "q": "Which function filters arrays?",
        "type": "mcq",
        "o": [
            "filter",
            "select",
            "where",
            "pick"
        ]
    },
    {
        "q": "Higher-order functions work on arrays.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the window specs:",
        "type": "match",
        "left": [
            "rowsBetween",
            "rangeBetween",
            "unboundedPreceding",
            "currentRow"
        ],
        "right": [
            "Row window",
            "Value window",
            "Start",
            "Current"
        ]
    },
    {
        "q": "The ______ sets row-based window.",
        "type": "fill_blank",
        "answers": [
            "rowsBetween"
        ],
        "other_options": [
            "rows",
            "rowWindow",
            "betweenRows"
        ]
    },
    {
        "q": "Which constant marks window end?",
        "type": "mcq",
        "o": [
            "unboundedFollowing",
            "unboundedEnd",
            "windowEnd",
            "lastRow"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "Window.partitionBy(\"col\").rowsBetween(-1, 1)",
        "o": [
            "WindowSpec for 3 rows",
            "Error",
            "1",
            "null"
        ]
    },
    {
        "q": "Rearrange window spec:",
        "type": "rearrange",
        "words": [
            "Window",
            ".",
            "partitionBy()",
            ".",
            "orderBy()",
            ".",
            "rowsBetween()"
        ]
    },
    {
        "q": "Match the sampling:",
        "type": "match",
        "left": [
            "sample",
            "sampleBy",
            "stratified",
            "randomSplit"
        ],
        "right": [
            "Random sample",
            "By column",
            "Proportional",
            "Split dataset"
        ]
    },
    {
        "q": "The ______ creates random sample.",
        "type": "fill_blank",
        "answers": [
            "sample"
        ],
        "other_options": [
            "random",
            "pick",
            "choose"
        ]
    },
    {
        "q": "Which method stratifies by column?",
        "type": "mcq",
        "o": [
            "sampleBy",
            "stratify",
            "groupSample",
            "columnSample"
        ]
    },
    {
        "q": "randomSplit creates train/test sets.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the distinct:",
        "type": "match",
        "left": [
            "distinct",
            "dropDuplicates",
            "countDistinct",
            "approx_count_distinct"
        ],
        "right": [
            "Unique rows",
            "By columns",
            "Exact count",
            "Approximate"
        ]
    },
    {
        "q": "The ______ removes all duplicates.",
        "type": "fill_blank",
        "answers": [
            "distinct"
        ],
        "other_options": [
            "unique",
            "deduplicate",
            "removeDups"
        ]
    },
    {
        "q": "Which method dedupes by columns?",
        "type": "mcq",
        "o": [
            "dropDuplicates",
            "distinct",
            "unique",
            "removeDuplicates"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.dropDuplicates(Seq(\"col\")).count()",
        "o": [
            "Unique count by col",
            "Error",
            "All rows",
            "null"
        ]
    },
    {
        "q": "Rearrange deduplication:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "dropDuplicates()",
            ".",
            "show()"
        ]
    },
    {
        "q": "Match the union operations:",
        "type": "match",
        "left": [
            "union",
            "unionAll",
            "unionByName",
            "intersect"
        ],
        "right": [
            "Combine",
            "Combine all",
            "By column name",
            "Common rows"
        ]
    },
    {
        "q": "The ______ unions by position.",
        "type": "fill_blank",
        "answers": [
            "union"
        ],
        "other_options": [
            "combine",
            "merge",
            "append"
        ]
    },
    {
        "q": "Which method unions by name?",
        "type": "mcq",
        "o": [
            "unionByName",
            "union",
            "merge",
            "combine"
        ]
    },
    {
        "q": "union removes duplicates.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the except/minus:",
        "type": "match",
        "left": [
            "except",
            "exceptAll",
            "subtract",
            "minus"
        ],
        "right": [
            "Distinct diff",
            "All diff",
            "RDD diff",
            "Alias"
        ]
    },
    {
        "q": "The ______ removes rows in other.",
        "type": "fill_blank",
        "answers": [
            "except"
        ],
        "other_options": [
            "minus",
            "remove",
            "without"
        ]
    },
    {
        "q": "Which keeps all duplicates?",
        "type": "mcq",
        "o": [
            "exceptAll",
            "except",
            "subtract",
            "minus"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df1.except(df2).count()",
        "o": [
            "Rows in df1 not df2",
            "Error",
            "0",
            "null"
        ]
    },
    {
        "q": "Rearrange set operations:",
        "type": "rearrange",
        "words": [
            "df1",
            ".",
            "union(df2)",
            ".",
            "distinct()"
        ]
    },
    {
        "q": "Match the pivot operations:",
        "type": "match",
        "left": [
            "pivot",
            "unpivot",
            "melt",
            "stack"
        ],
        "right": [
            "Columns from rows",
            "Rows from columns",
            "Wide to long",
            "SQL unpivot"
        ]
    },
    {
        "q": "The ______ creates columns from values.",
        "type": "fill_blank",
        "answers": [
            "pivot"
        ],
        "other_options": [
            "spread",
            "widen",
            "transpose"
        ]
    },
    {
        "q": "Which method converts wide to long?",
        "type": "mcq",
        "o": [
            "unpivot/melt",
            "pivot",
            "stack",
            "transpose"
        ]
    },
    {
        "q": "Pivot requires aggregation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the cube/rollup:",
        "type": "match",
        "left": [
            "cube",
            "rollup",
            "grouping",
            "grouping_id"
        ],
        "right": [
            "All combinations",
            "Hierarchical",
            "Is null",
            "Bit mask"
        ]
    },
    {
        "q": "The ______ creates all combinations.",
        "type": "fill_blank",
        "answers": [
            "cube"
        ],
        "other_options": [
            "all",
            "combinations",
            "cross"
        ]
    },
    {
        "q": "Which creates hierarchical groups?",
        "type": "mcq",
        "o": [
            "rollup",
            "cube",
            "groupBy",
            "hierarchy"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "df.cube(\"a\", \"b\").count().show()",
        "o": [
            "All grouping combinations",
            "Error",
            "Two columns",
            "null"
        ]
    },
    {
        "q": "Rearrange rollup:",
        "type": "rearrange",
        "words": [
            "df",
            ".",
            "rollup()",
            ".",
            "agg()",
            ".",
            "show()"
        ]
    },
    {
        "q": "Match the hints:",
        "type": "match",
        "left": [
            "broadcast",
            "shuffle_hash",
            "shuffle_merge",
            "coalesce"
        ],
        "right": [
            "Broadcast join",
            "Hash join",
            "Sort merge",
            "Reduce partitions"
        ]
    },
    {
        "q": "The ______ hint forces broadcast.",
        "type": "fill_blank",
        "answers": [
            "broadcast"
        ],
        "other_options": [
            "bcast",
            "small",
            "replicate"
        ]
    },
    {
        "q": "Which hint forces sort merge?",
        "type": "mcq",
        "o": [
            "shuffle_merge",
            "merge",
            "sort",
            "sorted"
        ]
    },
    {
        "q": "Hints guide optimizer decisions.",
        "type": "true_false",
        "correct": "True"
    }
]