{
    "id": "learn_neural_nets",
    "topicId": "neural_nets",
    "topicTitle": "Neural Networks",
    "description": "Introduction to neural networks, deep learning, and modern architectures",
    "baseKP": 90,
    "slides": [
        {
            "id": "neural_nets_1",
            "type": "content",
            "title": "Introduction to Neural Networks",
            "content": "# Neural Networks ğŸ§ \n\nLearning inspired by the brain.\n\n## What is a Neural Network?\n\nLayers of interconnected nodes that learn patterns.\n\n## Key Components\n\n| Component | Function |\n|-----------|----------|\n| Input layer | Receives data |\n| Hidden layers | Learn features |\n| Output layer | Makes predictions |\n| Weights | Connection strengths |\n| Activation | Introduces non-linearity |\n\n## Why Neural Networks?\n\n- Learn complex patterns\n- Automatic feature extraction\n- State-of-the-art many tasks\n\n> ğŸ’¡ Deep Learning = Neural Networks with many layers!"
        },
        {
            "id": "neural_nets_2",
            "type": "content",
            "title": "Building Blocks",
            "content": "# Neural Network Building Blocks ğŸ”§\n\n## Neurons\n\noutput = activation(Î£(weight Ã— input) + bias)\n\n## Activation Functions\n\n| Function | Output | Use Case |\n|----------|--------|----------|\n| ReLU | [0, âˆ) | Hidden layers |\n| Sigmoid | [0, 1] | Binary output |\n| Softmax | Probabilities | Multi-class |\n| Tanh | [-1, 1] | Hidden layers |\n\n## Loss Functions\n\n- Classification: Cross-entropy\n- Regression: MSE\n\n## Optimization\n\n- Gradient Descent\n- Adam (popular)\n- Learning rate\n\n> ğŸ¯ Choose components based on task!"
        },
        {
            "id": "neural_nets_quiz_1",
            "type": "quiz",
            "title": "NN Basics Quiz",
            "content": "Test your knowledge!",
            "quizQuestion": "Which activation function is most commonly used in hidden layers?",
            "quizOptions": [
                "Sigmoid",
                "ReLU",
                "Softmax",
                "Linear"
            ],
            "correctOptionIndex": 1
        },
        {
            "id": "neural_nets_3",
            "type": "content",
            "title": "Training Neural Networks",
            "content": "# Training Neural Networks ğŸ“ˆ\n\n## Forward Pass\n\nData flows through network to output.\n\n## Loss Calculation\n\nMeasure error between prediction and actual.\n\n## Backpropagation\n\nCalculate gradients of loss w.r.t. weights.\n\n## Weight Update\n\nw = w - learning_rate Ã— gradient\n\n## Training Tips\n\n| Issue | Solution |\n|-------|----------|\n| Slow convergence | Adjust learning rate |\n| Overfitting | Dropout, regularization |\n| Vanishing gradient | ReLU, batch norm |\n\n> ğŸ’¡ Training is iterative optimization!"
        },
        {
            "id": "neural_nets_4",
            "type": "content",
            "title": "Types of Networks",
            "content": "# Types of Neural Networks ğŸŒ\n\n## Feedforward (MLP)\n\n- Fully connected layers\n- General purpose\n\n## CNN (Convolutional)\n\n- Image processing\n- Spatial patterns\n\n## RNN (Recurrent)\n\n- Sequential data\n- Time series, text\n\n## Transformer\n\n- Attention mechanism\n- NLP revolution (BERT, GPT)\n\n| Network | Best For |\n|---------|----------|\n| MLP | Tabular data |\n| CNN | Images |\n| RNN/LSTM | Sequences |\n| Transformer | Text, large data |\n\n> ğŸ¯ Choose architecture based on data type!"
        },
        {
            "id": "neural_nets_5",
            "type": "content",
            "title": "Deep Learning Frameworks",
            "content": "# Deep Learning Frameworks ğŸ› ï¸\n\n## Popular Frameworks\n\n### TensorFlow\n- Google\n- Production ready\n- TensorFlow Lite for mobile\n\n### PyTorch\n- Facebook/Meta\n- Research favorite\n- Dynamic computation\n\n### Keras\n- High-level API\n- Built into TensorFlow\n- Beginner friendly\n\n## Comparison\n\n| Framework | Strength |\n|-----------|----------|\n| TensorFlow | Production |\n| PyTorch | Research |\n| Keras | Simplicity |\n\n> ğŸ’¡ PyTorch gaining in popularity!"
        },
        {
            "id": "neural_nets_quiz_2",
            "type": "quiz",
            "title": "Architecture Quiz",
            "content": "Test your knowledge!",
            "quizQuestion": "Which architecture is best for image classification?",
            "quizOptions": [
                "RNN",
                "CNN",
                "Transformer",
                "Simple MLP"
            ],
            "correctOptionIndex": 1
        },
        {
            "id": "neural_nets_6",
            "type": "content",
            "title": "Summary",
            "content": "# Congratulations! ğŸ‰\n\nYou've learned Neural Networks!\n\n## Key Concepts\n\n- âœ… Layers learn features\n- âœ… Backprop updates weights\n- âœ… Activation adds non-linearity\n- âœ… Architecture depends on data type\n\n## Architecture Guide\n\n| Data Type | Use |\n|-----------|-----|\n| Tabular | MLP |\n| Images | CNN |\n| Sequences | RNN/LSTM |\n| Text | Transformer |\n\n## Next Steps\n\n- Try TensorFlow or PyTorch\n- Build simple models first\n- Learn transfer learning\n\n> ğŸš€ Deep Learning powers modern AI!\n\nKeep learning! ğŸ§ "
        }
    ]
}