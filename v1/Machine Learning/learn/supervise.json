{
    "id": "learn_supervised",
    "topicId": "supervised",
    "topicTitle": "Supervised Learning",
    "description": "Master classification and regression algorithms including decision trees and SVM",
    "baseKP": 85,
    "slides": [
        {
            "id": "supervised_1",
            "type": "content",
            "title": "What is Supervised Learning",
            "content": "# Supervised Learning ğŸ¯\n\nLearning from labeled examples.\n\n## Definition\n\nSupervised learning uses labeled training data (input + correct output) to learn a mapping function.\n\n## Two Main Types\n\n### Classification\n- Predict discrete categories\n- Spam/Not spam, Cat/Dog\n\n### Regression\n- Predict continuous values\n- House price, temperature\n\n## The Process\n\n1. Collect labeled data\n2. Train model\n3. Predict new instances\n4. Evaluate performance\n\n> ğŸ’¡ The 'supervision' comes from labeled examples!"
        },
        {
            "id": "supervised_2",
            "type": "content",
            "title": "Linear Regression",
            "content": "# Linear Regression ğŸ“ˆ\n\nPredicting continuous values.\n\n## The Model\n\n**y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Îµ**\n\n## Goal\n\nMinimize squared errors (MSE).\n\n## Use Cases\n\n- Price prediction\n- Sales forecasting\n- Stock returns\n\n## Pros/Cons\n\n| Pros | Cons |\n|------|------|\n| Simple | Linear only |\n| Interpretable | Sensitive to outliers |\n| Fast | Assumes normality |\n\n```python\nimport numpy as np\nX = np.array([[1], [2], [3], [4], [5]])\ny = np.array([2, 4, 5, 4, 5])\n# Use: from sklearn.linear_model import LinearRegression\n```"
        },
        {
            "id": "supervised_quiz_1",
            "type": "quiz",
            "title": "Regression Quiz",
            "content": "Test your knowledge!",
            "quizQuestion": "Which metric is commonly used to evaluate regression models?",
            "quizOptions": [
                "Accuracy",
                "Precision",
                "Mean Squared Error (MSE)",
                "F1 Score"
            ],
            "correctOptionIndex": 2
        },
        {
            "id": "supervised_3",
            "type": "content",
            "title": "Logistic Regression",
            "content": "# Logistic Regression ğŸ“Š\n\nClassification despite the name!\n\n## The Model\n\nPredicts probability using sigmoid function.\n\n**P(y=1) = 1 / (1 + e^-(Î²â‚€ + Î²â‚x))**\n\n## Output\n\n- Probability between 0 and 1\n- Apply threshold (usually 0.5)\n\n## Use Cases\n\n- Spam detection\n- Medical diagnosis\n- Credit scoring\n\n## Decision Boundary\n\nLinear separator between classes.\n\n> ğŸ’¡ Logistic regression is the baseline for classification!"
        },
        {
            "id": "supervised_4",
            "type": "content",
            "title": "Decision Trees",
            "content": "# Decision Trees ğŸŒ³\n\nTree-structured decisions.\n\n## How It Works\n\n- Split data on features\n- Create if-then rules\n- Leaf nodes = predictions\n\n## Key Terms\n\n| Term | Meaning |\n|------|--------|\n| Node | Decision point |\n| Branch | Outcome path |\n| Leaf | Final prediction |\n| Depth | Levels in tree |\n\n## Pros/Cons\n\n| Pros | Cons |\n|------|------|\n| Interpretable | Overfits easily |\n| No scaling needed | Unstable |\n| Handles mixed types | Biased to dominant |\n\n## Hyperparameters\n\n- max_depth\n- min_samples_split\n- min_samples_leaf\n\n> ğŸ¯ Great for interpretability!"
        },
        {
            "id": "supervised_5",
            "type": "content",
            "title": "Random Forest",
            "content": "# Random Forest ğŸŒ²ğŸŒ²ğŸŒ²\n\nEnsemble of decision trees.\n\n## How It Works\n\n1. Build many trees on random subsets\n2. Each tree votes\n3. Majority vote wins (classification)\n4. Average for regression\n\n## Why It Works\n\n- Reduces overfitting\n- Averages out noise\n- Handles outliers\n\n## Key Parameters\n\n| Parameter | Effect |\n|-----------|--------|\n| n_estimators | Number of trees |\n| max_depth | Tree complexity |\n| max_features | Features per split |\n\n## When to Use\n\n- Strong baseline model\n- Mixed feature types\n- Need feature importance\n\n> ğŸ’¡ RF is often the go-to algorithm!"
        },
        {
            "id": "supervised_quiz_2",
            "type": "quiz",
            "title": "Trees Quiz",
            "content": "Test your knowledge!",
            "quizQuestion": "Random Forest reduces overfitting by:",
            "quizOptions": [
                "Using deeper trees",
                "Training on ALL data",
                "Averaging predictions from many trees",
                "Using fewer features total"
            ],
            "correctOptionIndex": 2
        },
        {
            "id": "supervised_6",
            "type": "content",
            "title": "Support Vector Machines",
            "content": "# Support Vector Machines ğŸ“\n\nFinding the optimal decision boundary.\n\n## Key Concept\n\nMaximize margin between classes.\n\n## Support Vectors\n\nData points closest to boundary.\n\n## Kernel Trick\n\n- Linear: Straight boundary\n- RBF: Curved boundary\n- Poly: Polynomial boundary\n\n## When to Use\n\n- Clear margin of separation\n- High-dimensional data\n- Text classification\n\n## Pros/Cons\n\n| Pros | Cons |\n|------|------|\n| Works in high dimensions | Slow on large data |\n| Memory efficient | Sensitive to scaling |\n| Effective | Hard to interpret |\n\n> ğŸ¯ Great for text and image classification!"
        },
        {
            "id": "supervised_7",
            "type": "content",
            "title": "Summary",
            "content": "# Congratulations! ğŸ‰\n\nYou've mastered Supervised Learning!\n\n## Algorithms Summary\n\n| Algorithm | Type | Best For |\n|-----------|------|----------|\n| Linear Regression | Regression | Simple relationships |\n| Logistic Regression | Classification | Baseline |\n| Decision Trees | Both | Interpretability |\n| Random Forest | Both | General purpose |\n| SVM | Classification | High dimensions |\n\n## Key Takeaways\n\n- âœ… Start with simple models\n- âœ… Use Random Forest as baseline\n- âœ… Evaluate on test data\n- âœ… Consider interpretability needs\n\n> ğŸš€ Supervised learning solves most business problems!\n\nKeep learning! ğŸ¤–"
        }
    ]
}