[
    {
        "title": "Neural Networks Intro ðŸ§ ",
        "ques": "What is a **Neural Network**?",
        "answer": {
            "type": "text",
            "content": "### Neural Network:\n\n**Definition:** Computing system inspired by biological neurons.\n\n### Structure:\n| Layer | Function |\n|-------|----------|\n| Input | Receive features |\n| Hidden | Learn patterns |\n| Output | Make predictions |\n\n### Deep Learning: Networks with many hidden layers"
        },
        "explanation": "**Neural networks** learn complex patterns through layers."
    },
    {
        "title": "Activation Functions âš¡",
        "ques": "What are **activation functions**?",
        "answer": {
            "type": "text",
            "content": "### Activation Functions:\n\n**Purpose:** Add non-linearity to networks.\n\n| Function | Use Case |\n|----------|----------|\n| **ReLU** | Hidden layers (most common) |\n| **Sigmoid** | Binary output |\n| **Softmax** | Multi-class output |\n| **Tanh** | Range -1 to 1 |\n\n### Why Needed:\nWithout activation, network is just linear."
        },
        "explanation": "**Activations** enable learning complex patterns."
    },
    {
        "title": "CNN Basics ðŸ“·",
        "ques": "What are **CNNs** used for?",
        "answer": {
            "type": "text",
            "content": "### Convolutional Neural Networks:\n\n**Best For:** Image and spatial data.\n\n### Key Layers:\n| Layer | Purpose |\n|-------|--------|\n| **Convolution** | Detect features |\n| **Pooling** | Reduce dimensions |\n| **Fully Connected** | Final predictions |\n\n### Applications:\n- Image classification\n- Object detection\n- Facial recognition"
        },
        "explanation": "**CNNs** excel at visual pattern recognition."
    },
    {
        "title": "RNN Overview ðŸ”„",
        "ques": "What are **RNNs** designed for?",
        "answer": {
            "type": "text",
            "content": "### Recurrent Neural Networks:\n\n**Best For:** Sequential/time series data.\n\n### Key Feature:\nLoops allow information to persist.\n\n### Variants:\n| Type | Improvement |\n|------|-------------|\n| **LSTM** | Long-term memory |\n| **GRU** | Simpler, faster |\n\n### Applications:\n- Text generation\n- Time series prediction\n- Speech recognition"
        },
        "explanation": "**RNNs** process sequences with memory."
    },
    {
        "title": "Training Methods ðŸŽ¯",
        "ques": "What is **backpropagation**?",
        "answer": {
            "type": "text",
            "content": "### Backpropagation:\n\n**Definition:** Algorithm to update network weights.\n\n### Process:\n1. Forward pass: Calculate predictions\n2. Calculate loss\n3. Backward pass: Compute gradients\n4. Update weights using gradient descent\n\n### Optimizers:\n- SGD, Adam, RMSprop"
        },
        "explanation": "**Backpropagation** is how neural networks learn."
    },
    {
        "title": "Transfer Learning ðŸ”„",
        "ques": "What is **transfer learning**?",
        "answer": {
            "type": "text",
            "content": "### Transfer Learning:\n\n**Definition:** Use pre-trained model for new task.\n\n### Benefits:\n| Benefit | Reason |\n|---------|--------|\n| Less data needed | Leverages existing knowledge |\n| Faster training | Start from trained weights |\n| Better results | Pre-trained on large data |\n\n### Popular Models:\n- ResNet, VGG (images)\n- BERT, GPT (text)"
        },
        "explanation": "**Transfer learning** accelerates development with less data."
    }
]