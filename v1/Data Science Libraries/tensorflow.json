[
    {
        "q": "Which library is TensorFlow built by?",
        "type": "mcq",
        "o": [
            "Google",
            "Facebook",
            "Microsoft",
            "Amazon"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(tf.__name__)",
        "o": [
            "tensorflow",
            "tf",
            "TensorFlow",
            "None"
        ]
    },
    {
        "q": "Match the TensorFlow concepts:",
        "type": "match",
        "left": [
            "Tensor",
            "Graph",
            "Session"
        ],
        "right": [
            "Multi-dimensional array",
            "Computation structure",
            "Execution context"
        ]
    },
    {
        "q": "The ______ alias is commonly used for TensorFlow.",
        "type": "fill_blank",
        "answers": [
            "tf"
        ],
        "other_options": [
            "tensorflow",
            "tens",
            "tflow"
        ]
    },
    {
        "q": "TensorFlow 2.x uses eager execution by default.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which API is the high-level interface in TensorFlow?",
        "type": "mcq",
        "o": [
            "Keras",
            "Core",
            "Lite",
            "Graph"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3])\nprint(type(x).__name__)",
        "o": [
            "EagerTensor",
            "Tensor",
            "Constant",
            "Array"
        ]
    },
    {
        "q": "Match the TensorFlow components:",
        "type": "match",
        "left": [
            "tf.keras",
            "tf.data",
            "tf.lite"
        ],
        "right": [
            "Neural networks",
            "Data pipelines",
            "Mobile deployment"
        ]
    },
    {
        "q": "The ______ creates constant tensors.",
        "type": "fill_blank",
        "answers": [
            "tf.constant"
        ],
        "other_options": [
            "tf.tensor",
            "tf.array",
            "tf.create"
        ]
    },
    {
        "q": "Rearrange the TensorFlow workflow:",
        "type": "rearrange",
        "words": [
            "import tensorflow",
            "build model",
            "train model",
            "evaluate"
        ]
    },
    {
        "q": "Keras is integrated into TensorFlow 2.x.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates a variable tensor?",
        "type": "mcq",
        "o": [
            "tf.Variable",
            "tf.var",
            "tf.mutable",
            "tf.changeable"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nv = tf.Variable([1, 2, 3])\nprint(v.trainable)",
        "o": [
            "True",
            "False",
            "None",
            "Error"
        ]
    },
    {
        "q": "Match the tensor types:",
        "type": "match",
        "left": [
            "tf.constant",
            "tf.Variable",
            "tf.placeholder"
        ],
        "right": [
            "Immutable",
            "Trainable",
            "TF1 input"
        ]
    },
    {
        "q": "The ______ attribute indicates if variable is trainable.",
        "type": "fill_blank",
        "answers": [
            "trainable"
        ],
        "other_options": [
            "mutable",
            "learnable",
            "updatable"
        ]
    },
    {
        "q": "Variables are used for model weights.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates tensors filled with zeros?",
        "type": "mcq",
        "o": [
            "tf.zeros",
            "tf.zero",
            "tf.empty",
            "tf.null"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.zeros([2, 3])\nprint(x.shape)",
        "o": [
            "(2, 3)",
            "[2, 3]",
            "6",
            "None"
        ]
    },
    {
        "q": "Match the tensor creation functions:",
        "type": "match",
        "left": [
            "tf.zeros",
            "tf.ones",
            "tf.fill"
        ],
        "right": [
            "All zeros",
            "All ones",
            "Custom value"
        ]
    },
    {
        "q": "The ______ creates tensors filled with ones.",
        "type": "fill_blank",
        "answers": [
            "tf.ones"
        ],
        "other_options": [
            "tf.one",
            "tf.all_ones",
            "tf.unit"
        ]
    },
    {
        "q": "Rearrange the tensor creation by complexity:",
        "type": "rearrange",
        "words": [
            "tf.zeros",
            "tf.ones",
            "tf.random.normal"
        ]
    },
    {
        "q": "tf.zeros_like creates zeros with same shape.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function gets tensor shape?",
        "type": "mcq",
        "o": [
            "tensor.shape or tf.shape()",
            "tensor.size()",
            "tensor.dims()",
            "tf.dimensions()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([[1, 2], [3, 4], [5, 6]])\nprint(len(x.shape))",
        "o": [
            "2",
            "3",
            "6",
            "1"
        ]
    },
    {
        "q": "Match the tensor attributes:",
        "type": "match",
        "left": [
            "shape",
            "dtype",
            "device"
        ],
        "right": [
            "Dimensions",
            "Data type",
            "Placement"
        ]
    },
    {
        "q": "The ______ attribute shows tensor data type.",
        "type": "fill_blank",
        "answers": [
            "dtype"
        ],
        "other_options": [
            "type",
            "datatype",
            "kind"
        ]
    },
    {
        "q": "Tensors can be placed on CPU or GPU.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function reshapes tensors?",
        "type": "mcq",
        "o": [
            "tf.reshape",
            "tf.resize",
            "tf.transform",
            "tf.reformat"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3, 4, 5, 6])\ny = tf.reshape(x, [2, 3])\nprint(y.shape)",
        "o": [
            "(2, 3)",
            "(3, 2)",
            "(6,)",
            "Error"
        ]
    },
    {
        "q": "Match the shape operations:",
        "type": "match",
        "left": [
            "tf.reshape",
            "tf.squeeze",
            "tf.expand_dims"
        ],
        "right": [
            "Change shape",
            "Remove dim",
            "Add dim"
        ]
    },
    {
        "q": "The ______ removes dimensions of size 1.",
        "type": "fill_blank",
        "answers": [
            "tf.squeeze"
        ],
        "other_options": [
            "tf.reduce",
            "tf.flatten",
            "tf.compress"
        ]
    },
    {
        "q": "-1 in reshape infers the dimension.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the shape manipulation:",
        "type": "rearrange",
        "words": [
            "original shape",
            "calculate new shape",
            "call reshape"
        ]
    },
    {
        "q": "Which function performs matrix multiplication?",
        "type": "mcq",
        "o": [
            "tf.matmul",
            "tf.multiply",
            "tf.dot",
            "tf.mm"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\na = tf.constant([[1, 2], [3, 4]])\nb = tf.constant([[5, 6], [7, 8]])\nc = tf.matmul(a, b)\nprint(c[0, 0].numpy())",
        "o": [
            "19",
            "5",
            "26",
            "12"
        ]
    },
    {
        "q": "Match the math operations:",
        "type": "match",
        "left": [
            "tf.add",
            "tf.multiply",
            "tf.matmul"
        ],
        "right": [
            "Element-wise add",
            "Element-wise multiply",
            "Matrix multiply"
        ]
    },
    {
        "q": "The ______ performs element-wise multiplication.",
        "type": "fill_blank",
        "answers": [
            "tf.multiply"
        ],
        "other_options": [
            "tf.matmul",
            "tf.dot",
            "tf.mul"
        ]
    },
    {
        "q": "@ operator can be used for matrix multiplication.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates Sequential model?",
        "type": "mcq",
        "o": [
            "tf.keras.Sequential",
            "tf.Sequential",
            "keras.Sequential",
            "tf.model.Sequential"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential()\nprint(type(model).__name__)",
        "o": [
            "Sequential",
            "Model",
            "Keras",
            "Network"
        ]
    },
    {
        "q": "Match the model types:",
        "type": "match",
        "left": [
            "Sequential",
            "Functional",
            "Subclassed"
        ],
        "right": [
            "Linear stack",
            "DAG topology",
            "Custom logic"
        ]
    },
    {
        "q": "The ______ API creates models from layers list.",
        "type": "fill_blank",
        "answers": [
            "Sequential"
        ],
        "other_options": [
            "Functional",
            "Stack",
            "Linear"
        ]
    },
    {
        "q": "Rearrange the model creation:",
        "type": "rearrange",
        "words": [
            "create Sequential",
            "add layers",
            "compile",
            "train"
        ]
    },
    {
        "q": "Sequential models support multiple inputs.",
        "type": "true_false",
        "correct": "False"
    },
    {
        "q": "Which layer is the most basic neural network layer?",
        "type": "mcq",
        "o": [
            "Dense",
            "Conv2D",
            "LSTM",
            "Flatten"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Dense(10)\nprint(type(layer).__name__)",
        "o": [
            "Dense",
            "Layer",
            "FullyConnected",
            "Linear"
        ]
    },
    {
        "q": "Match the layer types:",
        "type": "match",
        "left": [
            "Dense",
            "Conv2D",
            "LSTM"
        ],
        "right": [
            "Fully connected",
            "Convolutional",
            "Recurrent"
        ]
    },
    {
        "q": "The ______ parameter sets number of neurons.",
        "type": "fill_blank",
        "answers": [
            "units"
        ],
        "other_options": [
            "neurons",
            "nodes",
            "size"
        ]
    },
    {
        "q": "Dense layers apply weights and bias.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which activation function is commonly used?",
        "type": "mcq",
        "o": [
            "relu",
            "step",
            "linear",
            "identity"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([-1.0, 0.0, 1.0])\ny = tf.nn.relu(x)\nprint(y.numpy()[0])",
        "o": [
            "0.0",
            "-1.0",
            "1.0",
            "None"
        ]
    },
    {
        "q": "Match the activation functions:",
        "type": "match",
        "left": [
            "relu",
            "sigmoid",
            "softmax"
        ],
        "right": [
            "Max(0, x)",
            "0 to 1",
            "Probability distribution"
        ]
    },
    {
        "q": "The ______ activation outputs probabilities.",
        "type": "fill_blank",
        "answers": [
            "softmax"
        ],
        "other_options": [
            "sigmoid",
            "relu",
            "tanh"
        ]
    },
    {
        "q": "Rearrange the activation by range:",
        "type": "rearrange",
        "words": [
            "relu: 0 to inf",
            "sigmoid: 0 to 1",
            "tanh: -1 to 1"
        ]
    },
    {
        "q": "ReLU helps with vanishing gradient.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function compiles a model?",
        "type": "mcq",
        "o": [
            "model.compile()",
            "model.build()",
            "model.setup()",
            "model.configure()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(10)])\nmodel.compile(optimizer='adam', loss='mse')\nprint('success')",
        "o": [
            "success",
            "Error",
            "None",
            "Model"
        ]
    },
    {
        "q": "Match the compile parameters:",
        "type": "match",
        "left": [
            "optimizer",
            "loss",
            "metrics"
        ],
        "right": [
            "Update algorithm",
            "Objective function",
            "Evaluation measures"
        ]
    },
    {
        "q": "The ______ parameter sets the loss function.",
        "type": "fill_blank",
        "answers": [
            "loss"
        ],
        "other_options": [
            "objective",
            "cost",
            "error"
        ]
    },
    {
        "q": "compile() must be called before training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which optimizer is commonly used?",
        "type": "mcq",
        "o": [
            "adam",
            "basic",
            "simple",
            "default"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\nprint(type(opt).__name__)",
        "o": [
            "Adam",
            "Optimizer",
            "SGD",
            "Gradient"
        ]
    },
    {
        "q": "Match the optimizers:",
        "type": "match",
        "left": [
            "SGD",
            "Adam",
            "RMSprop"
        ],
        "right": [
            "Basic gradient",
            "Adaptive momentum",
            "Root mean square"
        ]
    },
    {
        "q": "The ______ parameter controls step size.",
        "type": "fill_blank",
        "answers": [
            "learning_rate"
        ],
        "other_options": [
            "lr",
            "step",
            "rate"
        ]
    },
    {
        "q": "Rearrange the optimizers by complexity:",
        "type": "rearrange",
        "words": [
            "SGD: basic",
            "Momentum: accelerated",
            "Adam: adaptive"
        ]
    },
    {
        "q": "Adam combines momentum and RMSprop.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which loss is used for binary classification?",
        "type": "mcq",
        "o": [
            "binary_crossentropy",
            "mse",
            "mae",
            "hinge"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nloss_fn = tf.keras.losses.BinaryCrossentropy()\nprint(type(loss_fn).__name__)",
        "o": [
            "BinaryCrossentropy",
            "Loss",
            "Binary",
            "Crossentropy"
        ]
    },
    {
        "q": "Match the loss functions:",
        "type": "match",
        "left": [
            "mse",
            "binary_crossentropy",
            "sparse_categorical_crossentropy"
        ],
        "right": [
            "Regression",
            "Binary class",
            "Multi-class integer"
        ]
    },
    {
        "q": "The ______ loss is for regression.",
        "type": "fill_blank",
        "answers": [
            "mse"
        ],
        "other_options": [
            "bce",
            "cce",
            "mae"
        ]
    },
    {
        "q": "Crossentropy measures prediction confidence.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function trains the model?",
        "type": "mcq",
        "o": [
            "model.fit()",
            "model.train()",
            "model.learn()",
            "model.run()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nimport numpy as np\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nmodel.compile(optimizer='adam', loss='mse')\nX = np.array([[1], [2]])\ny = np.array([1, 2])\nhistory = model.fit(X, y, epochs=1, verbose=0)\nprint(type(history).__name__)",
        "o": [
            "History",
            "Model",
            "Fit",
            "Training"
        ]
    },
    {
        "q": "Match the fit parameters:",
        "type": "match",
        "left": [
            "epochs",
            "batch_size",
            "validation_data"
        ],
        "right": [
            "Training passes",
            "Samples per update",
            "Validation set"
        ]
    },
    {
        "q": "The ______ parameter sets number of passes.",
        "type": "fill_blank",
        "answers": [
            "epochs"
        ],
        "other_options": [
            "iterations",
            "passes",
            "cycles"
        ]
    },
    {
        "q": "fit() returns training history.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the training workflow:",
        "type": "rearrange",
        "words": [
            "prepare data",
            "build model",
            "compile",
            "fit"
        ]
    },
    {
        "q": "Which function evaluates the model?",
        "type": "mcq",
        "o": [
            "model.evaluate()",
            "model.test()",
            "model.score()",
            "model.check()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nimport numpy as np\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nmodel.compile(optimizer='adam', loss='mse')\nX = np.array([[1], [2]])\ny = np.array([1, 2])\nresult = model.evaluate(X, y, verbose=0)\nprint(type(result))",
        "o": [
            "<class 'float'>",
            "<class 'list'>",
            "<class 'dict'>",
            "<class 'tuple'>"
        ]
    },
    {
        "q": "evaluate() returns loss and metrics.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the model methods:",
        "type": "match",
        "left": [
            "fit",
            "evaluate",
            "predict"
        ],
        "right": [
            "Train",
            "Test",
            "Inference"
        ]
    },
    {
        "q": "Which function makes predictions?",
        "type": "mcq",
        "o": [
            "model.predict()",
            "model.inference()",
            "model.forward()",
            "model.output()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nimport numpy as np\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nX = np.array([[1], [2]])\npreds = model.predict(X, verbose=0)\nprint(preds.shape)",
        "o": [
            "(2, 1)",
            "(2,)",
            "(1, 2)",
            "Error"
        ]
    },
    {
        "q": "The ______ method returns predictions.",
        "type": "fill_blank",
        "answers": [
            "predict"
        ],
        "other_options": [
            "inference",
            "forward",
            "call"
        ]
    },
    {
        "q": "predict() returns numpy arrays.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer flattens input?",
        "type": "mcq",
        "o": [
            "Flatten",
            "Reshape",
            "Dense",
            "Squeeze"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Flatten()\nx = tf.constant([[[1, 2], [3, 4]]])\nprint(layer(x).shape)",
        "o": [
            "(1, 4)",
            "(4,)",
            "(2, 2)",
            "(1, 2, 2)"
        ]
    },
    {
        "q": "Match the reshaping layers:",
        "type": "match",
        "left": [
            "Flatten",
            "Reshape",
            "Permute"
        ],
        "right": [
            "To 1D",
            "Any shape",
            "Reorder dims"
        ]
    },
    {
        "q": "Flatten is used before Dense layers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the CNN structure:",
        "type": "rearrange",
        "words": [
            "Conv2D",
            "MaxPooling2D",
            "Flatten",
            "Dense"
        ]
    },
    {
        "q": "Which layer performs 2D convolution?",
        "type": "mcq",
        "o": [
            "Conv2D",
            "Convolution",
            "Filter2D",
            "Kernel2D"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Conv2D(32, (3, 3))\nprint(type(layer).__name__)",
        "o": [
            "Conv2D",
            "Convolution",
            "Layer",
            "Filter"
        ]
    },
    {
        "q": "Match the Conv2D parameters:",
        "type": "match",
        "left": [
            "filters",
            "kernel_size",
            "strides"
        ],
        "right": [
            "Number of outputs",
            "Filter dimensions",
            "Step size"
        ]
    },
    {
        "q": "The ______ parameter sets filter dimensions.",
        "type": "fill_blank",
        "answers": [
            "kernel_size"
        ],
        "other_options": [
            "filter_size",
            "window",
            "size"
        ]
    },
    {
        "q": "Conv2D extracts spatial features.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer performs pooling?",
        "type": "mcq",
        "o": [
            "MaxPooling2D",
            "Pool2D",
            "Downsample",
            "Reduce2D"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.MaxPooling2D((2, 2))\nprint(type(layer).__name__)",
        "o": [
            "MaxPooling2D",
            "Pooling",
            "MaxPool",
            "Layer"
        ]
    },
    {
        "q": "Match the pooling types:",
        "type": "match",
        "left": [
            "MaxPooling2D",
            "AveragePooling2D",
            "GlobalMaxPooling2D"
        ],
        "right": [
            "Max value",
            "Average value",
            "Global max"
        ]
    },
    {
        "q": "Pooling reduces spatial dimensions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer adds dropout regularization?",
        "type": "mcq",
        "o": [
            "Dropout",
            "Regularize",
            "DropConnect",
            "Noise"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Dropout(0.25)\nprint(type(layer).__name__)",
        "o": [
            "Dropout",
            "Regularization",
            "Layer",
            "Drop"
        ]
    },
    {
        "q": "Match the regularization layers:",
        "type": "match",
        "left": [
            "Dropout",
            "BatchNormalization",
            "L2"
        ],
        "right": [
            "Random zeroing",
            "Normalize activations",
            "Weight penalty"
        ]
    },
    {
        "q": "The ______ parameter sets dropout rate.",
        "type": "fill_blank",
        "answers": [
            "rate"
        ],
        "other_options": [
            "drop",
            "prob",
            "percent"
        ]
    },
    {
        "q": "Dropout is only active during training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the regularization by type:",
        "type": "rearrange",
        "words": [
            "Dropout: random",
            "L1/L2: weight",
            "BatchNorm: activation"
        ]
    },
    {
        "q": "Which layer normalizes batch activations?",
        "type": "mcq",
        "o": [
            "BatchNormalization",
            "LayerNormalization",
            "Normalize",
            "StandardScale"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.BatchNormalization()\nprint(type(layer).__name__)",
        "o": [
            "BatchNormalization",
            "Normalization",
            "Layer",
            "Batch"
        ]
    },
    {
        "q": "BatchNormalization speeds up training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the normalization layers:",
        "type": "match",
        "left": [
            "BatchNormalization",
            "LayerNormalization"
        ],
        "right": [
            "Across batch",
            "Across layer"
        ]
    },
    {
        "q": "Which LSTM layer processes sequences?",
        "type": "mcq",
        "o": [
            "LSTM",
            "RNN",
            "Sequence",
            "Temporal"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.LSTM(64)\nprint(type(layer).__name__)",
        "o": [
            "LSTM",
            "RNN",
            "Recurrent",
            "Layer"
        ]
    },
    {
        "q": "Match the recurrent layers:",
        "type": "match",
        "left": [
            "SimpleRNN",
            "LSTM",
            "GRU"
        ],
        "right": [
            "Basic",
            "Long memory",
            "Gated"
        ]
    },
    {
        "q": "The ______ parameter returns sequences.",
        "type": "fill_blank",
        "answers": [
            "return_sequences"
        ],
        "other_options": [
            "output_sequences",
            "seq",
            "full_output"
        ]
    },
    {
        "q": "LSTM handles vanishing gradients better.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the RNN by capability:",
        "type": "rearrange",
        "words": [
            "SimpleRNN: basic",
            "GRU: gated",
            "LSTM: full gates"
        ]
    },
    {
        "q": "Which layer does embedding?",
        "type": "mcq",
        "o": [
            "Embedding",
            "Encode",
            "Vectorize",
            "WordVec"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Embedding(1000, 64)\nprint(type(layer).__name__)",
        "o": [
            "Embedding",
            "Encode",
            "Layer",
            "Vector"
        ]
    },
    {
        "q": "Match the Embedding parameters:",
        "type": "match",
        "left": [
            "input_dim",
            "output_dim",
            "input_length"
        ],
        "right": [
            "Vocabulary size",
            "Embedding size",
            "Sequence length"
        ]
    },
    {
        "q": "Embedding converts integers to vectors.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which API creates functional models?",
        "type": "mcq",
        "o": [
            "Input and Model",
            "Sequential",
            "Subclass",
            "Builder"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ninputs = tf.keras.Input(shape=(10,))\nprint(type(inputs).__name__)",
        "o": [
            "KerasTensor",
            "Input",
            "Tensor",
            "Layer"
        ]
    },
    {
        "q": "Match the model APIs:",
        "type": "match",
        "left": [
            "Sequential",
            "Functional",
            "Subclass"
        ],
        "right": [
            "Linear",
            "DAG",
            "Custom"
        ]
    },
    {
        "q": "The ______ defines input shape.",
        "type": "fill_blank",
        "answers": [
            "Input"
        ],
        "other_options": [
            "InputLayer",
            "Shape",
            "Entry"
        ]
    },
    {
        "q": "Rearrange the functional API workflow:",
        "type": "rearrange",
        "words": [
            "define Input",
            "chain layers",
            "create Model"
        ]
    },
    {
        "q": "Functional API supports multiple inputs.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which class subclasses Model?",
        "type": "mcq",
        "o": [
            "tf.keras.Model",
            "tf.keras.Sequential",
            "tf.nn.Module",
            "tf.keras.Layer"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nclass MyModel(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.dense = tf.keras.layers.Dense(10)\nm = MyModel()\nprint(type(m).__name__)",
        "o": [
            "MyModel",
            "Model",
            "Keras",
            "Object"
        ]
    },
    {
        "q": "Match the subclass methods:",
        "type": "match",
        "left": [
            "__init__",
            "call",
            "build"
        ],
        "right": [
            "Setup layers",
            "Forward pass",
            "Lazy creation"
        ]
    },
    {
        "q": "Subclassing provides maximum flexibility.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which method defines forward pass?",
        "type": "mcq",
        "o": [
            "call",
            "forward",
            "run",
            "__call__"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nclass MyLayer(tf.keras.layers.Layer):\n    def call(self, inputs):\n        return inputs * 2\nlayer = MyLayer()\nprint(layer(tf.constant([1.0])).numpy()[0])",
        "o": [
            "2.0",
            "1.0",
            "0.5",
            "Error"
        ]
    },
    {
        "q": "call() is invoked when layer is called.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the custom layer methods:",
        "type": "rearrange",
        "words": [
            "__init__: setup",
            "build: create weights",
            "call: compute"
        ]
    },
    {
        "q": "Which function creates datasets?",
        "type": "mcq",
        "o": [
            "tf.data.Dataset",
            "tf.dataset",
            "tf.Data",
            "tf.loader"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\nprint(type(ds).__name__)",
        "o": [
            "TensorSliceDataset",
            "Dataset",
            "Data",
            "Tensor"
        ]
    },
    {
        "q": "Match the Dataset methods:",
        "type": "match",
        "left": [
            "batch",
            "shuffle",
            "map"
        ],
        "right": [
            "Group samples",
            "Randomize",
            "Transform"
        ]
    },
    {
        "q": "The ______ method groups samples.",
        "type": "fill_blank",
        "answers": [
            "batch"
        ],
        "other_options": [
            "group",
            "chunk",
            "combine"
        ]
    },
    {
        "q": "tf.data enables efficient data loading.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the data pipeline:",
        "type": "rearrange",
        "words": [
            "create dataset",
            "shuffle",
            "batch",
            "prefetch"
        ]
    },
    {
        "q": "Which method caches dataset?",
        "type": "mcq",
        "o": [
            "cache()",
            "save()",
            "store()",
            "memory()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nds = tf.data.Dataset.range(5).batch(2)\nfor batch in ds.take(1):\n    print(len(batch))",
        "o": [
            "2",
            "5",
            "1",
            "3"
        ]
    },
    {
        "q": "Match the pipeline optimization:",
        "type": "match",
        "left": [
            "cache",
            "prefetch",
            "parallel map"
        ],
        "right": [
            "Store in memory",
            "Async loading",
            "Parallel transform"
        ]
    },
    {
        "q": "prefetch() overlaps processing and loading.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which callback saves models?",
        "type": "mcq",
        "o": [
            "ModelCheckpoint",
            "SaveModel",
            "Checkpoint",
            "Saver"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ncb = tf.keras.callbacks.ModelCheckpoint('model.keras')\nprint(type(cb).__name__)",
        "o": [
            "ModelCheckpoint",
            "Callback",
            "Saver",
            "Checkpoint"
        ]
    },
    {
        "q": "Match the callbacks:",
        "type": "match",
        "left": [
            "ModelCheckpoint",
            "EarlyStopping",
            "TensorBoard"
        ],
        "right": [
            "Save weights",
            "Stop early",
            "Visualize"
        ]
    },
    {
        "q": "The ______ stops training early.",
        "type": "fill_blank",
        "answers": [
            "EarlyStopping"
        ],
        "other_options": [
            "StopEarly",
            "Terminate",
            "Halt"
        ]
    },
    {
        "q": "Callbacks are passed to fit().",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the callback usage:",
        "type": "rearrange",
        "words": [
            "create callbacks",
            "pass to fit",
            "automatic invocation"
        ]
    },
    {
        "q": "Which callback reduces learning rate?",
        "type": "mcq",
        "o": [
            "ReduceLROnPlateau",
            "LRScheduler",
            "AdaptiveLR",
            "DecayLR"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ncb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss')\nprint(type(cb).__name__)",
        "o": [
            "ReduceLROnPlateau",
            "LRCallback",
            "Callback",
            "Reducer"
        ]
    },
    {
        "q": "ReduceLROnPlateau monitors metrics.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the LR scheduling:",
        "type": "match",
        "left": [
            "ReduceLROnPlateau",
            "LearningRateScheduler"
        ],
        "right": [
            "Metric-based",
            "Epoch-based"
        ]
    },
    {
        "q": "Which function saves entire model?",
        "type": "mcq",
        "o": [
            "model.save()",
            "model.export()",
            "tf.save_model()",
            "model.dump()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nmodel.save('test_model.keras')\nprint('success')",
        "o": [
            "success",
            "Error",
            "None",
            "Model"
        ]
    },
    {
        "q": "Match the save formats:",
        "type": "match",
        "left": [
            ".keras",
            "SavedModel",
            ".h5"
        ],
        "right": [
            "New format",
            "TensorFlow format",
            "Legacy Keras"
        ]
    },
    {
        "q": "The ______ format is recommended.",
        "type": "fill_blank",
        "answers": [
            ".keras"
        ],
        "other_options": [
            ".h5",
            ".pb",
            ".ckpt"
        ]
    },
    {
        "q": "model.save() saves architecture and weights.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the model persistence:",
        "type": "rearrange",
        "words": [
            "train model",
            "save model",
            "load model"
        ]
    },
    {
        "q": "Which function loads saved model?",
        "type": "mcq",
        "o": [
            "tf.keras.models.load_model",
            "tf.load_model",
            "keras.load",
            "tf.restore"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nmodel.save('test.keras')\nloaded = tf.keras.models.load_model('test.keras')\nprint(type(loaded).__name__)",
        "o": [
            "Sequential",
            "Model",
            "Loaded",
            "Keras"
        ]
    },
    {
        "q": "load_model() restores full model.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which method saves only weights?",
        "type": "mcq",
        "o": [
            "model.save_weights()",
            "model.weights.save()",
            "tf.save_weights()",
            "model.dump_weights()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\nmodel.save_weights('weights.weights.h5')\nprint('success')",
        "o": [
            "success",
            "Error",
            "None",
            "Weights"
        ]
    },
    {
        "q": "Match the persistence options:",
        "type": "match",
        "left": [
            "save()",
            "save_weights()",
            "to_json()"
        ],
        "right": [
            "Full model",
            "Only weights",
            "Architecture"
        ]
    },
    {
        "q": "save_weights() requires matching architecture.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates gradient tape?",
        "type": "mcq",
        "o": [
            "tf.GradientTape",
            "tf.gradient",
            "tf.AutoGrad",
            "tf.Tape"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.Variable(3.0)\nwith tf.GradientTape() as tape:\n    y = x ** 2\ngrad = tape.gradient(y, x)\nprint(grad.numpy())",
        "o": [
            "6.0",
            "9.0",
            "3.0",
            "2.0"
        ]
    },
    {
        "q": "Match the GradientTape methods:",
        "type": "match",
        "left": [
            "watch",
            "gradient",
            "persistent"
        ],
        "right": [
            "Track tensor",
            "Compute gradient",
            "Multiple calls"
        ]
    },
    {
        "q": "The ______ parameter allows multiple gradients.",
        "type": "fill_blank",
        "answers": [
            "persistent"
        ],
        "other_options": [
            "reuse",
            "multi",
            "repeat"
        ]
    },
    {
        "q": "GradientTape enables custom training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the custom training loop:",
        "type": "rearrange",
        "words": [
            "forward pass",
            "compute loss",
            "compute gradients",
            "apply gradients"
        ]
    },
    {
        "q": "Which decorator enables graph mode?",
        "type": "mcq",
        "o": [
            "@tf.function",
            "@tf.graph",
            "@tf.compile",
            "@tf.trace"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\n@tf.function\ndef add(a, b):\n    return a + b\nresult = add(tf.constant(1), tf.constant(2))\nprint(result.numpy())",
        "o": [
            "3",
            "12",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match the execution modes:",
        "type": "match",
        "left": [
            "eager",
            "graph"
        ],
        "right": [
            "Immediate",
            "Compiled"
        ]
    },
    {
        "q": "@tf.function compiles to graph.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Graph mode is faster for production.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer adds attention?",
        "type": "mcq",
        "o": [
            "Attention",
            "Focus",
            "Attend",
            "Weight"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Attention()\nprint(type(layer).__name__)",
        "o": [
            "Attention",
            "Layer",
            "Focus",
            "Query"
        ]
    },
    {
        "q": "Match the attention types:",
        "type": "match",
        "left": [
            "Attention",
            "MultiHeadAttention"
        ],
        "right": [
            "Single head",
            "Multiple heads"
        ]
    },
    {
        "q": "Attention learns to focus on relevant parts.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer is multi-head attention?",
        "type": "mcq",
        "o": [
            "MultiHeadAttention",
            "MultiAttention",
            "HeadedAttention",
            "ParallelAttention"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)\nprint(type(layer).__name__)",
        "o": [
            "MultiHeadAttention",
            "Attention",
            "Layer",
            "Multi"
        ]
    },
    {
        "q": "Match the attention parameters:",
        "type": "match",
        "left": [
            "num_heads",
            "key_dim"
        ],
        "right": [
            "Number of heads",
            "Key dimension"
        ]
    },
    {
        "q": "The ______ parameter sets head count.",
        "type": "fill_blank",
        "answers": [
            "num_heads"
        ],
        "other_options": [
            "heads",
            "n_heads",
            "head_count"
        ]
    },
    {
        "q": "MultiHeadAttention is used in Transformers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the Transformer components:",
        "type": "rearrange",
        "words": [
            "embedding",
            "positional encoding",
            "attention",
            "feed-forward"
        ]
    },
    {
        "q": "Which function loads pretrained models?",
        "type": "mcq",
        "o": [
            "tf.keras.applications",
            "tf.pretrained",
            "tf.models",
            "keras.hub"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras.applications, 'ResNet50'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match the pretrained models:",
        "type": "match",
        "left": [
            "VGG16",
            "ResNet50",
            "MobileNet"
        ],
        "right": [
            "VGG network",
            "Residual network",
            "Mobile-friendly"
        ]
    },
    {
        "q": "The ______ parameter loads ImageNet weights.",
        "type": "fill_blank",
        "answers": [
            "weights"
        ],
        "other_options": [
            "pretrained",
            "imagenet",
            "trained"
        ]
    },
    {
        "q": "Transfer learning uses pretrained models.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the transfer learning workflow:",
        "type": "rearrange",
        "words": [
            "load base model",
            "freeze layers",
            "add new head",
            "train"
        ]
    },
    {
        "q": "Which attribute freezes layers?",
        "type": "mcq",
        "o": [
            "trainable = False",
            "freeze = True",
            "locked = True",
            "fixed = True"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Dense(10)\nlayer.trainable = False\nprint(layer.trainable)",
        "o": [
            "False",
            "True",
            "Error",
            "None"
        ]
    },
    {
        "q": "Freezing prevents weight updates.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the training strategies:",
        "type": "match",
        "left": [
            "Freeze all",
            "Fine-tune top",
            "Fine-tune all"
        ],
        "right": [
            "Feature extraction",
            "Top layers only",
            "Full training"
        ]
    },
    {
        "q": "Which function preprocesses images?",
        "type": "mcq",
        "o": [
            "tf.keras.applications.*.preprocess_input",
            "tf.image.preprocess",
            "tf.preprocess",
            "keras.preprocess"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras.applications.resnet50, 'preprocess_input'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Preprocessing matches training normalization.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates image datasets?",
        "type": "mcq",
        "o": [
            "tf.keras.utils.image_dataset_from_directory",
            "tf.data.ImageDataset",
            "keras.ImageGenerator",
            "tf.image.dataset"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras.utils, 'image_dataset_from_directory'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match the dataset utilities:",
        "type": "match",
        "left": [
            "image_dataset_from_directory",
            "text_dataset_from_directory"
        ],
        "right": [
            "Image folders",
            "Text folders"
        ]
    },
    {
        "q": "Rearrange the image loading:",
        "type": "rearrange",
        "words": [
            "organize folders",
            "call function",
            "preprocess",
            "batch"
        ]
    },
    {
        "q": "Folder structure determines labels.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer does data augmentation?",
        "type": "mcq",
        "o": [
            "tf.keras.layers.RandomFlip",
            "tf.augment.Flip",
            "keras.augmentation.Flip",
            "tf.image.flip"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.RandomFlip('horizontal')\nprint(type(layer).__name__)",
        "o": [
            "RandomFlip",
            "Augmentation",
            "Layer",
            "Flip"
        ]
    },
    {
        "q": "Match the augmentation layers:",
        "type": "match",
        "left": [
            "RandomFlip",
            "RandomRotation",
            "RandomZoom"
        ],
        "right": [
            "Mirror",
            "Rotate",
            "Zoom"
        ]
    },
    {
        "q": "Data augmentation increases diversity.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ augments during training.",
        "type": "fill_blank",
        "answers": [
            "RandomFlip"
        ],
        "other_options": [
            "Flip",
            "Augment",
            "Mirror"
        ]
    },
    {
        "q": "Rearrange the augmentation pipeline:",
        "type": "rearrange",
        "words": [
            "load image",
            "augment",
            "normalize",
            "feed to model"
        ]
    },
    {
        "q": "Which strategy enables distributed training?",
        "type": "mcq",
        "o": [
            "tf.distribute.Strategy",
            "tf.parallel",
            "tf.multi_gpu",
            "tf.cluster"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\nprint(type(strategy).__name__)",
        "o": [
            "MirroredStrategy",
            "Strategy",
            "Distributed",
            "Parallel"
        ]
    },
    {
        "q": "Match the distribution strategies:",
        "type": "match",
        "left": [
            "MirroredStrategy",
            "MultiWorkerMirroredStrategy",
            "TPUStrategy"
        ],
        "right": [
            "Single machine",
            "Multiple machines",
            "TPU"
        ]
    },
    {
        "q": "MirroredStrategy uses all GPUs.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer does global pooling?",
        "type": "mcq",
        "o": [
            "GlobalAveragePooling2D",
            "GlobalPool2D",
            "AvgPool2D",
            "ReducePool"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.GlobalAveragePooling2D()\nprint(type(layer).__name__)",
        "o": [
            "GlobalAveragePooling2D",
            "Pooling",
            "Layer",
            "Global"
        ]
    },
    {
        "q": "Match the global pooling:",
        "type": "match",
        "left": [
            "GlobalAveragePooling2D",
            "GlobalMaxPooling2D"
        ],
        "right": [
            "Average",
            "Maximum"
        ]
    },
    {
        "q": "Global pooling reduces to single values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer concatenates inputs?",
        "type": "mcq",
        "o": [
            "Concatenate",
            "Merge",
            "Join",
            "Combine"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Concatenate()\nprint(type(layer).__name__)",
        "o": [
            "Concatenate",
            "Merge",
            "Layer",
            "Join"
        ]
    },
    {
        "q": "Match the merge layers:",
        "type": "match",
        "left": [
            "Concatenate",
            "Add",
            "Multiply"
        ],
        "right": [
            "Join along axis",
            "Element-wise add",
            "Element-wise multiply"
        ]
    },
    {
        "q": "Rearrange the merge operations:",
        "type": "rearrange",
        "words": [
            "Concatenate: join",
            "Add: sum",
            "Multiply: product"
        ]
    },
    {
        "q": "Concatenate joins tensors along axis.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer applies activation separately?",
        "type": "mcq",
        "o": [
            "Activation",
            "Apply",
            "Function",
            "Transform"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Activation('relu')\nprint(type(layer).__name__)",
        "o": [
            "Activation",
            "ReLU",
            "Layer",
            "Function"
        ]
    },
    {
        "q": "Activation layer allows separate activation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which regularizer adds L2 penalty?",
        "type": "mcq",
        "o": [
            "tf.keras.regularizers.L2",
            "tf.regularizers.l2",
            "keras.L2",
            "tf.penalty.l2"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nreg = tf.keras.regularizers.L2(0.01)\nprint(type(reg).__name__)",
        "o": [
            "L2",
            "Regularizer",
            "Penalty",
            "Weight"
        ]
    },
    {
        "q": "Match the regularizers:",
        "type": "match",
        "left": [
            "L1",
            "L2",
            "L1L2"
        ],
        "right": [
            "Sparse weights",
            "Weight decay",
            "Combined"
        ]
    },
    {
        "q": "The ______ parameter applies to kernel.",
        "type": "fill_blank",
        "answers": [
            "kernel_regularizer"
        ],
        "other_options": [
            "weight_regularizer",
            "regularizer",
            "penalty"
        ]
    },
    {
        "q": "L2 regularization prevents overfitting.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which initializer sets initial weights?",
        "type": "mcq",
        "o": [
            "tf.keras.initializers",
            "tf.initialize",
            "keras.weights",
            "tf.init"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ninit = tf.keras.initializers.GlorotUniform()\nprint(type(init).__name__)",
        "o": [
            "GlorotUniform",
            "Initializer",
            "Init",
            "Glorot"
        ]
    },
    {
        "q": "Match the initializers:",
        "type": "match",
        "left": [
            "GlorotUniform",
            "HeNormal",
            "Zeros"
        ],
        "right": [
            "Xavier",
            "He",
            "All zeros"
        ]
    },
    {
        "q": "Rearrange the initializers by variance:",
        "type": "rearrange",
        "words": [
            "Zeros: none",
            "GlorotUniform: moderate",
            "HeNormal: higher"
        ]
    },
    {
        "q": "GlorotUniform is default for Dense.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which constraint limits weights?",
        "type": "mcq",
        "o": [
            "tf.keras.constraints",
            "tf.limit",
            "keras.bounds",
            "tf.clip"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ncon = tf.keras.constraints.MaxNorm(2)\nprint(type(con).__name__)",
        "o": [
            "MaxNorm",
            "Constraint",
            "Limit",
            "Norm"
        ]
    },
    {
        "q": "Match the constraints:",
        "type": "match",
        "left": [
            "MaxNorm",
            "UnitNorm",
            "NonNeg"
        ],
        "right": [
            "Max magnitude",
            "Unit length",
            "Non-negative"
        ]
    },
    {
        "q": "Constraints are applied after updates.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function creates custom metrics?",
        "type": "mcq",
        "o": [
            "tf.keras.metrics.Metric",
            "tf.metrics.Custom",
            "keras.Metric",
            "tf.measure"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmetric = tf.keras.metrics.Accuracy()\nprint(type(metric).__name__)",
        "o": [
            "Accuracy",
            "Metric",
            "Measure",
            "Score"
        ]
    },
    {
        "q": "Match the metrics:",
        "type": "match",
        "left": [
            "Accuracy",
            "Precision",
            "Recall"
        ],
        "right": [
            "Correct ratio",
            "True positive ratio",
            "Sensitivity"
        ]
    },
    {
        "q": "The ______ metric measures false positives.",
        "type": "fill_blank",
        "answers": [
            "Precision"
        ],
        "other_options": [
            "Recall",
            "F1",
            "Accuracy"
        ]
    },
    {
        "q": "Metrics are tracked during training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the classification metrics:",
        "type": "rearrange",
        "words": [
            "Accuracy: overall",
            "Precision: positive",
            "Recall: complete"
        ]
    },
    {
        "q": "Which function creates custom losses?",
        "type": "mcq",
        "o": [
            "tf.keras.losses.Loss",
            "tf.loss.Custom",
            "keras.Loss",
            "tf.objective"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nclass CustomLoss(tf.keras.losses.Loss):\n    def call(self, y_true, y_pred):\n        return tf.reduce_mean((y_true - y_pred) ** 2)\nloss = CustomLoss()\nprint(type(loss).__name__)",
        "o": [
            "CustomLoss",
            "Loss",
            "Custom",
            "Objective"
        ]
    },
    {
        "q": "Custom losses subclass tf.keras.losses.Loss.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which callback logs to TensorBoard?",
        "type": "mcq",
        "o": [
            "TensorBoard",
            "Logger",
            "Visualize",
            "Board"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\ncb = tf.keras.callbacks.TensorBoard(log_dir='./logs')\nprint(type(cb).__name__)",
        "o": [
            "TensorBoard",
            "Callback",
            "Logger",
            "Board"
        ]
    },
    {
        "q": "Match the TensorBoard features:",
        "type": "match",
        "left": [
            "Scalars",
            "Graphs",
            "Histograms"
        ],
        "right": [
            "Metrics",
            "Model structure",
            "Weight distributions"
        ]
    },
    {
        "q": "TensorBoard provides visualization.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ parameter sets log directory.",
        "type": "fill_blank",
        "answers": [
            "log_dir"
        ],
        "other_options": [
            "logdir",
            "path",
            "directory"
        ]
    },
    {
        "q": "Rearrange the TensorBoard workflow:",
        "type": "rearrange",
        "words": [
            "create callback",
            "train model",
            "launch tensorboard"
        ]
    },
    {
        "q": "Which function converts tensor to numpy?",
        "type": "mcq",
        "o": [
            "tensor.numpy()",
            "np.array(tensor)",
            "tensor.to_numpy()",
            "All of the above"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nimport numpy as np\nx = tf.constant([1, 2, 3])\narr = x.numpy()\nprint(type(arr).__name__)",
        "o": [
            "ndarray",
            "Tensor",
            "EagerTensor",
            "Array"
        ]
    },
    {
        "q": ".numpy() converts to NumPy array.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the conversions:",
        "type": "match",
        "left": [
            ".numpy()",
            "tf.constant()"
        ],
        "right": [
            "To NumPy",
            "From NumPy"
        ]
    },
    {
        "q": "Which function casts tensor dtype?",
        "type": "mcq",
        "o": [
            "tf.cast",
            "tf.convert",
            "tf.astype",
            "tensor.cast()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1.5, 2.5])\ny = tf.cast(x, tf.int32)\nprint(y.numpy()[0])",
        "o": [
            "1",
            "1.5",
            "2",
            "Error"
        ]
    },
    {
        "q": "tf.cast changes data type.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the dtypes:",
        "type": "match",
        "left": [
            "tf.float32",
            "tf.int32",
            "tf.bool"
        ],
        "right": [
            "Float",
            "Integer",
            "Boolean"
        ]
    },
    {
        "q": "Which function reduces dimensions?",
        "type": "mcq",
        "o": [
            "tf.reduce_sum, tf.reduce_mean",
            "tf.sum, tf.mean",
            "tf.aggregate",
            "tf.collapse"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([[1, 2], [3, 4]])\nprint(tf.reduce_sum(x).numpy())",
        "o": [
            "10",
            "[[1, 2], [3, 4]]",
            "[4, 6]",
            "Error"
        ]
    },
    {
        "q": "Match the reduce functions:",
        "type": "match",
        "left": [
            "reduce_sum",
            "reduce_mean",
            "reduce_max"
        ],
        "right": [
            "Sum",
            "Average",
            "Maximum"
        ]
    },
    {
        "q": "The ______ parameter specifies axis.",
        "type": "fill_blank",
        "answers": [
            "axis"
        ],
        "other_options": [
            "dim",
            "dimension",
            "reduce_axis"
        ]
    },
    {
        "q": "reduce_mean computes average.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the reduction operations:",
        "type": "rearrange",
        "words": [
            "reduce_sum: total",
            "reduce_mean: average",
            "reduce_max: maximum"
        ]
    },
    {
        "q": "Which function broadcasts tensors?",
        "type": "mcq",
        "o": [
            "Automatic broadcasting",
            "tf.broadcast",
            "tf.expand",
            "tf.tile"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\na = tf.constant([[1], [2]])\nb = tf.constant([1, 2, 3])\nprint((a + b).shape)",
        "o": [
            "(2, 3)",
            "(3, 2)",
            "Error",
            "(2,)"
        ]
    },
    {
        "q": "Broadcasting expands dimensions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function stacks tensors?",
        "type": "mcq",
        "o": [
            "tf.stack",
            "tf.pile",
            "tf.combine",
            "tf.merge"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\na = tf.constant([1, 2])\nb = tf.constant([3, 4])\nstacked = tf.stack([a, b])\nprint(stacked.shape)",
        "o": [
            "(2, 2)",
            "(4,)",
            "(2,)",
            "(1, 4)"
        ]
    },
    {
        "q": "Match the combining functions:",
        "type": "match",
        "left": [
            "tf.stack",
            "tf.concat"
        ],
        "right": [
            "New axis",
            "Existing axis"
        ]
    },
    {
        "q": "tf.stack creates new dimension.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function splits tensors?",
        "type": "mcq",
        "o": [
            "tf.split",
            "tf.divide",
            "tf.separate",
            "tf.chunk"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3, 4])\nparts = tf.split(x, 2)\nprint(len(parts))",
        "o": [
            "2",
            "4",
            "1",
            "Error"
        ]
    },
    {
        "q": "tf.split divides into parts.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the tensor operations:",
        "type": "rearrange",
        "words": [
            "stack: combine",
            "concat: join",
            "split: divide"
        ]
    },
    {
        "q": "Which function generates random tensors?",
        "type": "mcq",
        "o": [
            "tf.random",
            "tf.rand",
            "tf.generate",
            "tf.sample"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.random.normal([2, 3])\nprint(x.shape)",
        "o": [
            "(2, 3)",
            "(3, 2)",
            "(6,)",
            "Error"
        ]
    },
    {
        "q": "Match the random functions:",
        "type": "match",
        "left": [
            "random.normal",
            "random.uniform",
            "random.shuffle"
        ],
        "right": [
            "Gaussian",
            "Uniform",
            "Shuffle"
        ]
    },
    {
        "q": "The ______ sets random state.",
        "type": "fill_blank",
        "answers": [
            "seed"
        ],
        "other_options": [
            "state",
            "random_state",
            "init"
        ]
    },
    {
        "q": "tf.random.set_seed ensures reproducibility.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer uses 1D convolution?",
        "type": "mcq",
        "o": [
            "Conv1D",
            "Conv2D",
            "Temporal",
            "Sequence"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Conv1D(32, 3)\nprint(type(layer).__name__)",
        "o": [
            "Conv1D",
            "Convolution",
            "Layer",
            "Temporal"
        ]
    },
    {
        "q": "Match the convolution dimensions:",
        "type": "match",
        "left": [
            "Conv1D",
            "Conv2D",
            "Conv3D"
        ],
        "right": [
            "Sequences",
            "Images",
            "Video"
        ]
    },
    {
        "q": "Conv1D processes sequential data.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer transposes convolution?",
        "type": "mcq",
        "o": [
            "Conv2DTranspose",
            "Deconv2D",
            "Upsample",
            "InverseConv"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Conv2DTranspose(32, (3, 3))\nprint(type(layer).__name__)",
        "o": [
            "Conv2DTranspose",
            "Transpose",
            "Layer",
            "Deconv"
        ]
    },
    {
        "q": "Conv2DTranspose upsamples feature maps.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the convolution types:",
        "type": "match",
        "left": [
            "Conv2D",
            "DepthwiseConv2D",
            "SeparableConv2D"
        ],
        "right": [
            "Standard",
            "Channel-wise",
            "Depthwise + pointwise"
        ]
    },
    {
        "q": "Which layer is depthwise convolution?",
        "type": "mcq",
        "o": [
            "DepthwiseConv2D",
            "Depthwise",
            "ChannelConv",
            "SplitConv"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.DepthwiseConv2D((3, 3))\nprint(type(layer).__name__)",
        "o": [
            "DepthwiseConv2D",
            "Depthwise",
            "Layer",
            "Conv"
        ]
    },
    {
        "q": "DepthwiseConv2D is efficient for mobile.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the efficient convolutions:",
        "type": "rearrange",
        "words": [
            "DepthwiseConv2D",
            "SeparableConv2D",
            "Conv2D"
        ]
    },
    {
        "q": "Which layer is separable convolution?",
        "type": "mcq",
        "o": [
            "SeparableConv2D",
            "Separable",
            "SplitConv",
            "TwoStep"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.SeparableConv2D(32, (3, 3))\nprint(type(layer).__name__)",
        "o": [
            "SeparableConv2D",
            "Separable",
            "Layer",
            "Conv"
        ]
    },
    {
        "q": "SeparableConv2D uses fewer parameters.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer pads input?",
        "type": "mcq",
        "o": [
            "ZeroPadding2D",
            "Padding",
            "Pad2D",
            "Border"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.ZeroPadding2D(padding=1)\nprint(type(layer).__name__)",
        "o": [
            "ZeroPadding2D",
            "Padding",
            "Layer",
            "Zero"
        ]
    },
    {
        "q": "ZeroPadding2D adds border of zeros.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the padding modes:",
        "type": "match",
        "left": [
            "valid",
            "same"
        ],
        "right": [
            "No padding",
            "Output same size"
        ]
    },
    {
        "q": "Which layer crops input?",
        "type": "mcq",
        "o": [
            "Cropping2D",
            "Crop",
            "Trim",
            "Cut"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Cropping2D(cropping=((1, 1), (1, 1)))\nprint(type(layer).__name__)",
        "o": [
            "Cropping2D",
            "Crop",
            "Layer",
            "Trim"
        ]
    },
    {
        "q": "Cropping2D removes border pixels.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer upsamples?",
        "type": "mcq",
        "o": [
            "UpSampling2D",
            "Upsample",
            "Enlarge",
            "Expand"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.UpSampling2D(size=(2, 2))\nprint(type(layer).__name__)",
        "o": [
            "UpSampling2D",
            "Upsample",
            "Layer",
            "Resize"
        ]
    },
    {
        "q": "Match the resize operations:",
        "type": "match",
        "left": [
            "UpSampling2D",
            "MaxPooling2D"
        ],
        "right": [
            "Increase size",
            "Decrease size"
        ]
    },
    {
        "q": "UpSampling2D increases spatial size.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the size operations:",
        "type": "rearrange",
        "words": [
            "input",
            "pooling: reduce",
            "upsampling: increase"
        ]
    },
    {
        "q": "Which layer creates lambda functions?",
        "type": "mcq",
        "o": [
            "Lambda",
            "Function",
            "Custom",
            "Apply"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Lambda(lambda x: x * 2)\nprint(type(layer).__name__)",
        "o": [
            "Lambda",
            "Function",
            "Layer",
            "Custom"
        ]
    },
    {
        "q": "Lambda wraps arbitrary functions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer is bidirectional wrapper?",
        "type": "mcq",
        "o": [
            "Bidirectional",
            "BiLSTM",
            "TwoWay",
            "DoubleLSTM"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))\nprint(type(layer).__name__)",
        "o": [
            "Bidirectional",
            "BiLSTM",
            "LSTM",
            "Wrapper"
        ]
    },
    {
        "q": "Match the LSTM variants:",
        "type": "match",
        "left": [
            "LSTM",
            "Bidirectional(LSTM)"
        ],
        "right": [
            "Forward only",
            "Forward and backward"
        ]
    },
    {
        "q": "Bidirectional processes both directions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ merges forward and backward.",
        "type": "fill_blank",
        "answers": [
            "merge_mode"
        ],
        "other_options": [
            "combine",
            "join",
            "concat"
        ]
    },
    {
        "q": "Which layer wraps for time distribution?",
        "type": "mcq",
        "o": [
            "TimeDistributed",
            "Temporal",
            "Sequence",
            "TimeBased"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\nprint(type(layer).__name__)",
        "o": [
            "TimeDistributed",
            "Dense",
            "Wrapper",
            "Temporal"
        ]
    },
    {
        "q": "TimeDistributed applies to each timestep.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which optimizer has learning rate decay?",
        "type": "mcq",
        "o": [
            "schedules.ExponentialDecay",
            "AdamDecay",
            "SGDDecay",
            "DecayOptimizer"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nschedule = tf.keras.optimizers.schedules.ExponentialDecay(0.01, 1000, 0.96)\nprint(type(schedule).__name__)",
        "o": [
            "ExponentialDecay",
            "Schedule",
            "Decay",
            "LR"
        ]
    },
    {
        "q": "Match the learning rate schedules:",
        "type": "match",
        "left": [
            "ExponentialDecay",
            "PiecewiseConstantDecay",
            "CosineDecay"
        ],
        "right": [
            "Exponential",
            "Step-wise",
            "Cosine annealing"
        ]
    },
    {
        "q": "LR schedules reduce learning rate.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the LR decay types:",
        "type": "rearrange",
        "words": [
            "constant",
            "step",
            "exponential",
            "cosine"
        ]
    },
    {
        "q": "Which layer adds Gaussian noise?",
        "type": "mcq",
        "o": [
            "GaussianNoise",
            "Noise",
            "RandomNoise",
            "Perturb"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.GaussianNoise(0.1)\nprint(type(layer).__name__)",
        "o": [
            "GaussianNoise",
            "Noise",
            "Layer",
            "Random"
        ]
    },
    {
        "q": "GaussianNoise is regularization technique.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the noise layers:",
        "type": "match",
        "left": [
            "GaussianNoise",
            "GaussianDropout"
        ],
        "right": [
            "Additive noise",
            "Multiplicative noise"
        ]
    },
    {
        "q": "Which layer is Alpha Dropout?",
        "type": "mcq",
        "o": [
            "AlphaDropout",
            "SELUDropout",
            "ScaledDropout",
            "NormalDropout"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.AlphaDropout(0.5)\nprint(type(layer).__name__)",
        "o": [
            "AlphaDropout",
            "Dropout",
            "Layer",
            "Alpha"
        ]
    },
    {
        "q": "AlphaDropout works with SELU activation.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer is spatial dropout?",
        "type": "mcq",
        "o": [
            "SpatialDropout2D",
            "FeatureDropout",
            "ChannelDrop",
            "MapDropout"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.SpatialDropout2D(0.25)\nprint(type(layer).__name__)",
        "o": [
            "SpatialDropout2D",
            "Dropout",
            "Layer",
            "Spatial"
        ]
    },
    {
        "q": "SpatialDropout2D drops entire channels.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the dropout types:",
        "type": "rearrange",
        "words": [
            "Dropout: units",
            "SpatialDropout2D: channels",
            "AlphaDropout: SELU"
        ]
    },
    {
        "q": "Which layer is group normalization?",
        "type": "mcq",
        "o": [
            "GroupNormalization",
            "GroupNorm",
            "ChannelGroup",
            "NormGroup"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras.layers, 'GroupNormalization'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "GroupNormalization works with small batches.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the normalization types:",
        "type": "match",
        "left": [
            "BatchNorm",
            "LayerNorm",
            "GroupNorm"
        ],
        "right": [
            "Batch",
            "Layer",
            "Channel groups"
        ]
    },
    {
        "q": "Which function creates mixed precision?",
        "type": "mcq",
        "o": [
            "tf.keras.mixed_precision",
            "tf.precision",
            "tf.mixed",
            "keras.fp16"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras, 'mixed_precision'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Mixed precision speeds up training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the precision types:",
        "type": "match",
        "left": [
            "float32",
            "float16",
            "mixed"
        ],
        "right": [
            "Default",
            "Half precision",
            "Both"
        ]
    },
    {
        "q": "Which function profiles performance?",
        "type": "mcq",
        "o": [
            "tf.profiler",
            "tf.timing",
            "tf.perf",
            "tf.benchmark"
        ]
    },
    {
        "q": "Profiling identifies bottlenecks.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function enables XLA?",
        "type": "mcq",
        "o": [
            "jit_compile=True",
            "xla.compile()",
            "tf.xla()",
            "enable_xla()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\nmodel.compile(optimizer='adam', loss='mse', jit_compile=True)\nprint('success')",
        "o": [
            "success",
            "Error",
            "None",
            "XLA"
        ]
    },
    {
        "q": "XLA optimizes computation graphs.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the optimization techniques:",
        "type": "match",
        "left": [
            "XLA",
            "mixed_precision",
            "@tf.function"
        ],
        "right": [
            "Compilation",
            "Data type",
            "Graph mode"
        ]
    },
    {
        "q": "Rearrange the optimization priority:",
        "type": "rearrange",
        "words": [
            "@tf.function",
            "mixed_precision",
            "XLA"
        ]
    },
    {
        "q": "Which function distributes data?",
        "type": "mcq",
        "o": [
            "strategy.experimental_distribute_dataset",
            "tf.distribute_data",
            "strategy.split",
            "tf.shard"
        ]
    },
    {
        "q": "Data is sharded across workers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function saves as SavedModel?",
        "type": "mcq",
        "o": [
            "tf.saved_model.save",
            "model.save_as_saved_model",
            "tf.export",
            "model.to_saved_model"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.saved_model, 'save'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "SavedModel is portable format.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the export formats:",
        "type": "match",
        "left": [
            "SavedModel",
            "TFLite",
            "TensorFlow.js"
        ],
        "right": [
            "Server",
            "Mobile",
            "Browser"
        ]
    },
    {
        "q": "Which converter creates TFLite?",
        "type": "mcq",
        "o": [
            "tf.lite.TFLiteConverter",
            "tf.tflite.convert",
            "tf.mobile.convert",
            "tf.lite.export"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.lite, 'TFLiteConverter'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "TFLite optimizes for mobile.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ reduces model size.",
        "type": "fill_blank",
        "answers": [
            "quantization"
        ],
        "other_options": [
            "compression",
            "pruning",
            "conversion"
        ]
    },
    {
        "q": "Rearrange the TFLite workflow:",
        "type": "rearrange",
        "words": [
            "train model",
            "convert to TFLite",
            "deploy to mobile"
        ]
    },
    {
        "q": "Which function loads TF Hub models?",
        "type": "mcq",
        "o": [
            "hub.load",
            "tf.hub.get",
            "hub.download",
            "tf.load_hub"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow_hub as hub\nprint(hub.__name__)",
        "o": [
            "tensorflow_hub",
            "hub",
            "tfhub",
            "None"
        ]
    },
    {
        "q": "TF Hub provides pre-trained models.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the TF Hub model types:",
        "type": "match",
        "left": [
            "Image",
            "Text",
            "Audio"
        ],
        "right": [
            "Vision models",
            "NLP models",
            "Sound models"
        ]
    },
    {
        "q": "Which layer is from hub?",
        "type": "mcq",
        "o": [
            "hub.KerasLayer",
            "hub.Layer",
            "hub.TFLayer",
            "hub.ModelLayer"
        ]
    },
    {
        "q": "hub.KerasLayer wraps Hub models.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function loads TFDS datasets?",
        "type": "mcq",
        "o": [
            "tfds.load",
            "tf.datasets.load",
            "tfds.get",
            "tf.data.load"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow_datasets as tfds\nprint(tfds.__name__)",
        "o": [
            "tensorflow_datasets",
            "tfds",
            "datasets",
            "None"
        ]
    },
    {
        "q": "TFDS provides standard datasets.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the TFDS features:",
        "type": "match",
        "left": [
            "split",
            "as_supervised",
            "with_info"
        ],
        "right": [
            "Data portion",
            "Tuple format",
            "Metadata"
        ]
    },
    {
        "q": "The ______ parameter returns metadata.",
        "type": "fill_blank",
        "answers": [
            "with_info"
        ],
        "other_options": [
            "metadata",
            "info",
            "return_info"
        ]
    },
    {
        "q": "Rearrange the TFDS usage:",
        "type": "rearrange",
        "words": [
            "import tfds",
            "load dataset",
            "preprocess",
            "train"
        ]
    },
    {
        "q": "Which module handles text preprocessing?",
        "type": "mcq",
        "o": [
            "tf.keras.layers.TextVectorization",
            "tf.text.preprocess",
            "tf.nlp.tokenize",
            "keras.text.tokenize"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.TextVectorization()\nprint(type(layer).__name__)",
        "o": [
            "TextVectorization",
            "Text",
            "Layer",
            "Tokenizer"
        ]
    },
    {
        "q": "TextVectorization converts text to integers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the text modes:",
        "type": "match",
        "left": [
            "int",
            "binary",
            "count",
            "tf-idf"
        ],
        "right": [
            "Indices",
            "Presence",
            "Frequency",
            "Weighted"
        ]
    },
    {
        "q": "Which function masks sequence values?",
        "type": "mcq",
        "o": [
            "Masking layer or mask_zero",
            "tf.mask",
            "tf.sequence_mask",
            "layer.mask"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Masking(mask_value=0.0)\nprint(type(layer).__name__)",
        "o": [
            "Masking",
            "Mask",
            "Layer",
            "Zero"
        ]
    },
    {
        "q": "Masking skips padded values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the masking approaches:",
        "type": "match",
        "left": [
            "Masking layer",
            "mask_zero in Embedding"
        ],
        "right": [
            "Separate layer",
            "Embedding parameter"
        ]
    },
    {
        "q": "Which layer is positional encoding?",
        "type": "mcq",
        "o": [
            "Custom implementation needed",
            "PositionalEncoding",
            "tf.keras.layers.Position",
            "keras.Position"
        ]
    },
    {
        "q": "Positional encoding adds position info.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function computes attention scores?",
        "type": "mcq",
        "o": [
            "tf.matmul with softmax",
            "tf.attention",
            "tf.score",
            "attention.compute"
        ]
    },
    {
        "q": "Attention uses query, key, value.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the attention components:",
        "type": "match",
        "left": [
            "Query",
            "Key",
            "Value"
        ],
        "right": [
            "What to find",
            "Match against",
            "Return result"
        ]
    },
    {
        "q": "Rearrange the attention computation:",
        "type": "rearrange",
        "words": [
            "compute scores",
            "apply softmax",
            "weight values"
        ]
    },
    {
        "q": "Which layer is layer normalization?",
        "type": "mcq",
        "o": [
            "LayerNormalization",
            "LayerNorm",
            "NormLayer",
            "Normalize"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.LayerNormalization()\nprint(type(layer).__name__)",
        "o": [
            "LayerNormalization",
            "Normalization",
            "Layer",
            "Norm"
        ]
    },
    {
        "q": "LayerNormalization normalizes across features.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles checkpoints?",
        "type": "mcq",
        "o": [
            "tf.train.Checkpoint",
            "tf.checkpoint",
            "tf.save.Checkpoint",
            "keras.Checkpoint"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nckpt = tf.train.Checkpoint()\nprint(type(ckpt).__name__)",
        "o": [
            "Checkpoint",
            "Train",
            "Save",
            "Model"
        ]
    },
    {
        "q": "Checkpoint saves training state.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the checkpoint methods:",
        "type": "match",
        "left": [
            "save",
            "restore",
            "write"
        ],
        "right": [
            "Save state",
            "Load state",
            "Write prefix"
        ]
    },
    {
        "q": "The ______ manages checkpoint files.",
        "type": "fill_blank",
        "answers": [
            "CheckpointManager"
        ],
        "other_options": [
            "Manager",
            "CheckpointHandler",
            "Saver"
        ]
    },
    {
        "q": "Which function enables eager debugging?",
        "type": "mcq",
        "o": [
            "tf.debugging",
            "tf.debug",
            "tf.trace",
            "tf.inspect"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'debugging'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.debugging provides assertion tools.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the debugging functions:",
        "type": "match",
        "left": [
            "assert_equal",
            "assert_positive",
            "check_numerics"
        ],
        "right": [
            "Equality check",
            "Positive check",
            "NaN/Inf check"
        ]
    },
    {
        "q": "Rearrange the debugging workflow:",
        "type": "rearrange",
        "words": [
            "add assertions",
            "run with eager",
            "identify errors"
        ]
    },
    {
        "q": "Which function creates summary?",
        "type": "mcq",
        "o": [
            "tf.summary",
            "tf.log",
            "tf.record",
            "tf.write"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'summary'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.summary logs to TensorBoard.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the summary types:",
        "type": "match",
        "left": [
            "scalar",
            "histogram",
            "image"
        ],
        "right": [
            "Single value",
            "Distribution",
            "Picture"
        ]
    },
    {
        "q": "The ______ creates file writer.",
        "type": "fill_blank",
        "answers": [
            "create_file_writer"
        ],
        "other_options": [
            "file_writer",
            "writer",
            "log_writer"
        ]
    },
    {
        "q": "Which layer is for string lookup?",
        "type": "mcq",
        "o": [
            "StringLookup",
            "LookupString",
            "TextLookup",
            "Vocabulary"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.StringLookup()\nprint(type(layer).__name__)",
        "o": [
            "StringLookup",
            "Lookup",
            "Layer",
            "String"
        ]
    },
    {
        "q": "StringLookup maps strings to integers.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the preprocessing layers:",
        "type": "match",
        "left": [
            "StringLookup",
            "IntegerLookup",
            "Normalization"
        ],
        "right": [
            "String to int",
            "Int to int",
            "Normalize values"
        ]
    },
    {
        "q": "Which layer discretizes values?",
        "type": "mcq",
        "o": [
            "Discretization",
            "Bucket",
            "Binning",
            "Quantize"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Discretization(bin_boundaries=[0, 0.5, 1])\nprint(type(layer).__name__)",
        "o": [
            "Discretization",
            "Bucket",
            "Layer",
            "Bin"
        ]
    },
    {
        "q": "Discretization creates buckets.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the preprocessing pipeline:",
        "type": "rearrange",
        "words": [
            "normalize",
            "discretize",
            "lookup",
            "embed"
        ]
    },
    {
        "q": "Which layer handles category crossings?",
        "type": "mcq",
        "o": [
            "CategoryCrossing",
            "FeatureCross",
            "CrossFeature",
            "Interaction"
        ]
    },
    {
        "q": "CategoryCrossing creates feature interactions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer is category encoding?",
        "type": "mcq",
        "o": [
            "CategoryEncoding",
            "OneHot",
            "Encode",
            "Category"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.CategoryEncoding(num_tokens=5)\nprint(type(layer).__name__)",
        "o": [
            "CategoryEncoding",
            "Encoding",
            "Layer",
            "Category"
        ]
    },
    {
        "q": "Match the encodings:",
        "type": "match",
        "left": [
            "one_hot",
            "multi_hot",
            "count"
        ],
        "right": [
            "Single category",
            "Multiple categories",
            "Frequency"
        ]
    },
    {
        "q": "CategoryEncoding handles integer categories.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which feature handles hashing?",
        "type": "mcq",
        "o": [
            "Hashing",
            "Hash",
            "HashLookup",
            "FeatureHash"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Hashing(num_bins=100)\nprint(type(layer).__name__)",
        "o": [
            "Hashing",
            "Hash",
            "Layer",
            "Bin"
        ]
    },
    {
        "q": "Hashing maps to fixed bins.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ parameter sets number of bins.",
        "type": "fill_blank",
        "answers": [
            "num_bins"
        ],
        "other_options": [
            "bins",
            "buckets",
            "size"
        ]
    },
    {
        "q": "Which function creates ragged tensors?",
        "type": "mcq",
        "o": [
            "tf.RaggedTensor",
            "tf.ragged",
            "tf.variable_length",
            "tf.jagged"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nrt = tf.RaggedTensor.from_row_splits([1, 2, 3, 4], [0, 2, 4])\nprint(type(rt).__name__)",
        "o": [
            "RaggedTensor",
            "Tensor",
            "Ragged",
            "Variable"
        ]
    },
    {
        "q": "RaggedTensor handles variable-length sequences.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the tensor types:",
        "type": "match",
        "left": [
            "Tensor",
            "SparseTensor",
            "RaggedTensor"
        ],
        "right": [
            "Dense",
            "Sparse",
            "Variable-length"
        ]
    },
    {
        "q": "Which function creates sparse tensors?",
        "type": "mcq",
        "o": [
            "tf.SparseTensor",
            "tf.sparse",
            "tf.sparse_matrix",
            "tf.zero_tensor"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nst = tf.SparseTensor(indices=[[0, 0], [1, 1]], values=[1, 2], dense_shape=[2, 2])\nprint(type(st).__name__)",
        "o": [
            "SparseTensor",
            "Tensor",
            "Sparse",
            "Matrix"
        ]
    },
    {
        "q": "SparseTensor stores only non-zero values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the tensor types by density:",
        "type": "rearrange",
        "words": [
            "Dense: all values",
            "Sparse: non-zeros",
            "Ragged: variable"
        ]
    },
    {
        "q": "Which function converts sparse to dense?",
        "type": "mcq",
        "o": [
            "tf.sparse.to_dense",
            "tf.to_dense",
            "sparse.dense()",
            "tf.convert_sparse"
        ]
    },
    {
        "q": "tf.sparse.to_dense fills zero values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which module handles image processing?",
        "type": "mcq",
        "o": [
            "tf.image",
            "tf.vision",
            "tf.cv",
            "tf.img"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'image'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "Match the image functions:",
        "type": "match",
        "left": [
            "resize",
            "crop",
            "flip_left_right"
        ],
        "right": [
            "Change size",
            "Cut portion",
            "Mirror"
        ]
    },
    {
        "q": "tf.image provides image operations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ resizes images.",
        "type": "fill_blank",
        "answers": [
            "tf.image.resize"
        ],
        "other_options": [
            "tf.resize",
            "image.resize",
            "tf.scale"
        ]
    },
    {
        "q": "Which function decodes images?",
        "type": "mcq",
        "o": [
            "tf.io.decode_image",
            "tf.decode",
            "tf.read_image",
            "tf.load_image"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.io, 'decode_image'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "decode_image converts bytes to tensor.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the IO functions:",
        "type": "match",
        "left": [
            "read_file",
            "decode_image",
            "encode_jpeg"
        ],
        "right": [
            "Read bytes",
            "Decode tensor",
            "Encode bytes"
        ]
    },
    {
        "q": "Rearrange the image loading:",
        "type": "rearrange",
        "words": [
            "read_file",
            "decode_image",
            "resize",
            "normalize"
        ]
    },
    {
        "q": "Which function handles audio?",
        "type": "mcq",
        "o": [
            "tf.audio",
            "tf.sound",
            "tf.signal",
            "tf.wav"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'audio'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.audio.decode_wav loads WAV files.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the audio functions:",
        "type": "match",
        "left": [
            "decode_wav",
            "encode_wav"
        ],
        "right": [
            "Read audio",
            "Write audio"
        ]
    },
    {
        "q": "Which module handles signal processing?",
        "type": "mcq",
        "o": [
            "tf.signal",
            "tf.fft",
            "tf.frequency",
            "tf.spectrum"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'signal'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.signal includes FFT functions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the signal functions:",
        "type": "match",
        "left": [
            "stft",
            "mel_banks",
            "mfcc"
        ],
        "right": [
            "Spectrogram",
            "Mel filter",
            "Audio features"
        ]
    },
    {
        "q": "Which function computes STFT?",
        "type": "mcq",
        "o": [
            "tf.signal.stft",
            "tf.stft",
            "tf.fft.stft",
            "signal.stft"
        ]
    },
    {
        "q": "STFT converts time to frequency domain.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the audio pipeline:",
        "type": "rearrange",
        "words": [
            "load audio",
            "compute STFT",
            "mel spectrogram",
            "extract MFCC"
        ]
    },
    {
        "q": "Which function handles string tensors?",
        "type": "mcq",
        "o": [
            "tf.strings",
            "tf.text",
            "tf.str",
            "tf.string"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'strings'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.strings provides string operations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the string functions:",
        "type": "match",
        "left": [
            "split",
            "lower",
            "regex_replace"
        ],
        "right": [
            "Tokenize",
            "Lowercase",
            "Pattern replace"
        ]
    },
    {
        "q": "The ______ splits strings.",
        "type": "fill_blank",
        "answers": [
            "tf.strings.split"
        ],
        "other_options": [
            "tf.split",
            "strings.split",
            "tf.tokenize"
        ]
    },
    {
        "q": "Which function handles math operations?",
        "type": "mcq",
        "o": [
            "tf.math",
            "tf.numerical",
            "tf.compute",
            "tf.ops"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'math'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.math includes mathematical functions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the math functions:",
        "type": "match",
        "left": [
            "log",
            "exp",
            "sqrt"
        ],
        "right": [
            "Logarithm",
            "Exponential",
            "Square root"
        ]
    },
    {
        "q": "Which function handles linear algebra?",
        "type": "mcq",
        "o": [
            "tf.linalg",
            "tf.linear",
            "tf.algebra",
            "tf.matrix"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'linalg'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.linalg includes matrix operations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the linalg functions:",
        "type": "match",
        "left": [
            "matmul",
            "inv",
            "det"
        ],
        "right": [
            "Multiply",
            "Inverse",
            "Determinant"
        ]
    },
    {
        "q": "The ______ computes matrix inverse.",
        "type": "fill_blank",
        "answers": [
            "tf.linalg.inv"
        ],
        "other_options": [
            "tf.inverse",
            "linalg.inverse",
            "tf.matrix_inverse"
        ]
    },
    {
        "q": "Rearrange the linalg by complexity:",
        "type": "rearrange",
        "words": [
            "matmul",
            "transpose",
            "det",
            "inv",
            "svd"
        ]
    },
    {
        "q": "Which function handles sets?",
        "type": "mcq",
        "o": [
            "tf.sets",
            "tf.set",
            "tf.unique",
            "tf.collection"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'sets'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.sets provides set operations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the set operations:",
        "type": "match",
        "left": [
            "union",
            "intersection",
            "difference"
        ],
        "right": [
            "Combine",
            "Common",
            "Exclusive"
        ]
    },
    {
        "q": "Which module handles bitwise operations?",
        "type": "mcq",
        "o": [
            "tf.bitwise",
            "tf.bits",
            "tf.binary",
            "tf.bit"
        ]
    },
    {
        "q": "tf.bitwise includes AND, OR, XOR.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles sorting?",
        "type": "mcq",
        "o": [
            "tf.sort",
            "tf.order",
            "tf.arrange",
            "tf.rank"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([3, 1, 2])\nprint(tf.sort(x).numpy())",
        "o": [
            "[1 2 3]",
            "[3 1 2]",
            "[3 2 1]",
            "Error"
        ]
    },
    {
        "q": "tf.sort returns sorted tensor.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the sorting functions:",
        "type": "match",
        "left": [
            "sort",
            "argsort",
            "top_k"
        ],
        "right": [
            "Values",
            "Indices",
            "Top values"
        ]
    },
    {
        "q": "The ______ returns sorted indices.",
        "type": "fill_blank",
        "answers": [
            "tf.argsort"
        ],
        "other_options": [
            "tf.sort_indices",
            "argsort",
            "tf.order"
        ]
    },
    {
        "q": "Which function finds unique values?",
        "type": "mcq",
        "o": [
            "tf.unique",
            "tf.distinct",
            "tf.dedupe",
            "tf.set"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 2, 3, 3, 3])\ny, _ = tf.unique(x)\nprint(len(y.numpy()))",
        "o": [
            "3",
            "6",
            "1",
            "Error"
        ]
    },
    {
        "q": "tf.unique removes duplicates.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles conditions?",
        "type": "mcq",
        "o": [
            "tf.where",
            "tf.if",
            "tf.condition",
            "tf.select"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3])\ny = tf.where(x > 1, x, 0)\nprint(y.numpy())",
        "o": [
            "[0 2 3]",
            "[1 2 3]",
            "[1 0 0]",
            "Error"
        ]
    },
    {
        "q": "tf.where applies conditional logic.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the conditional functions:",
        "type": "match",
        "left": [
            "where",
            "cond",
            "case"
        ],
        "right": [
            "Element-wise",
            "Branch",
            "Multiple branches"
        ]
    },
    {
        "q": "Rearrange the control flow:",
        "type": "rearrange",
        "words": [
            "tf.where: simple",
            "tf.cond: binary",
            "tf.case: multiple"
        ]
    },
    {
        "q": "Which function creates one-hot encoding?",
        "type": "mcq",
        "o": [
            "tf.one_hot",
            "tf.encode",
            "tf.to_categorical",
            "tf.onehot"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\none_hot = tf.one_hot([0, 1, 2], depth=3)\nprint(one_hot.shape)",
        "o": [
            "(3, 3)",
            "(3,)",
            "(1, 3)",
            "Error"
        ]
    },
    {
        "q": "tf.one_hot creates binary vectors.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "The ______ parameter sets vector length.",
        "type": "fill_blank",
        "answers": [
            "depth"
        ],
        "other_options": [
            "size",
            "length",
            "num_classes"
        ]
    },
    {
        "q": "Which function clips values?",
        "type": "mcq",
        "o": [
            "tf.clip_by_value",
            "tf.clip",
            "tf.bound",
            "tf.limit"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1.0, 5.0, 10.0])\ny = tf.clip_by_value(x, 2.0, 8.0)\nprint(y.numpy())",
        "o": [
            "[2. 5. 8.]",
            "[1. 5. 10.]",
            "[2. 2. 2.]",
            "Error"
        ]
    },
    {
        "q": "tf.clip_by_value limits value range.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the clipping functions:",
        "type": "match",
        "left": [
            "clip_by_value",
            "clip_by_norm",
            "clip_by_global_norm"
        ],
        "right": [
            "Value range",
            "Tensor norm",
            "Multiple tensors"
        ]
    },
    {
        "q": "The ______ clips gradients by norm.",
        "type": "fill_blank",
        "answers": [
            "clip_by_norm"
        ],
        "other_options": [
            "clip_gradient",
            "norm_clip",
            "bound_norm"
        ]
    },
    {
        "q": "Which function gathers values?",
        "type": "mcq",
        "o": [
            "tf.gather",
            "tf.index",
            "tf.select",
            "tf.pick"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([10, 20, 30, 40])\nindices = tf.constant([0, 2])\nprint(tf.gather(x, indices).numpy())",
        "o": [
            "[10 30]",
            "[10 20]",
            "[30 40]",
            "Error"
        ]
    },
    {
        "q": "tf.gather selects by indices.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the gather functions:",
        "type": "match",
        "left": [
            "gather",
            "gather_nd",
            "boolean_mask"
        ],
        "right": [
            "1D indices",
            "ND indices",
            "Mask selection"
        ]
    },
    {
        "q": "Rearrange the indexing complexity:",
        "type": "rearrange",
        "words": [
            "gather: simple",
            "gather_nd: advanced",
            "boolean_mask: conditional"
        ]
    },
    {
        "q": "Which function scatters values?",
        "type": "mcq",
        "o": [
            "tf.tensor_scatter_nd_update",
            "tf.scatter",
            "tf.put",
            "tf.insert"
        ]
    },
    {
        "q": "Scatter updates tensor at indices.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function tiles tensors?",
        "type": "mcq",
        "o": [
            "tf.tile",
            "tf.repeat",
            "tf.replicate",
            "tf.copy"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([[1, 2]])\ny = tf.tile(x, [2, 1])\nprint(y.shape)",
        "o": [
            "(2, 2)",
            "(1, 4)",
            "(4, 2)",
            "Error"
        ]
    },
    {
        "q": "tf.tile repeats tensor.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the repeat functions:",
        "type": "match",
        "left": [
            "tile",
            "repeat"
        ],
        "right": [
            "Whole tensor",
            "Individual elements"
        ]
    },
    {
        "q": "Which function pads tensors?",
        "type": "mcq",
        "o": [
            "tf.pad",
            "tf.border",
            "tf.extend",
            "tf.expand"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([[1, 2], [3, 4]])\ny = tf.pad(x, [[1, 1], [1, 1]])\nprint(y.shape)",
        "o": [
            "(4, 4)",
            "(2, 2)",
            "(3, 3)",
            "Error"
        ]
    },
    {
        "q": "tf.pad adds border values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the padding modes:",
        "type": "match",
        "left": [
            "CONSTANT",
            "REFLECT",
            "SYMMETRIC"
        ],
        "right": [
            "Zeros",
            "Mirror",
            "Edge mirror"
        ]
    },
    {
        "q": "The ______ mode reflects values.",
        "type": "fill_blank",
        "answers": [
            "REFLECT"
        ],
        "other_options": [
            "MIRROR",
            "SYMMETRIC",
            "BORDER"
        ]
    },
    {
        "q": "Rearrange the padding types:",
        "type": "rearrange",
        "words": [
            "CONSTANT: fill value",
            "REFLECT: mirror",
            "SYMMETRIC: edge mirror"
        ]
    },
    {
        "q": "Which function reverses tensors?",
        "type": "mcq",
        "o": [
            "tf.reverse",
            "tf.flip",
            "tf.invert",
            "tf.backward"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3])\nprint(tf.reverse(x, axis=[0]).numpy())",
        "o": [
            "[3 2 1]",
            "[1 2 3]",
            "[1 3 2]",
            "Error"
        ]
    },
    {
        "q": "tf.reverse reverses along axis.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function transposes tensors?",
        "type": "mcq",
        "o": [
            "tf.transpose",
            "tf.T",
            "tf.swap",
            "tf.reorder"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([[1, 2, 3], [4, 5, 6]])\nprint(tf.transpose(x).shape)",
        "o": [
            "(3, 2)",
            "(2, 3)",
            "(6,)",
            "Error"
        ]
    },
    {
        "q": "tf.transpose swaps dimensions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the shape operations:",
        "type": "match",
        "left": [
            "reshape",
            "transpose",
            "squeeze"
        ],
        "right": [
            "Change shape",
            "Swap dims",
            "Remove dims"
        ]
    },
    {
        "q": "Which function finds argmax?",
        "type": "mcq",
        "o": [
            "tf.argmax",
            "tf.max_index",
            "tf.find_max",
            "tf.which_max"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 5, 3, 2])\nprint(tf.argmax(x).numpy())",
        "o": [
            "1",
            "5",
            "3",
            "0"
        ]
    },
    {
        "q": "tf.argmax returns index of maximum.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the arg functions:",
        "type": "match",
        "left": [
            "argmax",
            "argmin"
        ],
        "right": [
            "Max index",
            "Min index"
        ]
    },
    {
        "q": "The ______ returns minimum index.",
        "type": "fill_blank",
        "answers": [
            "tf.argmin"
        ],
        "other_options": [
            "tf.min_index",
            "argmin",
            "tf.which_min"
        ]
    },
    {
        "q": "Which function creates boolean mask?",
        "type": "mcq",
        "o": [
            "tf.boolean_mask",
            "tf.mask",
            "tf.filter",
            "tf.select"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.constant([1, 2, 3, 4])\nmask = tf.constant([True, False, True, False])\nprint(tf.boolean_mask(x, mask).numpy())",
        "o": [
            "[1 3]",
            "[2 4]",
            "[1 2]",
            "Error"
        ]
    },
    {
        "q": "boolean_mask selects by boolean array.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles while loops?",
        "type": "mcq",
        "o": [
            "tf.while_loop",
            "tf.loop",
            "tf.iterate",
            "tf.repeat_while"
        ]
    },
    {
        "q": "tf.while_loop enables graph loops.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the control flow:",
        "type": "match",
        "left": [
            "while_loop",
            "cond",
            "case"
        ],
        "right": [
            "Loop",
            "If-else",
            "Switch"
        ]
    },
    {
        "q": "Which module handles queues?",
        "type": "mcq",
        "o": [
            "tf.queue (deprecated)",
            "tf.data.Dataset",
            "tf.pipeline",
            "tf.buffer"
        ]
    },
    {
        "q": "tf.data is preferred over queues.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles assertions?",
        "type": "mcq",
        "o": [
            "tf.debugging.assert_*",
            "tf.assert",
            "tf.check",
            "tf.verify"
        ]
    },
    {
        "q": "tf.debugging.assert_equal checks equality.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the assertion types:",
        "type": "rearrange",
        "words": [
            "assert_equal",
            "assert_positive",
            "assert_shapes"
        ]
    },
    {
        "q": "Which function handles printing?",
        "type": "mcq",
        "o": [
            "tf.print",
            "print()",
            "tf.log",
            "tf.output"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf, 'print'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "tf.print works in graph mode.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the debugging tools:",
        "type": "match",
        "left": [
            "tf.print",
            "tf.debugging",
            "pdb"
        ],
        "right": [
            "Graph print",
            "Assertions",
            "Breakpoints"
        ]
    },
    {
        "q": "Which function creates custom gradient?",
        "type": "mcq",
        "o": [
            "@tf.custom_gradient",
            "tf.manual_gradient",
            "tf.define_gradient",
            "@tf.gradient"
        ]
    },
    {
        "q": "custom_gradient overrides autodiff.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles stop gradient?",
        "type": "mcq",
        "o": [
            "tf.stop_gradient",
            "tf.no_gradient",
            "tf.detach",
            "tf.block_gradient"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nx = tf.Variable(3.0)\nwith tf.GradientTape() as tape:\n    y = tf.stop_gradient(x) * 2\ngrad = tape.gradient(y, x)\nprint(grad)",
        "o": [
            "None",
            "2.0",
            "6.0",
            "0.0"
        ]
    },
    {
        "q": "stop_gradient prevents gradient flow.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the gradient control:",
        "type": "match",
        "left": [
            "stop_gradient",
            "custom_gradient"
        ],
        "right": [
            "Block flow",
            "Override computation"
        ]
    },
    {
        "q": "The ______ decorator defines custom gradients.",
        "type": "fill_blank",
        "answers": [
            "@tf.custom_gradient"
        ],
        "other_options": [
            "@custom",
            "@gradient",
            "@tf.grad"
        ]
    },
    {
        "q": "Which layer handles rescaling?",
        "type": "mcq",
        "o": [
            "Rescaling",
            "Scale",
            "Normalize",
            "Transform"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Rescaling(1./255)\nprint(type(layer).__name__)",
        "o": [
            "Rescaling",
            "Scale",
            "Layer",
            "Normalize"
        ]
    },
    {
        "q": "Rescaling normalizes pixel values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the preprocessing layers:",
        "type": "match",
        "left": [
            "Rescaling",
            "Normalization",
            "Discretization"
        ],
        "right": [
            "Scale",
            "Standardize",
            "Bucketize"
        ]
    },
    {
        "q": "Rearrange the preprocessing order:",
        "type": "rearrange",
        "words": [
            "Rescaling",
            "Normalization",
            "Augmentation"
        ]
    },
    {
        "q": "Which layer handles resizing?",
        "type": "mcq",
        "o": [
            "Resizing",
            "Resize",
            "Scale",
            "Transform"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.Resizing(224, 224)\nprint(type(layer).__name__)",
        "o": [
            "Resizing",
            "Resize",
            "Layer",
            "Image"
        ]
    },
    {
        "q": "Resizing layer changes image dimensions.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the image layers:",
        "type": "match",
        "left": [
            "Resizing",
            "CenterCrop",
            "RandomCrop"
        ],
        "right": [
            "Change size",
            "Center portion",
            "Random portion"
        ]
    },
    {
        "q": "Which layer centers and crops?",
        "type": "mcq",
        "o": [
            "CenterCrop",
            "Crop",
            "CenteredCrop",
            "CropCenter"
        ]
    },
    {
        "q": "CenterCrop extracts center portion.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which activation is leaky ReLU?",
        "type": "mcq",
        "o": [
            "tf.keras.layers.LeakyReLU",
            "tf.nn.leaky",
            "LeakyActivation",
            "tf.leaky"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nlayer = tf.keras.layers.LeakyReLU(alpha=0.1)\nprint(type(layer).__name__)",
        "o": [
            "LeakyReLU",
            "ReLU",
            "Activation",
            "Leaky"
        ]
    },
    {
        "q": "LeakyReLU allows small negative values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the ReLU variants:",
        "type": "match",
        "left": [
            "ReLU",
            "LeakyReLU",
            "PReLU"
        ],
        "right": [
            "Zero negative",
            "Small negative",
            "Learned slope"
        ]
    },
    {
        "q": "The ______ parameter controls negative slope.",
        "type": "fill_blank",
        "answers": [
            "alpha"
        ],
        "other_options": [
            "slope",
            "leak",
            "negative"
        ]
    },
    {
        "q": "Rearrange the ReLU by complexity:",
        "type": "rearrange",
        "words": [
            "ReLU: simple",
            "LeakyReLU: fixed leak",
            "PReLU: learned leak"
        ]
    },
    {
        "q": "Which activation is ELU?",
        "type": "mcq",
        "o": [
            "tf.keras.layers.ELU",
            "tf.nn.elu",
            "ELUActivation",
            "tf.elu"
        ]
    },
    {
        "q": "ELU smooths negative values.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the smooth activations:",
        "type": "match",
        "left": [
            "ELU",
            "SELU",
            "Swish"
        ],
        "right": [
            "Exponential",
            "Self-normalizing",
            "Gated"
        ]
    },
    {
        "q": "Which loss is for multi-label?",
        "type": "mcq",
        "o": [
            "BinaryCrossentropy",
            "CategoricalCrossentropy",
            "SparseCategoricalCrossentropy",
            "MultiLabelLoss"
        ]
    },
    {
        "q": "BinaryCrossentropy works for multi-label.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the loss scenarios:",
        "type": "match",
        "left": [
            "Binary",
            "Categorical",
            "SparseCategorical"
        ],
        "right": [
            "Two classes",
            "One-hot labels",
            "Integer labels"
        ]
    },
    {
        "q": "The ______ parameter handles logits.",
        "type": "fill_blank",
        "answers": [
            "from_logits"
        ],
        "other_options": [
            "logits",
            "raw",
            "unnormalized"
        ]
    },
    {
        "q": "Rearrange the classification by complexity:",
        "type": "rearrange",
        "words": [
            "Binary: 2 classes",
            "Multiclass: N classes",
            "Multilabel: N labels"
        ]
    },
    {
        "q": "Which metric is F1 score?",
        "type": "mcq",
        "o": [
            "Custom implementation needed",
            "tf.keras.metrics.F1",
            "tf.metrics.f1_score",
            "keras.F1Score"
        ]
    },
    {
        "q": "F1 combines precision and recall.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the metric combinations:",
        "type": "match",
        "left": [
            "Precision",
            "Recall",
            "F1"
        ],
        "right": [
            "TP/Predicted",
            "TP/Actual",
            "Harmonic mean"
        ]
    },
    {
        "q": "Which metric is AUC?",
        "type": "mcq",
        "o": [
            "tf.keras.metrics.AUC",
            "tf.auc",
            "keras.AUC",
            "metrics.AUC"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmetric = tf.keras.metrics.AUC()\nprint(type(metric).__name__)",
        "o": [
            "AUC",
            "Metric",
            "Area",
            "ROC"
        ]
    },
    {
        "q": "AUC measures classifier performance.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the AUC curves:",
        "type": "match",
        "left": [
            "ROC",
            "PR"
        ],
        "right": [
            "TPR vs FPR",
            "Precision vs Recall"
        ]
    },
    {
        "q": "Which metric handles MeanIoU?",
        "type": "mcq",
        "o": [
            "tf.keras.metrics.MeanIoU",
            "tf.metrics.iou",
            "keras.IoU",
            "tf.MeanIoU"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nmetric = tf.keras.metrics.MeanIoU(num_classes=3)\nprint(type(metric).__name__)",
        "o": [
            "MeanIoU",
            "IoU",
            "Metric",
            "Segmentation"
        ]
    },
    {
        "q": "MeanIoU is for segmentation tasks.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the segmentation metrics:",
        "type": "match",
        "left": [
            "MeanIoU",
            "Dice"
        ],
        "right": [
            "Intersection over union",
            "Overlap coefficient"
        ]
    },
    {
        "q": "Which layer handles spectral normalization?",
        "type": "mcq",
        "o": [
            "tfa.layers.SpectralNormalization",
            "tf.keras.layers.SpectralNorm",
            "keras.SpectralNorm",
            "tf.spectral"
        ]
    },
    {
        "q": "Spectral normalization stabilizes GANs.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which layer handles weight normalization?",
        "type": "mcq",
        "o": [
            "tfa.layers.WeightNormalization",
            "tf.keras.layers.WeightNorm",
            "keras.WeightNorm",
            "tf.weight"
        ]
    },
    {
        "q": "Weight normalization improves training.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the normalization types:",
        "type": "match",
        "left": [
            "Spectral",
            "Weight",
            "Batch"
        ],
        "right": [
            "GAN stable",
            "Decoupled",
            "Batch stats"
        ]
    },
    {
        "q": "Which loss is for contrastive learning?",
        "type": "mcq",
        "o": [
            "Contrastive or Triplet Loss",
            "tf.keras.losses.Contrastive",
            "keras.ContrastiveLoss",
            "tf.triplet"
        ]
    },
    {
        "q": "Contrastive loss learns representations.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the embedding losses:",
        "type": "match",
        "left": [
            "Contrastive",
            "Triplet"
        ],
        "right": [
            "Pairs",
            "Anchor-positive-negative"
        ]
    },
    {
        "q": "Which layer handles instance normalization?",
        "type": "mcq",
        "o": [
            "tfa.layers.InstanceNormalization",
            "tf.keras.layers.InstanceNorm",
            "keras.InstanceNorm",
            "tf.instance"
        ]
    },
    {
        "q": "Instance normalization is for style transfer.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the normalization by use case:",
        "type": "rearrange",
        "words": [
            "BatchNorm: classification",
            "InstanceNorm: style",
            "LayerNorm: NLP"
        ]
    },
    {
        "q": "Which function handles tf.Variable assignment?",
        "type": "mcq",
        "o": [
            "variable.assign()",
            "variable.set()",
            "tf.update()",
            "variable.update()"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nv = tf.Variable(1.0)\nv.assign(5.0)\nprint(v.numpy())",
        "o": [
            "5.0",
            "1.0",
            "Error",
            "None"
        ]
    },
    {
        "q": "assign() updates Variable value.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the Variable methods:",
        "type": "match",
        "left": [
            "assign",
            "assign_add",
            "assign_sub"
        ],
        "right": [
            "Set",
            "Add",
            "Subtract"
        ]
    },
    {
        "q": "The ______ adds to Variable.",
        "type": "fill_blank",
        "answers": [
            "assign_add"
        ],
        "other_options": [
            "add",
            "increment",
            "plus"
        ]
    },
    {
        "q": "Which function handles gradient accumulation?",
        "type": "mcq",
        "o": [
            "Manual with GradientTape",
            "tf.gradient_accumulate",
            "tf.accumulate",
            "optimizer.accumulate"
        ]
    },
    {
        "q": "Gradient accumulation simulates larger batches.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Rearrange the gradient accumulation steps:",
        "type": "rearrange",
        "words": [
            "compute gradients",
            "accumulate",
            "average",
            "apply"
        ]
    },
    {
        "q": "Which function enables model tracing?",
        "type": "mcq",
        "o": [
            "tf.saved_model.save with signatures",
            "tf.trace",
            "model.trace",
            "tf.export_graph"
        ]
    },
    {
        "q": "Tracing captures computation graph.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function handles model signatures?",
        "type": "mcq",
        "o": [
            "@tf.function with input_signature",
            "model.signature",
            "tf.signature",
            "keras.signature"
        ]
    },
    {
        "q": "Signatures define input shapes.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the model export features:",
        "type": "match",
        "left": [
            "Signatures",
            "Concrete functions"
        ],
        "right": [
            "Input specs",
            "Traced graphs"
        ]
    },
    {
        "q": "The ______ specifies input types.",
        "type": "fill_blank",
        "answers": [
            "input_signature"
        ],
        "other_options": [
            "signature",
            "input_spec",
            "type_hint"
        ]
    },
    {
        "q": "Which optimizer handles gradient clipping?",
        "type": "mcq",
        "o": [
            "clipnorm/clipvalue in optimizer",
            "ClipOptimizer",
            "tf.clip_optimizer",
            "optimizer.clip"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nopt = tf.keras.optimizers.Adam(clipnorm=1.0)\nprint(type(opt).__name__)",
        "o": [
            "Adam",
            "ClipAdam",
            "Optimizer",
            "Clipped"
        ]
    },
    {
        "q": "clipnorm limits gradient magnitude.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the gradient clipping:",
        "type": "match",
        "left": [
            "clipnorm",
            "clipvalue"
        ],
        "right": [
            "By norm",
            "By value"
        ]
    },
    {
        "q": "Which function handles model summary?",
        "type": "mcq",
        "o": [
            "model.summary()",
            "tf.summary(model)",
            "keras.summarize",
            "model.describe()"
        ]
    },
    {
        "q": "summary() shows model architecture.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Which function plots model?",
        "type": "mcq",
        "o": [
            "tf.keras.utils.plot_model",
            "model.plot()",
            "keras.plot",
            "tf.visualize_model"
        ]
    },
    {
        "q": "What is the output of this code?",
        "type": "mcq",
        "c": "import tensorflow as tf\nprint(hasattr(tf.keras.utils, 'plot_model'))",
        "o": [
            "True",
            "False",
            "Error",
            "None"
        ]
    },
    {
        "q": "plot_model creates architecture diagram.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the visualization tools:",
        "type": "match",
        "left": [
            "summary()",
            "plot_model"
        ],
        "right": [
            "Text output",
            "Image output"
        ]
    },
    {
        "q": "Rearrange the model inspection:",
        "type": "rearrange",
        "words": [
            "summary: overview",
            "plot_model: diagram",
            "config: JSON"
        ]
    },
    {
        "q": "Which function gets model config?",
        "type": "mcq",
        "o": [
            "model.get_config()",
            "model.config",
            "tf.get_config",
            "model.to_config()"
        ]
    },
    {
        "q": "get_config() returns model configuration.",
        "type": "true_false",
        "correct": "True"
    },
    {
        "q": "Match the model serialization:",
        "type": "match",
        "left": [
            "get_config",
            "to_json",
            "get_weights"
        ],
        "right": [
            "Python dict",
            "JSON string",
            "Numpy arrays"
        ]
    },
    {
        "q": "The ______ returns weights as numpy.",
        "type": "fill_blank",
        "answers": [
            "get_weights"
        ],
        "other_options": [
            "weights",
            "numpy_weights",
            "extract_weights"
        ]
    }
]